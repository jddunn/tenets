# .tenets.example.yml - Example Tenets Configuration
# Copy this to .tenets.yml and customize for your project
# https://github.com/jddunn/tenets

# ============================================================================
# API KEYS (OPTIONAL - Currently only used for LLM summarization)
# ============================================================================
# WARNING: Add .tenets.yml to .gitignore if you put API keys here!
# 
# Priority order: Environment variables override these config values
# So you can commit a config without keys and use env vars in production

# OpenAI API key for GPT models
# OPENAI_API_KEY: ""

# Anthropic API key for Claude models  
# ANTHROPIC_API_KEY: ""

# OpenRouter API key for multiple models
# OPENROUTER_API_KEY: ""

# ============================================================================
# GLOBAL SETTINGS
# ============================================================================

# Maximum tokens for context generation (affects LLM costs)
max_tokens: 100000  # Range: 1000-2000000

# Debug mode - enables verbose logging
debug: false

# Quiet mode - suppresses non-essential output
quiet: false

# ============================================================================
# FILE RANKING - How files are scored for relevance
# ============================================================================

ranking:
  # Algorithm for ranking files by relevance
  # Options: fast, balanced, thorough, ml, custom
  algorithm: balanced
  
  # Minimum relevance score to include file (0.0-1.0)
  # Lower values include more files
  threshold: 0.10
  
  # Use TF-IDF for keyword matching (improves accuracy)
  use_tfidf: true
  
  # Filter common programming keywords (reduces noise)
  use_stopwords: false
  
  # Use semantic embeddings for similarity (requires ML)
  use_embeddings: false
  
  # Embedding model for ML mode
  embedding_model: all-MiniLM-L6-v2
  
  # Custom weights for ranking factors (advanced)
  custom_weights:
    keyword_match: 0.25
    path_relevance: 0.20
    import_graph: 0.20
    git_activity: 0.15
    file_type: 0.10
    complexity: 0.10
  
  # Parallel processing settings
  workers: 2
  parallel_mode: auto  # thread, process, or auto

# ============================================================================
# CONTENT SUMMARIZATION - Compress large files to fit token limits
# ============================================================================

summarizer:
  # Default summarization strategy
  # Options: extractive, compressive, textrank, transformer, llm, auto
  default_mode: auto
  
  # Target compression ratio (0.3 = compress to 30% of original)
  target_ratio: 0.3
  
  # Cache summaries for repeated content
  enable_cache: true
  max_cache_size: 100
  
  # Preserve code structure (imports, function signatures)
  preserve_code_structure: true
  
  # LLM Configuration (optional - requires API keys above)
  # llm_provider: ""  # openai, anthropic, openrouter
  # llm_model: ""     # gpt-3.5-turbo, gpt-4, claude-3-haiku, etc.
  # llm_temperature: 0.3  # 0-1, lower = more deterministic
  # llm_max_tokens: 500   # Max tokens in response
  
  # ML Configuration
  enable_ml_strategies: true   # Enable transformer models (requires ML)
  quality_threshold: medium    # Quality target: low, medium, high
  batch_size: 10               # Files to process in parallel

# ============================================================================
# FILE SCANNING - Control which files are analyzed
# ============================================================================

scanner:
  # Respect .gitignore patterns
  respect_gitignore: true
  
  # Follow symbolic links
  follow_symlinks: false
  
  # Maximum file size to analyze (bytes)
  max_file_size: 5000000  # 5MB
  
  # Maximum total files to scan
  max_files: 10000
  
  # Check for and skip binary files
  binary_check: true
  
  # File encoding
  encoding: utf-8
  
  # Additional patterns to ignore (glob patterns)
  additional_ignore_patterns:
    - "*.generated.*"
    - "*.min.js"
    - "*.min.css"
    - vendor/
    - node_modules/
    - .venv/
    - "*.log"
    - "*.tmp"
  
  # Patterns to explicitly include (overrides ignores)
  additional_include_patterns: []
  
  # Parallel scanning settings
  workers: 4
  parallel_mode: auto
  timeout: 5.0  # Per-file timeout in seconds

# ============================================================================
# OUTPUT FORMATTING - How context is formatted
# ============================================================================

output:
  # Default output format
  # Options: markdown, xml (for Claude), json
  default_format: markdown
  
  # Enable syntax highlighting in output
  syntax_highlighting: true
  
  # Include line numbers in code blocks
  line_numbers: false
  
  # Maximum line length before wrapping
  max_line_length: 120
  
  # Include metadata (file stats, git info, etc.)
  include_metadata: true
  
  # Automatically summarize files larger than this (characters)
  compression_threshold: 10000
  
  # Target compression ratio for large files
  summary_ratio: 0.25
  
  # Automatically copy distill output to clipboard
  copy_on_distill: false

# ============================================================================
# CACHING - Speed up repeated operations
# ============================================================================

cache:
  # Enable caching system
  enabled: true
  
  # Cache directory (defaults to ~/.tenets/cache)
  # directory: /custom/cache/path
  
  # How long to keep cached data (days)
  ttl_days: 7
  
  # Maximum cache size (MB)
  max_size_mb: 500
  
  # Compress cached data (saves space, slower)
  compression: false
  
  # In-memory cache size
  memory_cache_size: 1000
  
  # SQLite performance tuning
  sqlite_pragmas:
    journal_mode: WAL
    synchronous: NORMAL
    cache_size: "-64000"  # 64MB
    temp_store: MEMORY
  
  # Maximum age for analysis cache (hours)
  max_age_hours: 24

# ============================================================================
# GIT INTEGRATION - Include version control context
# ============================================================================

git:
  # Enable git integration
  enabled: true
  
  # Include commit history in context
  include_history: true
  
  # Maximum commits to include
  history_limit: 100
  
  # Include git blame information
  include_blame: false
  
  # Include repository statistics
  include_stats: true
  
  # Authors to ignore (bots, etc.)
  ignore_authors:
    - "dependabot[bot]"
    - "github-actions[bot]"
    - "renovate[bot]"
  
  # Branch names considered "main"
  main_branches:
    - main
    - master
    - develop
    - trunk

# ============================================================================
# TENET SYSTEM - Guiding principles for consistent AI interactions
# ============================================================================

tenet:
  # Automatically inject tenets into context
  auto_instill: true
  
  # Maximum tenets to include per context
  max_per_context: 5
  
  # Reinforce critical tenets at end
  reinforcement: true
  
  # Injection strategy
  injection_strategy: strategic  # strategic, uniform, random
  
  # Minimum distance between tenet injections (characters)
  min_distance_between: 1000
  
  # Prefer injecting at natural break points
  prefer_natural_breaks: true
  
  # Tenet storage directory (defaults to ~/.tenets/tenets)
  # storage_path: /custom/tenets/path
  
  # Enable tenet collections (grouped tenets)
  collections_enabled: true

# ============================================================================
# CUSTOM CONFIGURATION - Project-specific settings
# ============================================================================

custom:
  # Add any project-specific configuration here
  # These values are accessible via config.custom
  
  # Example: Project metadata
  # project_name: "My Project"
  # project_version: "1.0.0"
  
  # Example: Team preferences
  # team:
  #   lead: "john.doe@example.com"
  #   slack_channel: "#dev-team"
  
  # Example: Integration settings
  # integrations:
  #   jira_url: "https://company.atlassian.net"
  #   github_org: "my-org"

# ============================================================================
# ENVIRONMENT VARIABLE OVERRIDES
# ============================================================================
# 
# Any configuration value can be overridden using environment variables.
# This includes API keys - env vars take precedence over config values.
# 
# Format: TENETS_<SECTION>_<KEY>=value
# 
# Examples:
#   TENETS_MAX_TOKENS=150000
#   TENETS_RANKING_ALGORITHM=thorough
#   TENETS_RANKING_THRESHOLD=0.05
#   TENETS_SUMMARIZER_DEFAULT_MODE=extractive
#   TENETS_SUMMARIZER_TARGET_RATIO=0.2
#   TENETS_CACHE_ENABLED=false
#   TENETS_GIT_ENABLED=true
#   TENETS_SCANNER_MAX_FILE_SIZE=10000000
# 
# API Keys can also be set as env vars (overrides config):
#   export OPENAI_API_KEY=sk-...
#   export ANTHROPIC_API_KEY=sk-ant-...
#   export OPENROUTER_API_KEY=sk-or-...
# 
# Use 'tenets config show --key models' to see model pricing
# Use 'tenets estimate-cost' to calculate costs before running
# 
# ============================================================================