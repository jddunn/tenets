{"config":{"lang":["en"],"separator":"[\\s\\u200b\\-_,:!=\\[\\]()\"/]+|\\.(?!\\d)|&[lg]t;|(?!\\b)(?=[A-Z][a-z])","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Tenets - Context that feeds your prompts","text":"<p>Context that feeds your prompts</p> <p>Illuminate your codebase. Surface relevant files. Build optimal context.</p> <p>All without leaving your machine. 20+ languages including Python, Go, Rust, Java, C#, Kotlin, Swift, Dart, GDScript &amp; more.</p>        Quick Start             View on GitHub      Terminal <pre><code>$ pip install tenets\n$ tenets distill \"implement OAuth2 authentication\"\n\u2728 Finding relevant files...\n\ud83d\udcca Ranking by importance...\n\ud83d\udce6 Aggregating context (45,231 tokens)\n\u2705 Context ready for your LLM!</code></pre> Illuminating Features Why\u00a0Tenets? Context on Demand <p>Stop hunting for files. Tenets discovers, ranks and assembles your code for you\u2014so you can focus on solving the problem.</p> Deeper Insight <p>Visualize dependencies, uncover complexity hotspots and track velocity trends. Know your codebase like never before.</p> Local &amp; Private <p>Your source never leaves your machine. With zero external API calls, Tenets keeps your intellectual property safe.</p> Flexible &amp; Extensible <p>Dial the ranking algorithm, expand the token budget and add plugins when you need more. Tenets grows with you.</p> Architecture at a Glance Input Scanner Analyzer Ranker Aggregator <p>Tenets flows your query through a pipeline of scanners, analyzers, rankers and aggregators, delivering context precisely tailored to your task.</p> Intelligent Context <p>Multi-factor ranking finds exactly what you need. No more manual file hunting.</p> 100% Local <p>Your code never leaves your machine. Complete privacy, zero API calls.</p> Lightning Fast <p>Analyzes thousands of files in seconds with intelligent caching.</p> Guiding Principles <p>Add persistent instructions that maintain consistency across AI sessions.</p> Code Intelligence <p>Visualize dependencies, track velocity, identify hotspots at a glance.</p> Zero Config <p>Works instantly with smart defaults. Just install and start distilling.</p> How It Works 1 Scan <p>Discovers files respecting .gitignore</p> \u2192 2 Analyze <p>Extracts structure and dependencies</p> \u2192 3 Rank <p>Scores by relevance to your prompt</p> \u2192 4 Aggregate <p>Optimizes within token limits</p> See it in action CLI Bash<pre><code>$ tenets distill \"implement OAuth2 authentication\"\n\u2728 Finding relevant files...\n\ud83d\udcca Ranking by importance...\n\ud83d\udce6 Aggregating context (45,231 tokens)\n\u2705 Context ready for your LLM!\n</code></pre> Output Rank Files Bash<pre><code>$ tenets rank \"fix authentication bug\" --top 10 --factors\n\ud83d\udd0d Scanning codebase...\n\ud83d\udcca Ranking files by relevance...\n\n1. src/auth/service.py - Score: 0.892\n   - semantic_similarity: 85%\n   - keyword_match: 92%\n   - import_centrality: 78%\n\n2. src/auth/middleware.py - Score: 0.834\n   - semantic_similarity: 79%\n   - keyword_match: 88%\n   - import_centrality: 65%\n</code></pre> Tree View Bash<pre><code>$ tenets rank \"add caching\" --tree --scores\n\ud83d\udcc1 Ranked Files\n\u251c\u2500\u2500 \ud83d\udcc2 src/\n\u2502   \u251c\u2500\u2500 \ud83d\udcc4 cache_manager.py [0.892]\n\u2502   \u251c\u2500\u2500 \ud83d\udcc4 redis_client.py [0.834]\n\u2502   \u2514\u2500\u2500 \ud83d\udcc4 config.py [0.756]\n\u251c\u2500\u2500 \ud83d\udcc2 src/api/\n\u2502   \u251c\u2500\u2500 \ud83d\udcc4 endpoints.py [0.723]\n\u2502   \u2514\u2500\u2500 \ud83d\udcc4 middleware.py [0.689]\n\u2514\u2500\u2500 \ud83d\udcc2 tests/\n    \u2514\u2500\u2500 \ud83d\udcc4 test_cache.py [0.534]\n</code></pre> Python Python<pre><code>from tenets import Tenets\nt = Tenets()\nresult = t.distill(\n    prompt=\"map request lifecycle\"\n)\nprint(result.context[:500])  # First 500 chars\n</code></pre> Output Sessions Python<pre><code># Sessions are managed through distill parameters\nctx = t.distill(\"design payment flow\", session_name=\"checkout-flow\")\n# Pin files through pin_file method\nt.pin_file(\"payment.py\")\nt.pin_file(\"stripe.py\")\nctx = t.distill(\"add refund support\", session_name=\"checkout-flow\")\n</code></pre> Output Ready to illuminate your codebase? <p>Join thousands of developers building better with Tenets.</p>          Get Started Now        <code>pip install tenets</code>"},{"location":"ARCHITECTURE/","title":"Tenets Complete Architecture Documentation","text":""},{"location":"ARCHITECTURE/#table-of-contents","title":"Table of Contents","text":"<ol> <li>System Overview</li> <li>Core Philosophy &amp; Design Principles</li> <li>Complete System Architecture</li> <li>NLP/ML Pipeline Architecture</li> <li>File Discovery &amp; Scanning System</li> <li>Code Analysis Engine</li> <li>Relevance Ranking System</li> <li>Git Integration &amp; Chronicle System</li> <li>Context Management &amp; Optimization</li> <li>Session Management Architecture</li> <li>Storage &amp; Caching Architecture</li> <li>Performance Architecture</li> <li>Configuration System</li> <li>CLI &amp; API Architecture</li> <li>Security &amp; Privacy Architecture</li> <li>Testing &amp; Quality Assurance</li> <li>Guiding Principles (Tenets) System</li> <li>Output Generation &amp; Visualization</li> <li>Future Roadmap &amp; Vision</li> </ol>"},{"location":"ARCHITECTURE/#system-overview","title":"System Overview","text":"<p>Tenets is a sophisticated, local-first code intelligence platform that revolutionizes how developers interact with their codebases when working with AI assistants. Unlike traditional code search tools, Tenets employs advanced multi-stage analysis combining NLP, ML, static code analysis, git history mining, and intelligent ranking to build optimal context.</p>"},{"location":"ARCHITECTURE/#core-architecture-principles","title":"Core Architecture Principles","text":"<ol> <li> <p>Local-First Processing: All analysis happens on the developer's machine. No code leaves the local environment. External API calls only for optional LLM-based summarization with explicit consent.</p> </li> <li> <p>Progressive Enhancement: Provides value immediately with just Python installed, scales with optional dependencies. Core functionality works without ML libraries, git integration works without configuration.</p> </li> <li> <p>Intelligent Caching: Every expensive operation is cached at multiple levels - memory caches for hot data, SQLite for structured data, disk caches for analysis results, specialized caches for embeddings.</p> </li> <li> <p>Configurable Intelligence: Every aspect of ranking and analysis can be configured. Users can adjust factor weights, enable/disable features, add custom ranking functions.</p> </li> <li> <p>Streaming Architecture: Uses streaming and incremental processing wherever possible. Files analyzed as discovered, rankings computed in parallel, results stream to user.</p> </li> </ol>"},{"location":"ARCHITECTURE/#complete-system-architecture","title":"Complete System Architecture","text":""},{"location":"ARCHITECTURE/#high-level-data-flow","title":"High-Level Data Flow","text":"<pre><code>graph TB\n    subgraph \"User Interaction Layer\"\n        CLI[CLI Interface&lt;br/&gt;typer]\n        API[Python API&lt;br/&gt;Library]\n        WebUI[Web UI&lt;br/&gt;Future]\n        IDE[IDE Extensions]\n    end\n\n    subgraph \"Command Orchestration\"\n        DISPATCHER[Command Dispatcher]\n        DISTILL[Distill Command]\n        EXAMINE[Examine Command]\n        CHRONICLE[Chronicle Command]\n        MOMENTUM[Momentum Command]\n        SESSION[Session Management]\n    end\n\n    subgraph \"Prompt Processing Layer\"\n        PARSER[Prompt Parser]\n        INTENT[Intent Detection]\n        KEYWORDS[Keyword Extraction]\n        ENTITIES[Entity Extraction]\n\n        subgraph \"NLP Pipeline\"\n            TOKENIZER[Tokenizer]\n            STOPWORDS[Stopwords]\n            RAKE[RAKE Keywords]\n            YAKE[YAKE Fallback]\n            TFIDF[BM25/TF-IDF Analysis]\n            BM25[BM25 Ranking]\n        end\n    end\n\n    subgraph \"File Discovery &amp; Analysis\"\n        SCANNER[File Scanner]\n        GITIGNORE[.gitignore Parser]\n        BINARY[Binary Detection]\n        PARALLEL[Parallel Scanner]\n\n        subgraph \"Code Analysis Engine\"\n            PYTHON_ANALYZER[Python Analyzer]\n            JS_ANALYZER[JavaScript Analyzer]\n            GO_ANALYZER[Go Analyzer]\n            JAVA_ANALYZER[Java Analyzer]\n            GENERIC_ANALYZER[Generic Analyzer]\n        end\n\n        subgraph \"AST &amp; Structure\"\n            CLASSES[Class Extraction]\n            FUNCTIONS[Function Extraction]\n            IMPORTS[Import Analysis]\n            EXPORTS[Export Analysis]\n        end\n    end\n\n    subgraph \"Intelligence &amp; Ranking\"\n        subgraph \"Ranking Engine\"\n            FAST[Fast Strategy]\n            BALANCED[Balanced Strategy]\n            THOROUGH[Thorough Strategy]\n            ML[ML Strategy]\n        end\n\n        subgraph \"Ranking Factors\"\n            SEMANTIC[Semantic Similarity&lt;br/&gt;25%]\n            KEYWORD_MATCH[Keyword Matching&lt;br/&gt;15%]\n            BM25_SIM[BM25 Similarity&lt;br/&gt;15%]\n            IMPORT_CENT[Import Centrality&lt;br/&gt;10%]\n            PATH_REL[Path Relevance&lt;br/&gt;10%]\n            GIT_SIG[Git Signals&lt;br/&gt;15%]\n        end\n\n        subgraph \"ML/NLP Pipeline\"\n            EMBEDDINGS[Local Embeddings]\n            EMBED_CACHE[Embedding Cache]\n            SIMILARITY[Similarity Computing]\n        end\n    end\n\n    subgraph \"Context Optimization\"\n        CONTEXT_BUILDER[Context Builder]\n        TOKEN_COUNTER[Token Counter]\n        SUMMARIZER[Summarizer]\n        FORMATTER[Output Formatter]\n    end\n\n    subgraph \"Storage &amp; Persistence\"\n        SQLITE[SQLite Database&lt;br/&gt;Sessions]\n        MEMORY[Memory Cache&lt;br/&gt;LRU]\n        DISK[Disk Cache&lt;br/&gt;Analysis Results]\n    end\n\n    CLI --&gt; DISPATCHER\n    API --&gt; DISPATCHER\n    WebUI --&gt; DISPATCHER\n    IDE --&gt; DISPATCHER\n\n    DISPATCHER --&gt; DISTILL\n    DISPATCHER --&gt; EXAMINE\n    DISPATCHER --&gt; CHRONICLE\n    DISPATCHER --&gt; MOMENTUM\n    DISPATCHER --&gt; SESSION\n\n    DISTILL --&gt; PARSER\n    PARSER --&gt; INTENT\n    PARSER --&gt; KEYWORDS\n    PARSER --&gt; ENTITIES\n\n    INTENT --&gt; TOKENIZER\n    KEYWORDS --&gt; RAKE\n    RAKE --&gt; YAKE\n    ENTITIES --&gt; TFIDF\n    ENTITIES --&gt; BM25\n\n    PARSER --&gt; SCANNER\n    SCANNER --&gt; GITIGNORE\n    SCANNER --&gt; BINARY\n    SCANNER --&gt; PARALLEL\n\n    SCANNER --&gt; PYTHON_ANALYZER\n    SCANNER --&gt; JS_ANALYZER\n    SCANNER --&gt; GO_ANALYZER\n    SCANNER --&gt; JAVA_ANALYZER\n    SCANNER --&gt; GENERIC_ANALYZER\n\n    PYTHON_ANALYZER --&gt; CLASSES\n    PYTHON_ANALYZER --&gt; FUNCTIONS\n    PYTHON_ANALYZER --&gt; IMPORTS\n    PYTHON_ANALYZER --&gt; EXPORTS\n\n    CLASSES --&gt; FAST\n    FUNCTIONS --&gt; BALANCED\n    IMPORTS --&gt; THOROUGH\n    EXPORTS --&gt; ML\n\n    FAST --&gt; SEMANTIC\n    BALANCED --&gt; KEYWORD_MATCH\n    THOROUGH --&gt; BM25_SIM\n    ML --&gt; IMPORT_CENT\n\n    SEMANTIC --&gt; EMBEDDINGS\n    EMBEDDINGS --&gt; EMBED_CACHE\n    EMBED_CACHE --&gt; SIMILARITY\n\n    SIMILARITY --&gt; CONTEXT_BUILDER\n    KEYWORD_MATCH --&gt; CONTEXT_BUILDER\n    BM25_SIM --&gt; CONTEXT_BUILDER\n\n    CONTEXT_BUILDER --&gt; TOKEN_COUNTER\n    CONTEXT_BUILDER --&gt; SUMMARIZER\n    CONTEXT_BUILDER --&gt; FORMATTER\n\n    FORMATTER --&gt; SQLITE\n    FORMATTER --&gt; MEMORY\n    FORMATTER --&gt; DISK</code></pre>"},{"location":"ARCHITECTURE/#system-component-overview","title":"System Component Overview","text":"<pre><code>graph LR\n    subgraph \"Core Components\"\n        NLP[NLP/ML Pipeline]\n        SCAN[File Scanner]\n        ANALYZE[Code Analyzer]\n        RANK[Ranking Engine]\n        CONTEXT[Context Builder]\n    end\n\n    subgraph \"Analysis Tools\"\n        EXAMINE[Examine Tool]\n        CHRONICLE[Chronicle Tool]\n        MOMENTUM[Momentum Tool]\n    end\n\n    subgraph \"Storage Systems\"\n        CACHE[Cache Manager]\n        SESSION[Session Store]\n        CONFIG[Configuration]\n    end\n\n    NLP --&gt; RANK\n    SCAN --&gt; ANALYZE\n    ANALYZE --&gt; RANK\n    RANK --&gt; CONTEXT\n\n    ANALYZE --&gt; EXAMINE\n    SCAN --&gt; CHRONICLE\n    CHRONICLE --&gt; MOMENTUM\n\n    RANK --&gt; CACHE\n    CONTEXT --&gt; SESSION\n    SESSION --&gt; CONFIG</code></pre>"},{"location":"ARCHITECTURE/#nlpml-pipeline-architecture","title":"NLP/ML Pipeline Architecture","text":""},{"location":"ARCHITECTURE/#centralized-nlp-components","title":"Centralized NLP Components","text":"Text Only<pre><code>tenets/core/nlp/\n\u251c\u2500\u2500 __init__.py          # Main NLP API exports\n\u251c\u2500\u2500 similarity.py        # Centralized similarity computations\n\u251c\u2500\u2500 keyword_extractor.py # Unified keyword extraction with SimpleRAKE\n\u251c\u2500\u2500 tokenizer.py        # Code and text tokenization\n\u251c\u2500\u2500 stopwords.py        # Stopword management with fallbacks\n\u251c\u2500\u2500 embeddings.py       # Embedding generation (ML optional)\n\u251c\u2500\u2500 ml_utils.py         # ML utility functions\n\u251c\u2500\u2500 bm25.py            # BM25 ranking algorithm (primary)\n\u2514\u2500\u2500 tfidf.py           # TF-IDF calculations (optional alternative)\n</code></pre>"},{"location":"ARCHITECTURE/#pipeline-component-flow","title":"Pipeline Component Flow","text":"<pre><code>graph TD\n    subgraph \"Input Processing\"\n        INPUT[Raw Text Input]\n        PROMPT[User Prompt]\n        CODE[Code Content]\n    end\n\n    subgraph \"Tokenization Layer\"\n        CODE_TOK[Code Tokenizer&lt;br/&gt;camelCase, snake_case]\n        TEXT_TOK[Text Tokenizer&lt;br/&gt;NLP processing]\n    end\n\n    subgraph \"Keyword Extraction\"\n        RAKE_EXT[RAKE Extractor&lt;br/&gt;Primary - Fast &amp; Python 3.13 Compatible]\n        YAKE_EXT[YAKE Extractor&lt;br/&gt;Secondary - Python &lt; 3.13 Only]\n        TFIDF_EXT[BM25/TF-IDF Extractor&lt;br/&gt;Frequency-based Fallback]\n        FREQ_EXT[Frequency Extractor&lt;br/&gt;Final Fallback]\n    end\n\n    subgraph \"Stopword Management\"\n        CODE_STOP[Code Stopwords&lt;br/&gt;Minimal - 30 words]\n        PROMPT_STOP[Prompt Stopwords&lt;br/&gt;Aggressive - 200+ words]\n    end\n\n    subgraph \"Embedding Generation\"\n        LOCAL_EMB[Local Embeddings&lt;br/&gt;sentence-transformers]\n        MODEL_SEL[Model Selection&lt;br/&gt;MiniLM, MPNet]\n        FALLBACK[BM25 Fallback&lt;br/&gt;No ML required]\n    end\n\n    subgraph \"Similarity Computing\"\n        COSINE[Cosine Similarity]\n        EUCLIDEAN[Euclidean Distance]\n        BATCH[Batch Processing]\n    end\n\n    subgraph \"Caching System\"\n        MEM_CACHE[Memory Cache&lt;br/&gt;LRU 1000 items]\n        DISK_CACHE[SQLite Cache&lt;br/&gt;30 day TTL]\n    end\n\n    INPUT --&gt; CODE_TOK\n    INPUT --&gt; TEXT_TOK\n    PROMPT --&gt; TEXT_TOK\n    CODE --&gt; CODE_TOK\n\n    CODE_TOK --&gt; CODE_STOP\n    TEXT_TOK --&gt; PROMPT_STOP\n\n    CODE_STOP --&gt; RAKE_EXT\n    PROMPT_STOP --&gt; RAKE_EXT\n    RAKE_EXT --&gt; YAKE_EXT\n    YAKE_EXT --&gt; TFIDF_EXT\n    TFIDF_EXT --&gt; FREQ_EXT\n\n    FREQ_EXT --&gt; LOCAL_EMB\n    LOCAL_EMB --&gt; MODEL_SEL\n    MODEL_SEL --&gt; FALLBACK\n\n    FALLBACK --&gt; COSINE\n    COSINE --&gt; EUCLIDEAN\n    EUCLIDEAN --&gt; BATCH\n\n    BATCH --&gt; MEM_CACHE\n    MEM_CACHE --&gt; DISK_CACHE</code></pre>"},{"location":"ARCHITECTURE/#keyword-extraction-algorithms-comparison","title":"Keyword Extraction Algorithms Comparison","text":"Algorithm Speed Quality Memory Python 3.13 Best For Limitations RAKE Fast Good Low \u2705 Yes Technical docs, Multi-word phrases No semantic understanding SimpleRAKE Fast Good Minimal \u2705 Yes No NLTK dependencies, Built-in Basic tokenization only YAKE Moderate Very Good Low \u274c No Statistical analysis, Capital aware Python 3.13 bug BM25 Fast Excellent High \u2705 Yes Primary ranking, Length variation Needs corpus TF-IDF Fast Good Medium \u2705 Yes Alternative to BM25 Less effective for varying lengths Frequency Very Fast Basic Minimal \u2705 Yes Fallback option Very basic"},{"location":"ARCHITECTURE/#embedding-model-architecture","title":"Embedding Model Architecture","text":"<pre><code>graph LR\n    subgraph \"Model Options\"\n        MINI_L6[all-MiniLM-L6-v2&lt;br/&gt;90MB, Fast]\n        MINI_L12[all-MiniLM-L12-v2&lt;br/&gt;120MB, Better]\n        MPNET[all-mpnet-base-v2&lt;br/&gt;420MB, Best]\n        QA_MINI[multi-qa-MiniLM&lt;br/&gt;Q&amp;A Optimized]\n    end\n\n    subgraph \"Processing Pipeline\"\n        BATCH_ENC[Batch Encoding]\n        CHUNK[Document Chunking&lt;br/&gt;1000 chars, 100 overlap]\n        VECTOR[Vector Operations&lt;br/&gt;NumPy optimized]\n    end\n\n    subgraph \"Cache Strategy\"\n        KEY_GEN[Cache Key Generation&lt;br/&gt;model + content hash]\n        WARM[Cache Warming]\n        INVALID[Intelligent Invalidation]\n    end\n\n    MINI_L6 --&gt; BATCH_ENC\n    MINI_L12 --&gt; BATCH_ENC\n    MPNET --&gt; BATCH_ENC\n    QA_MINI --&gt; BATCH_ENC\n\n    BATCH_ENC --&gt; CHUNK\n    CHUNK --&gt; VECTOR\n\n    VECTOR --&gt; KEY_GEN\n    KEY_GEN --&gt; WARM\n    WARM --&gt; INVALID</code></pre>"},{"location":"ARCHITECTURE/#file-discovery--scanning-system","title":"File Discovery &amp; Scanning System","text":""},{"location":"ARCHITECTURE/#scanner-architecture-flow","title":"Scanner Architecture Flow","text":"<pre><code>graph TD\n    subgraph \"Entry Points\"\n        ROOT[Project Root]\n        PATHS[Specified Paths]\n        PATTERNS[Include Patterns]\n    end\n\n    subgraph \"Ignore System Hierarchy\"\n        CLI_IGNORE[CLI Arguments&lt;br/&gt;--exclude&lt;br/&gt;Highest Priority]\n        TENETS_IGNORE[.tenetsignore&lt;br/&gt;Project-specific]\n        GIT_IGNORE[.gitignore&lt;br/&gt;Version control]\n        GLOBAL_IGNORE[Global Ignores&lt;br/&gt;~/.config/tenets/ignore&lt;br/&gt;Lowest Priority]\n    end\n\n    subgraph \"Intelligent Test Exclusion\"\n        INTENT_DETECT[Intent Detection&lt;br/&gt;Test-related prompts?]\n        CLI_OVERRIDE[CLI Override&lt;br/&gt;--include-tests / --exclude-tests]\n        TEST_PATTERNS[Test Pattern Matching&lt;br/&gt;Multi-language support]\n        TEST_DIRS[Test Directory Detection&lt;br/&gt;tests/, __tests__, spec/]\n    end\n\n    subgraph \"Minified &amp; Build File Exclusion\"\n        MINIFIED_CHECK[Minified Detection&lt;br/&gt;*.min.js, *.bundle.js]\n        BUILD_DIRS[Build Directories&lt;br/&gt;dist/, build/, out/]\n        PROD_FILES[Production Files&lt;br/&gt;*.prod.js, *.compiled.js]\n        NODE_MODULES[Dependencies&lt;br/&gt;node_modules/, vendor/]\n    end\n\n    subgraph \"Detection Systems\"\n        BINARY_DET[Binary Detection]\n        EXT_CHECK[Extension Check]\n        SIZE_CHECK[Size Check&lt;br/&gt;Max 10MB default]\n        CONTENT_CHECK[Content Sampling&lt;br/&gt;Null byte detection]\n        MAGIC_CHECK[Magic Number&lt;br/&gt;File signatures]\n    end\n\n    subgraph \"Parallel Processing\"\n        WORK_QUEUE[Work Queue]\n        PROCESS_POOL[Process Pool&lt;br/&gt;CPU-bound operations]\n        THREAD_POOL[Thread Pool&lt;br/&gt;I/O operations]\n        PROGRESS[Progress Tracking&lt;br/&gt;tqdm]\n    end\n\n    subgraph \"Output\"\n        SCANNED_FILE[Scanned File Objects]\n        METADATA[File Metadata]\n        ANALYSIS_READY[Ready for Analysis]\n    end\n\n    ROOT --&gt; CLI_IGNORE\n    PATHS --&gt; CLI_IGNORE\n    PATTERNS --&gt; CLI_IGNORE\n\n    CLI_IGNORE --&gt; TENETS_IGNORE\n    TENETS_IGNORE --&gt; GIT_IGNORE\n    GIT_IGNORE --&gt; GLOBAL_IGNORE\n\n    GLOBAL_IGNORE --&gt; BINARY_DET\n    BINARY_DET --&gt; EXT_CHECK\n    EXT_CHECK --&gt; SIZE_CHECK\n    SIZE_CHECK --&gt; CONTENT_CHECK\n    CONTENT_CHECK --&gt; MAGIC_CHECK\n\n    MAGIC_CHECK --&gt; WORK_QUEUE\n    WORK_QUEUE --&gt; PROCESS_POOL\n    WORK_QUEUE --&gt; THREAD_POOL\n    PROCESS_POOL --&gt; PROGRESS\n    THREAD_POOL --&gt; PROGRESS\n\n    PROGRESS --&gt; SCANNED_FILE\n    SCANNED_FILE --&gt; METADATA\n    METADATA --&gt; ANALYSIS_READY</code></pre>"},{"location":"ARCHITECTURE/#binary-detection-strategy","title":"Binary Detection Strategy","text":"<pre><code>flowchart TD\n    FILE[Input File] --&gt; EXT{Known Binary&lt;br/&gt;Extension?}\n    EXT --&gt;|Yes| BINARY[Mark as Binary]\n    EXT --&gt;|No| SIZE{Size &gt; 10MB?}\n    SIZE --&gt;|Yes| SKIP[Skip File]\n    SIZE --&gt;|No| SAMPLE[Sample First 8KB]\n    SAMPLE --&gt; NULL{Contains&lt;br/&gt;Null Bytes?}\n    NULL --&gt;|Yes| BINARY\n    NULL --&gt;|No| RATIO[Calculate Text Ratio]\n    RATIO --&gt; THRESHOLD{Ratio &gt; 95%&lt;br/&gt;Printable?}\n    THRESHOLD --&gt;|Yes| TEXT[Mark as Text]\n    THRESHOLD --&gt;|No| BINARY\n    TEXT --&gt; ANALYZE[Ready for Analysis]\n    BINARY --&gt; IGNORE[Skip Analysis]\n    SKIP --&gt; IGNORE</code></pre>"},{"location":"ARCHITECTURE/#intelligent-test-file-exclusion","title":"Intelligent Test File Exclusion","text":"<pre><code>flowchart TD\n    PROMPT[User Prompt] --&gt; PARSE[Prompt Parsing]\n    PARSE --&gt; INTENT{Intent Detection&lt;br/&gt;Test-related?}\n\n    INTENT --&gt;|Yes| INCLUDE_TESTS[include_tests = True]\n    INTENT --&gt;|No| EXCLUDE_TESTS[include_tests = False]\n\n    CLI_OVERRIDE{CLI Override?&lt;br/&gt;--include-tests&lt;br/&gt;--exclude-tests}\n    CLI_OVERRIDE --&gt;|--include-tests| FORCE_INCLUDE[include_tests = True]\n    CLI_OVERRIDE --&gt;|--exclude-tests| FORCE_EXCLUDE[include_tests = False]\n    CLI_OVERRIDE --&gt;|None| INTENT\n\n    INCLUDE_TESTS --&gt; SCAN_ALL[Scan All Files]\n    EXCLUDE_TESTS --&gt; TEST_FILTER[Apply Test Filters]\n    FORCE_INCLUDE --&gt; SCAN_ALL\n    FORCE_EXCLUDE --&gt; TEST_FILTER\n\n    TEST_FILTER --&gt; PATTERN_MATCH[Pattern Matching]\n    PATTERN_MATCH --&gt; DIR_MATCH[Directory Matching]\n\n    subgraph \"Test Patterns (Multi-language)\"\n        PY_PATTERNS[\"Python: test_*.py, *_test.py\"]\n        JS_PATTERNS[\"JavaScript: *.test.js, *.spec.js\"]\n        JAVA_PATTERNS[\"Java: *Test.java, *Tests.java\"]\n        GO_PATTERNS[\"Go: *_test.go\"]\n        GENERIC_PATTERNS[\"Generic: **/test/**, **/tests/**\"]\n    end\n\n    PATTERN_MATCH --&gt; PY_PATTERNS\n    PATTERN_MATCH --&gt; JS_PATTERNS\n    PATTERN_MATCH --&gt; JAVA_PATTERNS\n    PATTERN_MATCH --&gt; GO_PATTERNS\n    PATTERN_MATCH --&gt; GENERIC_PATTERNS\n\n    PY_PATTERNS --&gt; FILTERED_FILES[Filtered File List]\n    JS_PATTERNS --&gt; FILTERED_FILES\n    JAVA_PATTERNS --&gt; FILTERED_FILES\n    GO_PATTERNS --&gt; FILTERED_FILES\n    GENERIC_PATTERNS --&gt; FILTERED_FILES\n\n    SCAN_ALL --&gt; ANALYSIS[File Analysis]\n    FILTERED_FILES --&gt; ANALYSIS</code></pre>"},{"location":"ARCHITECTURE/#code-analysis-engine","title":"Code Analysis Engine","text":""},{"location":"ARCHITECTURE/#language-analyzer-architecture","title":"Language Analyzer Architecture","text":"<pre><code>graph TB\n    subgraph \"Base Analyzer Interface\"\n        BASE[LanguageAnalyzer&lt;br/&gt;Abstract Base Class]\n        EXTRACT_IMP[extract_imports()]\n        EXTRACT_EXP[extract_exports()]\n        EXTRACT_CLS[extract_classes()]\n        EXTRACT_FN[extract_functions()]\n        CALC_COMP[calculate_complexity()]\n        TRACE_DEP[trace_dependencies()]\n    end\n\n    subgraph \"Language-Specific Analyzers\"\n        PYTHON[Python Analyzer&lt;br/&gt;Full AST parsing]\n        JAVASCRIPT[JavaScript Analyzer&lt;br/&gt;ES6+ support]\n        GOLANG[Go Analyzer&lt;br/&gt;Package detection]\n        JAVA[Java Analyzer&lt;br/&gt;OOP patterns]\n        RUST[Rust Analyzer&lt;br/&gt;Ownership patterns]\n        GENERIC[Generic Analyzer&lt;br/&gt;Pattern-based fallback]\n    end\n\n    subgraph \"Analysis Features\"\n        AST[AST Parsing]\n        IMPORTS[Import Resolution]\n        TYPES[Type Extraction]\n        DOCS[Documentation Parsing]\n        PATTERNS[Code Patterns]\n        COMPLEXITY[Complexity Metrics]\n    end\n\n    BASE --&gt; EXTRACT_IMP\n    BASE --&gt; EXTRACT_EXP\n    BASE --&gt; EXTRACT_CLS\n    BASE --&gt; EXTRACT_FN\n    BASE --&gt; CALC_COMP\n    BASE --&gt; TRACE_DEP\n\n    BASE --&gt; PYTHON\n    BASE --&gt; JAVASCRIPT\n    BASE --&gt; GOLANG\n    BASE --&gt; JAVA\n    BASE --&gt; RUST\n    BASE --&gt; GENERIC\n\n    PYTHON --&gt; AST\n    PYTHON --&gt; IMPORTS\n    PYTHON --&gt; TYPES\n    PYTHON --&gt; DOCS\n\n    JAVASCRIPT --&gt; PATTERNS\n    GOLANG --&gt; PATTERNS\n    JAVA --&gt; COMPLEXITY\n    RUST --&gt; COMPLEXITY\n    GENERIC --&gt; PATTERNS</code></pre>"},{"location":"ARCHITECTURE/#python-analyzer-detail","title":"Python Analyzer Detail","text":"<pre><code>graph LR\n    subgraph \"Python AST Analysis\"\n        AST_PARSE[AST Parser]\n        NODE_VISIT[Node Visitor]\n        SYMBOL_TABLE[Symbol Table]\n    end\n\n    subgraph \"Code Structure\"\n        CLASSES[Class Definitions&lt;br/&gt;Inheritance chains]\n        FUNCTIONS[Function Definitions&lt;br/&gt;Async detection]\n        DECORATORS[Decorator Analysis]\n        TYPE_HINTS[Type Hint Extraction]\n    end\n\n    subgraph \"Import Analysis\"\n        ABS_IMP[Absolute Imports]\n        REL_IMP[Relative Imports]\n        STAR_IMP[Star Imports]\n        IMPORT_GRAPH[Import Graph Building]\n    end\n\n    subgraph \"Complexity Metrics\"\n        CYCLO[Cyclomatic Complexity&lt;br/&gt;+1 for if, for, while]\n        COGNITIVE[Cognitive Complexity&lt;br/&gt;Nesting penalties]\n        HALSTEAD[Halstead Metrics&lt;br/&gt;Operators/operands]\n    end\n\n    AST_PARSE --&gt; NODE_VISIT\n    NODE_VISIT --&gt; SYMBOL_TABLE\n\n    SYMBOL_TABLE --&gt; CLASSES\n    SYMBOL_TABLE --&gt; FUNCTIONS\n    SYMBOL_TABLE --&gt; DECORATORS\n    SYMBOL_TABLE --&gt; TYPE_HINTS\n\n    NODE_VISIT --&gt; ABS_IMP\n    NODE_VISIT --&gt; REL_IMP\n    NODE_VISIT --&gt; STAR_IMP\n    ABS_IMP --&gt; IMPORT_GRAPH\n    REL_IMP --&gt; IMPORT_GRAPH\n    STAR_IMP --&gt; IMPORT_GRAPH\n\n    SYMBOL_TABLE --&gt; CYCLO\n    SYMBOL_TABLE --&gt; COGNITIVE\n    SYMBOL_TABLE --&gt; HALSTEAD</code></pre>"},{"location":"ARCHITECTURE/#relevance-ranking-system","title":"Relevance Ranking System","text":""},{"location":"ARCHITECTURE/#unified-ranking-architecture","title":"Unified Ranking Architecture","text":"<pre><code>graph TD\n    subgraph \"Ranking Strategies\"\n        FAST[Fast Strategy&lt;br/&gt;Fastest&lt;br/&gt;Keyword + Path Only]\n        BALANCED[Balanced Strategy&lt;br/&gt;1.5x slower&lt;br/&gt;BM25 + Structure]\n        THOROUGH[Thorough Strategy&lt;br/&gt;4x slower&lt;br/&gt;Full Analysis + ML]\n        ML_STRAT[ML Strategy&lt;br/&gt;5x slower&lt;br/&gt;Semantic Embeddings]\n    end\n\n    subgraph \"Text Analysis (40% in Balanced)\"\n        KEY_MATCH[Keyword Matching&lt;br/&gt;20%&lt;br/&gt;Direct term hits]\n        BM25_SIM[BM25 Similarity&lt;br/&gt;20%&lt;br/&gt;Statistical relevance]\n        BM25_SCORE[BM25 Score&lt;br/&gt;15%&lt;br/&gt;Probabilistic ranking]\n    end\n\n    subgraph \"Code Structure Analysis (25% in Balanced)\"\n        PATH_REL[Path Relevance&lt;br/&gt;15%&lt;br/&gt;Directory structure]\n        IMP_CENT[Import Centrality&lt;br/&gt;10%&lt;br/&gt;Dependency importance]\n    end\n\n    subgraph \"File Characteristics (15% in Balanced)\"\n        COMPLEXITY_REL[Complexity Relevance&lt;br/&gt;5%&lt;br/&gt;Code complexity signals]\n        FILE_TYPE[File Type Relevance&lt;br/&gt;5%&lt;br/&gt;Extension/type matching]\n        CODE_PAT[Code Patterns&lt;br/&gt;5%&lt;br/&gt;AST pattern matching]\n    end\n\n    subgraph \"Git Signals (10% in Balanced)\"\n        GIT_REC[Git Recency&lt;br/&gt;5%&lt;br/&gt;Recent changes]\n        GIT_FREQ[Git Frequency&lt;br/&gt;5%&lt;br/&gt;Change frequency]\n    end\n\n    subgraph \"ML Enhancement (Only in ML Strategy)\"\n        SEM_SIM[Semantic Similarity&lt;br/&gt;25%&lt;br/&gt;Embedding-based understanding]\n        LOCAL_EMB[Local Embeddings&lt;br/&gt;sentence-transformers]\n        EMBED_CACHE[Embedding Cache&lt;br/&gt;Performance optimization]\n    end\n\n    subgraph \"Unified Pipeline\"\n        FILE_DISCOVERY[File Discovery&lt;br/&gt;Scanner + Filters]\n        ANALYSIS[Code Analysis&lt;br/&gt;AST + Structure]\n        RANKING[Multi-Factor Ranking&lt;br/&gt;Strategy-specific weights]\n        AGGREGATION[Context Aggregation&lt;br/&gt;Token optimization]\n    end\n\n    FAST --&gt; KEY_MATCH\n    BALANCED --&gt; BM25_SIM\n    BALANCED --&gt; BM25_SCORE\n    THOROUGH --&gt; IMP_CENT\n    ML_STRAT --&gt; SEM_SIM\n\n    FILE_DISCOVERY --&gt; ANALYSIS\n    ANALYSIS --&gt; RANKING\n    RANKING --&gt; AGGREGATION\n\n    KEY_MATCH --&gt; RANKING\n    BM25_SIM --&gt; RANKING\n    BM25_SCORE --&gt; RANKING\n    PATH_REL --&gt; RANKING\n    IMP_CENT --&gt; RANKING\n    COMPLEXITY_REL --&gt; RANKING\n    FILE_TYPE --&gt; RANKING\n    CODE_PAT --&gt; RANKING\n    GIT_REC --&gt; RANKING\n    GIT_FREQ --&gt; RANKING\n\n    SEM_SIM --&gt; LOCAL_EMB\n    LOCAL_EMB --&gt; EMBED_CACHE\n    EMBED_CACHE --&gt; RANKING</code></pre>"},{"location":"ARCHITECTURE/#strategy-comparison","title":"Strategy Comparison","text":"Strategy Speed Accuracy Use Cases Factors Used Fast Fastest Basic Quick file discovery Keyword (60%), Path (30%), File type (10%) Balanced 1.5x slower Good DEFAULT Production usage Keyword (20%), BM25 (35%), Structure (25%), Git (10%) Thorough 4x slower High Complex codebases All balanced factors + enhanced analysis ML 5x slower Highest Semantic search Embeddings (25%) + all thorough factors"},{"location":"ARCHITECTURE/#factor-calculation-details","title":"Factor Calculation Details","text":"<pre><code>graph LR\n    subgraph \"Semantic Similarity Calculation\"\n        CHUNK[Chunk Long Files&lt;br/&gt;1000 chars, 100 overlap]\n        EMBED[Generate Embeddings&lt;br/&gt;Local model]\n        COSINE[Cosine Similarity]\n        CACHE_SEM[Cache Results]\n    end\n\n    subgraph \"Keyword Matching\"\n        FILENAME[Filename Match&lt;br/&gt;Weight: 0.4]\n        IMPORT_M[Import Match&lt;br/&gt;Weight: 0.3]\n        CLASS_FN[Class/Function Name&lt;br/&gt;Weight: 0.25]\n        POSITION[Position Weight&lt;br/&gt;Early lines favored]\n    end\n\n    subgraph \"Import Centrality\"\n        IN_EDGES[Incoming Edges&lt;br/&gt;Files importing this&lt;br/&gt;70% weight]\n        OUT_EDGES[Outgoing Edges&lt;br/&gt;Files this imports&lt;br/&gt;30% weight]\n        LOG_SCALE[Logarithmic Scaling&lt;br/&gt;High-degree nodes]\n        NORMALIZE[Normalize 0-1]\n    end\n\n    subgraph \"Git Signals\"\n        RECENCY[Recency Score&lt;br/&gt;Exponential decay&lt;br/&gt;30-day half-life]\n        FREQUENCY[Frequency Score&lt;br/&gt;Log of commit count]\n        EXPERTISE[Author Expertise&lt;br/&gt;Contribution volume]\n        CHURN[Recent Churn&lt;br/&gt;Lines changed]\n    end\n\n    CHUNK --&gt; EMBED\n    EMBED --&gt; COSINE\n    COSINE --&gt; CACHE_SEM\n\n    FILENAME --&gt; POSITION\n    IMPORT_M --&gt; POSITION\n    CLASS_FN --&gt; POSITION\n\n    IN_EDGES --&gt; LOG_SCALE\n    OUT_EDGES --&gt; LOG_SCALE\n    LOG_SCALE --&gt; NORMALIZE\n\n    RECENCY --&gt; EXPERTISE\n    FREQUENCY --&gt; EXPERTISE\n    EXPERTISE --&gt; CHURN</code></pre>"},{"location":"ARCHITECTURE/#git-integration--chronicle-system","title":"Git Integration &amp; Chronicle System","text":""},{"location":"ARCHITECTURE/#git-analysis-architecture","title":"Git Analysis Architecture","text":"<pre><code>graph TD\n    subgraph \"Git Data Sources\"\n        COMMIT_LOG[Commit History]\n        BLAME_DATA[Blame Information]\n        BRANCH_INFO[Branch Analysis]\n        MERGE_DATA[Merge Detection]\n        CONFLICT_HIST[Conflict History]\n    end\n\n    subgraph \"Chronicle Analysis\"\n        TEMPORAL[Temporal Analysis&lt;br/&gt;Activity patterns]\n        CONTRIBUTORS[Contributor Tracking&lt;br/&gt;Author patterns]\n        VELOCITY[Change Velocity&lt;br/&gt;Trend analysis]\n        HOTSPOTS[Change Hotspots&lt;br/&gt;Problem areas]\n    end\n\n    subgraph \"Metrics Calculation\"\n        BUS_FACTOR[Bus Factor&lt;br/&gt;Knowledge concentration]\n        EXPERTISE[Author Expertise&lt;br/&gt;Domain knowledge]\n        FRESHNESS[Code Freshness&lt;br/&gt;Age distribution]\n        STABILITY[Change Stability&lt;br/&gt;Frequency patterns]\n    end\n\n    subgraph \"Risk Assessment\"\n        KNOWLEDGE_RISK[Knowledge Risk&lt;br/&gt;Single points of failure]\n        CHURN_RISK[Churn Risk&lt;br/&gt;High-change areas]\n        COMPLEXITY_RISK[Complexity Risk&lt;br/&gt;Hard-to-maintain code]\n        SUCCESSION[Succession Planning&lt;br/&gt;Knowledge transfer]\n    end\n\n    COMMIT_LOG --&gt; TEMPORAL\n    BLAME_DATA --&gt; CONTRIBUTORS\n    BRANCH_INFO --&gt; VELOCITY\n    MERGE_DATA --&gt; HOTSPOTS\n    CONFLICT_HIST --&gt; HOTSPOTS\n\n    CONTRIBUTORS --&gt; BUS_FACTOR\n    TEMPORAL --&gt; EXPERTISE\n    VELOCITY --&gt; FRESHNESS\n    HOTSPOTS --&gt; STABILITY\n\n    BUS_FACTOR --&gt; KNOWLEDGE_RISK\n    EXPERTISE --&gt; CHURN_RISK\n    FRESHNESS --&gt; COMPLEXITY_RISK\n    STABILITY --&gt; SUCCESSION</code></pre>"},{"location":"ARCHITECTURE/#chronicle-report-structure","title":"Chronicle Report Structure","text":"<pre><code>graph LR\n    subgraph \"Executive Summary\"\n        HEALTH[Repository Health Score]\n        KEY_METRICS[Key Metrics Dashboard]\n        ALERTS[Risk Alerts]\n    end\n\n    subgraph \"Activity Analysis\"\n        TIMELINE[Activity Timeline]\n        PATTERNS[Change Patterns]\n        TRENDS[Velocity Trends]\n    end\n\n    subgraph \"Contributor Analysis\"\n        TEAM[Team Composition]\n        EXPERTISE_MAP[Expertise Mapping]\n        CONTRIBUTION[Contribution Patterns]\n    end\n\n    subgraph \"Risk Assessment\"\n        RISKS[Identified Risks]\n        RECOMMENDATIONS[Recommendations]\n        ACTION_ITEMS[Action Items]\n    end\n\n    HEALTH --&gt; TIMELINE\n    KEY_METRICS --&gt; PATTERNS\n    ALERTS --&gt; TRENDS\n\n    TIMELINE --&gt; TEAM\n    PATTERNS --&gt; EXPERTISE_MAP\n    TRENDS --&gt; CONTRIBUTION\n\n    TEAM --&gt; RISKS\n    EXPERTISE_MAP --&gt; RECOMMENDATIONS\n    CONTRIBUTION --&gt; ACTION_ITEMS</code></pre>"},{"location":"ARCHITECTURE/#context-management--optimization","title":"Context Management &amp; Optimization","text":""},{"location":"ARCHITECTURE/#context-building-pipeline","title":"Context Building Pipeline","text":"<pre><code>graph TD\n    subgraph \"Input Processing\"\n        RANKED_FILES[Ranked File Results]\n        TOKEN_BUDGET[Available Token Budget]\n        USER_PREFS[User Preferences]\n    end\n\n    subgraph \"Selection Strategy\"\n        THRESHOLD[Score Threshold Filtering]\n        TOP_N[Top-N Selection]\n        DIVERSITY[Diversity Optimization]\n        DEPENDENCIES[Dependency Inclusion]\n    end\n\n    subgraph \"Token Management\"\n        MODEL_LIMITS[Model-Specific Limits&lt;br/&gt;4K, 8K, 16K, 32K, 100K]\n        PROMPT_RESERVE[Prompt Token Reserve]\n        RESPONSE_RESERVE[Response Token Reserve&lt;br/&gt;2K-4K]\n        SAFETY_MARGIN[Safety Margin&lt;br/&gt;5% buffer]\n    end\n\n    subgraph \"Content Optimization\"\n        SUMMARIZATION[Summarization Strategy]\n        EXTRACTION[Key Component Extraction]\n        COMPRESSION[Content Compression]\n        FORMATTING[Output Formatting]\n    end\n\n    subgraph \"Quality Assurance\"\n        COHERENCE[Context Coherence Check]\n        COMPLETENESS[Completeness Validation]\n        RELEVANCE[Relevance Verification]\n        FINAL_OUTPUT[Final Context Output]\n    end\n\n    RANKED_FILES --&gt; THRESHOLD\n    TOKEN_BUDGET --&gt; MODEL_LIMITS\n    USER_PREFS --&gt; TOP_N\n\n    THRESHOLD --&gt; TOP_N\n    TOP_N --&gt; DIVERSITY\n    DIVERSITY --&gt; DEPENDENCIES\n\n    MODEL_LIMITS --&gt; PROMPT_RESERVE\n    PROMPT_RESERVE --&gt; RESPONSE_RESERVE\n    RESPONSE_RESERVE --&gt; SAFETY_MARGIN\n\n    DEPENDENCIES --&gt; SUMMARIZATION\n    SAFETY_MARGIN --&gt; SUMMARIZATION\n    SUMMARIZATION --&gt; EXTRACTION\n    EXTRACTION --&gt; COMPRESSION\n    COMPRESSION --&gt; FORMATTING\n\n    FORMATTING --&gt; COHERENCE\n    COHERENCE --&gt; COMPLETENESS\n    COMPLETENESS --&gt; RELEVANCE\n    RELEVANCE --&gt; FINAL_OUTPUT</code></pre>"},{"location":"ARCHITECTURE/#summarization-strategies","title":"Summarization Strategies","text":"<pre><code>graph LR\n    subgraph \"Extraction Strategy\"\n        IMPORTS_EX[Import Summarization&lt;br/&gt;Condenses when &gt; threshold]\n        SIGNATURES[Function/Class Signatures&lt;br/&gt;High priority]\n        DOCSTRINGS[Docstrings/Comments&lt;br/&gt;Documentation]\n        TYPES[Type Definitions&lt;br/&gt;Interface contracts]\n    end\n\n    subgraph \"Compression Strategy\"\n        REDUNDANCY[Remove Redundancy&lt;br/&gt;Duplicate code]\n        WHITESPACE[Normalize Whitespace&lt;br/&gt;Consistent formatting]\n        COMMENTS[Condense Comments&lt;br/&gt;Key information only]\n        BOILERPLATE[Remove Boilerplate&lt;br/&gt;Standard patterns]\n    end\n\n    subgraph \"Semantic Strategy\"\n        MEANING[Preserve Meaning&lt;br/&gt;Core logic intact]\n        CONTEXT[Maintain Context&lt;br/&gt;Relationship preservation]\n        ABSTRACTIONS[Higher-level View&lt;br/&gt;Architectural overview]\n        EXAMPLES[Key Examples&lt;br/&gt;Usage patterns]\n    end\n\n    subgraph \"LLM Strategy (Optional)\"\n        EXTERNAL_API[External LLM API&lt;br/&gt;OpenAI/Anthropic]\n        INTELLIGENT[Intelligent Summarization&lt;br/&gt;Context-aware]\n        CONSENT[User Consent Required&lt;br/&gt;Privacy protection]\n        FALLBACK[Fallback to Local&lt;br/&gt;If API unavailable]\n    end\n\n    IMPORTS_EX --&gt; REDUNDANCY\n    SIGNATURES --&gt; WHITESPACE\n    DOCSTRINGS --&gt; COMMENTS\n    TYPES --&gt; BOILERPLATE\n\n    REDUNDANCY --&gt; MEANING\n    WHITESPACE --&gt; CONTEXT\n    COMMENTS --&gt; ABSTRACTIONS\n    BOILERPLATE --&gt; EXAMPLES\n\n    MEANING --&gt; EXTERNAL_API\n    CONTEXT --&gt; INTELLIGENT\n    ABSTRACTIONS --&gt; CONSENT\n    EXAMPLES --&gt; FALLBACK</code></pre>"},{"location":"ARCHITECTURE/#session-management-architecture","title":"Session Management Architecture","text":""},{"location":"ARCHITECTURE/#session-lifecycle-flow","title":"Session Lifecycle Flow","text":"<pre><code>stateDiagram-v2\n    [*] --&gt; Created\n    Created --&gt; FirstPrompt: User provides initial prompt\n    FirstPrompt --&gt; Analyzing: Full codebase analysis\n    Analyzing --&gt; Active: Context built\n    Active --&gt; Interaction: Subsequent prompts\n    Interaction --&gt; Analyzing: Incremental updates\n    Interaction --&gt; Branching: Alternative exploration\n    Branching --&gt; Active: Branch selected\n    Active --&gt; Export: Save for sharing\n    Export --&gt; Archived: Long-term storage\n    Archived --&gt; [*]\n    Active --&gt; [*]: Session ends\n\n    note right of FirstPrompt\n        - Comprehensive analysis\n        - All relevant files\n        - Setup instructions\n        - AI guidance\n    end note\n\n    note right of Interaction\n        - Incremental updates only\n        - Changed files highlighted\n        - Previous context referenced\n        - Minimal redundancy\n    end note</code></pre>"},{"location":"ARCHITECTURE/#session-storage-architecture","title":"Session Storage Architecture","text":"<pre><code>graph TB\n    subgraph \"Session Tables\"\n        SESSIONS[sessions&lt;br/&gt;id, name, project, created, updated]\n        PROMPTS[prompts&lt;br/&gt;id, session_id, text, timestamp]\n        CONTEXTS[contexts&lt;br/&gt;id, session_id, prompt_id, content]\n        FILE_STATES[file_states&lt;br/&gt;session_id, file_path, state]\n        AI_REQUESTS[ai_requests&lt;br/&gt;id, session_id, type, request]\n    end\n\n    subgraph \"Relationships\"\n        SESSION_PROMPT[Session \u2192 Prompts&lt;br/&gt;One-to-Many]\n        PROMPT_CONTEXT[Prompt \u2192 Context&lt;br/&gt;One-to-One]\n        SESSION_FILES[Session \u2192 File States&lt;br/&gt;One-to-Many]\n        SESSION_AI[Session \u2192 AI Requests&lt;br/&gt;One-to-Many]\n    end\n\n    subgraph \"Operations\"\n        CREATE[Create Session]\n        SAVE[Save State]\n        RESTORE[Restore State]\n        BRANCH[Branch Session]\n        MERGE[Merge Sessions]\n        EXPORT[Export Session]\n    end\n\n    SESSIONS --&gt; SESSION_PROMPT\n    SESSIONS --&gt; SESSION_FILES\n    SESSIONS --&gt; SESSION_AI\n    PROMPTS --&gt; PROMPT_CONTEXT\n\n    SESSION_PROMPT --&gt; CREATE\n    PROMPT_CONTEXT --&gt; SAVE\n    SESSION_FILES --&gt; RESTORE\n    SESSION_AI --&gt; BRANCH\n    CREATE --&gt; MERGE\n    SAVE --&gt; EXPORT</code></pre>"},{"location":"ARCHITECTURE/#storage--caching-architecture","title":"Storage &amp; Caching Architecture","text":""},{"location":"ARCHITECTURE/#storage-hierarchy","title":"Storage Hierarchy","text":"<pre><code>graph TB\n    subgraph \"Memory Cache (Hottest)\"\n        LRU[LRU Cache&lt;br/&gt;1000 items default&lt;br/&gt;Sub-millisecond access]\n        HOT_DATA[Frequently accessed data&lt;br/&gt;Recent analyses&lt;br/&gt;Active embeddings]\n    end\n\n    subgraph \"SQLite Database (Structured)\"\n        SESSIONS_DB[Session Storage&lt;br/&gt;User interactions]\n        CONFIG_DB[Configuration&lt;br/&gt;Settings &amp; preferences]\n        RELATIONS[Relationship data&lt;br/&gt;File dependencies]\n        PERF[1-10ms access time]\n    end\n\n    subgraph \"Disk Cache (Bulk)\"\n        ANALYSIS[Analysis Results&lt;br/&gt;File parsing cache]\n        EMBEDDINGS[Embedding Cache&lt;br/&gt;ML vectors]\n        FILE_CONTENT[File Content Cache&lt;br/&gt;Preprocessed data]\n        BULK_PERF[10-100ms access time]\n    end\n\n    subgraph \"File System (Cold)\"\n        LOGS[Application Logs&lt;br/&gt;Debugging information]\n        EXPORTS[Exported Sessions&lt;br/&gt;Sharing &amp; backup]\n        ARCHIVES[Archived Data&lt;br/&gt;Historical sessions]\n        COLD_PERF[100ms+ access time]\n    end\n\n    LRU --&gt; SESSIONS_DB\n    HOT_DATA --&gt; CONFIG_DB\n\n    SESSIONS_DB --&gt; ANALYSIS\n    CONFIG_DB --&gt; EMBEDDINGS\n    RELATIONS --&gt; FILE_CONTENT\n\n    ANALYSIS --&gt; LOGS\n    EMBEDDINGS --&gt; EXPORTS\n    FILE_CONTENT --&gt; ARCHIVES</code></pre>"},{"location":"ARCHITECTURE/#cache-invalidation-strategy","title":"Cache Invalidation Strategy","text":"<pre><code>graph LR\n    subgraph \"Invalidation Triggers\"\n        FILE_MTIME[File Modification Time&lt;br/&gt;Filesystem change]\n        CONTENT_HASH[Content Hash Change&lt;br/&gt;Actual content differs]\n        GIT_COMMIT[Git Commit&lt;br/&gt;Version control change]\n        DEP_CHANGE[Dependency Change&lt;br/&gt;Import graph update]\n        TTL_EXPIRE[TTL Expiration&lt;br/&gt;Time-based cleanup]\n        MANUAL[Manual Refresh&lt;br/&gt;User-initiated]\n    end\n\n    subgraph \"Cache Levels Affected\"\n        MEMORY_INV[Memory Cache&lt;br/&gt;Immediate eviction]\n        SQLITE_INV[SQLite Cache&lt;br/&gt;Mark as stale]\n        DISK_INV[Disk Cache&lt;br/&gt;File removal]\n        CASCADE[Cascade Invalidation&lt;br/&gt;Dependent entries]\n    end\n\n    subgraph \"Rebuilding Strategy\"\n        LAZY[Lazy Rebuilding&lt;br/&gt;On-demand refresh]\n        EAGER[Eager Rebuilding&lt;br/&gt;Background refresh]\n        PARTIAL[Partial Rebuilding&lt;br/&gt;Incremental updates]\n        BATCH[Batch Rebuilding&lt;br/&gt;Multiple files]\n    end\n\n    FILE_MTIME --&gt; MEMORY_INV\n    CONTENT_HASH --&gt; SQLITE_INV\n    GIT_COMMIT --&gt; DISK_INV\n    DEP_CHANGE --&gt; CASCADE\n    TTL_EXPIRE --&gt; CASCADE\n    MANUAL --&gt; CASCADE\n\n    MEMORY_INV --&gt; LAZY\n    SQLITE_INV --&gt; EAGER\n    DISK_INV --&gt; PARTIAL\n    CASCADE --&gt; BATCH</code></pre>"},{"location":"ARCHITECTURE/#performance-architecture","title":"Performance Architecture","text":""},{"location":"ARCHITECTURE/#optimization-strategy-overview","title":"Optimization Strategy Overview","text":"<pre><code>graph TD\n    subgraph \"Parallel Processing\"\n        FILE_SCAN[File Scanning&lt;br/&gt;Process Pool&lt;br/&gt;CPU-bound operations]\n        ANALYSIS[Code Analysis&lt;br/&gt;Thread Pool&lt;br/&gt;I/O operations]\n        RANKING[Relevance Ranking&lt;br/&gt;Thread Pool&lt;br/&gt;Computation]\n        EMBEDDING[Embedding Generation&lt;br/&gt;Batch Processing&lt;br/&gt;GPU if available]\n    end\n\n    subgraph \"Streaming Architecture\"\n        INCREMENTAL[Incremental Discovery&lt;br/&gt;Stream files as found]\n        PROGRESSIVE[Progressive Ranking&lt;br/&gt;Rank as analyzed]\n        CHUNKED[Chunked Analysis&lt;br/&gt;Process in batches]\n        STREAMING[Result Streaming&lt;br/&gt;First results quickly]\n    end\n\n    subgraph \"Lazy Evaluation\"\n        DEFER[Defer Analysis&lt;br/&gt;Until needed]\n        ON_DEMAND[On-demand Embeddings&lt;br/&gt;Generate when required]\n        PROGRESSIVE_ENH[Progressive Enhancement&lt;br/&gt;Add features incrementally]\n        JIT[Just-in-time Compilation&lt;br/&gt;Optimize hot paths]\n    end\n\n    subgraph \"Memory Management\"\n        STREAMING_PROC[Streaming Processing&lt;br/&gt;Constant memory usage]\n        GC[Incremental GC&lt;br/&gt;Prevent pauses]\n        MMAP[Memory-mapped Files&lt;br/&gt;Large file handling]\n        PRESSURE[Memory Pressure Monitor&lt;br/&gt;Adaptive behavior]\n    end\n\n    FILE_SCAN --&gt; INCREMENTAL\n    ANALYSIS --&gt; PROGRESSIVE\n    RANKING --&gt; CHUNKED\n    EMBEDDING --&gt; STREAMING\n\n    INCREMENTAL --&gt; DEFER\n    PROGRESSIVE --&gt; ON_DEMAND\n    CHUNKED --&gt; PROGRESSIVE_ENH\n    STREAMING --&gt; JIT\n\n    DEFER --&gt; STREAMING_PROC\n    ON_DEMAND --&gt; GC\n    PROGRESSIVE_ENH --&gt; MMAP\n    JIT --&gt; PRESSURE</code></pre>"},{"location":"ARCHITECTURE/#configuration-system","title":"Configuration System","text":""},{"location":"ARCHITECTURE/#configuration-hierarchy","title":"Configuration Hierarchy","text":"<pre><code>graph TB\n    subgraph \"Configuration Sources (Priority Order)\"\n        CLI[Command-line Arguments&lt;br/&gt;Highest Priority&lt;br/&gt;--algorithm, --exclude]\n        ENV[Environment Variables&lt;br/&gt;TENETS_ALGORITHM=ml]\n        PROJECT[Project Configuration&lt;br/&gt;.tenets.yml in project root]\n        USER[User Configuration&lt;br/&gt;~/.config/tenets/config.yml]\n        SYSTEM[System Defaults&lt;br/&gt;Built-in fallbacks&lt;br/&gt;Lowest Priority]\n    end\n\n    subgraph \"Configuration Categories\"\n        RANKING_CONFIG[Ranking Configuration&lt;br/&gt;Algorithms, weights, factors]\n        NLP_CONFIG[NLP Configuration&lt;br/&gt;Tokenization, stopwords]\n        ML_CONFIG[ML Configuration&lt;br/&gt;Models, caching, devices]\n        CACHE_CONFIG[Cache Configuration&lt;br/&gt;TTL, size limits, storage]\n        SCANNER_CONFIG[Scanner Configuration&lt;br/&gt;Ignore patterns, limits&lt;br/&gt;Minified exclusion]\n        OUTPUT_CONFIG[Output Configuration&lt;br/&gt;Format, tokens, metadata]\n    end\n\n    subgraph \"Dynamic Configuration\"\n        HOT_RELOAD[Hot Reload&lt;br/&gt;File change detection]\n        API_UPDATE[Runtime API Updates&lt;br/&gt;Programmatic changes]\n        VALIDATION[Configuration Validation&lt;br/&gt;Type checking, constraints]\n        ROLLBACK[Error Rollback&lt;br/&gt;Revert on failure]\n    end\n\n    CLI --&gt; RANKING_CONFIG\n    ENV --&gt; NLP_CONFIG\n    PROJECT --&gt; ML_CONFIG\n    USER --&gt; CACHE_CONFIG\n    SYSTEM --&gt; SCANNER_CONFIG\n\n    RANKING_CONFIG --&gt; HOT_RELOAD\n    NLP_CONFIG --&gt; API_UPDATE\n    ML_CONFIG --&gt; VALIDATION\n    CACHE_CONFIG --&gt; ROLLBACK\n    SCANNER_CONFIG --&gt; ROLLBACK\n    OUTPUT_CONFIG --&gt; ROLLBACK</code></pre>"},{"location":"ARCHITECTURE/#complete-configuration-schema","title":"Complete Configuration Schema","text":"YAML<pre><code># .tenets.yml\nversion: 2\n\n# Ranking configuration\nranking:\n  algorithm: balanced  # fast|balanced|thorough|ml\n  threshold: 0.1       # Minimum relevance score\n  use_git: true        # Enable git signals\n  use_ml: true         # Enable ML features\n\n  # Factor weights (must sum to ~1.0)\n  weights:\n    semantic_similarity: 0.25\n    keyword_match: 0.15\n    bm25_similarity: 0.15\n    import_centrality: 0.10\n    path_relevance: 0.10\n    git_recency: 0.05\n    git_frequency: 0.05\n    git_authors: 0.05\n    file_type: 0.05\n    code_patterns: 0.05\n\n  # Performance\n  workers: 8           # Parallel workers\n  batch_size: 100      # Batch size for ML\n\n# NLP configuration\nnlp:\n  use_stopwords: true\n  stopword_set: minimal  # minimal|aggressive|custom\n  tokenizer: code        # code|text\n  keyword_extractor: rake # rake|yake|bm25|tfidf|frequency\n  text_similarity: bm25   # bm25|tfidf\n\n# ML configuration\nml:\n  model: all-MiniLM-L6-v2\n  device: auto         # auto|cpu|cuda\n  cache_embeddings: true\n  embedding_dim: 384\n\n# Cache configuration\ncache:\n  enabled: true\n  directory: ~/.tenets/cache\n  max_size_mb: 1000\n  ttl_days: 7\n\n  # SQLite pragmas\n  sqlite_pragmas:\n    journal_mode: WAL\n    synchronous: NORMAL\n    cache_size: -64000\n    temp_store: MEMORY\n\n# File scanning\nscanner:\n  respect_gitignore: true\n  include_hidden: false\n  follow_symlinks: false\n  max_file_size_mb: 10\n  binary_detection: true\n  exclude_minified: true\n  exclude_tests: auto\n\n  # Global ignores\n  ignore_patterns:\n    - \"*.pyc\"\n    - \"__pycache__\"\n    - \"node_modules\"\n    - \".git\"\n    - \".venv\"\n    - \"venv\"\n    - \"*.egg-info\"\n    - \"dist\"\n    - \"build\"\n\n# Summarization configuration\nsummarizer:\n  summarize_imports: true\n  import_summary_threshold: 5\n  docs_context_aware: true\n  docs_show_in_place_context: true\n  docs_context_search_depth: 2\n  docs_context_min_confidence: 0.6\n  docs_context_max_sections: 10\n  docs_context_preserve_examples: true\n\n# Output configuration\noutput:\n  format: markdown     # markdown|json|xml|html\n  max_tokens: 100000\n  include_metadata: true\n  include_instructions: true\n  copy_on_distill: false\n\n# Session configuration\nsession:\n  auto_save: true\n  history_limit: 100\n  branch_on_conflict: true\n\n# Examination configuration\nexamination:\n  complexity_threshold: 10\n  duplication_threshold: 0.1\n  min_test_coverage: 0.8\n\n# Chronicle configuration\nchronicle:\n  include_merges: false\n  max_commits: 1000\n  analyze_patterns: true\n\n# Momentum configuration\nmomentum:\n  sprint_duration: 14\n  velocity_window: 6\n  include_weekends: false\n\n# Tenet configuration\ntenet:\n  auto_instill: true\n  injection_frequency: adaptive\n  max_per_context: 5\n  system_instruction_enabled: true\n</code></pre>"},{"location":"ARCHITECTURE/#cli--api-architecture","title":"CLI &amp; API Architecture","text":""},{"location":"ARCHITECTURE/#command-structure","title":"Command Structure","text":"YAML<pre><code># Main Commands\ntenets:\n  distill:           # Build optimal context for prompts\n    --copy           # Copy to clipboard\n    --format         # Output format (markdown, xml, json, html)\n    --max-tokens     # Token limit\n    --exclude        # Exclude patterns\n    --session        # Session name\n    --algorithm      # Ranking algorithm\n\n  examine:           # Code quality analysis\n    --show-details   # Detailed metrics\n    --hotspots       # Show maintenance hotspots\n    --ownership      # Show code ownership\n    --format         # Output format\n\n  chronicle:         # Git history analysis\n    --since          # Time range\n    --author         # Filter by author\n    --format         # Output format\n\n  momentum:          # Velocity tracking (WIP)\n    --team           # Team metrics\n    --detailed       # Detailed breakdown\n\n  session:           # Session management\n    create           # Create new session\n    list             # List sessions\n    delete           # Delete session\n\n  tenet:            # Manage guiding principles\n    add             # Add new tenet\n    list            # List tenets\n    remove          # Remove tenet\n\n  instill:          # Apply tenets and system instructions\n    --dry-run       # Preview what would be applied\n    --force         # Force application\n\n  system-instruction: # Manage system instructions\n    set             # Set instruction\n    get             # Get current\n    enable/disable  # Toggle\n</code></pre>"},{"location":"ARCHITECTURE/#python-api-design","title":"Python API Design","text":"Python<pre><code>from tenets import Tenets\n\n# Initialize\ntenets = Tenets(path=\"./my-project\")\n\n# Simple usage\ncontext = tenets.distill(\"implement OAuth2 authentication\")\n\n# Advanced usage\nresult = tenets.distill(\n    prompt=\"refactor database layer\",\n    algorithm=\"ml\",\n    max_tokens=50000,\n    filters=[\"*.py\", \"!test_*\"]\n)\n\n# Session management\nsession = tenets.create_session(\"oauth-implementation\")\ncontext1 = session.distill(\"add OAuth2 support\")\ncontext2 = session.distill(\"add unit tests\", incremental=True)\n\n# Analysis tools\nexamination = tenets.examine()\nchronicle = tenets.chronicle()\nmomentum = tenets.momentum()\n\n# Configuration\ntenets.configure(\n    ranking_algorithm=\"thorough\",\n    use_ml=True,\n    cache_ttl_days=30\n)\n</code></pre>"},{"location":"ARCHITECTURE/#security--privacy-architecture","title":"Security &amp; Privacy Architecture","text":""},{"location":"ARCHITECTURE/#local-first-security-model","title":"Local-First Security Model","text":"<pre><code>graph TB\n    subgraph \"Privacy Guarantees\"\n        LOCAL[All Processing Local&lt;br/&gt;No external API calls for analysis]\n        NO_TELEMETRY[No Telemetry&lt;br/&gt;No usage tracking]\n        NO_CLOUD[No Cloud Storage&lt;br/&gt;All data stays local]\n        NO_PHONE_HOME[No Phone Home&lt;br/&gt;No automatic updates]\n    end\n\n    subgraph \"Secret Detection\"\n        API_KEYS[API Key Detection&lt;br/&gt;Common patterns]\n        PASSWORDS[Password Detection&lt;br/&gt;Credential patterns]\n        TOKENS[Token Detection&lt;br/&gt;JWT, OAuth tokens]\n        PRIVATE_KEYS[Private Key Detection&lt;br/&gt;RSA, SSH keys]\n        CONNECTION_STRINGS[Connection Strings&lt;br/&gt;Database URLs]\n        ENV_VARS[Environment Variables&lt;br/&gt;Sensitive values]\n    end\n\n    subgraph \"Output Sanitization (Roadmap)\"\n        REDACT[Redact Secrets&lt;br/&gt;**WIP** - Coming soon]\n        MASK_PII[Mask PII&lt;br/&gt;**WIP** - Planned feature]\n        CLEAN_PATHS[Clean File Paths&lt;br/&gt;Remove sensitive paths]\n        REMOVE_URLS[Remove Internal URLs&lt;br/&gt;**WIP** - Under development]\n        ANONYMIZE[Anonymization&lt;br/&gt;**WIP** - Future release]\n    end\n\n    subgraph \"Data Protection\"\n        ENCRYPTED_CACHE[Encrypted Cache&lt;br/&gt;Optional encryption at rest]\n        SECURE_DELETE[Secure Deletion&lt;br/&gt;Overwrite sensitive data]\n        ACCESS_CONTROL[File Access Control&lt;br/&gt;Respect permissions]\n        AUDIT_LOG[Audit Logging&lt;br/&gt;Security events]\n    end\n\n    LOCAL --&gt; API_KEYS\n    NO_TELEMETRY --&gt; PASSWORDS\n    NO_CLOUD --&gt; TOKENS\n    NO_PHONE_HOME --&gt; PRIVATE_KEYS\n\n    API_KEYS --&gt; REDACT\n    PASSWORDS --&gt; MASK_PII\n    TOKENS --&gt; CLEAN_PATHS\n    PRIVATE_KEYS --&gt; REMOVE_URLS\n    CONNECTION_STRINGS --&gt; ANONYMIZE\n    ENV_VARS --&gt; ANONYMIZE\n\n    REDACT --&gt; ENCRYPTED_CACHE\n    MASK_PII --&gt; SECURE_DELETE\n    CLEAN_PATHS --&gt; ACCESS_CONTROL\n    REMOVE_URLS --&gt; AUDIT_LOG\n    ANONYMIZE --&gt; AUDIT_LOG</code></pre>"},{"location":"ARCHITECTURE/#secret-detection-patterns-roadmap","title":"Secret Detection Patterns (Roadmap)","text":"<pre><code>graph LR\n    subgraph \"Detection Methods\"\n        REGEX[Regex Patterns&lt;br/&gt;Known formats]\n        ENTROPY[Entropy Analysis&lt;br/&gt;Random strings]\n        CONTEXT[Context Analysis&lt;br/&gt;Variable names]\n        KEYWORDS[Keyword Detection&lt;br/&gt;password, secret, key]\n    end\n\n    subgraph \"Secret Types\"\n        AWS[AWS Access Keys&lt;br/&gt;AKIA...]\n        GITHUB[GitHub Tokens&lt;br/&gt;ghp_, gho_]\n        JWT[JWT Tokens&lt;br/&gt;eyJ pattern]\n        RSA[RSA Private Keys&lt;br/&gt;-----BEGIN RSA]\n        DATABASE[Database URLs&lt;br/&gt;postgres://, mysql://]\n        GENERIC[Generic Secrets&lt;br/&gt;High entropy strings]\n    end\n\n    subgraph \"Response Actions\"\n        FLAG[Flag for Review&lt;br/&gt;Warn user]\n        REDACT_AUTO[Auto Redaction&lt;br/&gt;Replace with [REDACTED]]\n        EXCLUDE[Exclude File&lt;br/&gt;Skip entirely]\n        LOG[Security Log&lt;br/&gt;Record detection]\n    end\n\n    REGEX --&gt; AWS\n    ENTROPY --&gt; GITHUB\n    CONTEXT --&gt; JWT\n    KEYWORDS --&gt; RSA\n\n    AWS --&gt; FLAG\n    GITHUB --&gt; REDACT_AUTO\n    JWT --&gt; EXCLUDE\n    RSA --&gt; LOG\n    DATABASE --&gt; LOG\n    GENERIC --&gt; FLAG</code></pre>"},{"location":"ARCHITECTURE/#testing--quality-assurance","title":"Testing &amp; Quality Assurance","text":""},{"location":"ARCHITECTURE/#test-architecture","title":"Test Architecture","text":"<pre><code>graph TB\n    subgraph \"Test Categories\"\n        UNIT[Unit Tests&lt;br/&gt;Target: &gt;90% coverage&lt;br/&gt;Fast, isolated]\n        INTEGRATION[Integration Tests&lt;br/&gt;Component interaction&lt;br/&gt;Real workflows]\n        E2E[End-to-End Tests&lt;br/&gt;Complete user journeys&lt;br/&gt;CLI to output]\n        PERFORMANCE[Performance Tests&lt;br/&gt;Benchmark regression&lt;br/&gt;Memory usage]\n    end\n\n    subgraph \"Test Structure\"\n        FIXTURES[Test Fixtures&lt;br/&gt;Sample codebases&lt;br/&gt;Known outputs]\n        MOCKS[Mock Objects&lt;br/&gt;External dependencies&lt;br/&gt;Controlled behavior]\n        HELPERS[Test Helpers&lt;br/&gt;Common operations&lt;br/&gt;Assertion utilities]\n        FACTORIES[Data Factories&lt;br/&gt;Generate test data&lt;br/&gt;Realistic scenarios]\n    end\n\n    subgraph \"Quality Metrics\"\n        COVERAGE[Code Coverage&lt;br/&gt;Line and branch coverage]\n        COMPLEXITY[Complexity Limits&lt;br/&gt;Cyclomatic &lt; 10]\n        DUPLICATION[Duplication Check&lt;br/&gt;&lt; 5% duplicate code]\n        DOCUMENTATION[Documentation&lt;br/&gt;100% public API]\n    end\n\n    subgraph \"Continuous Testing\"\n        PRE_COMMIT[Pre-commit Hooks&lt;br/&gt;Fast feedback]\n        CI_PIPELINE[CI Pipeline&lt;br/&gt;Full test suite]\n        NIGHTLY[Nightly Tests&lt;br/&gt;Extended scenarios]\n        BENCHMARKS[Benchmark Tracking&lt;br/&gt;Performance trends]\n    end\n\n    UNIT --&gt; FIXTURES\n    INTEGRATION --&gt; MOCKS\n    E2E --&gt; HELPERS\n    PERFORMANCE --&gt; FACTORIES\n\n    FIXTURES --&gt; COVERAGE\n    MOCKS --&gt; COMPLEXITY\n    HELPERS --&gt; DUPLICATION\n    FACTORIES --&gt; DOCUMENTATION\n\n    COVERAGE --&gt; PRE_COMMIT\n    COMPLEXITY --&gt; CI_PIPELINE\n    DUPLICATION --&gt; NIGHTLY\n    DOCUMENTATION --&gt; BENCHMARKS</code></pre>"},{"location":"ARCHITECTURE/#test-coverage-requirements","title":"Test Coverage Requirements","text":"<pre><code>graph LR\n    subgraph \"Coverage Targets\"\n        UNIT_COV[Unit Tests&lt;br/&gt;&gt;90% coverage&lt;br/&gt;Critical paths 100%]\n        INTEGRATION_COV[Integration Tests&lt;br/&gt;All major workflows&lt;br/&gt;Error scenarios]\n        E2E_COV[E2E Tests&lt;br/&gt;Critical user journeys&lt;br/&gt;Happy paths]\n        PERF_COV[Performance Tests&lt;br/&gt;Regression prevention&lt;br/&gt;Memory leak detection]\n    end\n\n    subgraph \"Quality Gates\"\n        CODE_QUALITY[Code Quality&lt;br/&gt;Complexity &lt; 10&lt;br/&gt;Function length &lt; 50]\n        DOCUMENTATION[Documentation&lt;br/&gt;100% public API&lt;br/&gt;Usage examples]\n        SECURITY[Security Tests&lt;br/&gt;Secret detection&lt;br/&gt;Input validation]\n        COMPATIBILITY[Compatibility&lt;br/&gt;Python 3.8+&lt;br/&gt;Multiple platforms]\n    end\n\n    UNIT_COV --&gt; CODE_QUALITY\n    INTEGRATION_COV --&gt; DOCUMENTATION\n    E2E_COV --&gt; SECURITY\n    PERF_COV --&gt; COMPATIBILITY</code></pre>"},{"location":"ARCHITECTURE/#guiding-principles-tenets-system","title":"Guiding Principles (Tenets) System","text":""},{"location":"ARCHITECTURE/#overview","title":"Overview","text":"<p>The Guiding Principles system provides persistent, context-aware instructions to maintain consistency across AI interactions and combat context drift.</p>"},{"location":"ARCHITECTURE/#injection-strategy","title":"Injection Strategy","text":"<pre><code>graph TD\n    subgraph \"Injection Decision Engine\"\n        ANALYZER[Content Analyzer&lt;br/&gt;Structure &amp; complexity]\n        STRATEGY[Strategy Selector&lt;br/&gt;Top, distributed, contextual]\n        INJECTOR[Smart Injector&lt;br/&gt;Natural break detection]\n    end\n\n    subgraph \"Priority System\"\n        CRITICAL[Critical Principles&lt;br/&gt;Security, data integrity]\n        HIGH[High Priority&lt;br/&gt;Architecture, performance]\n        MEDIUM[Medium Priority&lt;br/&gt;Style, conventions]\n        LOW[Low Priority&lt;br/&gt;Preferences, suggestions]\n    end\n\n    subgraph \"Reinforcement\"\n        TOP_INJECTION[Top of Context&lt;br/&gt;Most visible]\n        DISTRIBUTED[Throughout Content&lt;br/&gt;Natural sections]\n        END_SUMMARY[End Reinforcement&lt;br/&gt;Key reminders]\n    end\n\n    ANALYZER --&gt; STRATEGY\n    STRATEGY --&gt; INJECTOR\n\n    CRITICAL --&gt; TOP_INJECTION\n    HIGH --&gt; DISTRIBUTED\n    MEDIUM --&gt; DISTRIBUTED\n    LOW --&gt; END_SUMMARY</code></pre>"},{"location":"ARCHITECTURE/#output-formats","title":"Output Formats","text":"<p>Markdown: Markdown<pre><code>**\ud83c\udfaf Key Guiding Principle:** Always validate user input before processing\n**\ud83d\udccc Important Guiding Principle:** Use async/await for all I/O operations\n**\ud83d\udca1 Guiding Principle:** Prefer composition over inheritance\n</code></pre></p> <p>XML (Recommended by OpenAI): XML<pre><code>&lt;guiding_principle priority=\"high\" category=\"security\"&gt;\n  Always validate and sanitize user input\n&lt;/guiding_principle&gt;\n\n&lt;guiding_principles&gt;\n  &lt;guiding_principle priority=\"critical\"&gt;Maintain backward compatibility&lt;/guiding_principle&gt;\n  &lt;guiding_principle priority=\"medium\"&gt;Use descriptive variable names&lt;/guiding_principle&gt;\n&lt;/guiding_principles&gt;\n</code></pre></p>"},{"location":"ARCHITECTURE/#configuration","title":"Configuration","text":"YAML<pre><code>tenet:\n  auto_instill: true\n  max_per_context: 5\n  injection_strategy: strategic\n  injection_frequency: adaptive  # 'always', 'periodic', 'adaptive', 'manual'\n  injection_interval: 3          # For periodic mode\n  min_session_length: 1          # First injection always happens\n  system_instruction: \"Prefer small, safe diffs and add tests\"\n  system_instruction_enabled: true\n</code></pre>"},{"location":"ARCHITECTURE/#output-generation--visualization","title":"Output Generation &amp; Visualization","text":""},{"location":"ARCHITECTURE/#output-formatting-system","title":"Output Formatting System","text":"<pre><code>graph TB\n    subgraph \"Format Types\"\n        MARKDOWN[Markdown Format&lt;br/&gt;Human-readable]\n        JSON[JSON Format&lt;br/&gt;Machine-parseable]\n        XML[XML Format&lt;br/&gt;Structured data]\n        HTML[HTML Format&lt;br/&gt;Interactive reports]\n    end\n\n    subgraph \"HTML Report Features\"\n        INTERACTIVE[Interactive Elements&lt;br/&gt;Collapsible sections]\n        VISUALS[Visualizations&lt;br/&gt;Charts &amp; graphs]\n        STYLING[Professional Styling&lt;br/&gt;Modern UI]\n        RESPONSIVE[Responsive Design&lt;br/&gt;Mobile-friendly]\n    end\n\n    subgraph \"Report Components\"\n        HEADER[Report Header&lt;br/&gt;Title &amp; metadata]\n        PROMPT_DISPLAY[Prompt Analysis&lt;br/&gt;Keywords &amp; intent]\n        STATS[Statistics Dashboard&lt;br/&gt;Metrics &amp; KPIs]\n        FILES[File Listings&lt;br/&gt;Code previews]\n        GIT[Git Context&lt;br/&gt;Commits &amp; contributors]\n    end\n\n    HTML --&gt; INTERACTIVE\n    HTML --&gt; VISUALS\n    HTML --&gt; STYLING\n    HTML --&gt; RESPONSIVE\n\n    INTERACTIVE --&gt; HEADER\n    VISUALS --&gt; STATS\n    STYLING --&gt; FILES\n    RESPONSIVE --&gt; GIT</code></pre>"},{"location":"ARCHITECTURE/#visualization-components","title":"Visualization Components","text":"<pre><code>graph LR\n    subgraph \"Project Detection\"\n        DETECTOR[Project Detector&lt;br/&gt;Auto-detects type]\n        LANGUAGES[Language Analysis&lt;br/&gt;% distribution]\n        FRAMEWORKS[Framework Detection&lt;br/&gt;Django, React, etc]\n        ENTRYPOINTS[Entry Points&lt;br/&gt;main.py, index.js]\n    end\n\n    subgraph \"Graph Generation\"\n        GRAPHGEN[Graph Generator&lt;br/&gt;Multiple formats]\n        NETWORKX[NetworkX&lt;br/&gt;Graph algorithms]\n        GRAPHVIZ[Graphviz&lt;br/&gt;DOT rendering]\n        PLOTLY[Plotly&lt;br/&gt;Interactive HTML]\n        D3JS[D3.js&lt;br/&gt;Web visualization]\n    end\n\n    subgraph \"Dependency Visualization\"\n        FILE_DEPS[File-level&lt;br/&gt;Individual files]\n        MODULE_DEPS[Module-level&lt;br/&gt;Aggregated modules]\n        PACKAGE_DEPS[Package-level&lt;br/&gt;Top-level packages]\n        CLUSTERING[Clustering&lt;br/&gt;Group by criteria]\n    end\n\n    subgraph \"Output Formats\"\n        ASCII[ASCII Tree&lt;br/&gt;Terminal output]\n        SVG[SVG&lt;br/&gt;Vector graphics]\n        PNG[PNG/PDF&lt;br/&gt;Static images]\n        HTML_INT[Interactive HTML&lt;br/&gt;D3.js/Plotly]\n        DOT[DOT Format&lt;br/&gt;Graphviz source]\n        JSON_OUT[JSON&lt;br/&gt;Raw data]\n    end\n\n    subgraph \"Layout Algorithms\"\n        HIERARCHICAL[Hierarchical&lt;br/&gt;Tree layout]\n        CIRCULAR[Circular&lt;br/&gt;Radial layout]\n        SHELL[Shell&lt;br/&gt;Concentric circles]\n        KAMADA[Kamada-Kawai&lt;br/&gt;Force-directed]\n    end\n\n    DETECTOR --&gt; LANGUAGES\n    DETECTOR --&gt; FRAMEWORKS\n    DETECTOR --&gt; ENTRYPOINTS\n\n    GRAPHGEN --&gt; NETWORKX\n    GRAPHGEN --&gt; GRAPHVIZ\n    GRAPHGEN --&gt; PLOTLY\n    GRAPHGEN --&gt; D3JS\n\n    FILE_DEPS --&gt; MODULE_DEPS\n    MODULE_DEPS --&gt; PACKAGE_DEPS\n    PACKAGE_DEPS --&gt; CLUSTERING\n\n    GRAPHGEN --&gt; ASCII\n    GRAPHGEN --&gt; SVG\n    GRAPHGEN --&gt; PNG\n    GRAPHGEN --&gt; HTML_INT\n    GRAPHGEN --&gt; DOT\n    GRAPHGEN --&gt; JSON_OUT</code></pre>"},{"location":"ARCHITECTURE/#future-roadmap--vision","title":"Future Roadmap &amp; Vision","text":""},{"location":"ARCHITECTURE/#near-term","title":"Near Term","text":"<pre><code>graph TB\n    subgraph \"Core Improvements\"\n        INCREMENTAL[Incremental Indexing&lt;br/&gt;Real-time updates&lt;br/&gt;Watch file changes]\n        FASTER_EMBED[Faster Embeddings&lt;br/&gt;Model quantization&lt;br/&gt;ONNX optimization]\n        LANGUAGE_SUP[Better Language Support&lt;br/&gt;30+ languages&lt;br/&gt;Language-specific patterns]\n        IDE_PLUGINS[IDE Plugin Ecosystem&lt;br/&gt;VS Code, IntelliJ, Vim]\n        CROSS_REPO[Cross-repository Analysis&lt;br/&gt;Monorepo support&lt;br/&gt;Dependency tracking]\n    end\n\n    subgraph \"ML Enhancements\"\n        NEWER_MODELS[Newer Embedding Models&lt;br/&gt;Code-specific transformers&lt;br/&gt;Better accuracy]\n        FINE_TUNING[Fine-tuning Pipeline&lt;br/&gt;Domain-specific models&lt;br/&gt;Custom training]\n        MULTIMODAL[Multi-modal Understanding&lt;br/&gt;Diagrams, images&lt;br/&gt;Architecture docs]\n        CODE_TRANSFORMERS[Code-specific Models&lt;br/&gt;Programming language aware&lt;br/&gt;Syntax understanding]\n    end\n\n    INCREMENTAL --&gt; NEWER_MODELS\n    FASTER_EMBED --&gt; FINE_TUNING\n    LANGUAGE_SUP --&gt; MULTIMODAL\n    IDE_PLUGINS --&gt; CODE_TRANSFORMERS\n    CROSS_REPO --&gt; CODE_TRANSFORMERS</code></pre>"},{"location":"ARCHITECTURE/#medium-term","title":"Medium Term","text":"<pre><code>graph TB\n    subgraph \"Platform Features\"\n        WEB_UI[Web UI&lt;br/&gt;Real-time collaboration&lt;br/&gt;Team workspaces]\n        SHARED_CONTEXT[Shared Context Libraries&lt;br/&gt;Team knowledge base&lt;br/&gt;Best practices]\n        KNOWLEDGE_GRAPHS[Knowledge Graphs&lt;br/&gt;Code relationships&lt;br/&gt;Semantic connections]\n        AI_AGENTS[AI Agent Integration&lt;br/&gt;Autonomous assistance&lt;br/&gt;Proactive suggestions]\n    end\n\n    subgraph \"Enterprise Features\"\n        SSO[SSO/SAML Support&lt;br/&gt;Enterprise authentication&lt;br/&gt;Role-based access]\n        AUDIT[Audit Logging&lt;br/&gt;Compliance tracking&lt;br/&gt;Usage monitoring]\n        COMPLIANCE[Compliance Modes&lt;br/&gt;GDPR, SOX, HIPAA&lt;br/&gt;Data governance]\n        AIR_GAPPED[Air-gapped Deployment&lt;br/&gt;Offline operation&lt;br/&gt;Secure environments]\n        CUSTOM_ML[Custom ML Models&lt;br/&gt;Private model training&lt;br/&gt;Domain expertise]\n    end\n\n    WEB_UI --&gt; SSO\n    SHARED_CONTEXT --&gt; AUDIT\n    KNOWLEDGE_GRAPHS --&gt; COMPLIANCE\n    AI_AGENTS --&gt; AIR_GAPPED\n    AI_AGENTS --&gt; CUSTOM_ML</code></pre>"},{"location":"ARCHITECTURE/#long-term-vision","title":"Long Term Vision","text":"<pre><code>graph TB\n    subgraph \"Vision Goals\"\n        AUTONOMOUS[Autonomous Code Understanding&lt;br/&gt;Self-improving analysis&lt;br/&gt;Minimal human input]\n        PREDICTIVE[Predictive Development&lt;br/&gt;Anticipate needs&lt;br/&gt;Suggest improvements]\n        UNIVERSAL[Universal Code Intelligence&lt;br/&gt;Any language, any domain&lt;br/&gt;Contextual understanding]\n        INDUSTRY_STANDARD[Industry Standard&lt;br/&gt;AI pair programming&lt;br/&gt;Developer toolchain]\n    end\n\n    subgraph \"Research Areas\"\n        GRAPH_NEURAL[Graph Neural Networks&lt;br/&gt;Code structure understanding&lt;br/&gt;Relationship modeling]\n        REINFORCEMENT[Reinforcement Learning&lt;br/&gt;Ranking optimization&lt;br/&gt;Adaptive behavior]\n        FEW_SHOT[Few-shot Learning&lt;br/&gt;New language support&lt;br/&gt;Rapid adaptation]\n        EXPLAINABLE[Explainable AI&lt;br/&gt;Ranking transparency&lt;br/&gt;Decision reasoning]\n        FEDERATED[Federated Learning&lt;br/&gt;Team knowledge sharing&lt;br/&gt;Privacy-preserving]\n    end\n\n    AUTONOMOUS --&gt; GRAPH_NEURAL\n    PREDICTIVE --&gt; REINFORCEMENT\n    UNIVERSAL --&gt; FEW_SHOT\n    INDUSTRY_STANDARD --&gt; EXPLAINABLE\n    INDUSTRY_STANDARD --&gt; FEDERATED</code></pre>"},{"location":"ARCHITECTURE/#conclusion","title":"Conclusion","text":"<p>Tenets combines sophisticated NLP/ML techniques with traditional code analysis, git mining, and intelligent caching to create a system that truly understands code in context. The architecture is designed for scalability, extensibility, and performance while maintaining complete privacy through local-first processing.</p> <p>The future of code intelligence is local, intelligent, and developer-centric. Tenets embodies this vision while remaining practical and immediately useful for development teams of any size.</p>"},{"location":"BRANDING/","title":"BRANDING","text":""},{"location":"BRANDING/#primary-colors","title":"Primary Colors","text":"<p>$navy-900: #1a2332;  // Logo dark blue $navy-800: #263244;  // Slightly lighter $navy-700: #364152;  // Card backgrounds (dark mode)</p>"},{"location":"BRANDING/#accent-colors","title":"Accent Colors","text":"<p>$amber-500: #f59e0b;  // Lantern flame/glow effect $amber-400: #fbbf24;  // Hover states $amber-300: #fcd34d;  // Highlights</p>"},{"location":"BRANDING/#neutral-palette","title":"Neutral Palette","text":"<p>$cream-50:  #fdfdf9;  // Light mode background (Victorian paper) $cream-100: #f7f5f0;  // Card backgrounds (light mode) $sepia-200: #e8e2d5;  // Borders light mode $sepia-600: #6b5d4f;  // Muted text $sepia-800: #3e342a;  // Body text light mode</p>"},{"location":"BRANDING/#semantic-colors","title":"Semantic Colors","text":"<p>$success: #059669;    // Victorian green $warning: #d97706;    // Brass/copper $error:   #dc2626;    // Deep red $info:    #0891b2;    // Teal</p>"},{"location":"CLI/","title":"Tenets CLI Reference","text":"<p>tenets - Context that feeds your prompts. A command-line tool for intelligent code aggregation, analysis, and visualization.</p>"},{"location":"CLI/#table-of-contents","title":"Table of Contents","text":"<ul> <li>Installation</li> <li>Quick Start</li> <li>Core Commands</li> <li>distill</li> <li>instill</li> <li>rank</li> <li>examine</li> <li>chronicle</li> <li>momentum</li> <li>tenet</li> <li>Visualization Commands</li> <li>viz deps</li> <li>viz complexity</li> <li>viz coupling</li> <li>viz contributors</li> <li>Session Commands</li> <li>Tenet Commands</li> <li>Instill Command</li> <li>System Instruction Commands</li> <li>Configuration</li> <li>Common Use Cases</li> <li>Examples</li> </ul>"},{"location":"CLI/#installation","title":"Installation","text":"Bash<pre><code># Basic install (core features only)\npip install tenets\n\n# With visualization support\npip install tenets[viz]\n\n# With ML-powered ranking\npip install tenets[ml]\n\n# Everything\npip install tenets[all]\n</code></pre>"},{"location":"CLI/#quick-start","title":"Quick Start","text":"Bash<pre><code># Generate context for AI pair programming\ntenets distill \"implement OAuth2\" ./src\n\n# Analyze your codebase\ntenets examine\n\n# Track recent changes\ntenets chronicle --since yesterday\n\n# Visualize dependencies (ASCII by default)\ntenets viz deps\n</code></pre>"},{"location":"CLI/#core-commands","title":"Core Commands","text":""},{"location":"CLI/#distill","title":"distill","text":"<p>Generate optimized context for LLMs from your codebase.</p> Bash<pre><code>tenets distill &lt;prompt&gt; [path] [options]\n</code></pre> <p>Arguments:</p> <ul> <li>prompt: Your query or task description (can be text or URL)</li> <li>path: Directory or files to analyze (default: current directory)</li> </ul> <p>Options:</p> <ul> <li><code>--format</code>, <code>-f</code>: Output format: markdown (default), xml, json</li> <li><code>--model</code>, <code>-m</code>: Target LLM model (e.g., gpt-4o, claude-3-opus)</li> <li><code>--output</code>, <code>-o</code>: Save to file instead of stdout</li> <li><code>--max-tokens</code>: Maximum tokens for context</li> <li><code>--mode</code>: Analysis mode: fast, balanced (default), thorough</li> <li><code>--no-git</code>: Disable git context inclusion</li> <li><code>--use-stopwords</code>: Enable stopword filtering for keyword analysis</li> <li><code>--include</code>, <code>-i</code>: Include file patterns (e.g., \".py,.js\")</li> <li><code>--exclude</code>, <code>-e</code>: Exclude file patterns (e.g., \"test_,.backup\")</li> <li><code>--session</code>, <code>-s</code>: Use a named session for stateful context</li> <li><code>--estimate-cost</code>: Show token usage and cost estimate</li> <li><code>--verbose</code>, <code>-v</code>: Show detailed analysis info</li> <li><code>--full</code>: Include full content for all ranked files (no summarization) until token budget reached</li> <li><code>--condense</code>: Condense whitespace (collapse large blank runs, trim trailing spaces) before token counting</li> <li><code>--remove-comments</code>: Strip comments (heuristic, language-aware) before token counting</li> <li><code>--copy</code>: Copy distilled context directly to clipboard (or set output.copy_on_distill: true in config)</li> </ul> <p>Examples:</p> Bash<pre><code># Basic usage - finds all relevant files for implementing OAuth2\ntenets distill \"implement OAuth2 authentication\"\n\n# From a GitHub issue\ntenets distill https://github.com/org/repo/issues/123\n\n# Target specific model with cost estimation\ntenets distill \"add caching layer\" --model gpt-4o --estimate-cost\n\n# Filter by file types\ntenets distill \"review API endpoints\" --include \"*.py,*.yaml\" --exclude \"test_*\"\n\n# Save context to file\ntenets distill \"debug login issue\" --output context.md\n\n# Use thorough analysis for complex tasks\ntenets distill \"refactor authentication system\" --mode thorough\n\n# Session-based context (maintains state)\ntenets distill \"build payment system\" --session payment-feature\n\n# Full mode (force raw content inclusion)\ntenets distill \"inspect performance code\" --full --max-tokens 60000\n\n# Reduce token usage by stripping comments &amp; whitespace\ntenets distill \"understand API surface\" --remove-comments --condense --stats\n</code></pre>"},{"location":"CLI/#content-transformations","title":"Content Transformations","text":"<p>You can optionally transform file content prior to aggregation/token counting:</p> Flag Effect Safety <code>--full</code> Disables summarization; includes raw file content until budget is hit Budget only <code>--remove-comments</code> Removes line &amp; block comments (language-aware heuristics) Aborts if &gt;60% of non-empty lines would vanish <code>--condense</code> Collapses 3+ blank lines to 1, trims trailing spaces, ensures final newline Lossless for code logic <p>Transformations are applied in this order: comment stripping -&gt; whitespace condensation. Statistics (e.g. removed comment lines) are tracked internally and may be surfaced in future <code>--stats</code> expansions.</p>"},{"location":"CLI/#pinned-files","title":"Pinned Files","text":"<p>Pin critical files so they're always considered first in subsequent distill runs for the same session:</p> Bash<pre><code># Pin individual files\ntenets instill --session refactor-auth --add-file src/auth/service.py --add-file src/auth/models.py\n\n# Pin all files in a folder (respects .gitignore)\ntenets instill --session refactor-auth --add-folder src/auth\n\n# List pinned files\ntenets instill --session refactor-auth --list-pinned\n\n# Generate context (pinned files prioritized)\ntenets distill \"add JWT refresh tokens\" --session refactor-auth --remove-comments\n</code></pre> <p>Pinned files are stored in the session metadata (SQLite) and reloaded automatically\u2014no extra flags needed when distilling.</p>"},{"location":"CLI/#ranking-presets-and-thresholds","title":"Ranking presets and thresholds","text":"<ul> <li>Presets (selected via <code>--mode</code> or config <code>ranking.algorithm</code>):</li> <li><code>fast</code> \u2013 keyword + path signals (broad, quick)</li> <li><code>balanced</code> (default) \u2013 multi-factor (keywords, path, imports, git, complexity)</li> <li> <p><code>thorough</code> \u2013 deeper analysis (heavier)</p> </li> <li> <p>Threshold (config <code>ranking.threshold</code>) controls inclusion. Lower = include more files.</p> </li> <li>Typical ranges:<ul> <li>fast: 0.05\u20130.10</li> <li>balanced: 0.10\u20130.20</li> <li>thorough: 0.10\u20130.20</li> </ul> </li> </ul> <p>Configure in <code>.tenets.yml</code> (repo root):</p> YAML<pre><code>ranking:\n  algorithm: fast      # fast | balanced | thorough\n  threshold: 0.05      # 0.0\u20131.0\n</code></pre> <p>One-off overrides (environment, Git Bash):</p> Bash<pre><code>TENETS_RANKING_THRESHOLD=0.05 TENETS_RANKING_ALGORITHM=fast \\\n  tenets distill \"implement OAuth2\" . --include \"*.py,*.md\" --max-tokens 50000\n\n# Copy output to clipboard directly\ntenets distill \"implement OAuth2\" --copy\n\n# Enable automatic copying in config\noutput:\n  copy_on_distill: true\n</code></pre> <p>Inspect current config:</p> Bash<pre><code>tenets config show --key ranking\n</code></pre> <p>See also: docs/CONFIG.md for full configuration details.</p>"},{"location":"CLI/#rank","title":"rank","text":"<p>Show ranked files by relevance without their content.</p> Bash<pre><code>tenets rank &lt;prompt&gt; [path] [options]\n</code></pre> <p>Arguments:</p> <ul> <li>prompt: Your query or task to rank files against</li> <li>path: Directory or files to analyze (default: current directory)</li> </ul> <p>Options:</p> <ul> <li><code>--format</code>, <code>-f</code>: Output format: markdown (default), json, xml, html, tree</li> <li><code>--output</code>, <code>-o</code>: Save to file instead of stdout</li> <li><code>--mode</code>, <code>-m</code>: Ranking mode: fast, balanced (default), thorough</li> <li><code>--top</code>, <code>-t</code>: Show only top N files</li> <li><code>--min-score</code>: Minimum relevance score (0.0-1.0)</li> <li><code>--max-files</code>: Maximum number of files to show</li> <li><code>--tree</code>: Show results as directory tree</li> <li><code>--scores/--no-scores</code>: Show/hide relevance scores (default: show)</li> <li><code>--factors</code>: Show ranking factor breakdown</li> <li><code>--path-style</code>: Path display: relative (default), absolute, name</li> <li><code>--include</code>, <code>-i</code>: Include file patterns (e.g., \".py,.js\")</li> <li><code>--exclude</code>, <code>-e</code>: Exclude file patterns (e.g., \"test_,.backup\")</li> <li><code>--include-tests</code>: Include test files</li> <li><code>--exclude-tests</code>: Explicitly exclude test files</li> <li><code>--no-git</code>: Disable git signals in ranking</li> <li><code>--session</code>, <code>-s</code>: Use session for stateful ranking</li> <li><code>--stats</code>: Show ranking statistics</li> <li><code>--verbose</code>, <code>-v</code>: Show detailed debug information</li> <li><code>--copy</code>: Copy file list to clipboard (also enabled automatically if config.output.copy_on_rank is true)</li> </ul> <p>Examples:</p> Bash<pre><code># Show top 10 most relevant files for OAuth implementation\ntenets rank \"implement OAuth2\" --top 10\n\n# Show files above a relevance threshold\ntenets rank \"fix authentication bug\" --min-score 0.3\n\n# Tree view with ranking factors breakdown\ntenets rank \"add caching layer\" --tree --factors\n\n# Export ranking as JSON for automation\ntenets rank \"review API endpoints\" --format json -o ranked_files.json\n\n# Quick file list to clipboard (no scores)\ntenets rank \"database queries\" --top 20 --copy --no-scores\n\n# Show only Python files with detailed factors\ntenets rank \"refactor models\" --include \"*.py\" --factors --stats\n\n# HTML report with interactive tree view\ntenets rank \"security audit\" --format html -o security_files.html --tree\n</code></pre> <p>Use Cases:</p> <ol> <li>Understanding Context: See which files would be included in a <code>distill</code> command without generating the full context</li> <li>File Discovery: Find relevant files for manual inspection</li> <li>Automation: Export ranked file lists for feeding into other tools or scripts</li> <li>Code Review: Identify files most relevant to a particular feature or bug</li> <li>Impact Analysis: See which files are most connected to a specific query</li> </ol> <p>Output Formats:</p> <ul> <li>Markdown: Numbered list sorted by relevance with scores and optional factors</li> <li>Tree: Directory tree structure sorted by relevance (directories ordered by their highest-scoring file)</li> <li>JSON: Structured data with paths, scores, ranks, and factors (preserves relevance order)</li> <li>XML: Structured XML for integration with other tools</li> <li>HTML: Interactive web page with relevance-sorted display</li> </ul> <p>The ranking uses the same intelligent multi-factor analysis as <code>distill</code>: - Semantic similarity (ML-based when available) - Keyword matching - BM25/TF-IDF statistical relevance - Import/dependency centrality - Path relevance - Git signals (recent changes, frequency)</p>"},{"location":"CLI/#examine","title":"examine","text":"<p>Analyze codebase structure, complexity, and patterns.</p> Bash<pre><code>tenets examine [path] [options]\n</code></pre> <p>Options: - <code>--deep, -d</code>: Perform deep analysis with AST parsing - <code>--output, -o</code>: Save results to file - <code>--metrics</code>: Show detailed code metrics - <code>--complexity</code>: Show complexity analysis - <code>--ownership</code>: Show code ownership (requires git) - <code>--hotspots</code>: Show frequently changed files - <code>--format, -f</code>: Output format: <code>table</code> (default), <code>json</code>, <code>yaml</code> - <code>--no-git</code>: Disable git analysis</p> <p>Examples:</p> Bash<pre><code># Basic analysis with summary table\ntenets examine\n\n# Deep analysis with metrics\ntenets examine --deep --metrics\n\n# Show complexity hotspots\ntenets examine --complexity --hotspots\n\n# Export full analysis as JSON\ntenets examine --output analysis.json --format json\n\n# Generate HTML examination report\ntenets examine --format html --output examination_report.html\n\n# Generate detailed HTML report with all analyses\ntenets examine --ownership --hotspots --show-details --format html -o report.html\n\n# Analyze specific directory with ownership tracking\ntenets examine ./src --ownership\n\n# Generate multiple format reports\ntenets examine --format json -o analysis.json\ntenets examine --format html -o analysis.html\ntenets examine --format markdown -o analysis.md\n</code></pre> <p>Coverage Reports:</p> Bash<pre><code># Run tests with coverage and generate HTML report\npytest --cov=tenets --cov-report=html\n\n# View HTML coverage report (opens htmlcov/index.html)\npython -m webbrowser htmlcov/index.html\n\n# Run tests with multiple coverage formats\npytest --cov=tenets --cov-report=html --cov-report=xml --cov-report=term\n\n# Run specific test module with coverage\npytest tests/cli/commands/test_examine.py --cov=tenets.cli.commands.examine --cov-report=html\n</code></pre> <p>Output Example (Table Format): Text Only<pre><code>Codebase Analysis\n\u250f\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2513\n\u2503 Metric          \u2503 Value     \u2503\n\u2521\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2529\n\u2502 Total Files     \u2502 156       \u2502\n\u2502 Total Lines     \u2502 24,531    \u2502\n\u2502 Languages       \u2502 Python,   \u2502\n\u2502                 \u2502 JavaScript\u2502\n\u2502 Avg Complexity  \u2502 4.32      \u2502\n\u2502 Git Branch      \u2502 main      \u2502\n\u2502 Contributors    \u2502 8         \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre></p>"},{"location":"CLI/#chronicle","title":"chronicle","text":"<p>Track code changes over time using git history.</p> Bash<pre><code>tenets chronicle [options]\n</code></pre> <p>Options: - <code>--since, -s</code>: Time period (e.g., \"yesterday\", \"last-month\", \"2024-01-01\") - <code>--path, -p</code>: Repository path (default: current directory) - <code>--author, -a</code>: Filter by author - <code>--limit, -n</code>: Maximum commits to display</p> <p>Examples:</p> Bash<pre><code># Changes in the last week\ntenets chronicle --since \"last-week\"\n\n# Changes since yesterday\ntenets chronicle --since yesterday\n\n# Filter by author\ntenets chronicle --author \"alice@example.com\"\n</code></pre>"},{"location":"CLI/#momentum","title":"momentum","text":"<p>Track development velocity and team productivity metrics.</p> Bash<pre><code>tenets momentum [options]\n</code></pre> <p>Options: - <code>--path, -p</code>: Repository path (default: current directory) - <code>--since, -s</code>: Time period (default: \"last-month\") - <code>--team</code>: Show team-wide statistics - <code>--author, -a</code>: Show stats for specific author</p> <p>Examples:</p> Bash<pre><code># Personal velocity for last month\ntenets momentum\n\n# Team velocity for the quarter\ntenets momentum --team --since \"3 months\"\n\n# Individual contributor stats\ntenets momentum --author \"alice@example.com\"\n</code></pre>"},{"location":"CLI/#instill","title":"instill","text":"<p>Apply tenets to your current context by injecting them into prompts and outputs.</p> Bash<pre><code>tenets instill [context] [options]\n</code></pre> <p>Options: - <code>--session, -s</code>: Session name for tracking - <code>--frequency</code>: Injection frequency: <code>always</code>, <code>periodic</code>, <code>adaptive</code> - <code>--priority</code>: Minimum tenet priority: <code>low</code>, <code>medium</code>, <code>high</code>, <code>critical</code> - <code>--max-tokens</code>: Maximum tokens to add - <code>--format</code>: Output format</p> <p>Examples:</p> Bash<pre><code># Apply all pending tenets\ntenets instill \"Current code context\"\n\n# Apply tenets for specific session\ntenets instill --session feature-x\n\n# Adaptive injection based on complexity\ntenets instill --frequency adaptive\n</code></pre>"},{"location":"CLI/#tenet","title":"tenet","text":"<p>Manage project tenets - rules and guidelines for your codebase.</p> Bash<pre><code>tenets tenet [subcommand] [options]\n</code></pre> <p>Subcommands: - <code>add</code>: Add a new tenet - <code>list</code>: List all tenets - <code>remove</code>: Remove a tenet - <code>show</code>: Show tenet details - <code>export</code>: Export tenets - <code>import</code>: Import tenets</p> <p>Examples:</p> Bash<pre><code># Add a new tenet\ntenets tenet add \"Always use type hints\"\n\n# List all tenets\ntenets tenet list\n\n# Remove a tenet\ntenets tenet remove &lt;tenet-id&gt;\n</code></pre>"},{"location":"CLI/#visualization-commands","title":"Visualization Commands","text":"<p>All visualization commands support ASCII output for terminal display, with optional graphical formats.</p>"},{"location":"CLI/#viz-deps","title":"viz deps","text":"<p>Visualize code dependencies and architecture with intelligent project detection.</p> Bash<pre><code>tenets viz deps [path] [options]\n</code></pre> <p>Options: - <code>--output, -o</code>: Save to file (e.g., architecture.svg) - <code>--format, -f</code>: Output format: <code>ascii</code>, <code>svg</code>, <code>png</code>, <code>html</code>, <code>json</code>, <code>dot</code> - <code>--level, -l</code>: Dependency level: <code>file</code> (default), <code>module</code>, <code>package</code> - <code>--cluster-by</code>: Group nodes by: <code>directory</code>, <code>module</code>, <code>package</code> - <code>--max-nodes</code>: Maximum nodes to display - <code>--include, -i</code>: Include file patterns (e.g., \".py\") - <code>--exclude, -e</code>: Exclude file patterns (e.g., \"*test\") - <code>--layout</code>: Graph layout: <code>hierarchical</code>, <code>circular</code>, <code>shell</code>, <code>kamada</code></p> <p>Features: - Auto-detection: Automatically detects project type (Python, Node.js, Java, Go, etc.) - Smart aggregation: Three levels of dependency views (file, module, package) - Interactive HTML: D3.js or Plotly-based interactive visualizations - Pure Python: All visualization libraries installable via <code>pip install tenets[viz]</code></p> <p>Examples:</p> Bash<pre><code># Auto-detect project type and show dependencies\ntenets viz deps\n\n# Generate interactive HTML visualization\ntenets viz deps --format html --output deps.html\n\n# Module-level dependencies as SVG\ntenets viz deps --level module --format svg --output modules.svg\n\n# Package architecture with clustering\ntenets viz deps --level package --cluster-by package --output packages.png\n\n# Circular layout for better visibility\ntenets viz deps --layout circular --format svg --output circular.svg\n\n# Limit to top 50 nodes for large projects\ntenets viz deps --max-nodes 50 --format png --output top50.png\n\n# Export to Graphviz DOT format\ntenets viz deps --format dot --output graph.dot\n\n# Filter specific files\ntenets viz deps src/ --include \"*.py\" --exclude \"*test*\"\n</code></pre> <p>ASCII Output Example: Text Only<pre><code>Dependency Tree\n\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\n\n\u251c\u2500\u2500 main.py\n\u2502   \u251c\u2500\u2500 auth/handler.py\n\u2502   \u2502   \u251c\u2500\u2500 auth/oauth.py\n\u2502   \u2502   \u2502   \u2514\u2500\u2500 utils/crypto.py\n\u2502   \u2502   \u2514\u2500\u2500 models/user.py\n\u2502   \u2502       \u2514\u2500\u2500 db/base.py\n\u2502   \u2514\u2500\u2500 api/routes.py\n\u2502       \u251c\u2500\u2500 api/endpoints.py\n\u2502       \u2514\u2500\u2500 middleware/cors.py\n\u2514\u2500\u2500 config.py\n</code></pre></p>"},{"location":"CLI/#viz-complexity","title":"viz complexity","text":"<p>Visualize code complexity metrics.</p> Bash<pre><code>tenets viz complexity [path] [options]\n</code></pre> <p>Options: - <code>--output, -o</code>: Save to file - <code>--format, -f</code>: Format: <code>ascii</code>, <code>png</code>, <code>html</code> - <code>--metric, -m</code>: Metric type: <code>cyclomatic</code> (default), <code>cognitive</code> - <code>--threshold</code>: Highlight files above threshold - <code>--hotspots</code>: Focus on complexity hotspots</p> <p>Examples:</p> Bash<pre><code># ASCII bar chart of complexity\ntenets viz complexity\n\n# Show only high-complexity files\ntenets viz complexity --threshold 10 --hotspots\n\n# Save as image\ntenets viz complexity --output complexity.png\n</code></pre> <p>ASCII Output Example: Text Only<pre><code>Complexity Analysis (cyclomatic)\n\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\n\nauth/oauth.py                 \u25cf \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588 28\nmodels/user.py               \u25d0 \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588 15\napi/endpoints.py             \u25d0 \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588 12\nutils/validators.py          \u25cf \u2588\u2588\u2588\u2588\u2588\u2588 8\nconfig/settings.py           \u25cf \u2588\u2588\u2588\u2588 5\n\nLegend: \u25cf Low  \u25d0 Medium  \u25d1 High  \u25cb Very High\n</code></pre></p>"},{"location":"CLI/#viz-coupling","title":"viz coupling","text":"<p>Visualize files that frequently change together.</p> Bash<pre><code>tenets viz coupling [path] [options]\n</code></pre> <p>Options: - <code>--output, -o</code>: Save to file - <code>--format, -f</code>: Format: <code>ascii</code>, <code>html</code> - <code>--min-coupling</code>: Minimum coupling count (default: 2)</p> <p>Examples:</p> Bash<pre><code># Show file coupling matrix\ntenets viz coupling\n\n# Only strong couplings\ntenets viz coupling --min-coupling 5\n\n# Interactive HTML matrix\ntenets viz coupling --output coupling.html\n</code></pre> <p>ASCII Output Example: Text Only<pre><code>File Coupling Matrix\n\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\n\n                    auth.py  user.py  api.py  test.py\nauth.py               -        8       3       12\nuser.py               8        -       5       10\napi.py                3        5       -       7\ntest_auth.py         12       10      7        -\n</code></pre></p>"},{"location":"CLI/#viz-contributors","title":"viz contributors","text":"<p>Visualize contributor activity and code ownership.</p> Bash<pre><code>tenets viz contributors [path] [options]\n</code></pre> <p>Options: - <code>--output, -o</code>: Save to file - <code>--format, -f</code>: Format: <code>ascii</code>, <code>png</code> - <code>--active</code>: Show only currently active contributors</p> <p>Examples:</p> Bash<pre><code># Contributor stats\ntenets viz contributors\n\n# Active contributors only\ntenets viz contributors --active\n</code></pre>"},{"location":"CLI/#session-commands","title":"Session Commands","text":"<p>Tenets can persist session state across distill runs. When a configuration is loaded, sessions are stored in a local SQLite database under the cache directory (see Storage below). Use <code>--session &lt;name&gt;</code> with commands like <code>distill</code> to build iterative context.</p> <ul> <li>Only one session is considered active at a time. Resuming a session will mark all others inactive.</li> <li>If a session NAME is omitted for <code>resume</code> or <code>exit</code>, Tenets operates on the currently active session.</li> </ul>"},{"location":"CLI/#session-create","title":"session create","text":"<p>Create a new analysis session.</p> Bash<pre><code>tenets session create &lt;name&gt;\n</code></pre> <p>Example: Bash<pre><code>tenets session create payment-integration\n</code></pre></p>"},{"location":"CLI/#session-start","title":"session start","text":"<p>Alias of <code>session create</code>.</p> Bash<pre><code>tenets session start &lt;name&gt;\n</code></pre>"},{"location":"CLI/#session-resume","title":"session resume","text":"<p>Mark an existing session as active.</p> Bash<pre><code># Resume the active session (if one exists)\ntenets session resume\n\n# Or specify by name\ntenets session resume &lt;name&gt;\n</code></pre>"},{"location":"CLI/#session-exit","title":"session exit","text":"<p>Mark a session as inactive.</p> Bash<pre><code># Exit the current active session\ntenets session exit\n\n# Or exit a specific session by name\ntenets session exit &lt;name&gt;\n</code></pre>"},{"location":"CLI/#session-list","title":"session list","text":"<p>List all sessions.</p> Bash<pre><code>tenets session list\n</code></pre> <p>The output includes an Active column (\"yes\" indicates the current session).</p>"},{"location":"CLI/#session-delete","title":"session delete","text":"<p>Delete a specific session.</p> Bash<pre><code>tenets session delete &lt;name&gt; [--keep-context]\n</code></pre> <p>Options: - <code>--keep-context</code>: Keep stored context artifacts (default: false)</p>"},{"location":"CLI/#session-reset","title":"session reset","text":"<p>Reset (delete and recreate) a session, purging its context.</p> Bash<pre><code>tenets session reset &lt;name&gt;\n</code></pre>"},{"location":"CLI/#session-clear","title":"session clear","text":"<p>Delete ALL sessions at once. Useful for clearing cache and starting fresh.</p> Bash<pre><code>tenets session clear [--keep-context]\n</code></pre> <p>Options: - <code>--keep-context</code>: Keep stored artifacts (default: false, deletes everything)</p> <p>Example: Bash<pre><code># Clear all sessions and their data\ntenets session clear\n\n# Clear sessions but preserve context files\ntenets session clear --keep-context\n</code></pre></p>"},{"location":"CLI/#session-show","title":"session show","text":"<p>Show details for a specific session.</p> Bash<pre><code>tenets session show &lt;name&gt;\n</code></pre>"},{"location":"CLI/#session-add","title":"session add","text":"<p>Attach arbitrary content to a session.</p> Bash<pre><code>tenets session add &lt;name&gt; &lt;kind&gt; &lt;file&gt;\n</code></pre> <p>Arguments: - <code>name</code>: Session name - <code>kind</code>: Content type tag (e.g., note, context_result) - <code>file</code>: File to attach</p> <p>Notes: - Creating or resetting a session marks it active. - Only one session is active at a time (resuming one deactivates others). - Session data is stored in SQLite under <code>~/.tenets/cache/sessions.db</code></p>"},{"location":"CLI/#tenet-commands","title":"Tenet Commands","text":"<p>Create and manage guiding principles (\u201ctenets\u201d) that can be injected into context.</p>"},{"location":"CLI/#tenet-add","title":"tenet add","text":"<p>Add a new tenet.</p> Bash<pre><code>tenets tenet add \"Always use type hints\" --priority high --category style\ntenets tenet add \"Validate all user inputs\" --priority critical --category security\ntenets tenet add \"Use async/await for I/O\" --session feature-x\n</code></pre> <p>Options: - <code>--priority, -p</code>: low | medium | high | critical (default: medium) - <code>--category, -c</code>: Freeform tag (e.g., architecture, security, style, performance, testing) - <code>--session, -s</code>: Bind tenet to a session</p>"},{"location":"CLI/#tenet-list","title":"tenet list","text":"<p>List tenets with filters.</p> Bash<pre><code>tenets tenet list\ntenets tenet list --pending\ntenets tenet list --session oauth --category security --verbose\n</code></pre> <p>Options: - <code>--pending</code>: Only pending - <code>--instilled</code>: Only instilled - <code>--session, -s</code>: Filter by session - <code>--category, -c</code>: Filter by category - <code>--verbose, -v</code>: Show full content and metadata</p>"},{"location":"CLI/#tenet-remove","title":"tenet remove","text":"<p>Remove a tenet by ID (partial ID accepted).</p> Bash<pre><code>tenets tenet remove abc123\ntenets tenet remove abc123 --force\n</code></pre>"},{"location":"CLI/#tenet-show","title":"tenet show","text":"<p>Show details for a tenet.</p> Bash<pre><code>tenets tenet show abc123\n</code></pre>"},{"location":"CLI/#tenet-export--import","title":"tenet export / import","text":"<p>Export/import tenets.</p> Bash<pre><code># Export to stdout or file\ntenets tenet export\ntenets tenet export --format json --session oauth -o team-tenets.json\n\n# Import from file (optionally into a session)\ntenets tenet import team-tenets.yml\ntenets tenet import standards.json --session feature-x\n</code></pre>"},{"location":"CLI/#instill-command","title":"Instill Command","text":"<p>Apply tenets to the current context with smart strategies (periodic/adaptive/manual).</p> Bash<pre><code>tenets instill [options]\n</code></pre> <p>Common options: - <code>--session, -s</code>: Use a named session for history and pinned files - <code>--force</code>: Force instillation regardless of frequency - <code>--max-tenets</code>: Cap number of tenets applied</p> <p>Examples:</p> Bash<pre><code># Apply pending tenets for a session\ntenets instill --session refactor-auth\n\n# Force all tenets once\ntenets instill --force\n</code></pre>"},{"location":"CLI/#system-instruction-commands","title":"System Instruction Commands","text":"<p>Manage the system instruction (system prompt) that can be auto-injected at the start of a session\u2019s first distill (or every output if no session is used).</p>"},{"location":"CLI/#system-instruction-set","title":"system-instruction set","text":"<p>Set/update the system instruction and options.</p> Bash<pre><code>tenets system-instruction set \"You are a helpful coding assistant\" \\\n  --enable \\\n  --position top \\\n  --format markdown\n\n# From file\ntenets system-instruction set --file prompts/system.md --enable\n</code></pre> <p>Options: - <code>--file, -f</code>: Read instruction from file - <code>--enable/--disable</code>: Enable or disable auto-injection - <code>--position</code>: Placement: <code>top</code>, <code>after_header</code>, <code>before_content</code> - <code>--format</code>: Format of injected block: <code>markdown</code>, <code>xml</code>, <code>comment</code>, <code>plain</code> - <code>--save/--no-save</code>: Persist to config</p>"},{"location":"CLI/#system-instruction-show","title":"system-instruction show","text":"<p>Display current configuration and instruction.</p> Bash<pre><code>tenets system-instruction show\ntenets system-instruction show --raw\n</code></pre> <p>Options: - <code>--raw</code>: Print raw instruction only</p>"},{"location":"CLI/#system-instruction-clear","title":"system-instruction clear","text":"<p>Clear and disable the system instruction.</p> Bash<pre><code>tenets system-instruction clear\ntenets system-instruction clear --yes\n</code></pre> <p>Options: - <code>--yes, -y</code>: Skip confirmation</p>"},{"location":"CLI/#system-instruction-test","title":"system-instruction test","text":"<p>Preview how injection would modify content.</p> Bash<pre><code>tenets system-instruction test\ntenets system-instruction test --session my-session\n</code></pre> <p>Options: - <code>--session</code>: Test with a session to respect once-per-session behavior</p>"},{"location":"CLI/#system-instruction-export","title":"system-instruction export","text":"<p>Export the instruction to a file.</p> Bash<pre><code>tenets system-instruction export prompts/system.md\n</code></pre>"},{"location":"CLI/#system-instruction-validate","title":"system-instruction validate","text":"<p>Validate the instruction for basic issues and optional token estimates.</p> Bash<pre><code>tenets system-instruction validate\ntenets system-instruction validate --tokens --max-tokens 800\n</code></pre> <p>Options: - <code>--tokens</code>: Show a rough token estimate - <code>--max-tokens</code>: Threshold for warnings/errors</p>"},{"location":"CLI/#system-instruction-edit","title":"system-instruction edit","text":"<p>Edit the instruction in your editor and save changes back to config.</p> Bash<pre><code>tenets system-instruction edit\ntenets system-instruction edit --editor code\n</code></pre>"},{"location":"CLI/#session-show_1","title":"session show","text":"<p>Show session details.</p> Bash<pre><code>tenets session show &lt;name&gt;\n</code></pre>"},{"location":"CLI/#session-add_1","title":"session add","text":"<p>Attach an artifact (stored as text) to a session.</p> Bash<pre><code>tenets session add &lt;name&gt; &lt;kind&gt; &lt;file&gt;\n</code></pre> <p>Examples of <code>kind</code>: <code>note</code>, <code>context_result</code>, <code>summary</code></p>"},{"location":"CLI/#session-reset_1","title":"session reset","text":"<p>Reset (delete and recreate) a session and purge its context.</p> Bash<pre><code>tenets session reset &lt;name&gt;\n</code></pre>"},{"location":"CLI/#session-delete_1","title":"session delete","text":"<p>Delete a session. Optionally keep stored artifacts.</p> Bash<pre><code>tenets session delete &lt;name&gt; [--keep-context]\n</code></pre>"},{"location":"CLI/#cache-management","title":"Cache Management","text":"Text Only<pre><code># Show cache stats (path, file count, size)\ntenets config cache-stats\n\n# Cleanup old/oversized entries respecting TTL\ntenets config cleanup-cache\n\n# Clear ALL caches (analysis + general) \u2013 destructive\ntenets config clear-cache --yes\n</code></pre> <p>Git data is used strictly for ranking relevance unless explicitly requested via commands like <code>chronicle</code> or <code>viz contributors</code>; it is not embedded in <code>distill</code> output.</p>"},{"location":"CLI/#configuration","title":"Configuration","text":""},{"location":"CLI/#config-set","title":"config set","text":"<p>Set configuration values.</p> Bash<pre><code>tenets config set &lt;key&gt; &lt;value&gt;\n</code></pre> <p>Examples: Bash<pre><code># Set default ranking algorithm\ntenets config set ranking.algorithm balanced\n\n# Set maximum file size\ntenets config set scanner.max_file_size 10000000\n\n# Enable ML features\ntenets config set nlp.use_embeddings true\n</code></pre></p>"},{"location":"CLI/#config-show","title":"config show","text":"<p>Show configuration.</p> Bash<pre><code>tenets config show [options]\n</code></pre> <p>Options: - <code>--key, -k</code>: Show specific key</p> <p>Examples: Bash<pre><code># Show all config\ntenets config show\n\n# Show model costs\ntenets config show --key costs\n\n# Show specific setting\ntenets config show --key ranking.algorithm\n</code></pre></p>"},{"location":"CLI/#storage","title":"Storage","text":"<p>Writable data is stored in a user/project cache directory:</p> <ul> <li>Default: <code>${HOME}/.tenets/cache</code> (Windows: <code>%USERPROFILE%\\\\.tenets\\\\cache</code>)</li> <li>Main DB: <code>${CACHE_DIR}/tenets.db</code> (sessions and future state)</li> <li>Analysis cache: <code>${CACHE_DIR}/analysis/analysis.db</code></li> </ul> <p>Override via <code>.tenets.yml</code>:</p> YAML<pre><code>cache:\n  directory: /path/to/custom/cache\n</code></pre> <p>Or environment:</p> Bash<pre><code>TENETS_CACHE_DIRECTORY=/path/to/custom/cache\n</code></pre> <p>Note on cost estimation: When <code>--estimate-cost</code> is used with <code>distill</code>, Tenets estimates costs using model limits and the built-in pricing table from <code>SUPPORTED_MODELS</code>.</p>"},{"location":"CLI/#common-use-cases","title":"Common Use Cases","text":""},{"location":"CLI/#1-ai-pair-programming","title":"1. AI Pair Programming","text":"<p>Generate context for ChatGPT/Claude when working on features:</p> Bash<pre><code># Initial context for new feature\ntenets distill \"implement user authentication with JWT\" &gt; auth_context.md\n\n# Paste auth_context.md into ChatGPT, then iterate:\ntenets distill \"add password reset functionality\" --session auth-feature\n\n# AI needs to see session info?\ntenets session show auth-feature\n</code></pre>"},{"location":"CLI/#2-code-review-preparation","title":"2. Code Review Preparation","text":"<p>Understand what changed and why:</p> Bash<pre><code># See what changed in the sprint\ntenets chronicle --since \"2 weeks\" --summary\n\n# Get context for reviewing a PR\ntenets distill \"review payment processing changes\"\n\n# Check complexity of changed files\ntenets examine --complexity --hotspots\n</code></pre>"},{"location":"CLI/#3-onboarding-to-new-codebase","title":"3. Onboarding to New Codebase","text":"<p>Quickly understand project structure:</p> Bash<pre><code># Get project overview\ntenets examine --metrics\n\n# Visualize architecture\ntenets viz deps --format ascii\n\n# Find the most complex areas\ntenets viz complexity --hotspots\n\n# See who knows what\ntenets viz contributors\n</code></pre>"},{"location":"CLI/#4-debugging-production-issues","title":"4. Debugging Production Issues","text":"<p>Find relevant code for debugging:</p> Bash<pre><code># Get all context related to the error\ntenets distill \"users getting 500 error on checkout\" --mode thorough\n\n# Include recent changes summary\ntenets chronicle --since \"last-deploy\"\n\n# Search for patterns within a session by iterating with prompts\ntenets distill \"find error handlers\" --session debug-session\n</code></pre>"},{"location":"CLI/#5-technical-debt-assessment","title":"5. Technical Debt Assessment","text":"<p>Identify areas needing refactoring:</p> Bash<pre><code># Find complex files\ntenets examine --complexity --threshold 15\n\n# Find tightly coupled code\ntenets viz coupling --min-coupling 5\n\n# Track velocity trends\ntenets momentum --team --since \"6 months\"\n</code></pre>"},{"location":"CLI/#6-architecture-documentation","title":"6. Architecture Documentation","text":"<p>Generate architecture insights:</p> Bash<pre><code># Export dependency graph\ntenets viz deps --output architecture.svg --cluster-by directory\n\n# Generate comprehensive analysis\ntenets examine --deep --output analysis.json --format json\n\n# Create context for documentation\ntenets distill \"document API architecture\" ./src/api\n</code></pre>"},{"location":"CLI/#examples","title":"Examples","text":""},{"location":"CLI/#complete-workflow-example","title":"Complete Workflow Example","text":"Bash<pre><code># 1. Start a new feature\ntenets session create oauth-integration\n\n# 2. Get initial context\ntenets distill \"implement OAuth2 with Google and GitHub\" \\\n  --session oauth-integration \\\n  --include \"*.py,*.yaml\" \\\n  --exclude \"test_*\" \\\n  --model gpt-4o \\\n  --estimate-cost &gt; oauth_context.md\n\n# 3. Paste into ChatGPT, start coding...\n\n# 4. AI needs more specific context\n# (Show session details)\ntenets session show oauth-integration\n\n# 5. Check your progress\ntenets chronicle --since \"today\"\n\n# 6. Visualize what you built\ntenets viz deps src/auth --format ascii\n\n# 7. Check complexity\ntenets examine src/auth --complexity\n\n# 8. Prepare for review\ntenets distill \"OAuth implementation ready for review\" \\\n  --session oauth-integration\n</code></pre>"},{"location":"CLI/#configuration-file-example","title":"Configuration File Example","text":"<p>Create <code>.tenets.yml</code> in your project:</p> YAML<pre><code># .tenets.yml\ncontext:\n  ranking: balanced\n  max_tokens: 100000\n  include_git: true\n\nscanner:\n  respect_gitignore: true\n  max_file_size: 5000000\n\nignore:\n  - \"*.generated.*\"\n  - \"vendor/\"\n  - \"build/\"\n\noutput:\n  format: markdown\n  summarize_long_files: true\n</code></pre>"},{"location":"CLI/#tips-and-tricks","title":"Tips and Tricks","text":"<ol> <li>Start with fast mode for quick exploration, use thorough for complex tasks</li> <li>Use sessions for multi-step features to maintain context</li> <li>ASCII visualizations are great for README files and documentation</li> <li>Combine commands - examine first, then distill with insights</li> <li>Git integration works automatically - no setup needed</li> <li>Include/exclude patterns support standard glob syntax</li> <li>Cost estimation helps budget API usage before sending to LLMs</li> </ol>"},{"location":"CLI/#environment-variables","title":"Environment Variables","text":"<ul> <li><code>TENETS_CONFIG_PATH</code>: Custom config file location</li> <li><code>TENETS_LOG_LEVEL</code>: Set log level (DEBUG, INFO, WARNING, ERROR)</li> <li><code>TENETS_CACHE_DIR</code>: Custom cache directory</li> <li><code>TENETS_NO_COLOR</code>: Disable colored output</li> </ul>"},{"location":"CLI/#exit-codes","title":"Exit Codes","text":"<ul> <li><code>0</code>: Success</li> <li><code>1</code>: General error</li> <li><code>2</code>: Invalid arguments</li> <li><code>3</code>: File not found</li> <li><code>4</code>: Git repository required but not found</li> </ul> <p>For more information, visit https://github.com/jddunn/tenets</p>"},{"location":"CLI/#verbosity--output-controls","title":"Verbosity &amp; Output Controls","text":"<p>Control log verbosity globally:</p> Bash<pre><code># Default (warnings and above only)\nTENETS_LOG_LEVEL=WARNING tenets distill \"add caching layer\"\n\n# Verbose\ntenets --verbose distill \"add caching layer\"\n\n# Quiet / errors only\ntenets --quiet distill \"add caching layer\"\n# or\ntenets --silent distill \"add caching layer\"\n</code></pre> <p>The <code>distill</code> command includes a Suggestions section when no files are included, with tips to adjust relevance thresholds, token budget, and include patterns.</p>"},{"location":"CODE_OF_CONDUCT/","title":"Code of Conduct","text":"<p>We are committed to a respectful, inclusive, and collaborative community. This Code of Conduct applies to all project spaces (GitHub issues/PRs, discussions, docs, chat) and anyone interacting with the project.</p>"},{"location":"CODE_OF_CONDUCT/#our-standards","title":"Our Standards","text":"<p>Positive behaviors: - Being welcoming, empathetic, and considerate - Giving and gracefully accepting constructive feedback - Focusing on what is best for the community - Showing respect for differing viewpoints and experiences</p> <p>Unacceptable behaviors: - Harassment, intimidation, or discrimination of any kind - Personal attacks or insults - Doxxing or sharing private information - Trolling, excessive disruption, or derailing conversations - Sexualized language or imagery; unwelcome advances</p>"},{"location":"CODE_OF_CONDUCT/#scope","title":"Scope","text":"<p>Applies within all project spaces and when representing the project in public.</p>"},{"location":"CODE_OF_CONDUCT/#enforcement","title":"Enforcement","text":"<p>Report incidents to: team@tenets.dev (core maintainers). Include: - Your contact (optional) - Names, links, or references involved - Context, timeline, and any evidence (screenshots, logs)</p> <p>Reports are handled confidentially. Maintainers may take any reasonable action: - Verbal / written warning - Temporary or permanent ban from interactions - Removal of unacceptable content - Escalation to hosting platforms if required</p>"},{"location":"CODE_OF_CONDUCT/#maintainer-responsibilities","title":"Maintainer Responsibilities","text":"<p>Maintainers must model acceptable behavior and are responsible for clarifying standards and taking corrective action when misconduct occurs.</p>"},{"location":"CODE_OF_CONDUCT/#attribution","title":"Attribution","text":"<p>Adapted from the Contributor Covenant v2.1 (https://www.contributor-covenant.org) with project-specific clarifications.</p>"},{"location":"CODE_OF_CONDUCT/#contact","title":"Contact","text":"<p>Questions or concerns: team@tenets.dev</p> <p>We strive for a community where all contributors feel safe and empowered to improve Tenets.</p>"},{"location":"CONFIG/","title":"Configuration Guide","text":"<p>Comprehensive guide to configuring Tenets for optimal code context building.</p>"},{"location":"CONFIG/#overview","title":"Overview","text":"<p>Tenets uses a hierarchical configuration system with multiple override levels:</p> <p>Precedence (lowest \u2192 highest): 1. Default configuration (built-in) 2. Project file (<code>.tenets.yml</code> at repo root) 3. User file (<code>~/.config/tenets/config.yml</code> or <code>~/.tenets.yml</code>) 4. Environment variables (<code>TENETS_*</code>) 5. CLI flags (<code>--mode</code>, <code>--max-tokens</code>, etc.) 6. Programmatic overrides (<code>Tenets(config=...)</code>)</p> <p>Inspect configuration: Bash<pre><code>tenets config show                # Full config\ntenets config show --key ranking  # Specific section\ntenets config show --format json  # JSON output\n</code></pre></p>"},{"location":"CONFIG/#files-and-locations","title":"Files and locations","text":"<p>Tenets searches these locations in order and uses the first it finds: - ./.tenets.yml - ./.tenets.yaml - ./tenets.yml - ./.config/tenets.yml - ~/.config/tenets/config.yml - ~/.tenets.yml</p> <p>Create a starter file:</p> <ul> <li>tenets config init  # writes .tenets.yml in the current directory</li> </ul>"},{"location":"CONFIG/#complete-configuration-schema","title":"Complete Configuration Schema","text":"<p>All available configuration sections and their options:</p> YAML<pre><code># ============= Core Settings =============\nmax_tokens: 100000          # Maximum tokens for context (default: 100000)\ndebug: false                # Enable debug logging\nquiet: false                # Suppress non-essential output\n\n# ============= File Scanning =============\nscanner:\n  respect_gitignore: true          # Honor .gitignore patterns\n  follow_symlinks: false           # Follow symbolic links\n  max_file_size: 5000000          # Max file size in bytes (5MB)\n  max_files: 10000                # Maximum files to scan\n  binary_check: true              # Skip binary files\n  encoding: utf-8                 # File encoding\n  workers: 4                      # Parallel scanning workers\n  parallel_mode: auto             # auto | thread | process\n  timeout: 5.0                    # Timeout per file (seconds)\n  exclude_minified: true          # Skip minified files\n  exclude_tests_by_default: true  # Skip test files unless explicit\n\n  # Ignore patterns (in addition to .gitignore)\n  additional_ignore_patterns:\n    - '*.generated.*'\n    - vendor/\n    - node_modules/\n    - '*.egg-info/'\n    - __pycache__/\n    - .pytest_cache/\n\n  # Test file patterns\n  test_patterns:\n    - test_*.py\n    - '*_test.py'\n    - '*.test.js'\n    - '*.spec.ts'\n\n  # Test directories\n  test_directories:\n    - test\n    - tests\n    - __tests__\n    - spec\n\n# ============= Ranking System =============\nranking:\n  algorithm: balanced             # fast | balanced | thorough | ml | custom\n  threshold: 0.10                 # 0.0-1.0 (lower includes more files)\n  text_similarity_algorithm: bm25 # bm25 (default) | tfidf (optional)\n  text_similarity_algorithm: bm25  # Using BM25 (default)               # Deprecated - use text_similarity_algorithm instead\n  use_stopwords: false           # Filter common tokens\n  use_embeddings: false          # Semantic similarity (requires ML)\n  use_git: true                  # Include git signals\n  use_ml: false                  # Machine learning features\n  embedding_model: all-MiniLM-L6-v2  # Embedding model name\n  workers: 2                     # Parallel ranking workers\n  parallel_mode: auto            # thread | process | auto\n  batch_size: 100               # Files per batch\n\n  # Custom factor weights (0.0-1.0)\n  custom_weights:\n    keyword_match: 0.25\n    path_relevance: 0.20\n    import_graph: 0.20\n    git_activity: 0.15\n    file_type: 0.10\n    complexity: 0.10\n\n# ============= Summarization =============\nsummarizer:\n  default_mode: auto             # auto | extractive | abstractive\n  target_ratio: 0.3              # Target compression ratio\n  enable_cache: true             # Cache summaries\n  preserve_code_structure: true  # Keep code structure intact\n  summarize_imports: true        # Condense import statements\n  import_summary_threshold: 5    # Min imports to trigger summary\n  max_cache_size: 100           # Max cached summaries\n  quality_threshold: medium      # low | medium | high\n  batch_size: 10                # Files per batch\n  docstring_weight: 0.5         # Weight for docstrings\n  include_all_signatures: true   # Include all function signatures\n\n  # LLM settings (optional)\n  llm_provider: null            # openai | anthropic | null\n  llm_model: null               # Model name\n  llm_temperature: 0.3          # Creativity (0.0-1.0)\n  llm_max_tokens: 500           # Max tokens per summary\n  enable_ml_strategies: false    # Use ML summarization\n\n# ============= Tenet System =============\ntenet:\n  auto_instill: true              # Auto-apply tenets\n  max_per_context: 5              # Max tenets per context\n  reinforcement: true             # Reinforce important tenets\n  injection_strategy: strategic   # strategic | sequential | random\n  min_distance_between: 1000      # Min chars between injections\n  prefer_natural_breaks: true     # Insert at natural boundaries\n  storage_path: ~/.tenets/tenets  # Tenet storage location\n  collections_enabled: true       # Enable tenet collections\n\n  # Injection frequency\n  injection_frequency: adaptive   # always | periodic | adaptive | manual\n  injection_interval: 3           # For periodic mode\n  session_complexity_threshold: 0.7  # Triggers adaptive injection\n  min_session_length: 5           # Min prompts before injection\n\n  # Advanced settings\n  adaptive_injection: true        # Smart injection timing\n  track_injection_history: true   # Track what was injected\n  decay_rate: 0.1                # How fast tenets decay\n  reinforcement_interval: 10      # Reinforce every N prompts\n  session_aware: true            # Use session context\n  session_memory_limit: 100      # Max session history\n  persist_session_history: true   # Save session data\n\n  # Priority settings\n  priority_boost_critical: 2.0    # Boost for critical tenets\n  priority_boost_high: 1.5       # Boost for high priority\n  skip_low_priority_on_complex: true  # Skip low priority when complex\n\n  # System instruction\n  system_instruction: null        # Global system instruction\n  system_instruction_enabled: false  # Enable system instruction\n  system_instruction_position: top   # top | bottom\n  system_instruction_format: markdown  # markdown | plain\n  system_instruction_once_per_session: true  # Inject once per session\n\n# ============= Caching =============\ncache:\n  enabled: true                  # Enable caching\n  directory: ~/.tenets/cache     # Cache directory\n  ttl_days: 7                   # Time to live (days)\n  max_size_mb: 500              # Max cache size (MB)\n  compression: false            # Compress cache data\n  memory_cache_size: 1000       # In-memory cache entries\n  max_age_hours: 24            # Max cache age (hours)\n\n  # SQLite settings\n  sqlite_pragmas:\n    journal_mode: WAL\n    synchronous: NORMAL\n    cache_size: '-64000'\n    temp_store: MEMORY\n\n  # LLM cache\n  llm_cache_enabled: true       # Cache LLM responses\n  llm_cache_ttl_hours: 24      # LLM cache TTL\n\n# ============= Output Formatting =============\noutput:\n  default_format: markdown       # markdown | xml | json | html\n  syntax_highlighting: true      # Enable syntax highlighting\n  line_numbers: false           # Show line numbers\n  max_line_length: 120          # Max line length\n  include_metadata: true        # Include metadata\n  compression_threshold: 10000  # Compress if larger (chars)\n  summary_ratio: 0.25           # Summary compression ratio\n  copy_on_distill: false        # Auto-copy to clipboard\n  show_token_usage: true        # Show token counts\n  show_cost_estimate: true      # Show LLM cost estimates\n\n# ============= Git Integration =============\ngit:\n  enabled: true                 # Use git information\n  include_history: true         # Include commit history\n  history_limit: 100           # Max commits to analyze\n  include_blame: false         # Include git blame\n  include_stats: true          # Include statistics\n\n  # Ignore these authors\n  ignore_authors:\n    - dependabot[bot]\n    - github-actions[bot]\n    - renovate[bot]\n\n  # Main branch names\n  main_branches:\n    - main\n    - master\n    - develop\n    - trunk\n\n# ============= NLP Settings =============\nnlp:\n  enabled: true                    # Enable NLP features\n  stopwords_enabled: true          # Use stopwords\n  code_stopword_set: minimal       # minimal | standard | aggressive\n  prompt_stopword_set: aggressive  # minimal | standard | aggressive\n  custom_stopword_files: []        # Custom stopword files\n\n  # Tokenization\n  tokenization_mode: auto          # auto | simple | advanced\n  preserve_original_tokens: true   # Keep original tokens\n  split_camelcase: true           # Split CamelCase\n  split_snakecase: true           # Split snake_case\n  min_token_length: 2             # Min token length\n\n  # Keyword extraction\n  keyword_extraction_method: auto  # auto | rake | yake | bm25 | tfidf\n  max_keywords: 30                # Max keywords to extract\n  ngram_size: 3                  # N-gram size\n  yake_dedup_threshold: 0.7      # YAKE deduplication\n\n  # BM25 settings\n  bm25_k1: 1.2                   # Term frequency saturation parameter\n  bm25_b: 0.75                   # Length normalization parameter\n\n  # TF-IDF settings (when explicitly configured as alternative to BM25)\n  tfidf_use_sublinear: true      # Sublinear TF scaling (only when TF-IDF is used)\n  tfidf_use_idf: true           # Use IDF\n  tfidf_norm: l2                # Normalization\n\n  # Embeddings\n  embeddings_enabled: false       # Enable embeddings\n  embeddings_model: all-MiniLM-L6-v2  # Model name\n  embeddings_device: auto        # cpu | cuda | auto\n  embeddings_cache: true         # Cache embeddings\n  embeddings_batch_size: 32      # Batch size\n  similarity_metric: cosine      # cosine | euclidean | manhattan\n  similarity_threshold: 0.7      # Similarity threshold\n\n  # Cache settings\n  cache_embeddings_ttl_days: 30  # Embeddings cache TTL\n  cache_tfidf_ttl_days: 7       # BM25/TF-IDF cache TTL\n  cache_keywords_ttl_days: 7     # Keywords cache TTL\n\n  # Performance\n  multiprocessing_enabled: true   # Use multiprocessing\n  multiprocessing_workers: null   # null = auto-detect\n  multiprocessing_chunk_size: 100 # Chunk size\n\n# ============= LLM Settings (Optional) =============\nllm:\n  enabled: false                # Enable LLM features\n  provider: openai              # openai | anthropic | ollama\n  fallback_providers:           # Fallback providers\n    - anthropic\n    - openrouter\n\n  # API keys (use environment variables)\n  api_keys:\n    openai: ${OPENAI_API_KEY}\n    anthropic: ${ANTHROPIC_API_KEY}\n    openrouter: ${OPENROUTER_API_KEY}\n\n  # API endpoints\n  api_base_urls:\n    openai: https://api.openai.com/v1\n    anthropic: https://api.anthropic.com/v1\n    openrouter: https://openrouter.ai/api/v1\n    ollama: http://localhost:11434\n\n  # Model selection\n  models:\n    default: gpt-4o-mini\n    summarization: gpt-3.5-turbo\n    analysis: gpt-4o\n    embeddings: text-embedding-3-small\n    code_generation: gpt-4o\n\n  # Rate limits and costs\n  max_cost_per_run: 0.1         # Max $ per run\n  max_cost_per_day: 10.0        # Max $ per day\n  max_tokens_per_request: 4000   # Max tokens per request\n  max_context_length: 100000     # Max context length\n\n  # Generation settings\n  temperature: 0.3              # Creativity (0.0-1.0)\n  top_p: 0.95                  # Nucleus sampling\n  frequency_penalty: 0.0        # Frequency penalty\n  presence_penalty: 0.0         # Presence penalty\n\n  # Network settings\n  requests_per_minute: 60       # Rate limit\n  retry_on_error: true         # Retry failed requests\n  max_retries: 3              # Max retry attempts\n  retry_delay: 1.0            # Initial retry delay\n  retry_backoff: 2.0          # Backoff multiplier\n  timeout: 30                 # Request timeout (seconds)\n  stream: false               # Stream responses\n\n  # Logging and caching\n  cache_responses: true        # Cache LLM responses\n  cache_ttl_hours: 24         # Cache TTL (hours)\n  log_requests: false         # Log requests\n  log_responses: false        # Log responses\n\n# ============= Custom Settings =============\ncustom: {}  # User-defined custom settings\n</code></pre>"},{"location":"CONFIG/#key-configuration-notes","title":"Key Configuration Notes","text":"<p>Ranking: - <code>threshold</code>: Lower values (0.05-0.10) include more files, higher (0.20-0.30) for stricter matching - <code>algorithm</code>:   - <code>fast</code>: Quick keyword matching (~10ms/file)   - <code>balanced</code>: Structural analysis + BM25 (default)   - <code>thorough</code>: Full analysis with relationships   - <code>ml</code>: Machine learning with embeddings (requires extras) - <code>custom_weights</code>: Fine-tune ranking factors (values 0.0-1.0)</p> <p>Scanner: - <code>respect_gitignore</code>: Always honors .gitignore patterns - <code>exclude_tests_by_default</code>: Tests excluded unless <code>--include-tests</code> used - <code>additional_ignore_patterns</code>: Added to built-in patterns</p> <p>Tenet System: - <code>auto_instill</code>: Automatically applies relevant tenets to context - <code>injection_frequency</code>:   - <code>always</code>: Every distill   - <code>periodic</code>: Every N distills   - <code>adaptive</code>: Based on complexity   - <code>manual</code>: Only when explicitly called - <code>system_instruction</code>: Global instruction added to all contexts</p> <p>Output: - <code>copy_on_distill</code>: Auto-copy result to clipboard - <code>default_format</code>: Default output format (markdown recommended for LLMs)</p> <p>Performance: - <code>workers</code>: More workers = faster but more CPU/memory - <code>cache.enabled</code>: Significantly speeds up repeated operations - <code>ranking.batch_size</code>: Larger batches = more memory but faster</p>"},{"location":"CONFIG/#environment-variable-overrides","title":"Environment Variable Overrides","text":"<p>Any configuration option can be overridden via environment variables.</p> <p>Format: - Nested keys: <code>TENETS_&lt;SECTION&gt;_&lt;KEY&gt;=value</code> - Top-level keys: <code>TENETS_&lt;KEY&gt;=value</code> - Lists: Comma-separated values - Booleans: <code>true</code> or <code>false</code> (case-insensitive)</p> <p>Common Examples: Bash<pre><code># Core settings\nexport TENETS_MAX_TOKENS=150000\nexport TENETS_DEBUG=true\nexport TENETS_QUIET=false\n\n# Ranking configuration\nexport TENETS_RANKING_ALGORITHM=thorough\nexport TENETS_RANKING_THRESHOLD=0.05\nexport TENETS_RANKING_TEXT_SIMILARITY_ALGORITHM=tfidf  # Use TF-IDF instead of BM25\nexport TENETS_RANKING_USE_EMBEDDINGS=true\nexport TENETS_RANKING_WORKERS=4\n\n# Scanner settings\nexport TENETS_SCANNER_MAX_FILE_SIZE=10000000\nexport TENETS_SCANNER_RESPECT_GITIGNORE=true\nexport TENETS_SCANNER_EXCLUDE_TESTS_BY_DEFAULT=false\n\n# Output settings\nexport TENETS_OUTPUT_DEFAULT_FORMAT=xml\nexport TENETS_OUTPUT_COPY_ON_DISTILL=true\nexport TENETS_OUTPUT_SHOW_TOKEN_USAGE=false\n\n# Cache settings\nexport TENETS_CACHE_ENABLED=false\nexport TENETS_CACHE_DIRECTORY=/tmp/tenets-cache\nexport TENETS_CACHE_TTL_DAYS=14\n\n# Git settings\nexport TENETS_GIT_ENABLED=false\nexport TENETS_GIT_HISTORY_LIMIT=50\n\n# Tenet system\nexport TENETS_TENET_AUTO_INSTILL=false\nexport TENETS_TENET_MAX_PER_CONTEXT=10\nexport TENETS_TENET_INJECTION_FREQUENCY=periodic\nexport TENETS_TENET_INJECTION_INTERVAL=5\n\n# System instruction\nexport TENETS_TENET_SYSTEM_INSTRUCTION=\"You are a senior engineer. Focus on security and performance.\"\nexport TENETS_TENET_SYSTEM_INSTRUCTION_ENABLED=true\n</code></pre></p> <p>Usage Patterns: Bash<pre><code># One-time override\nTENETS_RANKING_ALGORITHM=fast tenets distill \"fix bug\"\n\n# Session-wide settings\nexport TENETS_RANKING_THRESHOLD=0.05\nexport TENETS_OUTPUT_COPY_ON_DISTILL=true\ntenets distill \"implement feature\"  # Uses exported settings\n\n# Verify configuration\ntenets config show --key ranking\ntenets config show --format json | jq '.ranking'\n</code></pre></p>"},{"location":"CONFIG/#cli-flags-and-programmatic-control","title":"CLI Flags and Programmatic Control","text":""},{"location":"CONFIG/#cli-flags","title":"CLI Flags","text":"<p>Command-line flags override configuration for that specific run:</p> Bash<pre><code># Core overrides\ntenets distill \"query\" --max-tokens 50000\ntenets distill \"query\" --format xml\ntenets distill \"query\" --copy\n\n# Ranking mode\ntenets distill \"query\" --mode fast      # Quick analysis\ntenets distill \"query\" --mode thorough  # Deep analysis\ntenets distill \"query\" --mode ml        # With embeddings\n\n# File filtering\ntenets distill \"query\" --include \"*.py\" --exclude \"test_*.py\"\ntenets distill \"query\" --include-tests  # Include test files\n\n# Git control\ntenets distill \"query\" --no-git  # Disable git signals\n\n# Session management\ntenets distill \"query\" --session feature-x\n\n# Content optimization\ntenets distill \"query\" --condense        # Aggressive compression\ntenets distill \"query\" --remove-comments # Strip comments\ntenets distill \"query\" --full            # No summarization\n</code></pre>"},{"location":"CONFIG/#programmatic-configuration","title":"Programmatic Configuration","text":"<p>Basic usage with custom config: Python<pre><code>from tenets import Tenets\nfrom tenets.config import TenetsConfig\n\n# Create custom configuration\nconfig = TenetsConfig(\n    max_tokens=150000,\n    ranking={\n        \"algorithm\": \"thorough\",\n        \"threshold\": 0.05,\n        \"text_similarity_algorithm\": \"bm25\",  # or \"tfidf\" for TF-IDF\n        \"use_embeddings\": True,\n        \"workers\": 4,\n        \"custom_weights\": {\n            \"keyword_match\": 0.30,\n            \"path_relevance\": 0.25,\n            \"git_activity\": 0.20,\n        }\n    },\n    scanner={\n        \"respect_gitignore\": True,\n        \"max_file_size\": 10_000_000,\n        \"exclude_tests_by_default\": False,\n    },\n    output={\n        \"default_format\": \"xml\",\n        \"copy_on_distill\": True,\n    },\n    tenet={\n        \"auto_instill\": True,\n        \"max_per_context\": 10,\n        \"system_instruction\": \"Focus on security and performance\",\n        \"system_instruction_enabled\": True,\n    }\n)\n\n# Initialize with custom config\ntenets = Tenets(config=config)\n\n# Use it\nresult = tenets.distill(\n    \"implement caching layer\",\n    max_tokens=80000,  # Override config for this call\n    mode=\"balanced\",    # Override algorithm\n)\n</code></pre></p> <p>Load and modify existing config: Python<pre><code>from tenets import Tenets\nfrom tenets.config import TenetsConfig\n\n# Load from file\nconfig = TenetsConfig.from_file(\".tenets.yml\")\n\n# Modify specific settings\nconfig.ranking.algorithm = \"fast\"\nconfig.ranking.threshold = 0.08\nconfig.output.copy_on_distill = True\n\n# Use modified config\ntenets = Tenets(config=config)\n</code></pre></p> <p>Runtime overrides: Python<pre><code># Config precedence: method args &gt; instance config &gt; file config\nresult = tenets.distill(\n    prompt=\"add authentication\",\n    mode=\"thorough\",        # Overrides config.ranking.algorithm\n    max_tokens=100000,      # Overrides config.max_tokens\n    format=\"json\",          # Overrides config.output.default_format\n    session_name=\"auth\",    # Session-specific\n    include_patterns=[\"*.py\", \"*.js\"],\n    exclude_patterns=[\"*.test.js\"],\n)\n</code></pre></p>"},{"location":"CONFIG/#configuration-recipes","title":"Configuration Recipes","text":""},{"location":"CONFIG/#for-different-use-cases","title":"For Different Use Cases","text":"<p>Large Monorepo (millions of files): YAML<pre><code>max_tokens: 150000\nscanner:\n  max_files: 50000\n  workers: 8\n  parallel_mode: process\n  exclude_tests_by_default: true\nranking:\n  algorithm: fast\n  threshold: 0.15\n  workers: 4\n  batch_size: 500\ncache:\n  enabled: true\n  memory_cache_size: 5000\n</code></pre></p> <p>Small Project (high precision): YAML<pre><code>max_tokens: 80000\nranking:\n  algorithm: thorough\n  threshold: 0.08\n  text_similarity_algorithm: bm25  # Default algorithm\n  use_embeddings: true\n  custom_weights:\n    keyword_match: 0.35\n    import_graph: 0.25\n</code></pre></p> <p>Documentation-Heavy Project: YAML<pre><code>summarizer:\n  docstring_weight: 0.8\n  include_all_signatures: true\n  preserve_code_structure: false\nranking:\n  custom_weights:\n    keyword_match: 0.20\n    path_relevance: 0.30  # Prioritize doc paths\n</code></pre></p> <p>Security-Focused Analysis: YAML<pre><code>tenet:\n  system_instruction: |\n    Focus on security implications.\n    Flag any potential vulnerabilities.\n    Suggest secure alternatives.\n  system_instruction_enabled: true\n  auto_instill: true\nscanner:\n  additional_ignore_patterns: []  # Don't skip anything\n  exclude_tests_by_default: false\n</code></pre></p>"},{"location":"CONFIG/#performance-tuning","title":"Performance Tuning","text":"<p>Maximum Speed (sacrifices precision): YAML<pre><code>ranking:\n  algorithm: fast\n  threshold: 0.05\n  text_similarity_algorithm: bm25  # Using BM25 (default)\n  use_embeddings: false\n  workers: 8\nscanner:\n  workers: 8\n  timeout: 2.0\ncache:\n  enabled: true\n  compression: false\n</code></pre></p> <p>Maximum Precision (slower): YAML<pre><code>ranking:\n  algorithm: thorough\n  threshold: 0.20\n  text_similarity_algorithm: bm25  # Default algorithm\n  use_embeddings: true\n  use_git: true\n  workers: 2\nsummarizer:\n  quality_threshold: high\n  enable_ml_strategies: true\n</code></pre></p> <p>Memory-Constrained Environment: YAML<pre><code>scanner:\n  max_files: 1000\n  workers: 1\nranking:\n  workers: 1\n  batch_size: 50\ncache:\n  memory_cache_size: 100\n  max_size_mb: 100\nnlp:\n  embeddings_batch_size: 8\n  multiprocessing_enabled: false\n</code></pre></p>"},{"location":"CONFIG/#common-workflows","title":"Common Workflows","text":"<p>Bug Investigation: YAML<pre><code>ranking:\n  algorithm: balanced\n  threshold: 0.10\n  custom_weights:\n    git_activity: 0.30  # Recent changes matter\n    complexity: 0.20    # Complex code = more bugs\ngit:\n  include_history: true\n  history_limit: 200\n  include_blame: true\n</code></pre></p> <p>New Feature Development: YAML<pre><code>ranking:\n  algorithm: balanced\n  threshold: 0.08\n  custom_weights:\n    import_graph: 0.30  # Dependencies matter\n    path_relevance: 0.25 # Related modules\noutput:\n  copy_on_distill: true\n  show_token_usage: true\n</code></pre></p> <p>Code Review Preparation: YAML<pre><code>summarizer:\n  target_ratio: 0.5  # More detail\n  preserve_code_structure: true\n  include_all_signatures: true\noutput:\n  syntax_highlighting: true\n  line_numbers: true\n  include_metadata: true\n</code></pre></p>"},{"location":"CONFIG/#troubleshooting","title":"Troubleshooting","text":""},{"location":"CONFIG/#common-issues-and-solutions","title":"Common Issues and Solutions","text":"<p>No files included in context: - Lower <code>ranking.threshold</code> (try 0.05) - Use <code>--mode fast</code> for broader inclusion - Increase <code>max_tokens</code> limit - Check if files match <code>--include</code> patterns - Verify files aren't in <code>.gitignore</code> - Use <code>--include-tests</code> if analyzing test files</p> <p>Configuration not taking effect: Bash<pre><code># Check which config file is loaded\ntenets config show | head -20\n\n# Verify specific setting\ntenets config show --key ranking.threshold\n\n# Check config file location\nls -la .tenets.yml\n\n# Test with explicit config\ntenets --config ./my-config.yml distill \"query\"\n</code></pre></p> <p>Environment variables not working: Bash<pre><code># Verify export (not just set)\nexport TENETS_RANKING_THRESHOLD=0.05  # Correct\nTENETS_RANKING_THRESHOLD=0.05         # Wrong (not exported)\n\n# Check if variable is set\necho $TENETS_RANKING_THRESHOLD\n\n# Debug with explicit env\nTENETS_DEBUG=true tenets config show\n</code></pre></p> <p>Performance issues: - Reduce <code>scanner.max_files</code> and <code>scanner.max_file_size</code> - Enable caching: <code>cache.enabled: true</code> - Use <code>ranking.algorithm: fast</code> - Reduce <code>ranking.workers</code> if CPU-constrained - Exclude unnecessary paths with <code>additional_ignore_patterns</code></p> <p>Token limit exceeded: - Increase <code>max_tokens</code> or use <code>--max-tokens</code> - Enable <code>--condense</code> flag - Use <code>--remove-comments</code> - Increase <code>ranking.threshold</code> for stricter filtering - Exclude test files: <code>scanner.exclude_tests_by_default: true</code></p> <p>Cache issues: Bash<pre><code># Clear cache\nrm -rf ~/.tenets/cache\n\n# Disable cache temporarily\nTENETS_CACHE_ENABLED=false tenets distill \"query\"\n\n# Use custom cache location\nexport TENETS_CACHE_DIRECTORY=/tmp/tenets-cache\n</code></pre></p>"},{"location":"CONFIG/#validation-commands","title":"Validation Commands","text":"Bash<pre><code># Validate configuration syntax\ntenets config validate\n\n# Show effective configuration\ntenets config show --format json | jq\n\n# Test configuration with dry run\ntenets distill \"test query\" --dry-run\n\n# Check what files would be scanned\ntenets examine . --dry-run\n\n# Debug ranking process\nTENETS_DEBUG=true tenets distill \"query\" 2&gt;debug.log\n</code></pre>"},{"location":"CONFIG/#advanced-topics","title":"Advanced Topics","text":""},{"location":"CONFIG/#custom-ranking-strategies","title":"Custom Ranking Strategies","text":"<p>Create a custom ranking strategy by combining weights:</p> YAML<pre><code>ranking:\n  algorithm: custom\n  custom_weights:\n    keyword_match: 0.40    # Emphasize keyword relevance\n    path_relevance: 0.15   # De-emphasize path matching\n    import_graph: 0.15     # Moderate dependency weight\n    git_activity: 0.10     # Low git signal weight\n    file_type: 0.10        # File type matching\n    complexity: 0.10       # Code complexity\n</code></pre>"},{"location":"CONFIG/#multi-environment-setup","title":"Multi-Environment Setup","text":"<p>Create environment-specific configs:</p> Bash<pre><code># Development\ncp .tenets.yml .tenets.dev.yml\n# Edit for dev settings\n\n# Production analysis\ncp .tenets.yml .tenets.prod.yml\n# Edit for production settings\n\n# Use specific config\ntenets --config .tenets.dev.yml distill \"query\"\n</code></pre>"},{"location":"CONFIG/#integration-with-cicd","title":"Integration with CI/CD","text":"YAML<pre><code># .tenets.ci.yml - Optimized for CI\nmax_tokens: 50000\nquiet: true\nscanner:\n  max_files: 5000\n  workers: 2\nranking:\n  algorithm: fast\n  threshold: 0.10\ncache:\n  enabled: false  # Fresh analysis each run\noutput:\n  default_format: json  # Machine-readable\n</code></pre>"},{"location":"CONFIG/#see-also","title":"See Also","text":"<ul> <li>CLI Reference - Complete command documentation</li> <li>API Reference - Python API documentation</li> <li>Architecture - System design details</li> </ul>"},{"location":"CONTRIBUTING/","title":"Contributing to Tenets","text":"<p>Thanks for your interest in improving Tenets! Contributions of all kinds are welcome: bug reports, docs, tests, features, performance improvements, refactors, and feedback.</p>"},{"location":"CONTRIBUTING/#quick-start-tldr","title":"Quick Start (TL;DR)","text":"Bash<pre><code># Fork / clone\n git clone https://github.com/jddunn/tenets.git\n cd tenets\n\n# Create a virtual environment (or use pyenv / conda)\n python -m venv .venv &amp;&amp; source .venv/bin/activate  # Windows: .venv\\Scripts\\activate\n\n# Install core + dev extras\n pip install -e .[dev]\n # (or: make dev)\n\n# Run tests\n pytest -q\n\n# Lint &amp; type check\n ruff check .\n mypy tenets\n\n# Format\n black .\n\n# Run a sample command\n tenets distill \"hello world\" . --stats\n</code></pre>"},{"location":"CONTRIBUTING/#project-philosophy","title":"Project Philosophy","text":"<p>Tenets is: - Local-first, privacy-preserving - Fast with graceful scalability (analyze only as deep as necessary) - Extensible without forcing heavyweight ML (opt-in extras) - Transparent in ranking decisions (explanations where reasonable)</p>"},{"location":"CONTRIBUTING/#issue-tracking","title":"Issue Tracking","text":"<p>Before filing: 1. Search existing issues (open + closed) 2. For questions / ideas, consider starting a GitHub Discussion (if enabled) or Discord 3. Provide reproduction steps and environment info (OS, Python version, extras installed)</p> <p>Good bug report template: Text Only<pre><code>### Description\nClear, concise description of the problem.\n\n### Reproduction\nCommands or code snippet that reproduces the issue.\n\n### Expected vs Actual\nWhat you expected / what happened.\n\n### Environment\nOS / Python / tenets version / installed extras.\n</code></pre></p>"},{"location":"CONTRIBUTING/#branch--commit-conventions","title":"Branch &amp; Commit Conventions","text":"<ul> <li>Create feature branches off <code>dev</code> (default contribution branch)</li> <li>Keep PRs narrowly scoped when possible</li> <li>Conventional Commit prefixes (enforced via commitizen config):</li> <li>feat: new user-facing feature</li> <li>fix: bug fix</li> <li>refactor: code change without feature/bug semantics</li> <li>perf: performance improvement</li> <li>docs: docs only changes</li> <li>test: add or improve tests</li> <li>chore: tooling / infra / build</li> </ul> <p>Example: Text Only<pre><code>feat(ranking): add parallel TF-IDF corpus prepass\n</code></pre></p> <p>Use <code>cz commit</code> if you have commitizen installed.</p>"},{"location":"CONTRIBUTING/#code-style--tooling","title":"Code Style &amp; Tooling","text":"Tool Purpose Command black Formatting <code>black .</code> ruff Linting (multi-plugin) <code>ruff check .</code> mypy Static typing <code>mypy tenets</code> pytest Tests + coverage <code>pytest -q</code> coverage HTML / XML reports <code>pytest --cov</code> commitizen Conventional versioning <code>cz bump</code> <p>Pre-commit hooks (optional): Bash<pre><code>pip install pre-commit\npre-commit install\n</code></pre></p>"},{"location":"CONTRIBUTING/#tests","title":"Tests","text":"<p>Guidelines: - Place tests under <code>tests/</code> mirroring module paths - Use <code>pytest</code> fixtures; prefer explicit data over deep mocks - Mark slow tests with <code>@pytest.mark.slow</code> - Keep unit tests fast (&lt;300ms ideally) - Add at least one failing test before a bug fix</p> <p>Run selectively: Bash<pre><code>pytest tests/core/analysis -k python_analyzer\npytest -m \"not slow\"\n</code></pre></p>"},{"location":"CONTRIBUTING/#type-hints","title":"Type Hints","text":"<ul> <li>New/modified public functions must be fully typed</li> <li>Avoid <code>Any</code> unless absolutely necessary; justify in a comment</li> <li>mypy config is strict\u2014fix or silence with narrow <code># type: ignore[...]</code></li> </ul>"},{"location":"CONTRIBUTING/#documentation","title":"Documentation","text":"<p>User docs live in <code>docs/</code> (MkDocs Material). For changes affecting users: - Update <code>README.md</code> - Update or create relevant page under <code>docs/</code> - Add examples (<code>quickstart.md</code>) if CLI/API behavior changes - Link new pages in <code>mkdocs.yml</code></p> <p>Serve docs locally: Bash<pre><code>mkdocs serve\n</code></pre></p>"},{"location":"CONTRIBUTING/#adding-a-language-analyzer","title":"Adding a Language Analyzer","text":"<ol> <li>Create <code>&lt;language&gt;_analyzer.py</code> under <code>tenets/core/analysis/implementations/</code></li> <li>Subclass <code>LanguageAnalyzer</code></li> <li>Implement <code>match(path)</code> and <code>analyze(content)</code></li> <li>Add tests under <code>tests/core/analysis/implementations/</code></li> <li>Update <code>supported-languages.md</code></li> </ol>"},{"location":"CONTRIBUTING/#ranking-extensions","title":"Ranking Extensions","text":"<ul> <li>Register custom rankers via provided registration API (see <code>tenets/core/ranking/ranker.py</code>)</li> <li>Provide deterministic output; avoid network calls in ranking stage</li> <li>Document new algorithm flags in <code>CONFIG.md</code></li> </ul>"},{"location":"CONTRIBUTING/#performance-considerations","title":"Performance Considerations","text":"<ul> <li>Avoid O(n^2) scans over file lists when possible</li> <li>Cache expensive analysis (see existing caching layer)</li> <li>Add benchmarks if adding heavy operations (future / optional)</li> </ul>"},{"location":"CONTRIBUTING/#security--privacy","title":"Security / Privacy","text":"<ul> <li>Never exfiltrate code or send network requests without explicit user config</li> <li>Keep default extras minimal</li> </ul>"},{"location":"CONTRIBUTING/#release-process-maintainers","title":"Release Process (Maintainers)","text":"<ol> <li>Ensure <code>dev</code> is green (CI + coverage)</li> <li>Bump version: <code>cz bump</code> (updates <code>pyproject.toml</code>, tag, CHANGELOG)</li> <li>Build: <code>make build</code> (or <code>python -m build</code>)</li> <li>Publish: <code>twine upload dist/*</code></li> <li>Merge <code>dev</code> -&gt; <code>master</code> and push tags</li> </ol>"},{"location":"CONTRIBUTING/#code-of-conduct","title":"Code of Conduct","text":"<p>This project follows the Code of Conduct. By participating you agree to uphold it.</p>"},{"location":"CONTRIBUTING/#license","title":"License","text":"<p>By contributing you agree your contributions are licensed under the MIT License.</p> <p>Questions? Open an issue or reach out via Discord.</p>"},{"location":"DEPLOYMENT/","title":"Deployment Guide","text":"<p>This guide outlines the process for releasing new versions of Tenets to PyPI and deploying documentation.</p>"},{"location":"DEPLOYMENT/#release-process-automated","title":"Release Process (Automated)","text":"<p>Standard path: merge conventional commits into <code>main</code>; automation versions &amp; publishes.</p>"},{"location":"DEPLOYMENT/#how-it-works","title":"How It Works","text":"<ol> <li>Merge PR \u2192 <code>version-bump.yml</code> runs</li> <li>Determines bump size (major / minor / patch / skip) from commit messages</li> <li>Updates <code>pyproject.toml</code> + appends grouped section to <code>CHANGELOG.md</code></li> <li>Commits <code>chore(release): vX.Y.Z</code> and tags <code>vX.Y.Z</code></li> <li>Tag triggers <code>release.yml</code>: build, publish to PyPI, (future) Docker, docs deploy</li> <li>Release notes composed from changelog / draft config</li> </ol>"},{"location":"DEPLOYMENT/#bump-rules-summary","title":"Bump Rules (Summary)","text":"Commit Types Seen Result BREAKING CHANGE / <code>!</code> Major feat / perf Minor fix / refactor / chore Patch (unless higher trigger present) Only docs / test / style Skip"},{"location":"DEPLOYMENT/#manual-overrides-rare","title":"Manual Overrides (Rare)","text":"<p>If automation blocked (workflow infra outage): Bash<pre><code>git checkout main &amp;&amp; git pull\ncz bump --increment PATCH  # or MINOR / MAJOR\ngit push &amp;&amp; git push --tags\n</code></pre> Resume automation next merge.</p>"},{"location":"DEPLOYMENT/#first-release-bootstrap-v010","title":"First Release Bootstrap (v0.1.0)","text":"<p>For the initial v0.1.0 release, follow this manual process:</p> <ol> <li>Update CHANGELOG.md with v0.1.0 entries (on dev branch)</li> <li>Commit and push to dev: <code>git commit -m \"docs: update CHANGELOG for v0.1.0\"</code></li> <li>Merge dev \u2192 master</li> <li>From master, create and push tag: Bash<pre><code>git checkout master &amp;&amp; git pull\ngit tag -a v0.1.0 -m \"Release v0.1.0 - Initial public release\"\ngit push origin v0.1.0  # This triggers everything!\n</code></pre></li> <li>The tag push automatically triggers:</li> <li>GitHub Release creation with artifacts</li> <li>PyPI package publishing (if PYPI_API_TOKEN is set)</li> <li>Documentation deployment to GitHub Pages</li> </ol> <p>After v0.1.0: Automation takes over - commits trigger version bumps based on conventional commit messages.</p>"},{"location":"DEPLOYMENT/#verification-checklist","title":"Verification Checklist","text":"Step Command / Action Install published wheel <code>pip install --no-cache-dir tenets==X.Y.Z</code> CLI version matches <code>tenets --version</code> Release notes present Check GitHub Release page Docs updated Visit docs site / gh-pages commit"},{"location":"DEPLOYMENT/#troubleshooting","title":"Troubleshooting","text":"Issue Cause Resolution No tag created Only docs/test/style commits Land a fix/feat/perf commit Wrong bump size Mis-typed commit message Amend &amp; force push before merge; or follow-up commit PyPI publish failed Missing PyPI token / trust approval pending Add <code>PYPI_API_TOKEN</code> or approve trusted publisher Duplicate releases Manual tag + automated tag Avoid manual tagging unless emergency"},{"location":"DEPLOYMENT/#documentation-deployment","title":"Documentation Deployment","text":"<p>Docs are (a) built in CI on PR for validation; (b) deployed on release tag push by <code>release.yml</code> (or dedicated docs deploy step on main). GitHub Pages serves from <code>gh-pages</code>.</p>"},{"location":"DEPLOYMENT/#required--optional-secrets","title":"Required / Optional Secrets","text":"Secret Required Purpose Notes <code>PYPI_API_TOKEN</code> Yes* PyPI publish in <code>release.yml</code> *Omit if using Trusted Publishing (approve first build). <code>CODECOV_TOKEN</code> Public: often no / Private: yes Coverage uploads Set to be explicit. <code>GOOGLE_ANALYTICS_ID</code> Optional GA4 measurement ID for docs analytics Used by MkDocs Material via <code>!ENV</code> in <code>mkdocs.yml</code> (e.g., <code>G-XXXXXXXXXX</code>). If unset/empty, analytics are disabled. <code>DOCKER_USERNAME</code> / <code>DOCKER_TOKEN</code> Optional Future Docker image publishing Not required yet. <code>GH_PAT</code> No Cross-repo automation (not standard) Avoid storing if unused. <p>Environment (optional): <code>TENETS_DEBUG</code>, <code>TENETS_CACHE_DIRECTORY</code>.</p>"},{"location":"DEPLOYMENT/#google-analytics-optional","title":"Google Analytics (optional)","text":"<p>MkDocs Material analytics are wired to an environment variable:</p> <ul> <li>In <code>mkdocs.yml</code>: <code>extra.analytics.property: !ENV [GOOGLE_ANALYTICS_ID, \"\"]</code></li> <li>Provide a GA4 Measurement ID (format <code>G-XXXXXXXXXX</code>). If the variable is unset or empty, analytics are disabled automatically.</li> </ul> <p>Local usage</p> Bash<pre><code># bash / Git Bash / WSL\nexport GOOGLE_ANALYTICS_ID=G-XXXXXXXXXX\nmkdocs serve\n</code></pre> PowerShell<pre><code># PowerShell\n$env:GOOGLE_ANALYTICS_ID = 'G-XXXXXXXXXX'\nmkdocs serve\n</code></pre> <p>GitHub Actions (recommended)</p> YAML<pre><code>jobs:\n   docs:\n      runs-on: ubuntu-latest\n      env:\n         GOOGLE_ANALYTICS_ID: ${{ secrets.GOOGLE_ANALYTICS_ID }}\n      steps:\n         - uses: actions/checkout@v4\n         - uses: actions/setup-python@v5\n            with:\n               python-version: '3.12'\n         - run: pip install -e '.[docs]'\n         - run: mkdocs build --clean\n</code></pre> <p>Store your GA4 Measurement ID as a repository secret named <code>GOOGLE_ANALYTICS_ID</code>. The docs build will inject it at build time; if not present, analytics are off.</p>"},{"location":"DEPLOYMENT/#with-specific-features","title":"With specific features","text":"<p>pip install tenets[ml]  # ML features pip install tenets[viz]  # Visualization pip install tenets[all]  # Everything Text Only<pre><code>### 2. Development Installation\n\n```bash\n# From source\ngit clone https://github.com/jddunn/tenets.git\ncd tenets\npip install -e \".[dev]\"\n</code></pre></p>"},{"location":"DEPLOYMENT/#3-docker-container","title":"3. Docker Container","text":"Bash<pre><code># Pull from Docker Hub\ndocker pull tenets/tenets:latest\n\n# Run command\ndocker run --rm -v $(pwd):/workspace tenets/tenets make-context \"query\" .\n\n# Interactive shell\ndocker run -it --rm -v $(pwd):/workspace tenets/tenets bash\n</code></pre>"},{"location":"DEPLOYMENT/#4-standalone-binary","title":"4. Standalone Binary","text":"<p>Download from GitHub Releases:</p> Bash<pre><code># Linux/macOS\ncurl -L https://github.com/jddunn/tenets/releases/latest/download/tenets-linux -o tenets\nchmod +x tenets\n./tenets --version\n\n# Windows\n# Download tenets-windows.exe from releases page\n</code></pre>"},{"location":"DEPLOYMENT/#pypi-publishing","title":"PyPI Publishing","text":""},{"location":"DEPLOYMENT/#first-time-setup","title":"First-Time Setup","text":"<ol> <li>Create PyPI account:</li> <li>Register at pypi.org</li> <li> <p>Enable 2FA (required)</p> </li> <li> <p>Configure trusted publishing:</p> </li> <li>Go to your project settings on PyPI</li> <li>Add GitHub Actions as trusted publisher:<ul> <li>Owner: <code>jddunn</code></li> <li>Repository: <code>tenets</code></li> <li>Workflow: <code>release.yml</code></li> <li>Environment: <code>pypi</code></li> </ul> </li> </ol>"},{"location":"DEPLOYMENT/#manual-publishing-emergency-only","title":"Manual Publishing (Emergency Only)","text":"Bash<pre><code># Build distribution\npython -m build\n\n# Check package\ntwine check dist/*\n\n# Upload to TestPyPI first\ntwine upload --repository testpypi dist/*\n\n# Test installation\npip install --index-url https://test.pypi.org/simple/ tenets\n\n# Upload to PyPI\ntwine upload dist/*\n</code></pre>"},{"location":"DEPLOYMENT/#docker-deployment","title":"Docker Deployment","text":""},{"location":"DEPLOYMENT/#building-images","title":"Building Images","text":"Docker<pre><code># Dockerfile\nFROM python:3.11-slim\n\n# Install system dependencies\nRUN apt-get update &amp;&amp; apt-get install -y \\\n    git \\\n    &amp;&amp; rm -rf /var/lib/apt/lists/*\n\n# Create non-root user\nRUN useradd -m -s /bin/bash tenets\n\n# Set working directory\nWORKDIR /app\n\n# Install tenets\nCOPY requirements.txt .\nRUN pip install --no-cache-dir -r requirements.txt\n\nCOPY . .\nRUN pip install --no-cache-dir -e .\n\n# Switch to non-root user\nUSER tenets\n\n# Set entrypoint\nENTRYPOINT [\"tenets\"]\n</code></pre>"},{"location":"DEPLOYMENT/#multi-architecture-build","title":"Multi-Architecture Build","text":"Bash<pre><code># Setup buildx\ndocker buildx create --use\n\n# Build for multiple platforms\ndocker buildx build \\\n  --platform linux/amd64,linux/arm64 \\\n  --tag tenets/tenets:latest \\\n  --tag tenets/tenets:v0.1.0 \\\n  --push .\n</code></pre>"},{"location":"DEPLOYMENT/#docker-compose","title":"Docker Compose","text":"YAML<pre><code># docker-compose.yml\nversion: '3.8'\n\nservices:\n  tenets:\n    image: tenets/tenets:latest\n    volumes:\n      - .:/workspace\n      - ~/.tenets:/home/tenets/.tenets\n    working_dir: /workspace\n    environment:\n      - TENETS_LOG_LEVEL=INFO\n    command: make-context \"implement feature\" .\n</code></pre>"},{"location":"DEPLOYMENT/#binary-distribution","title":"Binary Distribution","text":""},{"location":"DEPLOYMENT/#building-binaries","title":"Building Binaries","text":"Bash<pre><code># Install PyInstaller\npip install pyinstaller\n\n# Build for current platform\npyinstaller \\\n  --onefile \\\n  --name tenets \\\n  --add-data \"tenets:tenets\" \\\n  --hidden-import tenets.core \\\n  --hidden-import tenets.models \\\n  --hidden-import tenets.utils \\\n  tenets/__main__.py\n\n# Output in dist/tenets\n</code></pre>"},{"location":"DEPLOYMENT/#cross-platform-building","title":"Cross-Platform Building","text":"<p>Use GitHub Actions for multi-platform builds: - Linux: Ubuntu runner - macOS: macOS runner - Windows: Windows runner</p>"},{"location":"DEPLOYMENT/#code-signing-optional","title":"Code Signing (Optional)","text":"Bash<pre><code># macOS\ncodesign --deep --force --verify --verbose \\\n  --sign \"Developer ID Application: Your Name\" \\\n  dist/tenets\n\n# Windows (using signtool)\nsigntool sign /t http://timestamp.digicert.com dist/tenets.exe\n</code></pre>"},{"location":"DEPLOYMENT/#documentation-deployment_1","title":"Documentation Deployment","text":""},{"location":"DEPLOYMENT/#building-documentation","title":"Building Documentation","text":"Bash<pre><code># Install dependencies\npip install -e \".[docs]\"\n\n# Build docs\nmkdocs build\n\n# Test locally\nmkdocs serve\n</code></pre>"},{"location":"DEPLOYMENT/#versioned-documentation","title":"Versioned Documentation","text":"Bash<pre><code># Deploy new version\nmike deploy --push --update-aliases 0.1.0 latest\n\n# Deploy development docs\nmike deploy --push dev\n\n# Set default version\nmike set-default --push latest\n</code></pre>"},{"location":"DEPLOYMENT/#github-pages-setup","title":"GitHub Pages Setup","text":"<ol> <li>Enable GitHub Pages in repository settings</li> <li>Set source to <code>gh-pages</code> branch</li> <li>Documentation auto-deploys on release</li> </ol>"},{"location":"DEPLOYMENT/#security-considerations","title":"Security Considerations","text":""},{"location":"DEPLOYMENT/#release-security","title":"Release Security","text":"<ol> <li> <p>Sign commits and tags:    Bash<pre><code>git config --global commit.gpgsign true\ngit config --global tag.gpgsign true\n</code></pre></p> </li> <li> <p>Verify dependencies:    Bash<pre><code># Check for vulnerabilities\nsafety check\n\n# Audit dependencies\npip-audit\n</code></pre></p> </li> <li> <p>Scan for secrets:    Bash<pre><code># Pre-release scan\ndetect-secrets scan --all-files\n</code></pre></p> </li> </ol>"},{"location":"DEPLOYMENT/#deployment-security","title":"Deployment Security","text":"<ol> <li> <p>Use minimal base images:    Docker<pre><code>FROM python:3.11-slim  # Not full python image\n</code></pre></p> </li> <li> <p>Run as non-root:    Docker<pre><code>USER nobody\n</code></pre></p> </li> <li> <p>Scan images:    Bash<pre><code># Scan for vulnerabilities\ndocker scan tenets/tenets:latest\n</code></pre></p> </li> </ol>"},{"location":"DEPLOYMENT/#monitoring--maintenance","title":"Monitoring &amp; Maintenance","text":""},{"location":"DEPLOYMENT/#release-monitoring","title":"Release Monitoring","text":"<ol> <li>PyPI Statistics:</li> <li>Check download stats</li> <li> <p>Monitor for unusual activity</p> </li> <li> <p>GitHub Insights:</p> </li> <li>Track clone/download metrics</li> <li> <p>Monitor issue trends</p> </li> <li> <p>Error Tracking:</p> </li> <li>Set up Sentry (optional)</li> <li>Monitor GitHub issues</li> </ol>"},{"location":"DEPLOYMENT/#maintenance-tasks","title":"Maintenance Tasks","text":""},{"location":"DEPLOYMENT/#weekly","title":"Weekly","text":"<ul> <li>Review and triage issues</li> <li>Check for security advisories</li> <li>Update dependencies</li> </ul>"},{"location":"DEPLOYMENT/#monthly","title":"Monthly","text":"<ul> <li>Review performance metrics</li> <li>Update documentation</li> <li>Clean up old releases</li> </ul>"},{"location":"DEPLOYMENT/#quarterly","title":"Quarterly","text":"<ul> <li>Major dependency updates</li> <li>Security audit</li> <li>Performance benchmarking</li> </ul>"},{"location":"DEPLOYMENT/#rollback-procedure","title":"Rollback Procedure","text":"<p>If a release has critical issues:</p> <ol> <li> <p>Yank from PyPI (last resort):    Bash<pre><code># This prevents new installations\n# Existing installations continue to work\ntwine yank tenets==0.1.0\n</code></pre></p> </li> <li> <p>Create hotfix:    Bash<pre><code>git checkout -b hotfix/critical-bug\n# Fix issue\ngit commit -m \"fix: critical bug in analyzer\"\ncz bump --increment PATCH\ngit push origin hotfix/critical-bug\n</code></pre></p> </li> <li> <p>Fast-track release:</p> </li> <li>Create PR with hotfix</li> <li>Bypass normal review (emergency)</li> <li>Merge and tag immediately</li> </ol>"},{"location":"DEPLOYMENT/#deployment-environments","title":"Deployment Environments","text":""},{"location":"DEPLOYMENT/#development","title":"Development","text":"Bash<pre><code>pip install -e \".[dev]\"\nexport TENETS_ENV=development\n</code></pre>"},{"location":"DEPLOYMENT/#staging","title":"Staging","text":"Bash<pre><code>pip install tenets==0.1.0rc1  # Release candidate\nexport TENETS_ENV=staging\n</code></pre>"},{"location":"DEPLOYMENT/#production","title":"Production","text":"Bash<pre><code>pip install tenets==0.1.0\nexport TENETS_ENV=production\n</code></pre>"},{"location":"DEPLOYMENT/#troubleshooting_1","title":"Troubleshooting","text":""},{"location":"DEPLOYMENT/#common-issues","title":"Common Issues","text":"<ol> <li>PyPI upload fails:</li> <li>Check PyPI status</li> <li>Verify credentials</li> <li> <p>Ensure version doesn't exist</p> </li> <li> <p>Docker build fails:</p> </li> <li>Clear builder cache</li> <li>Check Docker Hub limits</li> <li> <p>Verify multi-arch support</p> </li> <li> <p>Documentation not updating:</p> </li> <li>Check GitHub Pages settings</li> <li>Verify mike configuration</li> <li>Clear browser cache</li> </ol>"},{"location":"DEPLOYMENT/#getting-help","title":"Getting Help","text":"<ul> <li>GitHub Issues for bugs</li> <li>Discussions for questions</li> <li>team@tenets.dev for security issues</li> </ul> <p>Remember: Every release should make developers' lives easier. \ud83d\ude80</p>"},{"location":"DEVELOPMENT/","title":"Development Guide","text":"<p>This guide provides instructions for setting up your development environment, running tests, and contributing to the Tenets project.</p>"},{"location":"DEVELOPMENT/#1-initial-setup","title":"1. Initial Setup","text":""},{"location":"DEVELOPMENT/#prerequisites","title":"Prerequisites","text":"<ul> <li>Python 3.9+</li> <li>Git</li> <li>An activated Python virtual environment (e.g., <code>venv</code>, <code>conda</code>).</li> </ul>"},{"location":"DEVELOPMENT/#fork-and-clone","title":"Fork and Clone","text":"<ol> <li>Fork the repository on GitHub.</li> <li>Clone your fork locally:    Bash<pre><code>git clone https://github.com/jddunn/tenets.git\ncd tenets\n</code></pre></li> </ol>"},{"location":"DEVELOPMENT/#install-dependencies","title":"Install Dependencies","text":"<p>Install the project in \"editable\" mode along with all development dependencies. This allows you to modify the source code and have the changes immediately reflected.</p> <p>Bash<pre><code>pip install -e \".[all,dev]\"\n</code></pre> This command installs everything needed for development, including core dependencies, optional features (<code>all</code>), and development tools (<code>dev</code>).</p>"},{"location":"DEVELOPMENT/#set-up-pre-commit-hooks","title":"Set up Pre-Commit Hooks","text":"<p>This project uses <code>pre-commit</code> to automatically run linters and formatters before each commit.</p> Bash<pre><code>pre-commit install\n</code></pre>"},{"location":"DEVELOPMENT/#alternative-installs","title":"Alternative Installs","text":"<p>If you only need core + dev tooling (faster): Bash<pre><code>pip install -e \".[dev]\"\n</code></pre> If you need a minimal footprint for quick iteration (no optional extras): Bash<pre><code>pip install -e .\n</code></pre></p>"},{"location":"DEVELOPMENT/#verifying-the-cli","title":"Verifying the CLI","text":"Bash<pre><code>tenets --version\ntenets --help | head\n</code></pre> <p>If the command is not found, ensure your virtualenv is activated and that the <code>scripts</code> (Windows) or <code>bin</code> (Unix) directory is on PATH.</p>"},{"location":"DEVELOPMENT/#11-building-distribution-artifacts-optional","title":"1.1 Building Distribution Artifacts (Optional)","text":"<p>You typically do NOT need to build wheels / sdists for day\u2011to\u2011day development; the editable install auto-reflects code edits. Build only when testing packaging or release steps.</p> Bash<pre><code>python -m build               # creates dist/*.whl and dist/*.tar.gz\npip install --force-reinstall dist/tenets-*.whl  # sanity check install\n</code></pre> <p>To inspect what went into the wheel: Bash<pre><code>unzip -l dist/tenets-*.whl | grep analysis/implementations | head\n</code></pre></p>"},{"location":"DEVELOPMENT/#12-clean-environment-tasks","title":"1.2 Clean Environment Tasks","text":"Bash<pre><code>pip cache purge        # optional: clear wheel cache\nfind . -name \"__pycache__\" -exec rm -rf {} +\nrm -rf .pytest_cache .ruff_cache .mypy_cache build dist *.egg-info\n</code></pre>"},{"location":"DEVELOPMENT/#13-using-poetry-instead-of-pip-optional","title":"1.3 Using Poetry Instead of pip (Optional)","text":"<p>Poetry can manage the virtual environment and extras if you prefer: Bash<pre><code>poetry install -E all -E dev   # full feature + dev toolchain\npoetry run pytest              # run tests\npoetry run tenets --help       # invoke CLI\n</code></pre> Update dependencies: Bash<pre><code>poetry update\n</code></pre> Add a new optional dependency (example): Bash<pre><code>poetry add --optional rich\n</code></pre> Text Only<pre><code>## 2. Running Tests\n\nThe test suite uses `pytest`. We have a comprehensive configuration in `pytest.ini` that handles most settings automatically.\n\n### Running All Tests\nTo run the entire test suite:\n```bash\npytest\n</code></pre></p>"},{"location":"DEVELOPMENT/#running-tests-with-coverage","title":"Running Tests with Coverage","text":"<p>To generate a test coverage report: Bash<pre><code>pytest --cov\n</code></pre> This command is configured in <code>pytest.ini</code> to: - Measure coverage for the <code>tenets</code> package. - Generate reports in the terminal, as XML (<code>coverage.xml</code>), and as a detailed HTML report (<code>htmlcov/</code>). - Fail the build if coverage drops below 70%.</p> <p>To view the interactive HTML report: Bash<pre><code># On macOS\nopen htmlcov/index.html\n\n# On Windows\nstart htmlcov/index.html\n\n# On Linux\nxdg-open htmlcov/index.html\n</code></pre></p>"},{"location":"DEVELOPMENT/#3-required--optional-secrets","title":"3. Required / Optional Secrets","text":"<p>Configure these in GitHub: Settings \u2192 Secrets and variables \u2192 Actions.</p> Secret Required? Purpose Notes <code>PYPI_API_TOKEN</code> Yes* Upload package in <code>release.yml</code> *If using PyPI Trusted Publishing you can omit and approve first publication manually. Keep token while bootstrapping. <code>CODECOV_TOKEN</code> Yes (private repo) / No (public) Coverage uploads in CI Public repos sometimes auto-detect; set to be explicit. <code>DOCKER_USERNAME</code> Optional Auth for Docker image push (if enabled) Only needed if/when container publishing is turned on. <code>DOCKER_TOKEN</code> Optional Password / token for Docker Hub Pair with username. <code>GH_PAT</code> No Only for advanced workflows (e.g. cross\u2011repo automation) Not needed for standard release pipeline. <p>Additional environment driven configs (rarely needed): | Variable | Effect | |----------|-------| | <code>TENETS_CACHE_DIRECTORY</code> | Override default cache directory | | <code>TENETS_DEBUG</code> | Enables verbose debug logging when <code>true</code> |</p> <p>Security tips: - Grant least privilege (PyPI token scoped to project if possible) - Rotate any credentials annually or on role changes - Prefer Trusted Publishing over long\u2011lived API tokens once stable</p>"},{"location":"DEVELOPMENT/#4-code-style-and-linting","title":"4. Code Style and Linting","text":"<p>We use <code>ruff</code> for linting and formatting. The pre-commit hook runs it automatically, but you can also run it manually:</p> Bash<pre><code># Check for linting errors\nruff check .\n\n# Automatically fix linting errors\nruff check . --fix\n\n# Format the code\nruff format .\n</code></pre>"},{"location":"DEVELOPMENT/#5-building-documentation","title":"5. Building Documentation","text":"<p>The documentation is built using MkDocs with the Material theme.</p>"},{"location":"DEVELOPMENT/#installing-documentation-dependencies","title":"Installing Documentation Dependencies","text":"Bash<pre><code># Install MkDocs and theme\npip install mkdocs mkdocs-material\n\n# Or if you installed with dev dependencies, it's already included:\npip install -e \".[dev]\"\n</code></pre>"},{"location":"DEVELOPMENT/#serving-documentation-locally","title":"Serving Documentation Locally","text":""},{"location":"DEVELOPMENT/#fast-development-mode-recommended-for-editing-docs","title":"FAST Development Mode (Recommended for editing docs)","text":"Bash<pre><code># Use the lightweight dev config with dirty reload for FASTEST iteration\nmkdocs serve -f mkdocs.dev.yml --dirtyreload\n\n# Without dirty reload (still faster than full build)\nmkdocs serve -f mkdocs.dev.yml\n</code></pre> <p>mkdocs.dev.yml differences: - Disables heavy plugins: No API generation, no mkdocstrings, no minification - Faster rebuilds: Skips expensive operations - Dirty reload: Only rebuilds changed pages (not entire site) - Perfect for: Writing/editing documentation content</p>"},{"location":"DEVELOPMENT/#full-production-mode-for-testing-final-output","title":"Full Production Mode (for testing final output)","text":"Bash<pre><code># Full build with all features including API docs generation\nmkdocs serve\n\n# Serve on a different port\nmkdocs serve -a localhost:8080\n\n# Serve with verbose output for debugging\nmkdocs serve --verbose\n\n# With clean rebuild\nmkdocs serve --clean\n</code></pre> <p>The development server includes: - Live reload: Changes to docs files automatically refresh the browser - API docs generation: Auto-generates from Python docstrings - Full theme features: All navigation and search features enabled</p>"},{"location":"DEVELOPMENT/#building-static-documentation","title":"Building Static Documentation","text":"Bash<pre><code># Build the static site to site/ directory\nmkdocs build\n\n# Build with strict mode (fails on warnings)\nmkdocs build --strict\n\n# Build with verbose output\nmkdocs build --verbose\n\n# Clean build (removes old files first)\nmkdocs build --clean\n</code></pre>"},{"location":"DEVELOPMENT/#documentation-structure","title":"Documentation Structure","text":"Text Only<pre><code>docs/\n\u251c\u2500\u2500 index.md           # Homepage\n\u251c\u2500\u2500 overrides/        # Custom HTML templates\n\u2502   \u2514\u2500\u2500 home.html     # Custom homepage\n\u251c\u2500\u2500 styles/           # Custom CSS\n\u2502   \u251c\u2500\u2500 main.css\n\u2502   \u251c\u2500\u2500 search.css\n\u2502   \u2514\u2500\u2500 ...\n\u251c\u2500\u2500 assets/           # Images and screenshots\n\u2502   \u2514\u2500\u2500 images/\n\u2514\u2500\u2500 *.md             # Documentation pages\n</code></pre>"},{"location":"DEVELOPMENT/#api-documentation-generation","title":"API Documentation Generation","text":"<p>The API documentation is auto-generated from Python docstrings using <code>mkdocstrings</code> and <code>gen-files</code> plugins.</p>"},{"location":"DEVELOPMENT/#how-it-works","title":"How it works:","text":"<ol> <li><code>docs/gen_api.py</code> script runs during build:</li> <li>Scans all Python modules in <code>tenets/</code></li> <li>Generates markdown files with <code>:::</code> mkdocstrings syntax</li> <li> <p>Creates navigation structure in <code>api/</code> directory</p> </li> <li> <p><code>mkdocstrings</code> plugin processes the generated files:</p> </li> <li>Extracts docstrings from Python code</li> <li>Renders them as formatted documentation</li> <li>Includes type hints, parameters, returns, examples</li> </ol>"},{"location":"DEVELOPMENT/#regenerating-api-docs","title":"Regenerating API docs:","text":"Bash<pre><code># Full build with API generation (automatic)\nmkdocs build\n\n# Or serve with API generation\nmkdocs serve  # Uses mkdocs.yml which has gen-files enabled\n\n# Skip API generation for faster dev\nmkdocs serve -f mkdocs.dev.yml --dirtyreload\n</code></pre>"},{"location":"DEVELOPMENT/#writing-good-docstrings-for-api-docs","title":"Writing Good Docstrings for API docs:","text":"Python<pre><code>def example_function(param1: str, param2: int = 0) -&gt; bool:\n    \"\"\"Short summary of what this function does.\n\n    Longer description with more details about the function's\n    behavior, use cases, and any important notes.\n\n    Args:\n        param1: Description of first parameter\n        param2: Description of second parameter (default: 0)\n\n    Returns:\n        Description of return value\n\n    Raises:\n        ValueError: When something goes wrong\n\n    Example:\n        &gt;&gt;&gt; example_function(\"test\", 42)\n        True\n    \"\"\"\n</code></pre>"},{"location":"DEVELOPMENT/#making-documentation-changes","title":"Making Documentation Changes","text":"<ol> <li>For content/markdown: Edit files in <code>docs/</code> directory</li> <li>For API docs: Update docstrings in Python source files</li> <li>Preview changes:</li> <li>Fast: <code>mkdocs serve -f mkdocs.dev.yml --dirtyreload</code></li> <li>Full: <code>mkdocs serve</code></li> <li>Test the build: <code>mkdocs build --strict</code></li> <li>Check for broken links in the browser console</li> </ol>"},{"location":"DEVELOPMENT/#deploying-documentation","title":"Deploying Documentation","text":"Bash<pre><code># Deploy to GitHub Pages (requires push permissions)\nmkdocs gh-deploy\n\n# Deploy with custom commit message\nmkdocs gh-deploy -m \"Update documentation\"\n\n# Deploy without pushing (dry run)\nmkdocs gh-deploy --no-push\n</code></pre> <p>The site will be available at <code>https://[username].github.io/tenets/</code>.</p>"},{"location":"DEVELOPMENT/#2-making-changes","title":"2. Making Changes","text":"<p>Follow the coding standards: - Write clean, readable code - Add comprehensive docstrings (Google style) - Include type hints for all functions - Write tests for new functionality</p>"},{"location":"DEVELOPMENT/#3-committing-changes","title":"3. Committing Changes","text":"<p>We use Conventional Commits:</p> Bash<pre><code># Interactive commit\nmake commit  # or: cz commit\n\n# Manual commit (must follow format)\ngit commit -m \"feat(analyzer): add support for Rust AST parsing\"\n</code></pre> <p>Commit types: - <code>feat</code>: New feature - <code>fix</code>: Bug fix - <code>docs</code>: Documentation changes - <code>style</code>: Code style changes (formatting) - <code>refactor</code>: Code refactoring - <code>perf</code>: Performance improvements - <code>test</code>: Test additions or changes - <code>chore</code>: Maintenance tasks</p>"},{"location":"DEVELOPMENT/#4-running-tests","title":"4. Running Tests","text":"Bash<pre><code># Run all tests\nmake test\n\n# Run fast tests only\nmake test-fast\n\n# Run specific test file\npytest tests/test_analyzer.py\n\n# Run with coverage\npytest --cov=tenets --cov-report=html\n</code></pre>"},{"location":"DEVELOPMENT/#5-code-quality-checks","title":"5. Code Quality Checks","text":"Bash<pre><code># Run all checks\nmake lint\n\n# Auto-format code\nmake format\n\n# Individual tools\nblack .\nisort .\nruff check .\nmypy tenets --strict\nbandit -r tenets\n</code></pre>"},{"location":"DEVELOPMENT/#6-pushing-changes","title":"6. Pushing Changes","text":"Bash<pre><code># Pre-commit hooks will run automatically\ngit push origin feature/your-feature-name\n</code></pre>"},{"location":"DEVELOPMENT/#7-creating-a-pull-request","title":"7. Creating a Pull Request","text":"<ol> <li>Go to GitHub and create a PR</li> <li>Fill out the PR template</li> <li>Ensure all CI checks pass</li> <li>Request review from maintainers</li> </ol>"},{"location":"DEVELOPMENT/#testing","title":"Testing","text":""},{"location":"DEVELOPMENT/#test-structure","title":"Test Structure","text":"Text Only<pre><code>tests/\n\u251c\u2500\u2500 unit/              # Unit tests\n\u2502   \u251c\u2500\u2500 test_analyzer.py\n\u2502   \u251c\u2500\u2500 test_nlp.py\n\u2502   \u2514\u2500\u2500 test_scanner.py\n\u251c\u2500\u2500 integration/       # Integration tests\n\u2502   \u251c\u2500\u2500 test_cli.py\n\u2502   \u2514\u2500\u2500 test_workflow.py\n\u251c\u2500\u2500 fixtures/         # Test data\n\u2502   \u2514\u2500\u2500 sample_repo/\n\u2514\u2500\u2500 conftest.py      # Pytest configuration\n</code></pre>"},{"location":"DEVELOPMENT/#writing-tests","title":"Writing Tests","text":"Python<pre><code>\"\"\"Test module for analyzer functionality.\"\"\"\n\nimport pytest\nfrom tenets.core.analysis import CodeAnalyzer\n\n\nclass TestCodeAnalyzer:\n    \"\"\"Test suite for CodeAnalyzer.\"\"\"\n\n    @pytest.fixture\n    def analyzer(self):\n        \"\"\"Create analyzer instance.\"\"\"\n        return CodeAnalyzer()\n\n    def test_analyze_python_file(self, analyzer, tmp_path):\n        \"\"\"Test Python file analysis.\"\"\"\n        # Create test file\n        test_file = tmp_path / \"test.py\"\n        test_file.write_text(\"def hello():\\n    return 'world'\")\n\n        # Analyze\n        result = analyzer.analyze_file(test_file)\n\n        # Assertions\n        assert result.language == \"python\"\n        assert len(result.functions) == 1\n        assert result.functions[0][\"name\"] == \"hello\"\n</code></pre>"},{"location":"DEVELOPMENT/#test-markers","title":"Test Markers","text":"Bash<pre><code># Run only unit tests\npytest -m unit\n\n# Skip slow tests\npytest -m \"not slow\"\n\n# Run tests requiring git\npytest -m requires_git\n</code></pre>"},{"location":"DEVELOPMENT/#code-quality","title":"Code Quality","text":""},{"location":"DEVELOPMENT/#style-guide","title":"Style Guide","text":"<p>We follow PEP 8 with these modifications: - Line length: 100 characters - Use Black for formatting - Use Google-style docstrings</p>"},{"location":"DEVELOPMENT/#type-hints","title":"Type Hints","text":"<p>All functions must have type hints:</p> Python<pre><code>from typing import List, Optional, Dict, Any\n\n\ndef analyze_files(\n    paths: List[Path],\n    deep: bool = False,\n    max_workers: Optional[int] = None\n) -&gt; Dict[str, Any]:\n    \"\"\"\n    Analyze multiple files in parallel.\n\n    Args:\n        paths: List of file paths to analyze\n        deep: Whether to perform deep analysis\n        max_workers: Maximum number of parallel workers\n\n    Returns:\n        Dictionary containing analysis results\n    \"\"\"\n    ...\n</code></pre>"},{"location":"DEVELOPMENT/#docstrings","title":"Docstrings","text":"<p>Use Google-style docstrings:</p> Python<pre><code>def calculate_relevance(\n    file: FileAnalysis,\n    prompt: PromptContext,\n    algorithm: str = \"balanced\"\n) -&gt; float:\n    \"\"\"\n    Calculate relevance score for a file.\n\n    Uses multi-factor scoring to determine how relevant a file is\n    to the given prompt context.\n\n    Args:\n        file: Analyzed file data\n        prompt: Parsed prompt context\n        algorithm: Ranking algorithm to use\n\n    Returns:\n        Relevance score between 0.0 and 1.0\n\n    Raises:\n        ValueError: If algorithm is not recognized\n\n    Example:\n        &gt;&gt;&gt; relevance = calculate_relevance(file, prompt, \"thorough\")\n        &gt;&gt;&gt; print(f\"Relevance: {relevance:.2f}\")\n        0.85\n    \"\"\"\n    ...\n</code></pre>"},{"location":"DEVELOPMENT/#documentation","title":"Documentation","text":""},{"location":"DEVELOPMENT/#building-documentation","title":"Building Documentation","text":"Bash<pre><code># Build docs\nmake docs\n\n# Serve locally\nmake serve-docs\n# Visit http://localhost:8000\n</code></pre>"},{"location":"DEVELOPMENT/#writing-documentation","title":"Writing Documentation","text":"<ol> <li>API Documentation: Auto-generated from docstrings</li> <li>User Guides: Written in Markdown in <code>docs/</code></li> <li>Examples: Include code examples in docstrings</li> </ol>"},{"location":"DEVELOPMENT/#documentation-standards","title":"Documentation Standards","text":"<ul> <li>Use clear, concise language</li> <li>Include code examples</li> <li>Add diagrams where helpful</li> <li>Keep it up-to-date with code changes</li> </ul>"},{"location":"DEVELOPMENT/#debugging","title":"Debugging","text":""},{"location":"DEVELOPMENT/#debug-mode","title":"Debug Mode","text":"Bash<pre><code># Enable debug logging\nexport TENETS_DEBUG=true\ntenets make-context \"test\" . --verbose\n\n# Or in code\nimport logging\nlogging.basicConfig(level=logging.DEBUG)\n</code></pre>"},{"location":"DEVELOPMENT/#using-vs-code","title":"Using VS Code","text":"<p><code>.vscode/launch.json</code>: JSON<pre><code>{\n    \"version\": \"0.2.0\",\n    \"configurations\": [\n        {\n            \"name\": \"Debug tenets CLI\",\n            \"type\": \"python\",\n            \"request\": \"launch\",\n            \"module\": \"tenets.cli.main\",\n            \"args\": [\"make-context\", \"test query\", \".\"],\n            \"console\": \"integratedTerminal\"\n        }\n    ]\n}\n</code></pre></p>"},{"location":"DEVELOPMENT/#common-issues","title":"Common Issues","text":"<ol> <li>Import errors: Ensure you've installed in development mode (<code>pip install -e .</code>)</li> <li>Type errors: Run <code>mypy</code> to catch type issues</li> <li>Test failures: Check if you need to install optional dependencies</li> </ol>"},{"location":"DEVELOPMENT/#contributing-guidelines","title":"Contributing Guidelines","text":""},{"location":"DEVELOPMENT/#before-you-start","title":"Before You Start","text":"<ol> <li>Check existing issues and PRs</li> <li>Open an issue to discuss large changes</li> <li>Read the architecture documentation</li> </ol>"},{"location":"DEVELOPMENT/#code-review-checklist","title":"Code Review Checklist","text":"<ul> <li> Tests pass locally</li> <li> Code is formatted (black, isort)</li> <li> Type hints are present</li> <li> Docstrings are complete</li> <li> Tests cover new functionality</li> <li> Documentation is updated</li> <li> Commit messages follow convention</li> <li> No security issues (bandit)</li> </ul>"},{"location":"DEVELOPMENT/#getting-help","title":"Getting Help","text":"<ul> <li>Open an issue for bugs</li> <li>Start a discussion for features</li> <li>Join our Discord (coming soon)</li> <li>Email: team@tenets.dev</li> </ul>"},{"location":"DEVELOPMENT/#release--versioning","title":"Release &amp; Versioning","text":"<p>Releases are automated. Merging conventional commits into <code>main</code> (from PRs) is all you normally do.</p>"},{"location":"DEVELOPMENT/#branch-model","title":"Branch Model","text":"Branch Purpose <code>dev</code> (or feature branches) Integration / iterative work <code>main</code> Always releasable; auto-versioned on merge"},{"location":"DEVELOPMENT/#workflows-high-level","title":"Workflows (high level)","text":"<ol> <li>PR merged into <code>main</code>.</li> <li><code>version-bump.yml</code> runs:<ul> <li>Collects commits since last tag</li> <li>Determines next version:</li> <li>Major: commit body contains <code>BREAKING CHANGE:</code> or type suffixed with <code>!</code></li> <li>Minor: at least one <code>feat:</code> or <code>perf:</code> commit (performance treated as minor to signal impact)</li> <li>Patch: any <code>fix</code>, <code>refactor</code>, <code>chore</code> (unless a higher bump already chosen)</li> <li>Skip: only docs / test / style commits (no release)</li> <li>Updates <code>pyproject.toml</code></li> <li>Appends a section to <code>CHANGELOG.md</code> grouping commits (Features / Performance / Fixes / Refactoring / Chore)</li> <li>Commits with message <code>chore(release): vX.Y.Z</code> and creates annotated tag <code>vX.Y.Z</code></li> </ul> </li> <li>Tag push triggers <code>release.yml</code>:<ul> <li>Builds wheel + sdist</li> <li>Publishes to PyPI (token or Trusted Publishing)</li> <li>(Optional) Builds &amp; publishes Docker image (future enablement)</li> <li>Deploys docs (if configured) / updates site</li> </ul> </li> <li><code>release-drafter</code> (config) ensures GitHub Release notes reflect categorized changes (either via draft or final publish depending on config state).</li> </ol> <p>You do NOT run <code>cz bump</code> manually during normal flow; the workflow handles versioning.</p>"},{"location":"DEVELOPMENT/#conventional-commit-expectations","title":"Conventional Commit Expectations","text":"<p>Use clear scopes where possible: Text Only<pre><code>feat(ranking): add semantic similarity signal\nfix(cli): prevent crash on empty directory\nperf(analyzer): cache parsed ASTs\nrefactor(config): simplify loading logic\ndocs: update quickstart for --copy flag\n</code></pre></p> <p>Edge cases: - Multiple commit types: highest precedence decides (major &gt; minor &gt; patch) - Mixed docs + fix: still releases (fix wins) - Only docs/test/style: skipped; no tag produced</p>"},{"location":"DEVELOPMENT/#first-release-bootstrap","title":"First Release (Bootstrap)","text":"<p>If no existing tag: 1. Merge initial feature set into <code>main</code> 2. Push a commit with <code>feat: initial release</code> (or similar) 3. Workflow sets version to <code>0.1.0</code> (or bump logic starting point defined in workflow)</p> <p>If you need a different starting version (e.g. <code>0.3.0</code>): create an annotated tag manually once, then subsequent merges resume automation.</p>"},{"location":"DEVELOPMENT/#manual--emergency-release","title":"Manual / Emergency Release","text":"<p>Only when automation is blocked: Bash<pre><code>git checkout main &amp;&amp; git pull\ncz bump --increment PATCH  # or MINOR / MAJOR\ngit push &amp;&amp; git push --tags\n</code></pre> Monitor <code>release.yml</code>. After resolution, revert to automated flow.</p>"},{"location":"DEVELOPMENT/#verifying-a-release","title":"Verifying a Release","text":"<p>After automation completes: Bash<pre><code>pip install --no-cache-dir tenets==&lt;new_version&gt;\ntenets --version\n</code></pre> Smoke test a core command: Bash<pre><code>tenets distill \"smoke\" . --max-tokens 2000 --mode fast --stats || true\n</code></pre></p>"},{"location":"DEVELOPMENT/#troubleshooting","title":"Troubleshooting","text":"Symptom Likely Cause Fix No new tag after merge Only docs/test/style commits Land a non-skipped commit (e.g. fix) Wrong bump size Commit type misclassified Amend / add corrective commit (e.g. feat) PyPI publish failed Missing / invalid <code>PYPI_API_TOKEN</code> or Trusted Publishing not approved yet Add token or approve in PyPI UI Changelog missing section Commit type not in allowed list Ensure conventional type used Duplicate release notes Manual tag + automated tag Avoid manual tagging except emergencies"},{"location":"DEVELOPMENT/#philosophy","title":"Philosophy","text":"<p>Keep <code>main</code> always shippable. Small, frequent releases reduce risk and keep context fresh for users.</p>"},{"location":"DEVELOPMENT/#advanced-topics","title":"Advanced Topics","text":""},{"location":"DEVELOPMENT/#adding-a-new-language-analyzer","title":"Adding a New Language Analyzer","text":"<ol> <li> <p>Create analyzer in <code>tenets/core/analysis/</code>:    Python<pre><code>class RustAnalyzer(LanguageAnalyzer):\n    language_name = \"rust\"\n\n    def extract_imports(self, content: str) -&gt; List[Import]:\n        # Implementation\n        ...\n</code></pre></p> </li> <li> <p>Register in <code>analysis/analyzer.py</code>:    Python<pre><code>analyzers['.rs'] = RustAnalyzer()\n</code></pre></p> </li> <li> <p>Add tests in <code>tests/unit/test_rust_analyzer.py</code></p> </li> </ol>"},{"location":"DEVELOPMENT/#creating-custom-ranking-algorithms","title":"Creating Custom Ranking Algorithms","text":"<ol> <li> <p>Implement algorithm:    Python<pre><code>class SecurityRanking:\n    def score_file(self, file, prompt):\n        # Custom scoring logic\n        ...\n</code></pre></p> </li> <li> <p>Register algorithm:    Python<pre><code>@register_algorithm(\"security\")\nclass SecurityRanking:\n    ...\n</code></pre></p> </li> <li> <p>Document usage in <code>docs/api.md</code></p> </li> </ol> <p>Happy coding! \ud83d\ude80 Remember: context is everything.</p>"},{"location":"SECURITY/","title":"Security Policy","text":""},{"location":"SECURITY/#supported-versions","title":"Supported Versions","text":"<p>The project is pre-1.0; security fixes are applied to the latest released version. Older versions may not receive backports.</p>"},{"location":"SECURITY/#reporting-a-vulnerability","title":"Reporting a Vulnerability","text":"<p>Email: security@tenets.dev (or team@tenets.dev if unreachable)</p> <p>Please include: - Description of the issue - Steps to reproduce / proof-of-concept - Potential impact / affected components - Your environment (OS, Python, tenets version)</p> <p>We aim to acknowledge within 3 business days and provide a remediation ETA after triage.</p>"},{"location":"SECURITY/#responsible-disclosure","title":"Responsible Disclosure","text":"<p>Do not open public issues for exploitable vulnerabilities. Use the private email above. We will coordinate disclosure and credit (if desired) after a fix is released.</p>"},{"location":"SECURITY/#scope","title":"Scope","text":"<p>Tenets runs locally. Primary concerns: - Arbitrary code execution via file parsing - Directory traversal / path injection - Insecure temporary file handling - Leakage of private repository data beyond intended output</p> <p>Out of scope: - Issues requiring malicious local user privilege escalation - Vulnerabilities in optional third-party dependencies (report upstream)</p>"},{"location":"SECURITY/#security-best-practices-users","title":"Security Best Practices (Users)","text":"<ul> <li>Pin versions in production workflows</li> <li>Run latest patch release</li> <li>Review output before sharing externally</li> <li>Avoid running against untrusted repositories without isolation (use containers)</li> </ul>"},{"location":"SECURITY/#patching-process","title":"Patching Process","text":"<ol> <li>Triage &amp; reproduce</li> <li>Develop fix in private branch</li> <li>Add regression tests</li> <li>Coordinate release (patch version bump)</li> <li>Publish advisory in CHANGELOG / release notes</li> </ol>"},{"location":"SECURITY/#contact","title":"Contact","text":"<p>security@tenets.dev</p>"},{"location":"TESTING/","title":"Testing","text":""},{"location":"TESTING/#quick-start","title":"Quick Start","text":"Bash<pre><code># One-liner (editable install + test deps + coverage helpers)\npip install -e '.[test]' pytest pytest-cov\n\n# Run all tests (quiet)\npytest -q\n\n# Run with coverage + fail if below threshold (adjust as policy evolves)\npytest --cov=tenets --cov-report=term-missing --cov-fail-under=70\n\n# Generate XML (CI) + HTML\npytest --cov=tenets --cov-report=xml --cov-report=html\n\n# Open HTML (macOS/Linux)\nopen htmlcov/index.html || xdg-open htmlcov/index.html || true\n\n# Specific test file / test\npytest tests/core/analysis/test_analyzer.py::test_basic_python_analysis -q\n\n# Pattern match\npytest -k analyzer -q\n\n# Parallel (if pytest-xdist installed)\npytest -n auto\n</code></pre> <p>Optional feature extras (install before running related tests): Bash<pre><code>pip install -e '.[light]'   # BM25 / TF-IDF / YAKE ranking tests\npip install -e '.[viz]'     # Visualization tests\npip install -e '.[ml]'      # Embedding / semantic tests (heavy)\n</code></pre></p>"},{"location":"TESTING/#test-structure","title":"Test Structure","text":"Text Only<pre><code>tests/\n\u251c\u2500\u2500 conftest.py              # Shared fixtures\n\u251c\u2500\u2500 test_config.py           # Config tests\n\u251c\u2500\u2500 test_tenets.py           # Main module tests\n\u251c\u2500\u2500 core/\n\u2502   \u251c\u2500\u2500 analysis/           # Code analysis tests\n\u2502   \u251c\u2500\u2500 distiller/          # Context distillation tests\n\u2502   \u251c\u2500\u2500 git/                # Git integration tests\n\u2502   \u251c\u2500\u2500 prompt/             # Prompt parsing tests\n\u2502   \u251c\u2500\u2500 ranker/             # File ranking tests\n\u2502   \u251c\u2500\u2500 session/            # Session management tests\n\u2502   \u2514\u2500\u2500 summarizer/         # Summarization tests\n\u251c\u2500\u2500 storage/\n\u2502   \u251c\u2500\u2500 test_cache.py       # Caching system tests\n\u2502   \u251c\u2500\u2500 test_session_db.py  # Session persistence tests\n\u2502   \u2514\u2500\u2500 test_sqlite.py      # SQLite utilities tests\n\u2514\u2500\u2500 utils/\n    \u251c\u2500\u2500 test_scanner.py     # File scanning tests\n    \u251c\u2500\u2500 test_tokens.py      # Token counting tests\n    \u2514\u2500\u2500 test_logger.py      # Logging tests\n</code></pre>"},{"location":"TESTING/#running-tests","title":"Running Tests","text":""},{"location":"TESTING/#by-category","title":"By Category","text":"Bash<pre><code># Unit tests only\npytest -m unit\n\n# Integration tests\npytest -m integration\n\n# Skip slow tests\npytest -m \"not slow\"\n\n# Tests requiring git\npytest -m requires_git\n\n# Tests requiring ML dependencies\npytest -m requires_ml\n</code></pre>"},{"location":"TESTING/#coverage-reports","title":"Coverage Reports","text":"Bash<pre><code># Terminal report\npytest --cov=tenets --cov-report=term-missing\n\n# Enforce minimum (CI/local gate)\npytest --cov=tenets --cov-report=term-missing --cov-fail-under=80\n\n# HTML report\npytest --cov=tenets --cov-report=html\n\n# XML for CI services (Codecov)\npytest --cov=tenets --cov-report=xml\n</code></pre>"},{"location":"TESTING/#debug-mode","title":"Debug Mode","text":"Bash<pre><code># Show print statements\npytest -s\n\n# Stop on first failure\npytest -x\n\n# Drop into debugger on failure\npytest --pdb\n\n# Verbose output\npytest -vv\n</code></pre>"},{"location":"TESTING/#writing-tests","title":"Writing Tests","text":""},{"location":"TESTING/#basic-test","title":"Basic Test","text":"Python<pre><code>def test_feature(config, analyzer):\n    \"\"\"Test feature description.\"\"\"\n    result = analyzer.analyze_file(Path(\"test.py\"))\n    assert result.language == \"python\"\n</code></pre>"},{"location":"TESTING/#using-fixtures","title":"Using Fixtures","text":"Python<pre><code>@pytest.fixture\ndef temp_project(tmp_path):\n    \"\"\"Create temporary project structure.\"\"\"\n    (tmp_path / \"src\").mkdir()\n    (tmp_path / \"src/main.py\").write_text(\"print('hello')\")\n    return tmp_path\n\ndef test_with_project(temp_project):\n    files = list(temp_project.glob(\"**/*.py\"))\n    assert len(files) == 1\n</code></pre>"},{"location":"TESTING/#mocking","title":"Mocking","text":"Python<pre><code>from unittest.mock import Mock, patch\n\ndef test_with_mock():\n    with patch('tenets.utils.tokens.count_tokens') as mock_count:\n        mock_count.return_value = 100\n        # test code\n</code></pre>"},{"location":"TESTING/#parametrized-tests","title":"Parametrized Tests","text":"Python<pre><code>@pytest.mark.parametrize(\"input,expected\", [\n    (\"test.py\", \"python\"),\n    (\"test.js\", \"javascript\"),\n    (\"test.go\", \"go\"),\n])\ndef test_language_detection(analyzer, input, expected):\n    assert analyzer._detect_language(Path(input)) == expected\n</code></pre>"},{"location":"TESTING/#test-markers","title":"Test Markers","text":"<p>Add to test functions:</p> Python<pre><code>@pytest.mark.slow\ndef test_heavy_operation():\n    pass\n\n@pytest.mark.requires_git\ndef test_git_features():\n    pass\n\n@pytest.mark.skipif(not HAS_TIKTOKEN, reason=\"tiktoken not installed\")\ndef test_token_counting():\n    pass\n</code></pre>"},{"location":"TESTING/#ci-integration","title":"CI Integration","text":"YAML<pre><code># .github/workflows/test.yml\n- name: Run tests\n  run: |\n    pytest --cov=tenets --cov-report=xml\n\n- name: Upload coverage\n  uses: codecov/codecov-action@v3\n  with:\n    file: ./coverage.xml\n</code></pre>"},{"location":"TESTING/#pre-commit-hook","title":"Pre-commit Hook","text":"YAML<pre><code># .pre-commit-config.yaml\n- repo: local\n  hooks:\n    - id: tests\n      name: tests\n      entry: pytest\n      language: system\n      pass_filenames: false\n      always_run: true\n</code></pre>"},{"location":"TESTING/#release-test-checklist","title":"Release Test Checklist","text":"<p>Before tagging a release:</p> Bash<pre><code># 1. Clean environment\nrm -rf .venv dist build *.egg-info &amp;&amp; python -m venv .venv &amp;&amp; source .venv/bin/activate\n\n# 2. Install with all needed extras for full test surface\npip install -e '.[all,test]' pytest pytest-cov\n\n# 3. Lint / type (if tools configured)\n# ruff check .\n# mypy tenets\n\n# 4. Run tests with coverage gate\npytest --cov=tenets --cov-report=term-missing --cov-fail-under=80\n\n# 5. Spot-check critical CLI commands\nfor cmd in \\\n  \"distill 'smoke test' --stats\" \\\n  \"instill 'example tenet'\" \\\n  \"session create release-smoke\" \\\n  \"config cache-stats\"; do\n  echo \"tenets $cmd\"; tenets $cmd || exit 1; done\n\n# 6. Build sdist/wheel\npython -m build\n\n# 7. Install built artifact in fresh venv &amp; re-smoke\npython -m venv verify &amp;&amp; source verify/bin/activate &amp;&amp; pip install dist/*.whl &amp;&amp; tenets version\n</code></pre> <p>Minimal CHANGELOG update + version bump in <code>tenets/__init__.py</code> must precede tagging.</p>"},{"location":"TESTING/#performance-testing","title":"Performance Testing","text":"Bash<pre><code># Benchmark tests\npytest tests/performance/ --benchmark-only\n\n# Profile slow tests\npytest --durations=10\n</code></pre>"},{"location":"TESTING/#troubleshooting","title":"Troubleshooting","text":""},{"location":"TESTING/#common-issues","title":"Common Issues","text":"<p>Import errors: Ensure package is installed with test extras: Bash<pre><code>pip install -e \".[test]\"\n</code></pre></p> <p>Slow tests: Use parallel execution: Bash<pre><code>pytest -n auto\n</code></pre></p> <p>Flaky tests: Re-run failures: Bash<pre><code>pytest --reruns 3\n</code></pre></p> <p>Memory issues: Run tests in chunks: Bash<pre><code>pytest tests/core/\npytest tests/storage/\npytest tests/utils/\n</code></pre></p>"},{"location":"TESTING/#coverage-goals","title":"Coverage Goals","text":"<ul> <li>Overall: &gt;80%</li> <li>Core logic: &gt;90%</li> <li>Error paths: &gt;70%</li> <li>Utils: &gt;85%</li> </ul> <p>Check current coverage: Bash<pre><code>pytest --cov=tenets --cov-report=term-missing | grep TOTAL\n</code></pre></p>"},{"location":"VIZ_CHEATSHEET/","title":"Tenets Viz Deps Command Cheat Sheet","text":""},{"location":"VIZ_CHEATSHEET/#installation","title":"Installation","text":"Bash<pre><code>pip install tenets[viz]  # Install visualization dependencies\n</code></pre>"},{"location":"VIZ_CHEATSHEET/#basic-commands","title":"Basic Commands","text":""},{"location":"VIZ_CHEATSHEET/#simple-usage","title":"Simple Usage","text":"Bash<pre><code>tenets viz deps                     # Auto-detect project, show ASCII tree\ntenets viz deps .                   # Analyze current directory\ntenets viz deps src/                # Analyze specific directory\n</code></pre>"},{"location":"VIZ_CHEATSHEET/#output-formats","title":"Output Formats","text":"Bash<pre><code>tenets viz deps --format ascii      # Terminal tree (default)\ntenets viz deps --format svg --output arch.svg     # Scalable vector graphics\ntenets viz deps --format png --output arch.png     # PNG image\ntenets viz deps --format html --output deps.html   # Interactive HTML\ntenets viz deps --format dot --output graph.dot    # Graphviz DOT\ntenets viz deps --format json --output data.json   # Raw JSON data\n</code></pre>"},{"location":"VIZ_CHEATSHEET/#aggregation-levels","title":"Aggregation Levels","text":"Bash<pre><code>tenets viz deps --level file        # Individual file dependencies (detailed)\ntenets viz deps --level module      # Module-level aggregation (recommended)\ntenets viz deps --level package     # Package-level view (high-level)\n</code></pre>"},{"location":"VIZ_CHEATSHEET/#clustering-options","title":"Clustering Options","text":"Bash<pre><code>tenets viz deps --cluster-by directory   # Group by directory structure\ntenets viz deps --cluster-by module      # Group by module\ntenets viz deps --cluster-by package     # Group by package\n</code></pre>"},{"location":"VIZ_CHEATSHEET/#layout-algorithms","title":"Layout Algorithms","text":"Bash<pre><code>tenets viz deps --layout hierarchical   # Tree-like layout (default)\ntenets viz deps --layout circular       # Circular/radial layout\ntenets viz deps --layout shell          # Concentric circles\ntenets viz deps --layout kamada         # Force-directed layout\n</code></pre>"},{"location":"VIZ_CHEATSHEET/#filtering","title":"Filtering","text":"Bash<pre><code># Include specific patterns\ntenets viz deps --include \"*.py\"                    # Only Python files\ntenets viz deps --include \"*.js,*.jsx\"              # JavaScript files\ntenets viz deps --include \"src/**/*.py\"             # Python in src/\n\n# Exclude patterns\ntenets viz deps --exclude \"*test*\"                  # No test files\ntenets viz deps --exclude \"*.min.js,node_modules\"   # Skip minified and deps\n\n# Combined\ntenets viz deps --include \"*.py\" --exclude \"*test*\"\n</code></pre>"},{"location":"VIZ_CHEATSHEET/#node-limiting","title":"Node Limiting","text":"Bash<pre><code>tenets viz deps --max-nodes 50      # Show only top 50 most connected nodes\ntenets viz deps --max-nodes 100     # Useful for large projects\n</code></pre>"},{"location":"VIZ_CHEATSHEET/#real-world-examples","title":"Real-World Examples","text":""},{"location":"VIZ_CHEATSHEET/#for-documentation","title":"For Documentation","text":"Bash<pre><code># Clean architecture diagram for docs\ntenets viz deps . --level package --format svg --output docs/architecture.svg\n\n# Module overview with clustering\ntenets viz deps . --level module --cluster-by directory --format png --output modules.png\n</code></pre>"},{"location":"VIZ_CHEATSHEET/#for-code-review","title":"For Code Review","text":"Bash<pre><code># Interactive exploration\ntenets viz deps . --level module --format html --output review.html\n\n# Focused on specific subsystem\ntenets viz deps src/api --include \"*.py\" --format svg --output api_deps.svg\n</code></pre>"},{"location":"VIZ_CHEATSHEET/#for-refactoring","title":"For Refactoring","text":"Bash<pre><code># Find circular dependencies\ntenets viz deps . --layout circular --format html --output circular_deps.html\n\n# Identify tightly coupled modules\ntenets viz deps . --level module --layout circular --max-nodes 50 --output coupling.svg\n</code></pre>"},{"location":"VIZ_CHEATSHEET/#for-large-projects","title":"For Large Projects","text":"Bash<pre><code># Top-level overview\ntenets viz deps . --level package --max-nodes 20 --format svg --output overview.svg\n\n# Most connected files\ntenets viz deps . --max-nodes 100 --format html --output top100.html\n\n# Specific subsystem deep dive\ntenets viz deps backend/ --level module --cluster-by module --format html -o backend.html\n</code></pre>"},{"location":"VIZ_CHEATSHEET/#project-type-auto-detection","title":"Project Type Auto-Detection","text":"<p>The command automatically detects: - Python: Packages, Django, Flask, FastAPI - JavaScript/TypeScript: Node.js, React, Vue, Angular - Java: Maven, Gradle, Spring - Go: Go modules - Rust: Cargo projects - Ruby: Rails, Gems - PHP: Laravel, Composer - And more...</p>"},{"location":"VIZ_CHEATSHEET/#tips","title":"Tips","text":"<ol> <li>Start Simple: Use <code>tenets viz deps</code> first to see what's detected</li> <li>Use Levels: Start with <code>--level package</code> for overview, drill down to <code>module</code> or <code>file</code></li> <li>Interactive HTML: Best for exploration, use <code>--format html</code></li> <li>Filter Noise: Use <code>--exclude \"*test*,*mock*\"</code> to focus on core code</li> <li>Save Time: Use <code>--max-nodes</code> for large codebases</li> <li>Documentation: SVG format scales well for docs</li> <li>Clustering: Helps organize complex graphs visually</li> </ol>"},{"location":"VIZ_CHEATSHEET/#troubleshooting","title":"Troubleshooting","text":"Bash<pre><code># Check if dependencies are installed\npython -c \"import networkx, matplotlib, graphviz, plotly\" 2&gt;/dev/null &amp;&amp; echo \"All deps OK\" || echo \"Run: pip install tenets[viz]\"\n\n# Debug mode\nTENETS_LOG_LEVEL=DEBUG tenets viz deps . 2&gt;&amp;1 | grep -E \"(Detected|Found|Analyzing)\"\n\n# If graph is too large\ntenets viz deps . --max-nodes 50 --level module  # Reduce nodes and aggregate\n</code></pre>"},{"location":"VIZ_CHEATSHEET/#output-examples","title":"Output Examples","text":""},{"location":"VIZ_CHEATSHEET/#ascii-tree-default","title":"ASCII Tree (default)","text":"Text Only<pre><code>Dependency Graph:\n==================================================\n\nmain.py\n  \u2514\u2500&gt; utils.py\n  \u2514\u2500&gt; config.py\n  \u2514\u2500&gt; models.py\n\nutils.py\n  \u2514\u2500&gt; config.py\n\nmodels.py\n  \u2514\u2500&gt; utils.py\n</code></pre>"},{"location":"VIZ_CHEATSHEET/#what-you-get","title":"What You Get","text":"<ul> <li>Project Info: Auto-detected type, languages, frameworks</li> <li>Entry Points: Identified main files (main.py, index.js, etc.)</li> <li>Dependency Graph: Visual representation of code relationships</li> <li>Multiple Views: File, module, or package level perspectives</li> </ul>"},{"location":"best-practices/","title":"Best Practices","text":""},{"location":"best-practices/#repository-setup","title":"Repository Setup","text":""},{"location":"best-practices/#clean-working-directory","title":"Clean Working Directory","text":"<p>Always run Tenets on a clean working directory for accurate results: Bash<pre><code>git status  # Ensure no uncommitted changes\ntenets examine\n</code></pre></p>"},{"location":"best-practices/#gitignore-configuration","title":"Gitignore Configuration","text":"<p>Ensure your <code>.gitignore</code> is properly configured to exclude: - Build artifacts - Node modules - Virtual environments - Temporary files</p>"},{"location":"best-practices/#command-usage","title":"Command Usage","text":""},{"location":"best-practices/#examine-command","title":"Examine Command","text":"<ul> <li>Use <code>--format</code> for different output formats</li> <li>Filter by language with <code>--language</code></li> <li>Focus on specific paths for targeted analysis</li> </ul>"},{"location":"best-practices/#chronicle-command","title":"Chronicle Command","text":"<ul> <li>Use time ranges appropriate to your project's activity</li> <li>Filter by author for team member contributions</li> <li>Combine with <code>--pattern</code> for specific file analysis</li> </ul>"},{"location":"best-practices/#distill-command","title":"Distill Command","text":"<ul> <li>Run after significant development milestones</li> <li>Use to generate weekly or monthly insights</li> <li>Combine with chronicle for historical context</li> </ul>"},{"location":"best-practices/#performance-optimization","title":"Performance Optimization","text":""},{"location":"best-practices/#large-repositories","title":"Large Repositories","text":"<p>For repositories with many files: Bash<pre><code># Focus on specific directories\ntenets examine src/ --depth 3\n\n# Exclude certain patterns\ntenets examine --exclude \"**/test/**\"\n</code></pre></p>"},{"location":"best-practices/#memory-management","title":"Memory Management","text":"<ul> <li>Use <code>--batch-size</code> for large analyses</li> <li>Enable streaming output with <code>--stream</code></li> </ul>"},{"location":"best-practices/#integration","title":"Integration","text":""},{"location":"best-practices/#cicd-pipeline","title":"CI/CD Pipeline","text":"<p>Add Tenets to your CI pipeline: YAML<pre><code>- name: Code Analysis\n  run: |\n    pip install tenets\n    tenets examine --format json &gt; analysis.json\n</code></pre></p>"},{"location":"best-practices/#pre-commit-hooks","title":"Pre-commit Hooks","text":"<p>Use Tenets in pre-commit hooks: YAML<pre><code>repos:\n  - repo: local\n    hooks:\n      - id: tenets-check\n        name: Tenets Analysis\n        entry: tenets examine --quick\n        language: system\n        pass_filenames: false\n</code></pre></p>"},{"location":"best-practices/#team-collaboration","title":"Team Collaboration","text":""},{"location":"best-practices/#sharing-reports","title":"Sharing Reports","text":"<ul> <li>Generate HTML reports for stakeholder review</li> <li>Export JSON for further processing</li> <li>Use visualizations for architecture discussions</li> </ul>"},{"location":"best-practices/#code-reviews","title":"Code Reviews","text":"<p>Use Tenets output to: - Identify complex areas needing review - Track ownership changes - Monitor technical debt</p>"},{"location":"best-practices/#next-steps","title":"Next Steps","text":"<ul> <li>See Examples for real-world scenarios</li> <li>Review CLI Reference for all options</li> <li>Check Configuration for customization</li> </ul>"},{"location":"docs/","title":"Documentation","text":"<p>Welcome to the Tenets documentation hub. Explore guides and references below.</p> <ul> <li>Quick Start: Get started fast</li> <li>Supported Languages: List</li> <li>CLI Reference: Commands</li> <li>Configuration: Config guide</li> <li> <p>Architecture: System overview</p> </li> <li> <p>API Reference: Browse API</p> </li> </ul> <p>If you were looking for the homepage, go to /.</p>"},{"location":"examples/","title":"Examples","text":""},{"location":"examples/#basic-analysis-examples","title":"Basic Analysis Examples","text":""},{"location":"examples/#analyzing-a-python-project","title":"Analyzing a Python Project","text":"Bash<pre><code># Basic examination\ntenets examine my_python_project/\n\n# With specific focus\ntenets examine my_python_project/ --language python --depth 3\n\n# Output to JSON\ntenets examine my_python_project/ --format json &gt; analysis.json\n</code></pre>"},{"location":"examples/#analyzing-a-javascripttypescript-project","title":"Analyzing a JavaScript/TypeScript Project","text":"Bash<pre><code># Examine with TypeScript support\ntenets examine frontend/ --language typescript\n\n# Exclude node_modules\ntenets examine frontend/ --exclude \"**/node_modules/**\"\n</code></pre>"},{"location":"examples/#chronicle-examples","title":"Chronicle Examples","text":""},{"location":"examples/#team-contribution-analysis","title":"Team Contribution Analysis","text":"Bash<pre><code># Last month's team activity\ntenets chronicle --days 30 --format table\n\n# Specific developer's contributions\ntenets chronicle --author \"Jane Doe\" --days 90\n\n# Focus on feature branch\ntenets chronicle --branch feature/new-ui --days 14\n</code></pre>"},{"location":"examples/#release-analysis","title":"Release Analysis","text":"Bash<pre><code># Changes between releases\ntenets chronicle --from v1.0.0 --to v2.0.0\n\n# Recent hotfixes\ntenets chronicle --pattern \"**/hotfix/**\" --days 7\n</code></pre>"},{"location":"examples/#distill-examples","title":"Distill Examples","text":""},{"location":"examples/#project-insights","title":"Project Insights","text":"Bash<pre><code># Generate comprehensive insights\ntenets distill --comprehensive\n\n# Quick summary\ntenets distill --quick\n\n# Export for reporting\ntenets distill --format markdown &gt; insights.md\n</code></pre>"},{"location":"examples/#visualization-examples","title":"Visualization Examples","text":""},{"location":"examples/#architecture-visualization","title":"Architecture Visualization","text":"Bash<pre><code># Interactive HTML graph\ntenets viz --output architecture.html\n\n# Include all relationships\ntenets viz --include-all --output full-graph.html\n\n# Focus on core modules\ntenets viz --filter \"core/**\" --output core-modules.html\n</code></pre>"},{"location":"examples/#momentum-tracking","title":"Momentum Tracking","text":""},{"location":"examples/#development-velocity","title":"Development Velocity","text":"Bash<pre><code># Weekly momentum report\ntenets momentum --period week\n\n# Monthly trends\ntenets momentum --period month --format chart\n\n# Team momentum\ntenets momentum --team --days 30\n</code></pre>"},{"location":"examples/#advanced-combinations","title":"Advanced Combinations","text":""},{"location":"examples/#pre-release-audit","title":"Pre-Release Audit","text":"Bash<pre><code># Full pre-release analysis\ntenets examine --comprehensive &gt; examine-report.txt\ntenets chronicle --days 30 &gt; chronicle-report.txt\ntenets distill --format json &gt; insights.json\ntenets viz --output release-architecture.html\n</code></pre>"},{"location":"examples/#technical-debt-assessment","title":"Technical Debt Assessment","text":"Bash<pre><code># Identify complex areas\ntenets examine --metric complexity --threshold high\n\n# Find stale code\ntenets chronicle --stale --days 180\n\n# Ownership gaps\ntenets examine --ownership --unowned\n</code></pre>"},{"location":"examples/#team-performance-review","title":"Team Performance Review","text":"Bash<pre><code># Individual contributions\nfor author in \"Alice\" \"Bob\" \"Charlie\"; do\n  tenets chronicle --author \"$author\" --days 90 &gt; \"$author-report.txt\"\ndone\n\n# Team visualization\ntenets viz --team --output team-collaboration.html\n</code></pre>"},{"location":"examples/#integration-examples","title":"Integration Examples","text":""},{"location":"examples/#github-actions","title":"GitHub Actions","text":"YAML<pre><code>name: Code Analysis\non: [push, pull_request]\n\njobs:\n  analyze:\n    runs-on: ubuntu-latest\n    steps:\n      - uses: actions/checkout@v2\n      - name: Install Tenets\n        run: pip install tenets\n      - name: Run Analysis\n        run: |\n          tenets examine --format json &gt; examine.json\n          tenets chronicle --days 7 --format json &gt; chronicle.json\n      - name: Upload Results\n        uses: actions/upload-artifact@v2\n        with:\n          name: analysis-results\n          path: |\n            examine.json\n            chronicle.json\n</code></pre>"},{"location":"examples/#pre-commit-hook","title":"Pre-commit Hook","text":"YAML<pre><code># .pre-commit-config.yaml\nrepos:\n  - repo: local\n    hooks:\n      - id: tenets-complexity\n        name: Check Code Complexity\n        entry: tenets examine --metric complexity --fail-on high\n        language: system\n        pass_filenames: false\n</code></pre>"},{"location":"examples/#next-steps","title":"Next Steps","text":"<ul> <li>Review Best Practices for optimal usage</li> <li>See CLI Reference for all available options</li> <li>Check Configuration for customization options</li> </ul>"},{"location":"installation/","title":"Installation","text":""},{"location":"installation/#requirements","title":"Requirements","text":"<ul> <li>Python 3.9 or higher</li> <li>Git</li> </ul>"},{"location":"installation/#install-from-pypi","title":"Install from PyPI","text":"Bash<pre><code>pip install tenets\n</code></pre>"},{"location":"installation/#install-from-source","title":"Install from Source","text":"Bash<pre><code>git clone https://github.com/yourusername/tenets.git\ncd tenets\npip install -e .\n</code></pre>"},{"location":"installation/#verify-installation","title":"Verify Installation","text":"Bash<pre><code>tenets --version\n</code></pre>"},{"location":"installation/#next-steps","title":"Next Steps","text":"<p>After installation, see Quick Start to get started with your first analysis.</p>"},{"location":"quickstart/","title":"Quickstart","text":""},{"location":"quickstart/#real-world-flow-system-instruction--tenets--sessions","title":"Real-world flow: System instruction + Tenets + Sessions","text":"Bash<pre><code># Create a working session\ntenets session create auth-refresh\n\n# Add guiding principles (tenets)\ntenets tenet add \"Prefer small, safe diffs\" --priority high --category style\ntenets tenet add \"Always validate user input\" --priority critical --category security\n\n# Apply tenets for this session\ntenets instill --session auth-refresh\n\n# Set a global system instruction\ntenets system-instruction set \"You are a senior engineer. Add tests and document trade-offs.\" --enable\n\n# Build context with transformations for token efficiency\ntenets distill \"add OAuth2 refresh tokens\" --session auth-refresh --remove-comments --condense\n\n# Pin files as you learn what matters\ntenets instill --session auth-refresh --add-file src/auth/service.py --add-folder src/auth/routes\ntenets instill --session auth-refresh --list-pinned\n</code></pre> <p>See also: CLI &gt; System Instruction Commands, Tenet Commands, and Instill.</p>"},{"location":"quickstart/#quick-start","title":"Quick Start","text":"<p>Get productive with Tenets in under 60 seconds.</p>"},{"location":"quickstart/#1-install","title":"1. Install","text":"Bash<pre><code>pip install tenets\n</code></pre>"},{"location":"quickstart/#2-generate-context-cli","title":"2. Generate Context (CLI)","text":"Bash<pre><code>tenets distill \"add optimistic locking to order updates\"\n</code></pre> <p>Copy straight to your clipboard:</p> Bash<pre><code>tenets distill \"refactor payment flow\" --copy\n</code></pre> <p>Or enable auto-copy in <code>tenets.toml</code>:</p> TOML<pre><code>[output]\ncopy_on_distill = true\n</code></pre>"},{"location":"quickstart/#3-refine","title":"3. Refine","text":"<p>Pin or force-include critical files:</p> Bash<pre><code># Build context for investigation\ntenets distill \"investigate cache stampede\"\n\n# Pin files are managed through instill command for sessions\ntenets instill --add-file cache/*.py --add-file config/settings.py\n</code></pre> <p>Exclude noise:</p> Bash<pre><code>tenets distill \"debug webhook\" --exclude \"**/migrations/**,**/tests/**\"\n</code></pre>"},{"location":"quickstart/#4-python-api","title":"4. Python API","text":"Python<pre><code>from tenets import Tenets\n\ntenets = Tenets()\nresult = tenets.distill(\n    prompt=\"implement bulk import\",\n    max_tokens=80_000,\n)\nprint(result.token_count, \"tokens\")\n# Copy is done via CLI flag --copy or config setting\n</code></pre>"},{"location":"quickstart/#5-sessions-iterate","title":"5. Sessions (Iterate)","text":"Python<pre><code>tenets = Tenets()\n# Sessions are managed through distill parameters\nfirst = tenets.distill(\"trace 500 errors in checkout\", session_name=\"checkout-fixes\")\nsecond = tenets.distill(\"add instrumentation around payment retries\", session_name=\"checkout-fixes\")\n</code></pre>"},{"location":"quickstart/#6-visualization--insight","title":"6. Visualization &amp; Insight","text":"Bash<pre><code># Complexity &amp; hotspots\ntenets examine . --show-details --hotspots\n\n# Dependency graph (Interactive HTML)\ntenets viz deps --format html --output deps.html\n</code></pre>"},{"location":"quickstart/#7-next","title":"7. Next","text":"<ul> <li>See full CLI options: CLI Reference</li> <li>Tune ranking &amp; tokens: Configuration</li> <li>Dive deeper: Architecture</li> </ul>"},{"location":"supported-languages/","title":"Supported Languages","text":"<p>Tenets ships with first-class analyzers for a broad set of ecosystems. Each analyzer extracts structural signals (definitions, imports, dependencies) that feed ranking.</p> Language / Tech Analyzer Class Extensions Notes Python PythonAnalyzer .py AST parsing, imports, class/function graph JavaScript / TypeScript* JavaScriptAnalyzer .js, .jsx, .ts, .tsx Lightweight regex/heuristic (TypeScript treated as JS for now) Java JavaAnalyzer .java Package &amp; import extraction Go GoAnalyzer .go Import graph, function signatures C# CSharpAnalyzer .cs Namespace &amp; using directives (great for Unity scripts) C / C++ CppAnalyzer .c, .h, .cpp, .hpp Include graph detection Rust RustAnalyzer .rs Module/use extraction Scala ScalaAnalyzer .scala Object/class/trait discovery Kotlin KotlinAnalyzer .kt, .kts Package &amp; import extraction Swift SwiftAnalyzer .swift Import/use lines PHP PhpAnalyzer .php Namespace/use detection Ruby RubyAnalyzer .rb Class/module defs Dart DartAnalyzer .dart Import and class/function capture GDScript (Godot) GDScriptAnalyzer .gd Signals + extends parsing HTML HTMLAnalyzer .html, .htm Link/script/style references CSS CSSAnalyzer .css @import and rule summarization Generic Text GenericAnalyzer * (fallback) Used when no specific analyzer matches <p>*TypeScript currently leverages the JavaScript analyzer (roadmap: richer TS-specific parsing).</p>"},{"location":"supported-languages/#detection-rules","title":"Detection Rules","text":"<p>File extension matching selects the analyzer. Unsupported files fall back to the generic analyzer supplying minimal term frequency and path heuristics.</p>"},{"location":"supported-languages/#adding-a-new-language","title":"Adding a New Language","text":"<ol> <li>Subclass <code>LanguageAnalyzer</code> in <code>tenets/core/analysis/implementations</code></li> <li>Implement <code>match(path)</code> and <code>analyze(content)</code></li> <li>Register in the analyzer registry (if dynamic) or import to ensure discovery</li> <li>Add tests under <code>tests/core/analysis/implementations</code></li> <li>Update this page</li> </ol>"},{"location":"supported-languages/#roadmap","title":"Roadmap","text":"<p>Planned enhancements:</p> <ul> <li>Deeper TypeScript semantic model</li> <li>SQL schema/introspection analyzer</li> <li>Proto / gRPC IDL support</li> <li>Framework-aware weighting (Django, Rails, Spring) optional modules</li> </ul> <p>Got a priority? Open an issue or PR.</p>"},{"location":"api/","title":"API Reference","text":"<p>Complete API documentation for the Tenets package.</p>"},{"location":"api/#quick-links","title":"Quick Links","text":"<ul> <li>Core Module - Main functionality</li> <li>CLI Reference - Command-line interface</li> <li>Models - Data structures</li> <li>Utils - Helper functions</li> </ul>"},{"location":"api/#core-module","title":"Core Module","text":""},{"location":"api/#main-classes","title":"Main Classes","text":""},{"location":"api/#tenets","title":"<code>Tenets</code>","text":"<p>The main entry point for the Tenets library.</p> Python<pre><code>from tenets import Tenets\n\nt = Tenets(config=None)\n</code></pre> <p>Methods: - <code>analyze(path, **kwargs)</code> - Analyze a codebase - <code>get_context(**kwargs)</code> - Get code context - <code>instill(path, **kwargs)</code> - Generate instilled context</p>"},{"location":"api/#config","title":"<code>Config</code>","text":"<p>Configuration class for customizing Tenets behavior.</p> Python<pre><code>from tenets import Config\n\nconfig = Config(\n    max_depth=5,\n    include_tests=False,\n    ranking_method=\"bm25\"  # or \"tfidf\"\n)\n</code></pre>"},{"location":"api/#core-submodules","title":"Core Submodules","text":""},{"location":"api/#tenetscoreanalysis","title":"<code>tenets.core.analysis</code>","text":"<p>Code analysis and parsing functionality.</p> <p>Key Classes: - <code>Analyzer</code> - Main analysis orchestrator - <code>FileAnalyzer</code> - Individual file analysis - <code>SymbolExtractor</code> - Extract code symbols</p>"},{"location":"api/#tenetscoreranking","title":"<code>tenets.core.ranking</code>","text":"<p>Code ranking and relevance scoring.</p> <p>Key Classes: - <code>RankingEngine</code> - Main ranking interface - <code>BM25Ranker</code> - BM25 ranking implementation - <code>TFIDFRanker</code> - TF-IDF ranking implementation</p>"},{"location":"api/#tenetscoresession","title":"<code>tenets.core.session</code>","text":"<p>Session management and state tracking.</p> <p>Key Classes: - <code>Session</code> - Session state manager - <code>SessionConfig</code> - Session configuration</p>"},{"location":"api/#tenetscoreinstiller","title":"<code>tenets.core.instiller</code>","text":"<p>Context instillation and prompt generation.</p> <p>Key Classes: - <code>Instiller</code> - Main instillation engine - <code>ContextBuilder</code> - Build context for prompts</p>"},{"location":"api/#tenetscoregit","title":"<code>tenets.core.git</code>","text":"<p>Git repository integration.</p> <p>Key Classes: - <code>GitManager</code> - Git operations wrapper - <code>GitAnalyzer</code> - Analyze git history</p>"},{"location":"api/#cli-reference","title":"CLI Reference","text":"<p>The Tenets CLI provides commands for code analysis and context generation.</p>"},{"location":"api/#basic-usage","title":"Basic Usage","text":"Bash<pre><code># Analyze current directory\ntenets analyze .\n\n# Generate context\ntenets instill . --output context.md\n\n# With specific configuration\ntenets analyze . --config tenets.yaml\n</code></pre>"},{"location":"api/#commands","title":"Commands","text":""},{"location":"api/#analyze","title":"<code>analyze</code>","text":"<p>Analyze a codebase and generate insights.</p> Bash<pre><code>tenets analyze &lt;path&gt; [OPTIONS]\n</code></pre> <p>Options: - <code>--output, -o</code> - Output file path - <code>--format</code> - Output format (json, yaml, markdown) - <code>--max-depth</code> - Maximum directory depth - <code>--include</code> - Include patterns - <code>--exclude</code> - Exclude patterns</p>"},{"location":"api/#instill","title":"<code>instill</code>","text":"<p>Generate instilled context for AI prompts.</p> Bash<pre><code>tenets instill &lt;path&gt; [OPTIONS]\n</code></pre> <p>Options: - <code>--output, -o</code> - Output file path - <code>--max-tokens</code> - Maximum token count - <code>--ranking-method</code> - Ranking method (bm25, tfidf) - <code>--top-k</code> - Number of top results</p>"},{"location":"api/#config_1","title":"<code>config</code>","text":"<p>Manage Tenets configuration.</p> Bash<pre><code>tenets config [OPTIONS]\n</code></pre> <p>Options: - <code>--show</code> - Show current configuration - <code>--init</code> - Initialize configuration file - <code>--validate</code> - Validate configuration</p>"},{"location":"api/#models","title":"Models","text":""},{"location":"api/#data-structures","title":"Data Structures","text":""},{"location":"api/#codecontext","title":"<code>CodeContext</code>","text":"<p>Represents analyzed code context.</p> <p>Attributes: - <code>files</code> - List of analyzed files - <code>symbols</code> - Extracted symbols - <code>dependencies</code> - Dependency graph - <code>metrics</code> - Code metrics</p>"},{"location":"api/#fileinfo","title":"<code>FileInfo</code>","text":"<p>Information about a single file.</p> <p>Attributes: - <code>path</code> - File path - <code>language</code> - Programming language - <code>content</code> - File content - <code>symbols</code> - File symbols - <code>imports</code> - Import statements</p>"},{"location":"api/#symbol","title":"<code>Symbol</code>","text":"<p>Represents a code symbol (class, function, etc.).</p> <p>Attributes: - <code>name</code> - Symbol name - <code>type</code> - Symbol type - <code>line</code> - Line number - <code>docstring</code> - Documentation - <code>signature</code> - Function signature</p>"},{"location":"api/#utilities","title":"Utilities","text":""},{"location":"api/#helper-functions","title":"Helper Functions","text":""},{"location":"api/#file-operations","title":"File Operations","text":"<ul> <li><code>read_file(path)</code> - Read file content</li> <li><code>write_file(path, content)</code> - Write file</li> <li><code>find_files(pattern)</code> - Find files by pattern</li> </ul>"},{"location":"api/#text-processing","title":"Text Processing","text":"<ul> <li><code>tokenize(text)</code> - Tokenize text</li> <li><code>extract_keywords(text)</code> - Extract keywords</li> <li><code>summarize(text)</code> - Generate summary</li> </ul>"},{"location":"api/#language-detection","title":"Language Detection","text":"<ul> <li><code>detect_language(file)</code> - Detect programming language</li> <li><code>get_parser(language)</code> - Get language parser</li> </ul>"},{"location":"api/#configuration","title":"Configuration","text":""},{"location":"api/#configuration-file-format","title":"Configuration File Format","text":"YAML<pre><code># tenets.yaml\nversion: 1\n\nanalysis:\n  max_depth: 5\n  include_tests: false\n  follow_symlinks: false\n\nranking:\n  method: bm25  # or tfidf\n  top_k: 20\n  min_score: 0.1\n\noutput:\n  format: markdown\n  max_tokens: 8000\n  include_metadata: true\n\nlanguages:\n  - python\n  - javascript\n  - typescript\n  - go\n  - rust\n\nexclude:\n  - \"**/node_modules/**\"\n  - \"**/.venv/**\"\n  - \"**/dist/**\"\n  - \"**/build/**\"\n</code></pre>"},{"location":"api/#examples","title":"Examples","text":""},{"location":"api/#basic-analysis","title":"Basic Analysis","text":"Python<pre><code>from tenets import Tenets\n\n# Initialize\nt = Tenets()\n\n# Analyze a project\ncontext = t.analyze('path/to/project')\n\n# Get ranked files\nranked = context.get_ranked_files(query=\"authentication\")\n\n# Generate context\ninstilled = t.instill(\n    'path/to/project',\n    max_tokens=4000,\n    ranking_method=\"bm25\"\n)\n</code></pre>"},{"location":"api/#custom-configuration","title":"Custom Configuration","text":"Python<pre><code>from tenets import Tenets, Config\n\nconfig = Config(\n    max_depth=3,\n    include_tests=False,\n    languages=['python', 'javascript'],\n    exclude_patterns=['**/test_*.py']\n)\n\nt = Tenets(config=config)\ncontext = t.analyze('.')\n</code></pre>"},{"location":"api/#cli-integration","title":"CLI Integration","text":"Python<pre><code>import subprocess\nimport json\n\n# Run analysis via CLI\nresult = subprocess.run(\n    ['tenets', 'analyze', '.', '--format', 'json'],\n    capture_output=True,\n    text=True\n)\n\ndata = json.loads(result.stdout)\n</code></pre>"},{"location":"api/#api-stability","title":"API Stability","text":"<p>The Tenets API follows semantic versioning. The current version is 0.1.0 (alpha).</p> <ul> <li>Public API methods are considered stable</li> <li>Internal methods (prefixed with <code>_</code>) may change</li> <li>Configuration format is stable</li> <li>CLI commands are stable</li> </ul>"},{"location":"api/#further-reading","title":"Further Reading","text":"<ul> <li>Architecture Guide - System design and architecture</li> <li>Development Guide - Contributing and development</li> <li>CLI Documentation - Detailed CLI reference</li> <li>Configuration Guide - Configuration options</li> </ul>"}]}