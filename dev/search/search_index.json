{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Tenets - Context that feeds your prompts","text":"<p>Context that feeds your prompts</p> <p>Illuminate your codebase. Surface relevant files. Build optimal context.</p> <p>All without leaving your machine. 20+ languages including Python, Go, Rust, Java, C#, Kotlin, Swift, Dart, GDScript &amp; more.</p>        Quick Start             View on GitHub      Terminal <pre><code>$ pip install tenets\n$ tenets distill \"add mistral api to summarizer\"\n\u2728 Finding relevant files...\n\ud83d\udcca Ranking by importance...\n\ud83d\udce6 Aggregating context (251,146 tokens)\n\u2705 Context ready for your LLM!</code></pre> Illuminating Features Why\u00a0Tenets? Context on Demand <p>Stop hunting for files. Tenets discovers, ranks and assembles your code for you\u2014so you can focus on solving the problem.</p> Deeper Insight <p>Visualize dependencies, uncover complexity hotspots and track velocity trends. Know your codebase like never before.</p> Local &amp; Private <p>Your source never leaves your machine. With zero external API calls, Tenets keeps your intellectual property safe.</p> Flexible &amp; Extensible <p>Dial the ranking algorithm, expand the token budget and add plugins when you need more. Tenets grows with you.</p> Architecture at a Glance Input Scanner Analyzer Ranker Aggregator <p>Tenets flows your query through a pipeline of scanners, analyzers, rankers and aggregators, delivering context precisely tailored to your task.</p> Intelligent Context <p>Multi-factor ranking finds exactly what you need. No more manual file hunting.</p> 100% Local <p>Your code never leaves your machine. Complete privacy, zero API calls.</p> Lightning Fast <p>Analyzes thousands of files in seconds with intelligent caching.</p> Guiding Principles <p>Add persistent instructions that maintain consistency across AI sessions.</p> Code Intelligence <p>Visualize dependencies, track velocity, identify hotspots at a glance.</p> Zero Config <p>Works instantly with smart defaults. Just install and start distilling.</p> How It Works 1 Scan <p>Discovers files respecting .gitignore</p> \u2192 2 Analyze <p>Extracts structure and dependencies</p> \u2192 3 Rank <p>Scores by relevance to your prompt</p> \u2192 4 Aggregate <p>Optimizes within token limits</p> See it in action CLI Bash<pre><code>$ tenets distill \"implement OAuth2 authentication\"\n\u2728 Finding relevant files...\n\ud83d\udcca Ranking by importance...\n\ud83d\udce6 Aggregating context (45,231 tokens)\n\u2705 Context ready for your LLM!\n</code></pre> Output Rank Files Bash<pre><code>$ tenets rank \"fix authentication bug\" --top 10 --factors\n\ud83d\udd0d Scanning codebase...\n\ud83d\udcca Ranking files by relevance...\n\n1. src/auth/service.py - Score: 0.892\n   - semantic_similarity: 85%\n   - keyword_match: 92%\n   - import_centrality: 78%\n\n2. src/auth/middleware.py - Score: 0.834\n   - semantic_similarity: 79%\n   - keyword_match: 88%\n   - import_centrality: 65%\n</code></pre> Tree View Bash<pre><code>$ tenets rank \"add caching\" --tree --scores\n\ud83d\udcc1 Ranked Files\n\u251c\u2500\u2500 \ud83d\udcc2 src/\n\u2502   \u251c\u2500\u2500 \ud83d\udcc4 cache_manager.py [0.892]\n\u2502   \u251c\u2500\u2500 \ud83d\udcc4 redis_client.py [0.834]\n\u2502   \u2514\u2500\u2500 \ud83d\udcc4 config.py [0.756]\n\u251c\u2500\u2500 \ud83d\udcc2 src/api/\n\u2502   \u251c\u2500\u2500 \ud83d\udcc4 endpoints.py [0.723]\n\u2502   \u2514\u2500\u2500 \ud83d\udcc4 middleware.py [0.689]\n\u2514\u2500\u2500 \ud83d\udcc2 tests/\n    \u2514\u2500\u2500 \ud83d\udcc4 test_cache.py [0.534]\n</code></pre> Python Python<pre><code>from tenets import Tenets\nt = Tenets()\nresult = t.distill(\n    prompt=\"map request lifecycle\"\n)\nprint(result.context[:500])  # First 500 chars\n</code></pre> Output Sessions Python<pre><code># Sessions are managed through distill parameters\nctx = t.distill(\"design payment flow\", session_name=\"checkout-flow\")\n# Pin files through pin_file method\nt.pin_file(\"payment.py\")\nt.pin_file(\"stripe.py\")\nctx = t.distill(\"add refund support\", session_name=\"checkout-flow\")\n</code></pre> Output Ready to illuminate your codebase? <p>Join thousands of developers building better with Tenets.</p>          Get Started Now        <code>pip install tenets</code>"},{"location":"ARCHITECTURE/","title":"Tenets Architecture Documentation","text":"<p>Tenets is a sophisticated, local-first code intelligence platform that revolutionizes how developers interact with their codebases when working with AI assistants. This documentation provides a comprehensive overview of the system's architecture, organized into specialized areas.</p>"},{"location":"ARCHITECTURE/#overview","title":"Overview","text":"<p>Tenets employs advanced multi-stage analysis combining NLP, ML, static code analysis, git history mining, and intelligent ranking to build optimal context for AI interactions. The system is designed with local-first processing, progressive enhancement, intelligent caching, and configurable intelligence as core principles.</p>"},{"location":"ARCHITECTURE/#architecture-components","title":"Architecture Components","text":""},{"location":"ARCHITECTURE/#core-system","title":"Core System","text":"<ul> <li>System Overview - Core philosophy and architecture principles</li> <li>Complete System Architecture - High-level data flow and component diagrams</li> <li>Performance Architecture - Optimization strategies and performance considerations</li> </ul>"},{"location":"ARCHITECTURE/#processing-pipeline","title":"Processing Pipeline","text":"<ul> <li>NLP/ML Pipeline - Natural language processing and machine learning components</li> <li>File Discovery &amp; Scanning - Intelligent file discovery and filtering system</li> <li>Code Analysis Engine - Multi-language code analysis and AST parsing</li> <li>Relevance Ranking System - Multi-factor ranking algorithms and strategies</li> </ul>"},{"location":"ARCHITECTURE/#intelligence--context","title":"Intelligence &amp; Context","text":"<ul> <li>Context Management &amp; Optimization - Context building and token optimization</li> <li>Git Integration &amp; Chronicle System - Git analysis and repository insights</li> <li>Guiding Principles (Tenets) System - Persistent instruction system</li> </ul>"},{"location":"ARCHITECTURE/#data--storage","title":"Data &amp; Storage","text":"<ul> <li>Session Management - Session lifecycle and state management</li> <li>Storage &amp; Caching Architecture - Multi-tier caching and persistence</li> <li>Configuration System - Hierarchical configuration management</li> </ul>"},{"location":"ARCHITECTURE/#interfaces--security","title":"Interfaces &amp; Security","text":"<ul> <li>CLI &amp; API Architecture - Command-line and programmatic interfaces</li> <li>Output Generation &amp; Visualization - Report generation and visualization</li> <li>Security &amp; Privacy Architecture - Local-first security model and privacy protection</li> </ul>"},{"location":"ARCHITECTURE/#quality--future","title":"Quality &amp; Future","text":"<ul> <li>Testing &amp; Quality Assurance - Testing strategies and quality metrics</li> <li>Future Roadmap &amp; Vision - Development roadmap and long-term vision</li> </ul>"},{"location":"ARCHITECTURE/#key-features","title":"Key Features","text":"<ul> <li>Local-First Processing: All analysis happens locally, ensuring complete privacy</li> <li>Progressive Enhancement: Works immediately with basic Python, scales with optional dependencies</li> <li>Intelligent Caching: Multi-level caching for optimal performance</li> <li>Configurable Intelligence: Every aspect can be tuned and customized</li> <li>Streaming Architecture: Real-time results as analysis progresses</li> </ul>"},{"location":"ARCHITECTURE/#quick-start","title":"Quick Start","text":"<p>For implementation details and usage examples, refer to the individual architecture documents. Each component is designed to work independently while contributing to the overall system intelligence.</p>"},{"location":"ARCHITECTURE/#architecture-principles","title":"Architecture Principles","text":"<ol> <li>Privacy by Design: No code leaves the local environment</li> <li>Performance First: Optimized for speed and efficiency</li> <li>Extensibility: Modular design for easy enhancement</li> <li>Developer Experience: Intuitive interfaces and comprehensive tooling</li> </ol> <p>The future of code intelligence is local, intelligent, and developer-centric. Tenets embodies this vision while remaining practical and immediately useful for development teams of any size.</p>"},{"location":"BRANDING/","title":"BRANDING","text":""},{"location":"BRANDING/#primary-colors","title":"Primary Colors","text":"<p>$navy-900: #1a2332;  // Logo dark blue $navy-800: #263244;  // Slightly lighter $navy-700: #364152;  // Card backgrounds (dark mode)</p>"},{"location":"BRANDING/#accent-colors","title":"Accent Colors","text":"<p>$amber-500: #f59e0b;  // Lantern flame/glow effect $amber-400: #fbbf24;  // Hover states $amber-300: #fcd34d;  // Highlights</p>"},{"location":"BRANDING/#neutral-palette","title":"Neutral Palette","text":"<p>$cream-50:  #fdfdf9;  // Light mode background (Victorian paper) $cream-100: #f7f5f0;  // Card backgrounds (light mode) $sepia-200: #e8e2d5;  // Borders light mode $sepia-600: #6b5d4f;  // Muted text $sepia-800: #3e342a;  // Body text light mode</p>"},{"location":"BRANDING/#semantic-colors","title":"Semantic Colors","text":"<p>$success: #059669;    // Victorian green $warning: #d97706;    // Brass/copper $error:   #dc2626;    // Deep red $info:    #0891b2;    // Teal</p>"},{"location":"CLI/","title":"Tenets CLI Reference","text":"<p>tenets - Context that feeds your prompts. A command-line tool for intelligent code aggregation, analysis, and visualization.</p>"},{"location":"CLI/#table-of-contents","title":"Table of Contents","text":"<ul> <li>Installation</li> <li>Quick Start</li> <li>Core Commands</li> <li>distill</li> <li>instill</li> <li>rank</li> <li>examine</li> <li>chronicle</li> <li>momentum</li> <li>tenet</li> <li>Visualization Commands</li> <li>viz deps</li> <li>viz complexity</li> <li>viz coupling</li> <li>viz contributors</li> <li>Session Commands</li> <li>Tenet Commands</li> <li>Instill Command</li> <li>System Instruction Commands</li> <li>Configuration</li> <li>Common Use Cases</li> <li>Examples</li> </ul>"},{"location":"CLI/#installation","title":"Installation","text":"Bash<pre><code># Basic install (core features only)\npip install tenets\n\n# With visualization support\npip install tenets[viz]\n\n# With ML-powered ranking\npip install tenets[ml]\n\n# Everything\npip install tenets[all]\n</code></pre>"},{"location":"CLI/#quick-start","title":"Quick Start","text":"Bash<pre><code># Generate context for AI pair programming\ntenets distill \"implement OAuth2\" ./src\n\n# Analyze your codebase\ntenets examine\n\n# Track recent changes\ntenets chronicle --since yesterday\n\n# Visualize dependencies (ASCII by default)\ntenets viz deps\n</code></pre>"},{"location":"CLI/#core-commands","title":"Core Commands","text":""},{"location":"CLI/#distill","title":"distill","text":"<p>Generate optimized context for LLMs from your codebase.</p> Bash<pre><code>tenets distill [path] &lt;prompt&gt; [options]\n</code></pre> <p>Arguments:</p> <ul> <li>path: Directory or files to analyze (optional, defaults to current directory)</li> <li>prompt: Your query or task description (can be text or URL, required)</li> </ul> <p>Options:</p> <ul> <li><code>--format</code>, <code>-f</code>: Output format: markdown (default), xml, json</li> <li><code>--model</code>, <code>-m</code>: Target LLM model (e.g., gpt-4o, claude-3-opus)</li> <li><code>--output</code>, <code>-o</code>: Save to file instead of stdout</li> <li><code>--max-tokens</code>: Maximum tokens for context</li> <li><code>--mode</code>: Analysis mode: fast, balanced (default), thorough</li> <li><code>--no-git</code>: Disable git context inclusion</li> <li><code>--use-stopwords</code>: Enable stopword filtering for keyword analysis</li> <li><code>--include</code>, <code>-i</code>: Include file patterns (e.g., \".py,.js\")</li> <li><code>--exclude</code>, <code>-e</code>: Exclude file patterns (e.g., \"test_,.backup\")</li> <li><code>--session</code>, <code>-s</code>: Use a named session for stateful context</li> <li><code>--estimate-cost</code>: Show token usage and cost estimate</li> <li><code>--verbose</code>, <code>-v</code>: Show detailed analysis info</li> <li><code>--full</code>: Include full content for all ranked files (no summarization) until token budget reached</li> <li><code>--condense</code>: Condense whitespace (collapse large blank runs, trim trailing spaces) before token counting</li> <li><code>--remove-comments</code>: Strip comments (heuristic, language-aware) before token counting</li> <li><code>--copy</code>: Copy distilled context directly to clipboard (or set output.copy_on_distill: true in config)</li> </ul> <p>Examples:</p> Bash<pre><code># Basic usage - path is optional, defaults to current directory\ntenets distill . \"implement OAuth2 authentication\"  # Explicit current directory\ntenets distill ./src \"implement OAuth2\"             # Specific directory\ntenets distill \"implement OAuth2 authentication\"    # Path defaults to current directory\n\n# From a GitHub issue (path optional)\ntenets distill https://github.com/org/repo/issues/123\n\n# Target specific model with cost estimation\ntenets distill \"add caching layer\" --model gpt-4o --estimate-cost\n\n# Filter by file types (scans current directory by default)\ntenets distill \"review API endpoints\" --include \"*.py,*.yaml\" --exclude \"test_*\"\n\n# Save context to file\ntenets distill \"debug login issue\" --output context.md\n\n# Use thorough analysis for complex tasks\ntenets distill \"refactor authentication system\" --mode thorough\n\n# Session-based context (maintains state)\ntenets distill \"build payment system\" --session payment-feature\n\n# Full mode (force raw content inclusion)\ntenets distill \"inspect performance code\" --full --max-tokens 60000\n\n# Reduce token usage by stripping comments &amp; whitespace\ntenets distill \"understand API surface\" --remove-comments --condense --stats\n</code></pre>"},{"location":"CLI/#content-transformations","title":"Content Transformations","text":"<p>You can optionally transform file content prior to aggregation/token counting:</p> Flag Effect Safety <code>--full</code> Disables summarization; includes raw file content until budget is hit Budget only <code>--remove-comments</code> Removes line &amp; block comments (language-aware heuristics) Aborts if &gt;60% of non-empty lines would vanish <code>--condense</code> Collapses 3+ blank lines to 1, trims trailing spaces, ensures final newline Lossless for code logic <p>Transformations are applied in this order: comment stripping -&gt; whitespace condensation. Statistics (e.g. removed comment lines) are tracked internally and may be surfaced in future <code>--stats</code> expansions.</p>"},{"location":"CLI/#pinned-files","title":"Pinned Files","text":"<p>Pin critical files so they're always considered first in subsequent distill runs for the same session:</p> Bash<pre><code># Pin individual files\ntenets instill --session refactor-auth --add-file src/auth/service.py --add-file src/auth/models.py\n\n# Pin all files in a folder (respects .gitignore)\ntenets instill --session refactor-auth --add-folder src/auth\n\n# List pinned files\ntenets instill --session refactor-auth --list-pinned\n\n# Generate context (pinned files prioritized)\ntenets distill \"add JWT refresh tokens\" --session refactor-auth --remove-comments\n</code></pre> <p>Pinned files are stored in the session metadata (SQLite) and reloaded automatically\u2014no extra flags needed when distilling.</p>"},{"location":"CLI/#ranking-presets-and-thresholds","title":"Ranking presets and thresholds","text":"<ul> <li>Presets (selected via <code>--mode</code> or config <code>ranking.algorithm</code>):</li> <li><code>fast</code> \u2013 keyword + path signals (broad, quick)</li> <li><code>balanced</code> (default) \u2013 multi-factor (keywords, path, imports, git, complexity)</li> <li> <p><code>thorough</code> \u2013 deeper analysis (heavier)</p> </li> <li> <p>Threshold (config <code>ranking.threshold</code>) controls inclusion. Lower = include more files.</p> </li> <li>Typical ranges:<ul> <li>fast: 0.05\u20130.10</li> <li>balanced: 0.10\u20130.20</li> <li>thorough: 0.10\u20130.20</li> </ul> </li> </ul> <p>Configure in <code>.tenets.yml</code> (repo root):</p> YAML<pre><code>ranking:\n  algorithm: fast      # fast | balanced | thorough\n  threshold: 0.05      # 0.0\u20131.0\n</code></pre> <p>One-off overrides (environment, Git Bash):</p> Bash<pre><code>TENETS_RANKING_THRESHOLD=0.05 TENETS_RANKING_ALGORITHM=fast \\\n  tenets distill \"implement OAuth2\" --include \"*.py,*.md\" --max-tokens 50000\n\n# Copy output to clipboard directly\ntenets distill \"implement OAuth2\" --copy\n\n# Enable automatic copying in config\noutput:\n  copy_on_distill: true\n</code></pre> <p>Inspect current config:</p> Bash<pre><code>tenets config show --key ranking\n</code></pre> <p>See also: docs/CONFIG.md for full configuration details.</p>"},{"location":"CLI/#rank","title":"rank","text":"<p>Show ranked files by relevance without their content.</p> Bash<pre><code>tenets rank &lt;prompt&gt; [path] [options]\n</code></pre> <p>Arguments:</p> <ul> <li>prompt: Your query or task to rank files against (required)</li> <li>path: Directory or files to analyze (optional, defaults to current directory)</li> </ul> <p>Options:</p> <ul> <li><code>--format</code>, <code>-f</code>: Output format: markdown (default), json, xml, html, tree</li> <li><code>--output</code>, <code>-o</code>: Save to file instead of stdout</li> <li><code>--mode</code>, <code>-m</code>: Ranking mode: fast, balanced (default), thorough</li> <li><code>--top</code>, <code>-t</code>: Show only top N files</li> <li><code>--min-score</code>: Minimum relevance score (0.0-1.0)</li> <li><code>--max-files</code>: Maximum number of files to show</li> <li><code>--tree</code>: Show results as directory tree</li> <li><code>--scores/--no-scores</code>: Show/hide relevance scores (default: show)</li> <li><code>--factors</code>: Show ranking factor breakdown</li> <li><code>--path-style</code>: Path display: relative (default), absolute, name</li> <li><code>--include</code>, <code>-i</code>: Include file patterns (e.g., \".py,.js\")</li> <li><code>--exclude</code>, <code>-e</code>: Exclude file patterns (e.g., \"test_,.backup\")</li> <li><code>--include-tests</code>: Include test files</li> <li><code>--exclude-tests</code>: Explicitly exclude test files</li> <li><code>--no-git</code>: Disable git signals in ranking</li> <li><code>--session</code>, <code>-s</code>: Use session for stateful ranking</li> <li><code>--stats</code>: Show ranking statistics</li> <li><code>--verbose</code>, <code>-v</code>: Show detailed debug information</li> <li><code>--copy</code>: Copy file list to clipboard (also enabled automatically if config.output.copy_on_rank is true)</li> </ul> <p>Examples:</p> Bash<pre><code># Basic usage - prompt first, path optional (defaults to current directory)\ntenets rank \"implement OAuth2\" --top 10         # Scans current directory by default\ntenets rank \"implement OAuth2\" . --top 10       # Explicit current directory\ntenets rank \"implement OAuth2\" ./src --top 10   # Specific directory\n\n# Show files above a relevance threshold\ntenets rank \"fix authentication bug\" . --min-score 0.3\n\n# Tree view with ranking factors (path defaults to current dir if omitted)\ntenets rank \"add caching layer\" --tree --factors\n\n# Export ranking as JSON for automation\ntenets rank \"review API endpoints\" --format json -o ranked_files.json\n\n# Quick file list to clipboard (no scores)\ntenets rank \"database queries\" --top 20 --copy --no-scores\n\n# Show only Python files with detailed factors\ntenets rank \"refactor models\" --include \"*.py\" --factors --stats\n\n# HTML report with interactive tree view\ntenets rank \"security audit\" --format html -o security_files.html --tree\n</code></pre> <p>Use Cases:</p> <ol> <li>Understanding Context: See which files would be included in a <code>distill</code> command without generating the full context</li> <li>File Discovery: Find relevant files for manual inspection</li> <li>Automation: Export ranked file lists for feeding into other tools or scripts</li> <li>Code Review: Identify files most relevant to a particular feature or bug</li> <li>Impact Analysis: See which files are most connected to a specific query</li> </ol> <p>Output Formats:</p> <ul> <li>Markdown: Numbered list sorted by relevance with scores and optional factors</li> <li>Tree: Directory tree structure sorted by relevance (directories ordered by their highest-scoring file)</li> <li>JSON: Structured data with paths, scores, ranks, and factors (preserves relevance order)</li> <li>XML: Structured XML for integration with other tools</li> <li>HTML: Interactive web page with relevance-sorted display</li> </ul> <p>The ranking uses the same intelligent multi-factor analysis as <code>distill</code>: - Semantic similarity (ML-based when available) - Keyword matching - BM25/TF-IDF statistical relevance - Import/dependency centrality - Path relevance - Git signals (recent changes, frequency)</p>"},{"location":"CLI/#examine","title":"examine","text":"<p>Analyze codebase structure, complexity, and patterns.</p> Bash<pre><code>tenets examine [path] [options]\n</code></pre> <p>Options: - <code>--deep, -d</code>: Perform deep analysis with AST parsing - <code>--output, -o</code>: Save results to file - <code>--metrics</code>: Show detailed code metrics - <code>--complexity</code>: Show complexity analysis - <code>--ownership</code>: Show code ownership (requires git) - <code>--hotspots</code>: Show frequently changed files - <code>--format, -f</code>: Output format: <code>table</code> (default), <code>json</code>, <code>yaml</code> - <code>--no-git</code>: Disable git analysis</p> <p>Examples:</p> Bash<pre><code># Basic analysis with summary table\ntenets examine\n\n# Deep analysis with metrics\ntenets examine --deep --metrics\n\n# Show complexity hotspots\ntenets examine --complexity --hotspots\n\n# Export full analysis as JSON\ntenets examine --output analysis.json --format json\n\n# Generate HTML examination report\ntenets examine --format html --output examination_report.html\n\n# Generate detailed HTML report with all analyses\ntenets examine --ownership --hotspots --show-details --format html -o report.html\n\n# Analyze specific directory with ownership tracking\ntenets examine ./src --ownership\n\n# Generate multiple format reports\ntenets examine --format json -o analysis.json\ntenets examine --format html -o analysis.html\ntenets examine --format markdown -o analysis.md\n</code></pre> <p>Coverage Reports:</p> Bash<pre><code># Run tests with coverage and generate HTML report\npytest --cov=tenets --cov-report=html\n\n# View HTML coverage report (opens htmlcov/index.html)\npython -m webbrowser htmlcov/index.html\n\n# Run tests with multiple coverage formats\npytest --cov=tenets --cov-report=html --cov-report=xml --cov-report=term\n\n# Run specific test module with coverage\npytest tests/cli/commands/test_examine.py --cov=tenets.cli.commands.examine --cov-report=html\n</code></pre> <p>Output Example (Table Format): Text Only<pre><code>Codebase Analysis\n\u250f\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2513\n\u2503 Metric          \u2503 Value     \u2503\n\u2521\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2529\n\u2502 Total Files     \u2502 156       \u2502\n\u2502 Total Lines     \u2502 24,531    \u2502\n\u2502 Languages       \u2502 Python,   \u2502\n\u2502                 \u2502 JavaScript\u2502\n\u2502 Avg Complexity  \u2502 4.32      \u2502\n\u2502 Git Branch      \u2502 main      \u2502\n\u2502 Contributors    \u2502 8         \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre></p>"},{"location":"CLI/#chronicle","title":"chronicle","text":"<p>Track code changes over time using git history.</p> Bash<pre><code>tenets chronicle [options]\n</code></pre> <p>Options: - <code>--since, -s</code>: Time period (e.g., \"yesterday\", \"last-month\", \"2024-01-01\") - <code>--path, -p</code>: Repository path (default: current directory) - <code>--author, -a</code>: Filter by author - <code>--limit, -n</code>: Maximum commits to display</p> <p>Examples:</p> Bash<pre><code># Changes in the last week\ntenets chronicle --since \"last-week\"\n\n# Changes since yesterday\ntenets chronicle --since yesterday\n\n# Filter by author\ntenets chronicle --author \"alice@example.com\"\n</code></pre>"},{"location":"CLI/#momentum","title":"momentum","text":"<p>Track development velocity and team productivity metrics.</p> Bash<pre><code>tenets momentum [options]\n</code></pre> <p>Options: - <code>--path, -p</code>: Repository path (default: current directory) - <code>--since, -s</code>: Time period (default: \"last-month\") - <code>--team</code>: Show team-wide statistics - <code>--author, -a</code>: Show stats for specific author</p> <p>Examples:</p> Bash<pre><code># Personal velocity for last month\ntenets momentum\n\n# Team velocity for the quarter\ntenets momentum --team --since \"3 months\"\n\n# Individual contributor stats\ntenets momentum --author \"alice@example.com\"\n</code></pre>"},{"location":"CLI/#instill","title":"instill","text":"<p>Apply tenets to your current context by injecting them into prompts and outputs.</p> Bash<pre><code>tenets instill [context] [options]\n</code></pre> <p>Options: - <code>--session, -s</code>: Session name for tracking - <code>--frequency</code>: Injection frequency: <code>always</code>, <code>periodic</code>, <code>adaptive</code> - <code>--priority</code>: Minimum tenet priority: <code>low</code>, <code>medium</code>, <code>high</code>, <code>critical</code> - <code>--max-tokens</code>: Maximum tokens to add - <code>--format</code>: Output format</p> <p>Examples:</p> Bash<pre><code># Apply all pending tenets\ntenets instill \"Current code context\"\n\n# Apply tenets for specific session\ntenets instill --session feature-x\n\n# Adaptive injection based on complexity\ntenets instill --frequency adaptive\n</code></pre>"},{"location":"CLI/#tenet","title":"tenet","text":"<p>Manage project tenets - rules and guidelines for your codebase.</p> Bash<pre><code>tenets tenet [subcommand] [options]\n</code></pre> <p>Subcommands: - <code>add</code>: Add a new tenet - <code>list</code>: List all tenets - <code>remove</code>: Remove a tenet - <code>show</code>: Show tenet details - <code>export</code>: Export tenets - <code>import</code>: Import tenets</p> <p>Examples:</p> Bash<pre><code># Add a new tenet\ntenets tenet add \"Always use type hints\"\n\n# List all tenets\ntenets tenet list\n\n# Remove a tenet\ntenets tenet remove &lt;tenet-id&gt;\n</code></pre>"},{"location":"CLI/#visualization-commands","title":"Visualization Commands","text":"<p>All visualization commands support ASCII output for terminal display, with optional graphical formats.</p>"},{"location":"CLI/#viz-deps","title":"viz deps","text":"<p>Visualize code dependencies and architecture with intelligent project detection.</p> Bash<pre><code>tenets viz deps [path] [options]\n</code></pre> <p>Options: - <code>--output, -o</code>: Save to file (e.g., architecture.svg) - <code>--format, -f</code>: Output format: <code>ascii</code>, <code>svg</code>, <code>png</code>, <code>html</code>, <code>json</code>, <code>dot</code> - <code>--level, -l</code>: Dependency level: <code>file</code> (default), <code>module</code>, <code>package</code> - <code>--cluster-by</code>: Group nodes by: <code>directory</code>, <code>module</code>, <code>package</code> - <code>--max-nodes</code>: Maximum nodes to display - <code>--include, -i</code>: Include file patterns (e.g., \".py\") - <code>--exclude, -e</code>: Exclude file patterns (e.g., \"*test\") - <code>--layout</code>: Graph layout: <code>hierarchical</code>, <code>circular</code>, <code>shell</code>, <code>kamada</code></p> <p>Features: - Auto-detection: Automatically detects project type (Python, Node.js, Java, Go, etc.) - Smart aggregation: Three levels of dependency views (file, module, package) - Interactive HTML: D3.js or Plotly-based interactive visualizations - Pure Python: All visualization libraries installable via <code>pip install tenets[viz]</code></p> <p>Examples:</p> Bash<pre><code># Auto-detect project type and show dependencies\ntenets viz deps\n\n# Generate interactive HTML visualization\ntenets viz deps --format html --output deps.html\n\n# Module-level dependencies as SVG\ntenets viz deps --level module --format svg --output modules.svg\n\n# Package architecture with clustering\ntenets viz deps --level package --cluster-by package --output packages.png\n\n# Circular layout for better visibility\ntenets viz deps --layout circular --format svg --output circular.svg\n\n# Limit to top 50 nodes for large projects\ntenets viz deps --max-nodes 50 --format png --output top50.png\n\n# Export to Graphviz DOT format\ntenets viz deps --format dot --output graph.dot\n\n# Filter specific files\ntenets viz deps src/ --include \"*.py\" --exclude \"*test*\"\n</code></pre> <p>ASCII Output Example: Text Only<pre><code>Dependency Tree\n\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\n\n\u251c\u2500\u2500 main.py\n\u2502   \u251c\u2500\u2500 auth/handler.py\n\u2502   \u2502   \u251c\u2500\u2500 auth/oauth.py\n\u2502   \u2502   \u2502   \u2514\u2500\u2500 utils/crypto.py\n\u2502   \u2502   \u2514\u2500\u2500 models/user.py\n\u2502   \u2502       \u2514\u2500\u2500 db/base.py\n\u2502   \u2514\u2500\u2500 api/routes.py\n\u2502       \u251c\u2500\u2500 api/endpoints.py\n\u2502       \u2514\u2500\u2500 middleware/cors.py\n\u2514\u2500\u2500 config.py\n</code></pre></p>"},{"location":"CLI/#viz-complexity","title":"viz complexity","text":"<p>Visualize code complexity metrics.</p> Bash<pre><code>tenets viz complexity [path] [options]\n</code></pre> <p>Options: - <code>--output, -o</code>: Save to file - <code>--format, -f</code>: Format: <code>ascii</code>, <code>png</code>, <code>html</code> - <code>--metric, -m</code>: Metric type: <code>cyclomatic</code> (default), <code>cognitive</code> - <code>--threshold</code>: Highlight files above threshold - <code>--hotspots</code>: Focus on complexity hotspots</p> <p>Examples:</p> Bash<pre><code># ASCII bar chart of complexity\ntenets viz complexity\n\n# Show only high-complexity files\ntenets viz complexity --threshold 10 --hotspots\n\n# Save as image\ntenets viz complexity --output complexity.png\n</code></pre> <p>ASCII Output Example: Text Only<pre><code>Complexity Analysis (cyclomatic)\n\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\n\nauth/oauth.py                 \u25cf \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588 28\nmodels/user.py               \u25d0 \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588 15\napi/endpoints.py             \u25d0 \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588 12\nutils/validators.py          \u25cf \u2588\u2588\u2588\u2588\u2588\u2588 8\nconfig/settings.py           \u25cf \u2588\u2588\u2588\u2588 5\n\nLegend: \u25cf Low  \u25d0 Medium  \u25d1 High  \u25cb Very High\n</code></pre></p>"},{"location":"CLI/#viz-coupling","title":"viz coupling","text":"<p>Visualize files that frequently change together.</p> Bash<pre><code>tenets viz coupling [path] [options]\n</code></pre> <p>Options: - <code>--output, -o</code>: Save to file - <code>--format, -f</code>: Format: <code>ascii</code>, <code>html</code> - <code>--min-coupling</code>: Minimum coupling count (default: 2)</p> <p>Examples:</p> Bash<pre><code># Show file coupling matrix\ntenets viz coupling\n\n# Only strong couplings\ntenets viz coupling --min-coupling 5\n\n# Interactive HTML matrix\ntenets viz coupling --output coupling.html\n</code></pre> <p>ASCII Output Example: Text Only<pre><code>File Coupling Matrix\n\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\n\n                    auth.py  user.py  api.py  test.py\nauth.py               -        8       3       12\nuser.py               8        -       5       10\napi.py                3        5       -       7\ntest_auth.py         12       10      7        -\n</code></pre></p>"},{"location":"CLI/#viz-contributors","title":"viz contributors","text":"<p>Visualize contributor activity and code ownership.</p> Bash<pre><code>tenets viz contributors [path] [options]\n</code></pre> <p>Options: - <code>--output, -o</code>: Save to file - <code>--format, -f</code>: Format: <code>ascii</code>, <code>png</code> - <code>--active</code>: Show only currently active contributors</p> <p>Examples:</p> Bash<pre><code># Contributor stats\ntenets viz contributors\n\n# Active contributors only\ntenets viz contributors --active\n</code></pre>"},{"location":"CLI/#session-commands","title":"Session Commands","text":"<p>Tenets can persist session state across distill runs. When a configuration is loaded, sessions are stored in a local SQLite database under the cache directory (see Storage below). Use <code>--session &lt;name&gt;</code> with commands like <code>distill</code> to build iterative context.</p> <ul> <li>Only one session is considered active at a time. Resuming a session will mark all others inactive.</li> <li>If a session NAME is omitted for <code>resume</code> or <code>exit</code>, Tenets operates on the currently active session.</li> </ul>"},{"location":"CLI/#session-create","title":"session create","text":"<p>Create a new analysis session.</p> Bash<pre><code>tenets session create &lt;name&gt;\n</code></pre> <p>Example: Bash<pre><code>tenets session create payment-integration\n</code></pre></p>"},{"location":"CLI/#session-start","title":"session start","text":"<p>Alias of <code>session create</code>.</p> Bash<pre><code>tenets session start &lt;name&gt;\n</code></pre>"},{"location":"CLI/#session-resume","title":"session resume","text":"<p>Mark an existing session as active.</p> Bash<pre><code># Resume the active session (if one exists)\ntenets session resume\n\n# Or specify by name\ntenets session resume &lt;name&gt;\n</code></pre>"},{"location":"CLI/#session-exit","title":"session exit","text":"<p>Mark a session as inactive.</p> Bash<pre><code># Exit the current active session\ntenets session exit\n\n# Or exit a specific session by name\ntenets session exit &lt;name&gt;\n</code></pre>"},{"location":"CLI/#session-list","title":"session list","text":"<p>List all sessions.</p> Bash<pre><code>tenets session list\n</code></pre> <p>The output includes an Active column (\"yes\" indicates the current session).</p>"},{"location":"CLI/#session-delete","title":"session delete","text":"<p>Delete a specific session.</p> Bash<pre><code>tenets session delete &lt;name&gt; [--keep-context]\n</code></pre> <p>Options: - <code>--keep-context</code>: Keep stored context artifacts (default: false)</p>"},{"location":"CLI/#session-reset","title":"session reset","text":"<p>Reset (delete and recreate) a session, purging its context.</p> Bash<pre><code>tenets session reset &lt;name&gt;\n</code></pre>"},{"location":"CLI/#session-clear","title":"session clear","text":"<p>Delete ALL sessions at once. Useful for clearing cache and starting fresh.</p> Bash<pre><code>tenets session clear [--keep-context]\n</code></pre> <p>Options: - <code>--keep-context</code>: Keep stored artifacts (default: false, deletes everything)</p> <p>Example: Bash<pre><code># Clear all sessions and their data\ntenets session clear\n\n# Clear sessions but preserve context files\ntenets session clear --keep-context\n</code></pre></p>"},{"location":"CLI/#session-show","title":"session show","text":"<p>Show details for a specific session.</p> Bash<pre><code>tenets session show &lt;name&gt;\n</code></pre>"},{"location":"CLI/#session-add","title":"session add","text":"<p>Attach arbitrary content to a session.</p> Bash<pre><code>tenets session add &lt;name&gt; &lt;kind&gt; &lt;file&gt;\n</code></pre> <p>Arguments: - <code>name</code>: Session name - <code>kind</code>: Content type tag (e.g., note, context_result) - <code>file</code>: File to attach</p> <p>Notes: - Creating or resetting a session marks it active. - Only one session is active at a time (resuming one deactivates others). - Session data is stored in SQLite under <code>~/.tenets/cache/sessions.db</code></p>"},{"location":"CLI/#tenet-commands","title":"Tenet Commands","text":"<p>Create and manage guiding principles (\u201ctenets\u201d) that can be injected into context.</p>"},{"location":"CLI/#tenet-add","title":"tenet add","text":"<p>Add a new tenet.</p> Bash<pre><code>tenets tenet add \"Always use type hints\" --priority high --category style\ntenets tenet add \"Validate all user inputs\" --priority critical --category security\ntenets tenet add \"Use async/await for I/O\" --session feature-x\n</code></pre> <p>Options: - <code>--priority, -p</code>: low | medium | high | critical (default: medium) - <code>--category, -c</code>: Freeform tag (e.g., architecture, security, style, performance, testing) - <code>--session, -s</code>: Bind tenet to a session</p>"},{"location":"CLI/#tenet-list","title":"tenet list","text":"<p>List tenets with filters.</p> Bash<pre><code>tenets tenet list\ntenets tenet list --pending\ntenets tenet list --session oauth --category security --verbose\n</code></pre> <p>Options: - <code>--pending</code>: Only pending - <code>--instilled</code>: Only instilled - <code>--session, -s</code>: Filter by session - <code>--category, -c</code>: Filter by category - <code>--verbose, -v</code>: Show full content and metadata</p>"},{"location":"CLI/#tenet-remove","title":"tenet remove","text":"<p>Remove a tenet by ID (partial ID accepted).</p> Bash<pre><code>tenets tenet remove abc123\ntenets tenet remove abc123 --force\n</code></pre>"},{"location":"CLI/#tenet-show","title":"tenet show","text":"<p>Show details for a tenet.</p> Bash<pre><code>tenets tenet show abc123\n</code></pre>"},{"location":"CLI/#tenet-export--import","title":"tenet export / import","text":"<p>Export/import tenets.</p> Bash<pre><code># Export to stdout or file\ntenets tenet export\ntenets tenet export --format json --session oauth -o team-tenets.json\n\n# Import from file (optionally into a session)\ntenets tenet import team-tenets.yml\ntenets tenet import standards.json --session feature-x\n</code></pre>"},{"location":"CLI/#instill-command","title":"Instill Command","text":"<p>Apply tenets to the current context with smart strategies (periodic/adaptive/manual).</p> Bash<pre><code>tenets instill [options]\n</code></pre> <p>Common options: - <code>--session, -s</code>: Use a named session for history and pinned files - <code>--force</code>: Force instillation regardless of frequency - <code>--max-tenets</code>: Cap number of tenets applied</p> <p>Examples:</p> Bash<pre><code># Apply pending tenets for a session\ntenets instill --session refactor-auth\n\n# Force all tenets once\ntenets instill --force\n</code></pre>"},{"location":"CLI/#system-instruction-commands","title":"System Instruction Commands","text":"<p>Manage the system instruction (system prompt) that can be auto-injected at the start of a session\u2019s first distill (or every output if no session is used).</p>"},{"location":"CLI/#system-instruction-set","title":"system-instruction set","text":"<p>Set/update the system instruction and options.</p> Bash<pre><code>tenets system-instruction set \"You are a helpful coding assistant\" \\\n  --enable \\\n  --position top \\\n  --format markdown\n\n# From file\ntenets system-instruction set --file prompts/system.md --enable\n</code></pre> <p>Options: - <code>--file, -f</code>: Read instruction from file - <code>--enable/--disable</code>: Enable or disable auto-injection - <code>--position</code>: Placement: <code>top</code>, <code>after_header</code>, <code>before_content</code> - <code>--format</code>: Format of injected block: <code>markdown</code>, <code>xml</code>, <code>comment</code>, <code>plain</code> - <code>--save/--no-save</code>: Persist to config</p>"},{"location":"CLI/#system-instruction-show","title":"system-instruction show","text":"<p>Display current configuration and instruction.</p> Bash<pre><code>tenets system-instruction show\ntenets system-instruction show --raw\n</code></pre> <p>Options: - <code>--raw</code>: Print raw instruction only</p>"},{"location":"CLI/#system-instruction-clear","title":"system-instruction clear","text":"<p>Clear and disable the system instruction.</p> Bash<pre><code>tenets system-instruction clear\ntenets system-instruction clear --yes\n</code></pre> <p>Options: - <code>--yes, -y</code>: Skip confirmation</p>"},{"location":"CLI/#system-instruction-test","title":"system-instruction test","text":"<p>Preview how injection would modify content.</p> Bash<pre><code>tenets system-instruction test\ntenets system-instruction test --session my-session\n</code></pre> <p>Options: - <code>--session</code>: Test with a session to respect once-per-session behavior</p>"},{"location":"CLI/#system-instruction-export","title":"system-instruction export","text":"<p>Export the instruction to a file.</p> Bash<pre><code>tenets system-instruction export prompts/system.md\n</code></pre>"},{"location":"CLI/#system-instruction-validate","title":"system-instruction validate","text":"<p>Validate the instruction for basic issues and optional token estimates.</p> Bash<pre><code>tenets system-instruction validate\ntenets system-instruction validate --tokens --max-tokens 800\n</code></pre> <p>Options: - <code>--tokens</code>: Show a rough token estimate - <code>--max-tokens</code>: Threshold for warnings/errors</p>"},{"location":"CLI/#system-instruction-edit","title":"system-instruction edit","text":"<p>Edit the instruction in your editor and save changes back to config.</p> Bash<pre><code>tenets system-instruction edit\ntenets system-instruction edit --editor code\n</code></pre>"},{"location":"CLI/#session-show_1","title":"session show","text":"<p>Show session details.</p> Bash<pre><code>tenets session show &lt;name&gt;\n</code></pre>"},{"location":"CLI/#session-add_1","title":"session add","text":"<p>Attach an artifact (stored as text) to a session.</p> Bash<pre><code>tenets session add &lt;name&gt; &lt;kind&gt; &lt;file&gt;\n</code></pre> <p>Examples of <code>kind</code>: <code>note</code>, <code>context_result</code>, <code>summary</code></p>"},{"location":"CLI/#session-reset_1","title":"session reset","text":"<p>Reset (delete and recreate) a session and purge its context.</p> Bash<pre><code>tenets session reset &lt;name&gt;\n</code></pre>"},{"location":"CLI/#session-delete_1","title":"session delete","text":"<p>Delete a session. Optionally keep stored artifacts.</p> Bash<pre><code>tenets session delete &lt;name&gt; [--keep-context]\n</code></pre>"},{"location":"CLI/#cache-management","title":"Cache Management","text":"Text Only<pre><code># Show cache stats (path, file count, size)\ntenets config cache-stats\n\n# Cleanup old/oversized entries respecting TTL\ntenets config cleanup-cache\n\n# Clear ALL caches (analysis + general) \u2013 destructive\ntenets config clear-cache --yes\n</code></pre> <p>Git data is used strictly for ranking relevance unless explicitly requested via commands like <code>chronicle</code> or <code>viz contributors</code>; it is not embedded in <code>distill</code> output.</p>"},{"location":"CLI/#configuration","title":"Configuration","text":""},{"location":"CLI/#config-set","title":"config set","text":"<p>Set configuration values.</p> Bash<pre><code>tenets config set &lt;key&gt; &lt;value&gt;\n</code></pre> <p>Examples: Bash<pre><code># Set default ranking algorithm\ntenets config set ranking.algorithm balanced\n\n# Set maximum file size\ntenets config set scanner.max_file_size 10000000\n\n# Enable ML features\ntenets config set nlp.use_embeddings true\n</code></pre></p>"},{"location":"CLI/#config-show","title":"config show","text":"<p>Show configuration.</p> Bash<pre><code>tenets config show [options]\n</code></pre> <p>Options: - <code>--key, -k</code>: Show specific key</p> <p>Examples: Bash<pre><code># Show all config\ntenets config show\n\n# Show model costs\ntenets config show --key costs\n\n# Show specific setting\ntenets config show --key ranking.algorithm\n</code></pre></p>"},{"location":"CLI/#storage","title":"Storage","text":"<p>Writable data is stored in a user/project cache directory:</p> <ul> <li>Default: <code>${HOME}/.tenets/cache</code> (Windows: <code>%USERPROFILE%\\\\.tenets\\\\cache</code>)</li> <li>Main DB: <code>${CACHE_DIR}/tenets.db</code> (sessions and future state)</li> <li>Analysis cache: <code>${CACHE_DIR}/analysis/analysis.db</code></li> </ul> <p>Override via <code>.tenets.yml</code>:</p> YAML<pre><code>cache:\n  directory: /path/to/custom/cache\n</code></pre> <p>Or environment:</p> Bash<pre><code>TENETS_CACHE_DIRECTORY=/path/to/custom/cache\n</code></pre> <p>Note on cost estimation: When <code>--estimate-cost</code> is used with <code>distill</code>, Tenets estimates costs using model limits and the built-in pricing table from <code>SUPPORTED_MODELS</code>.</p>"},{"location":"CLI/#common-use-cases","title":"Common Use Cases","text":""},{"location":"CLI/#1-ai-pair-programming","title":"1. AI Pair Programming","text":"<p>Generate context for ChatGPT/Claude when working on features:</p> Bash<pre><code># Initial context for new feature\ntenets distill \"implement user authentication with JWT\" &gt; auth_context.md\n\n# Paste auth_context.md into ChatGPT, then iterate:\ntenets distill \"add password reset functionality\" --session auth-feature\n\n# AI needs to see session info?\ntenets session show auth-feature\n</code></pre>"},{"location":"CLI/#2-code-review-preparation","title":"2. Code Review Preparation","text":"<p>Understand what changed and why:</p> Bash<pre><code># See what changed in the sprint\ntenets chronicle --since \"2 weeks\" --summary\n\n# Get context for reviewing a PR\ntenets distill \"review payment processing changes\"\n\n# Check complexity of changed files\ntenets examine --complexity --hotspots\n</code></pre>"},{"location":"CLI/#3-onboarding-to-new-codebase","title":"3. Onboarding to New Codebase","text":"<p>Quickly understand project structure:</p> Bash<pre><code># Get project overview\ntenets examine --metrics\n\n# Visualize architecture\ntenets viz deps --format ascii\n\n# Find the most complex areas\ntenets viz complexity --hotspots\n\n# See who knows what\ntenets viz contributors\n</code></pre>"},{"location":"CLI/#4-debugging-production-issues","title":"4. Debugging Production Issues","text":"<p>Find relevant code for debugging:</p> Bash<pre><code># Get all context related to the error\ntenets distill \"users getting 500 error on checkout\" --mode thorough\n\n# Include recent changes summary\ntenets chronicle --since \"last-deploy\"\n\n# Search for patterns within a session by iterating with prompts\ntenets distill \"find error handlers\" --session debug-session\n</code></pre>"},{"location":"CLI/#5-technical-debt-assessment","title":"5. Technical Debt Assessment","text":"<p>Identify areas needing refactoring:</p> Bash<pre><code># Find complex files\ntenets examine --complexity --threshold 15\n\n# Find tightly coupled code\ntenets viz coupling --min-coupling 5\n\n# Track velocity trends\ntenets momentum --team --since \"6 months\"\n</code></pre>"},{"location":"CLI/#6-architecture-documentation","title":"6. Architecture Documentation","text":"<p>Generate architecture insights:</p> Bash<pre><code># Export dependency graph\ntenets viz deps --output architecture.svg --cluster-by directory\n\n# Generate comprehensive analysis\ntenets examine --deep --output analysis.json --format json\n\n# Create context for documentation\ntenets distill \"document API architecture\" ./src/api\n</code></pre>"},{"location":"CLI/#examples","title":"Examples","text":""},{"location":"CLI/#complete-workflow-example","title":"Complete Workflow Example","text":"Bash<pre><code># 1. Start a new feature\ntenets session create oauth-integration\n\n# 2. Get initial context\ntenets distill \"implement OAuth2 with Google and GitHub\" \\\n  --session oauth-integration \\\n  --include \"*.py,*.yaml\" \\\n  --exclude \"test_*\" \\\n  --model gpt-4o \\\n  --estimate-cost &gt; oauth_context.md\n\n# 3. Paste into ChatGPT, start coding...\n\n# 4. AI needs more specific context\n# (Show session details)\ntenets session show oauth-integration\n\n# 5. Check your progress\ntenets chronicle --since \"today\"\n\n# 6. Visualize what you built\ntenets viz deps src/auth --format ascii\n\n# 7. Check complexity\ntenets examine src/auth --complexity\n\n# 8. Prepare for review\ntenets distill \"OAuth implementation ready for review\" \\\n  --session oauth-integration\n</code></pre>"},{"location":"CLI/#configuration-file-example","title":"Configuration File Example","text":"<p>Create <code>.tenets.yml</code> in your project:</p> YAML<pre><code># .tenets.yml\ncontext:\n  ranking: balanced\n  max_tokens: 100000\n  include_git: true\n\nscanner:\n  respect_gitignore: true\n  max_file_size: 5000000\n\nignore:\n  - \"*.generated.*\"\n  - \"vendor/\"\n  - \"build/\"\n\noutput:\n  format: markdown\n  summarize_long_files: true\n</code></pre>"},{"location":"CLI/#tips-and-tricks","title":"Tips and Tricks","text":"<ol> <li>Start with fast mode for quick exploration, use thorough for complex tasks</li> <li>Use sessions for multi-step features to maintain context</li> <li>ASCII visualizations are great for README files and documentation</li> <li>Combine commands - examine first, then distill with insights</li> <li>Git integration works automatically - no setup needed</li> <li>Include/exclude patterns support standard glob syntax</li> <li>Cost estimation helps budget API usage before sending to LLMs</li> </ol>"},{"location":"CLI/#environment-variables","title":"Environment Variables","text":"<ul> <li><code>TENETS_CONFIG_PATH</code>: Custom config file location</li> <li><code>TENETS_LOG_LEVEL</code>: Set log level (DEBUG, INFO, WARNING, ERROR)</li> <li><code>TENETS_CACHE_DIR</code>: Custom cache directory</li> <li><code>TENETS_NO_COLOR</code>: Disable colored output</li> </ul>"},{"location":"CLI/#exit-codes","title":"Exit Codes","text":"<ul> <li><code>0</code>: Success</li> <li><code>1</code>: General error</li> <li><code>2</code>: Invalid arguments</li> <li><code>3</code>: File not found</li> <li><code>4</code>: Git repository required but not found</li> </ul> <p>For more information, visit https://github.com/jddunn/tenets</p>"},{"location":"CLI/#verbosity--output-controls","title":"Verbosity &amp; Output Controls","text":"<p>Control log verbosity globally:</p> Bash<pre><code># Default (warnings and above only)\nTENETS_LOG_LEVEL=WARNING tenets distill \"add caching layer\"\n\n# Verbose\ntenets --verbose distill \"add caching layer\"\n\n# Quiet / errors only\ntenets --quiet distill \"add caching layer\"\n# or\ntenets --silent distill \"add caching layer\"\n</code></pre> <p>The <code>distill</code> command includes a Suggestions section when no files are included, with tips to adjust relevance thresholds, token budget, and include patterns.</p>"},{"location":"CODE_OF_CONDUCT/","title":"Code of Conduct","text":"<p>We are committed to a respectful, inclusive, and collaborative community. This Code of Conduct applies to all project spaces (GitHub issues/PRs, discussions, docs, chat) and anyone interacting with the project.</p>"},{"location":"CODE_OF_CONDUCT/#our-standards","title":"Our Standards","text":"<p>Positive behaviors: - Being welcoming, empathetic, and considerate - Giving and gracefully accepting constructive feedback - Focusing on what is best for the community - Showing respect for differing viewpoints and experiences</p> <p>Unacceptable behaviors: - Harassment, intimidation, or discrimination of any kind - Personal attacks or insults - Doxxing or sharing private information - Trolling, excessive disruption, or derailing conversations - Sexualized language or imagery; unwelcome advances</p>"},{"location":"CODE_OF_CONDUCT/#scope","title":"Scope","text":"<p>Applies within all project spaces and when representing the project in public.</p>"},{"location":"CODE_OF_CONDUCT/#enforcement","title":"Enforcement","text":"<p>Report incidents to: team@tenets.dev (core maintainers). Include: - Your contact (optional) - Names, links, or references involved - Context, timeline, and any evidence (screenshots, logs)</p> <p>Reports are handled confidentially. Maintainers may take any reasonable action: - Verbal / written warning - Temporary or permanent ban from interactions - Removal of unacceptable content - Escalation to hosting platforms if required</p>"},{"location":"CODE_OF_CONDUCT/#maintainer-responsibilities","title":"Maintainer Responsibilities","text":"<p>Maintainers must model acceptable behavior and are responsible for clarifying standards and taking corrective action when misconduct occurs.</p>"},{"location":"CODE_OF_CONDUCT/#attribution","title":"Attribution","text":"<p>Adapted from the Contributor Covenant v2.1 (https://www.contributor-covenant.org) with project-specific clarifications.</p>"},{"location":"CODE_OF_CONDUCT/#contact","title":"Contact","text":"<p>Questions or concerns: team@tenets.dev</p> <p>We strive for a community where all contributors feel safe and empowered to improve Tenets.</p>"},{"location":"CONFIG/","title":"Configuration Guide","text":"<p>Comprehensive guide to configuring Tenets for optimal code context building.</p>"},{"location":"CONFIG/#overview","title":"Overview","text":"<p>Tenets uses a hierarchical configuration system with multiple override levels:</p> <p>Precedence (lowest \u2192 highest): 1. Default configuration (built-in) 2. Project file (<code>.tenets.yml</code> at repo root) 3. User file (<code>~/.config/tenets/config.yml</code> or <code>~/.tenets.yml</code>) 4. Environment variables (<code>TENETS_*</code>) 5. CLI flags (<code>--mode</code>, <code>--max-tokens</code>, etc.) 6. Programmatic overrides (<code>Tenets(config=...)</code>)</p> <p>Inspect configuration: Bash<pre><code>tenets config show                # Full config\ntenets config show --key ranking  # Specific section\ntenets config show --format json  # JSON output\n</code></pre></p>"},{"location":"CONFIG/#files-and-locations","title":"Files and locations","text":"<p>Tenets searches these locations in order and uses the first it finds: - ./.tenets.yml - ./.tenets.yaml - ./tenets.yml - ./.config/tenets.yml - ~/.config/tenets/config.yml - ~/.tenets.yml</p> <p>Create a starter file:</p> <ul> <li>tenets config init  # writes .tenets.yml in the current directory</li> </ul>"},{"location":"CONFIG/#complete-configuration-schema","title":"Complete Configuration Schema","text":"<p>All available configuration sections and their options:</p> YAML<pre><code># ============= Core Settings =============\nmax_tokens: 100000          # Maximum tokens for context (default: 100000)\ndebug: false                # Enable debug logging\nquiet: false                # Suppress non-essential output\n\n# ============= File Scanning =============\nscanner:\n  respect_gitignore: true          # Honor .gitignore patterns\n  follow_symlinks: false           # Follow symbolic links\n  max_file_size: 5000000          # Max file size in bytes (5MB)\n  max_files: 10000                # Maximum files to scan\n  binary_check: true              # Skip binary files\n  encoding: utf-8                 # File encoding\n  workers: 4                      # Parallel scanning workers\n  parallel_mode: auto             # auto | thread | process\n  timeout: 5.0                    # Timeout per file (seconds)\n  exclude_minified: true          # Skip minified files\n  exclude_tests_by_default: true  # Skip test files unless explicit\n\n  # Ignore patterns (in addition to .gitignore)\n  additional_ignore_patterns:\n    - '*.generated.*'\n    - vendor/\n    - node_modules/\n    - '*.egg-info/'\n    - __pycache__/\n    - .pytest_cache/\n\n  # Test file patterns\n  test_patterns:\n    - test_*.py\n    - '*_test.py'\n    - '*.test.js'\n    - '*.spec.ts'\n\n  # Test directories\n  test_directories:\n    - test\n    - tests\n    - __tests__\n    - spec\n\n# ============= Ranking System =============\nranking:\n  algorithm: balanced             # fast | balanced | thorough | ml | custom\n  threshold: 0.10                 # 0.0-1.0 (lower includes more files)\n  text_similarity_algorithm: bm25 # bm25 (default) | tfidf (optional)\n  text_similarity_algorithm: bm25  # Using BM25 (default)               # Deprecated - use text_similarity_algorithm instead\n  use_stopwords: false           # Filter common tokens\n  use_embeddings: false          # Semantic similarity (requires ML)\n  use_git: true                  # Include git signals\n  use_ml: false                  # Machine learning features\n  embedding_model: all-MiniLM-L6-v2  # Embedding model name\n  workers: 2                     # Parallel ranking workers\n  parallel_mode: auto            # thread | process | auto\n  batch_size: 100               # Files per batch\n\n  # Custom factor weights (0.0-1.0)\n  custom_weights:\n    keyword_match: 0.25\n    path_relevance: 0.20\n    import_graph: 0.20\n    git_activity: 0.15\n    file_type: 0.10\n    complexity: 0.10\n\n# ============= Summarization =============\nsummarizer:\n  default_mode: auto             # auto | extractive | abstractive\n  target_ratio: 0.3              # Target compression ratio\n  enable_cache: true             # Cache summaries\n  preserve_code_structure: true  # Keep code structure intact\n  summarize_imports: true        # Condense import statements\n  import_summary_threshold: 5    # Min imports to trigger summary\n  max_cache_size: 100           # Max cached summaries\n  quality_threshold: medium      # low | medium | high\n  batch_size: 10                # Files per batch\n  docstring_weight: 0.5         # Weight for docstrings\n  include_all_signatures: true   # Include all function signatures\n\n  # LLM settings (optional)\n  llm_provider: null            # openai | anthropic | null\n  llm_model: null               # Model name\n  llm_temperature: 0.3          # Creativity (0.0-1.0)\n  llm_max_tokens: 500           # Max tokens per summary\n  enable_ml_strategies: false    # Use ML summarization\n\n# ============= Tenet System =============\ntenet:\n  auto_instill: true              # Auto-apply tenets\n  max_per_context: 5              # Max tenets per context\n  reinforcement: true             # Reinforce important tenets\n  injection_strategy: strategic   # strategic | sequential | random\n  min_distance_between: 1000      # Min chars between injections\n  prefer_natural_breaks: true     # Insert at natural boundaries\n  storage_path: ~/.tenets/tenets  # Tenet storage location\n  collections_enabled: true       # Enable tenet collections\n\n  # Injection frequency\n  injection_frequency: adaptive   # always | periodic | adaptive | manual\n  injection_interval: 3           # For periodic mode\n  session_complexity_threshold: 0.7  # Triggers adaptive injection\n  min_session_length: 5           # Min prompts before injection\n\n  # Advanced settings\n  adaptive_injection: true        # Smart injection timing\n  track_injection_history: true   # Track what was injected\n  decay_rate: 0.1                # How fast tenets decay\n  reinforcement_interval: 10      # Reinforce every N prompts\n  session_aware: true            # Use session context\n  session_memory_limit: 100      # Max session history\n  persist_session_history: true   # Save session data\n\n  # Priority settings\n  priority_boost_critical: 2.0    # Boost for critical tenets\n  priority_boost_high: 1.5       # Boost for high priority\n  skip_low_priority_on_complex: true  # Skip low priority when complex\n\n  # System instruction\n  system_instruction: null        # Global system instruction\n  system_instruction_enabled: false  # Enable system instruction\n  system_instruction_position: top   # top | bottom\n  system_instruction_format: markdown  # markdown | plain\n  system_instruction_once_per_session: true  # Inject once per session\n\n# ============= Caching =============\ncache:\n  enabled: true                  # Enable caching\n  directory: ~/.tenets/cache     # Cache directory\n  ttl_days: 7                   # Time to live (days)\n  max_size_mb: 500              # Max cache size (MB)\n  compression: false            # Compress cache data\n  memory_cache_size: 1000       # In-memory cache entries\n  max_age_hours: 24            # Max cache age (hours)\n\n  # SQLite settings\n  sqlite_pragmas:\n    journal_mode: WAL\n    synchronous: NORMAL\n    cache_size: '-64000'\n    temp_store: MEMORY\n\n  # LLM cache\n  llm_cache_enabled: true       # Cache LLM responses\n  llm_cache_ttl_hours: 24      # LLM cache TTL\n\n# ============= Output Formatting =============\noutput:\n  default_format: markdown       # markdown | xml | json | html\n  syntax_highlighting: true      # Enable syntax highlighting\n  line_numbers: false           # Show line numbers\n  max_line_length: 120          # Max line length\n  include_metadata: true        # Include metadata\n  compression_threshold: 10000  # Compress if larger (chars)\n  summary_ratio: 0.25           # Summary compression ratio\n  copy_on_distill: false        # Auto-copy to clipboard\n  show_token_usage: true        # Show token counts\n  show_cost_estimate: true      # Show LLM cost estimates\n\n# ============= Git Integration =============\ngit:\n  enabled: true                 # Use git information\n  include_history: true         # Include commit history\n  history_limit: 100           # Max commits to analyze\n  include_blame: false         # Include git blame\n  include_stats: true          # Include statistics\n\n  # Ignore these authors\n  ignore_authors:\n    - dependabot[bot]\n    - github-actions[bot]\n    - renovate[bot]\n\n  # Main branch names\n  main_branches:\n    - main\n    - master\n    - develop\n    - trunk\n\n# ============= NLP Settings =============\nnlp:\n  enabled: true                    # Enable NLP features\n  stopwords_enabled: true          # Use stopwords\n  code_stopword_set: minimal       # minimal | standard | aggressive\n  prompt_stopword_set: aggressive  # minimal | standard | aggressive\n  custom_stopword_files: []        # Custom stopword files\n\n  # Tokenization\n  tokenization_mode: auto          # auto | simple | advanced\n  preserve_original_tokens: true   # Keep original tokens\n  split_camelcase: true           # Split CamelCase\n  split_snakecase: true           # Split snake_case\n  min_token_length: 2             # Min token length\n\n  # Keyword extraction\n  keyword_extraction_method: auto  # auto | rake | yake | bm25 | tfidf\n  max_keywords: 30                # Max keywords to extract\n  ngram_size: 3                  # N-gram size\n  yake_dedup_threshold: 0.7      # YAKE deduplication\n\n  # BM25 settings\n  bm25_k1: 1.2                   # Term frequency saturation parameter\n  bm25_b: 0.75                   # Length normalization parameter\n\n  # TF-IDF settings (when explicitly configured as alternative to BM25)\n  tfidf_use_sublinear: true      # Sublinear TF scaling (only when TF-IDF is used)\n  tfidf_use_idf: true           # Use IDF\n  tfidf_norm: l2                # Normalization\n\n  # Embeddings\n  embeddings_enabled: false       # Enable embeddings\n  embeddings_model: all-MiniLM-L6-v2  # Model name\n  embeddings_device: auto        # cpu | cuda | auto\n  embeddings_cache: true         # Cache embeddings\n  embeddings_batch_size: 32      # Batch size\n  similarity_metric: cosine      # cosine | euclidean | manhattan\n  similarity_threshold: 0.7      # Similarity threshold\n\n  # Cache settings\n  cache_embeddings_ttl_days: 30  # Embeddings cache TTL\n  cache_tfidf_ttl_days: 7       # BM25/TF-IDF cache TTL\n  cache_keywords_ttl_days: 7     # Keywords cache TTL\n\n  # Performance\n  multiprocessing_enabled: true   # Use multiprocessing\n  multiprocessing_workers: null   # null = auto-detect\n  multiprocessing_chunk_size: 100 # Chunk size\n\n# ============= LLM Settings (Optional) =============\nllm:\n  enabled: false                # Enable LLM features\n  provider: openai              # openai | anthropic | ollama\n  fallback_providers:           # Fallback providers\n    - anthropic\n    - openrouter\n\n  # API keys (use environment variables)\n  api_keys:\n    openai: ${OPENAI_API_KEY}\n    anthropic: ${ANTHROPIC_API_KEY}\n    openrouter: ${OPENROUTER_API_KEY}\n\n  # API endpoints\n  api_base_urls:\n    openai: https://api.openai.com/v1\n    anthropic: https://api.anthropic.com/v1\n    openrouter: https://openrouter.ai/api/v1\n    ollama: http://localhost:11434\n\n  # Model selection\n  models:\n    default: gpt-4o-mini\n    summarization: gpt-3.5-turbo\n    analysis: gpt-4o\n    embeddings: text-embedding-3-small\n    code_generation: gpt-4o\n\n  # Rate limits and costs\n  max_cost_per_run: 0.1         # Max $ per run\n  max_cost_per_day: 10.0        # Max $ per day\n  max_tokens_per_request: 4000   # Max tokens per request\n  max_context_length: 100000     # Max context length\n\n  # Generation settings\n  temperature: 0.3              # Creativity (0.0-1.0)\n  top_p: 0.95                  # Nucleus sampling\n  frequency_penalty: 0.0        # Frequency penalty\n  presence_penalty: 0.0         # Presence penalty\n\n  # Network settings\n  requests_per_minute: 60       # Rate limit\n  retry_on_error: true         # Retry failed requests\n  max_retries: 3              # Max retry attempts\n  retry_delay: 1.0            # Initial retry delay\n  retry_backoff: 2.0          # Backoff multiplier\n  timeout: 30                 # Request timeout (seconds)\n  stream: false               # Stream responses\n\n  # Logging and caching\n  cache_responses: true        # Cache LLM responses\n  cache_ttl_hours: 24         # Cache TTL (hours)\n  log_requests: false         # Log requests\n  log_responses: false        # Log responses\n\n# ============= Custom Settings =============\ncustom: {}  # User-defined custom settings\n</code></pre>"},{"location":"CONFIG/#key-configuration-notes","title":"Key Configuration Notes","text":"<p>Ranking: - <code>threshold</code>: Lower values (0.05-0.10) include more files, higher (0.20-0.30) for stricter matching - <code>algorithm</code>:   - <code>fast</code>: Quick keyword matching (~10ms/file)   - <code>balanced</code>: Structural analysis + BM25 (default)   - <code>thorough</code>: Full analysis with relationships   - <code>ml</code>: Machine learning with embeddings (requires extras) - <code>custom_weights</code>: Fine-tune ranking factors (values 0.0-1.0)</p> <p>Scanner: - <code>respect_gitignore</code>: Always honors .gitignore patterns - <code>exclude_tests_by_default</code>: Tests excluded unless <code>--include-tests</code> used - <code>additional_ignore_patterns</code>: Added to built-in patterns</p> <p>Tenet System: - <code>auto_instill</code>: Automatically applies relevant tenets to context - <code>injection_frequency</code>:   - <code>always</code>: Every distill   - <code>periodic</code>: Every N distills   - <code>adaptive</code>: Based on complexity   - <code>manual</code>: Only when explicitly called - <code>system_instruction</code>: Global instruction added to all contexts</p> <p>Output: - <code>copy_on_distill</code>: Auto-copy result to clipboard - <code>default_format</code>: Default output format (markdown recommended for LLMs)</p> <p>Performance: - <code>workers</code>: More workers = faster but more CPU/memory - <code>cache.enabled</code>: Significantly speeds up repeated operations - <code>ranking.batch_size</code>: Larger batches = more memory but faster</p>"},{"location":"CONFIG/#environment-variable-overrides","title":"Environment Variable Overrides","text":"<p>Any configuration option can be overridden via environment variables.</p> <p>Format: - Nested keys: <code>TENETS_&lt;SECTION&gt;_&lt;KEY&gt;=value</code> - Top-level keys: <code>TENETS_&lt;KEY&gt;=value</code> - Lists: Comma-separated values - Booleans: <code>true</code> or <code>false</code> (case-insensitive)</p> <p>Common Examples: Bash<pre><code># Core settings\nexport TENETS_MAX_TOKENS=150000\nexport TENETS_DEBUG=true\nexport TENETS_QUIET=false\n\n# Ranking configuration\nexport TENETS_RANKING_ALGORITHM=thorough\nexport TENETS_RANKING_THRESHOLD=0.05\nexport TENETS_RANKING_TEXT_SIMILARITY_ALGORITHM=tfidf  # Use TF-IDF instead of BM25\nexport TENETS_RANKING_USE_EMBEDDINGS=true\nexport TENETS_RANKING_WORKERS=4\n\n# Scanner settings\nexport TENETS_SCANNER_MAX_FILE_SIZE=10000000\nexport TENETS_SCANNER_RESPECT_GITIGNORE=true\nexport TENETS_SCANNER_EXCLUDE_TESTS_BY_DEFAULT=false\n\n# Output settings\nexport TENETS_OUTPUT_DEFAULT_FORMAT=xml\nexport TENETS_OUTPUT_COPY_ON_DISTILL=true\nexport TENETS_OUTPUT_SHOW_TOKEN_USAGE=false\n\n# Cache settings\nexport TENETS_CACHE_ENABLED=false\nexport TENETS_CACHE_DIRECTORY=/tmp/tenets-cache\nexport TENETS_CACHE_TTL_DAYS=14\n\n# Git settings\nexport TENETS_GIT_ENABLED=false\nexport TENETS_GIT_HISTORY_LIMIT=50\n\n# Tenet system\nexport TENETS_TENET_AUTO_INSTILL=false\nexport TENETS_TENET_MAX_PER_CONTEXT=10\nexport TENETS_TENET_INJECTION_FREQUENCY=periodic\nexport TENETS_TENET_INJECTION_INTERVAL=5\n\n# System instruction\nexport TENETS_TENET_SYSTEM_INSTRUCTION=\"You are a senior engineer. Focus on security and performance.\"\nexport TENETS_TENET_SYSTEM_INSTRUCTION_ENABLED=true\n</code></pre></p> <p>Usage Patterns: Bash<pre><code># One-time override\nTENETS_RANKING_ALGORITHM=fast tenets distill \"fix bug\"\n\n# Session-wide settings\nexport TENETS_RANKING_THRESHOLD=0.05\nexport TENETS_OUTPUT_COPY_ON_DISTILL=true\ntenets distill \"implement feature\"  # Uses exported settings\n\n# Verify configuration\ntenets config show --key ranking\ntenets config show --format json | jq '.ranking'\n</code></pre></p>"},{"location":"CONFIG/#cli-flags-and-programmatic-control","title":"CLI Flags and Programmatic Control","text":""},{"location":"CONFIG/#cli-flags","title":"CLI Flags","text":"<p>Command-line flags override configuration for that specific run:</p> Bash<pre><code># Core overrides\ntenets distill \"query\" --max-tokens 50000\ntenets distill \"query\" --format xml\ntenets distill \"query\" --copy\n\n# Ranking mode\ntenets distill \"query\" --mode fast      # Quick analysis\ntenets distill \"query\" --mode thorough  # Deep analysis\ntenets distill \"query\" --mode ml        # With embeddings\n\n# File filtering\ntenets distill \"query\" --include \"*.py\" --exclude \"test_*.py\"\ntenets distill \"query\" --include-tests  # Include test files\n\n# Git control\ntenets distill \"query\" --no-git  # Disable git signals\n\n# Session management\ntenets distill \"query\" --session feature-x\n\n# Content optimization\ntenets distill \"query\" --condense        # Aggressive compression\ntenets distill \"query\" --remove-comments # Strip comments\ntenets distill \"query\" --full            # No summarization\n</code></pre>"},{"location":"CONFIG/#programmatic-configuration","title":"Programmatic Configuration","text":"<p>Basic usage with custom config: Python<pre><code>from tenets import Tenets\nfrom tenets.config import TenetsConfig\n\n# Create custom configuration\nconfig = TenetsConfig(\n    max_tokens=150000,\n    ranking={\n        \"algorithm\": \"thorough\",\n        \"threshold\": 0.05,\n        \"text_similarity_algorithm\": \"bm25\",  # or \"tfidf\" for TF-IDF\n        \"use_embeddings\": True,\n        \"workers\": 4,\n        \"custom_weights\": {\n            \"keyword_match\": 0.30,\n            \"path_relevance\": 0.25,\n            \"git_activity\": 0.20,\n        }\n    },\n    scanner={\n        \"respect_gitignore\": True,\n        \"max_file_size\": 10_000_000,\n        \"exclude_tests_by_default\": False,\n    },\n    output={\n        \"default_format\": \"xml\",\n        \"copy_on_distill\": True,\n    },\n    tenet={\n        \"auto_instill\": True,\n        \"max_per_context\": 10,\n        \"system_instruction\": \"Focus on security and performance\",\n        \"system_instruction_enabled\": True,\n    }\n)\n\n# Initialize with custom config\ntenets = Tenets(config=config)\n\n# Use it\nresult = tenets.distill(\n    \"implement caching layer\",\n    max_tokens=80000,  # Override config for this call\n    mode=\"balanced\",    # Override algorithm\n)\n</code></pre></p> <p>Load and modify existing config: Python<pre><code>from tenets import Tenets\nfrom tenets.config import TenetsConfig\n\n# Load from file\nconfig = TenetsConfig.from_file(\".tenets.yml\")\n\n# Modify specific settings\nconfig.ranking.algorithm = \"fast\"\nconfig.ranking.threshold = 0.08\nconfig.output.copy_on_distill = True\n\n# Use modified config\ntenets = Tenets(config=config)\n</code></pre></p> <p>Runtime overrides: Python<pre><code># Config precedence: method args &gt; instance config &gt; file config\nresult = tenets.distill(\n    prompt=\"add authentication\",\n    mode=\"thorough\",        # Overrides config.ranking.algorithm\n    max_tokens=100000,      # Overrides config.max_tokens\n    format=\"json\",          # Overrides config.output.default_format\n    session_name=\"auth\",    # Session-specific\n    include_patterns=[\"*.py\", \"*.js\"],\n    exclude_patterns=[\"*.test.js\"],\n)\n</code></pre></p>"},{"location":"CONFIG/#configuration-recipes","title":"Configuration Recipes","text":""},{"location":"CONFIG/#for-different-use-cases","title":"For Different Use Cases","text":"<p>Large Monorepo (millions of files): YAML<pre><code>max_tokens: 150000\nscanner:\n  max_files: 50000\n  workers: 8\n  parallel_mode: process\n  exclude_tests_by_default: true\nranking:\n  algorithm: fast\n  threshold: 0.15\n  workers: 4\n  batch_size: 500\ncache:\n  enabled: true\n  memory_cache_size: 5000\n</code></pre></p> <p>Small Project (high precision): YAML<pre><code>max_tokens: 80000\nranking:\n  algorithm: thorough\n  threshold: 0.08\n  text_similarity_algorithm: bm25  # Default algorithm\n  use_embeddings: true\n  custom_weights:\n    keyword_match: 0.35\n    import_graph: 0.25\n</code></pre></p> <p>Documentation-Heavy Project: YAML<pre><code>summarizer:\n  docstring_weight: 0.8\n  include_all_signatures: true\n  preserve_code_structure: false\nranking:\n  custom_weights:\n    keyword_match: 0.20\n    path_relevance: 0.30  # Prioritize doc paths\n</code></pre></p> <p>Security-Focused Analysis: YAML<pre><code>tenet:\n  system_instruction: |\n    Focus on security implications.\n    Flag any potential vulnerabilities.\n    Suggest secure alternatives.\n  system_instruction_enabled: true\n  auto_instill: true\nscanner:\n  additional_ignore_patterns: []  # Don't skip anything\n  exclude_tests_by_default: false\n</code></pre></p>"},{"location":"CONFIG/#performance-tuning","title":"Performance Tuning","text":"<p>Maximum Speed (sacrifices precision): YAML<pre><code>ranking:\n  algorithm: fast\n  threshold: 0.05\n  text_similarity_algorithm: bm25  # Using BM25 (default)\n  use_embeddings: false\n  workers: 8\nscanner:\n  workers: 8\n  timeout: 2.0\ncache:\n  enabled: true\n  compression: false\n</code></pre></p> <p>Maximum Precision (slower): YAML<pre><code>ranking:\n  algorithm: thorough\n  threshold: 0.20\n  text_similarity_algorithm: bm25  # Default algorithm\n  use_embeddings: true\n  use_git: true\n  workers: 2\nsummarizer:\n  quality_threshold: high\n  enable_ml_strategies: true\n</code></pre></p> <p>Memory-Constrained Environment: YAML<pre><code>scanner:\n  max_files: 1000\n  workers: 1\nranking:\n  workers: 1\n  batch_size: 50\ncache:\n  memory_cache_size: 100\n  max_size_mb: 100\nnlp:\n  embeddings_batch_size: 8\n  multiprocessing_enabled: false\n</code></pre></p>"},{"location":"CONFIG/#common-workflows","title":"Common Workflows","text":"<p>Bug Investigation: YAML<pre><code>ranking:\n  algorithm: balanced\n  threshold: 0.10\n  custom_weights:\n    git_activity: 0.30  # Recent changes matter\n    complexity: 0.20    # Complex code = more bugs\ngit:\n  include_history: true\n  history_limit: 200\n  include_blame: true\n</code></pre></p> <p>New Feature Development: YAML<pre><code>ranking:\n  algorithm: balanced\n  threshold: 0.08\n  custom_weights:\n    import_graph: 0.30  # Dependencies matter\n    path_relevance: 0.25 # Related modules\noutput:\n  copy_on_distill: true\n  show_token_usage: true\n</code></pre></p> <p>Code Review Preparation: YAML<pre><code>summarizer:\n  target_ratio: 0.5  # More detail\n  preserve_code_structure: true\n  include_all_signatures: true\noutput:\n  syntax_highlighting: true\n  line_numbers: true\n  include_metadata: true\n</code></pre></p>"},{"location":"CONFIG/#troubleshooting","title":"Troubleshooting","text":""},{"location":"CONFIG/#common-issues-and-solutions","title":"Common Issues and Solutions","text":"<p>No files included in context: - Lower <code>ranking.threshold</code> (try 0.05) - Use <code>--mode fast</code> for broader inclusion - Increase <code>max_tokens</code> limit - Check if files match <code>--include</code> patterns - Verify files aren't in <code>.gitignore</code> - Use <code>--include-tests</code> if analyzing test files</p> <p>Configuration not taking effect: Bash<pre><code># Check which config file is loaded\ntenets config show | head -20\n\n# Verify specific setting\ntenets config show --key ranking.threshold\n\n# Check config file location\nls -la .tenets.yml\n\n# Test with explicit config\ntenets --config ./my-config.yml distill \"query\"\n</code></pre></p> <p>Environment variables not working: Bash<pre><code># Verify export (not just set)\nexport TENETS_RANKING_THRESHOLD=0.05  # Correct\nTENETS_RANKING_THRESHOLD=0.05         # Wrong (not exported)\n\n# Check if variable is set\necho $TENETS_RANKING_THRESHOLD\n\n# Debug with explicit env\nTENETS_DEBUG=true tenets config show\n</code></pre></p> <p>Performance issues: - Reduce <code>scanner.max_files</code> and <code>scanner.max_file_size</code> - Enable caching: <code>cache.enabled: true</code> - Use <code>ranking.algorithm: fast</code> - Reduce <code>ranking.workers</code> if CPU-constrained - Exclude unnecessary paths with <code>additional_ignore_patterns</code></p> <p>Token limit exceeded: - Increase <code>max_tokens</code> or use <code>--max-tokens</code> - Enable <code>--condense</code> flag - Use <code>--remove-comments</code> - Increase <code>ranking.threshold</code> for stricter filtering - Exclude test files: <code>scanner.exclude_tests_by_default: true</code></p> <p>Cache issues: Bash<pre><code># Clear cache\nrm -rf ~/.tenets/cache\n\n# Disable cache temporarily\nTENETS_CACHE_ENABLED=false tenets distill \"query\"\n\n# Use custom cache location\nexport TENETS_CACHE_DIRECTORY=/tmp/tenets-cache\n</code></pre></p>"},{"location":"CONFIG/#validation-commands","title":"Validation Commands","text":"Bash<pre><code># Validate configuration syntax\ntenets config validate\n\n# Show effective configuration\ntenets config show --format json | jq\n\n# Test configuration with dry run\ntenets distill \"test query\" --dry-run\n\n# Check what files would be scanned\ntenets examine . --dry-run\n\n# Debug ranking process\nTENETS_DEBUG=true tenets distill \"query\" 2&gt;debug.log\n</code></pre>"},{"location":"CONFIG/#advanced-topics","title":"Advanced Topics","text":""},{"location":"CONFIG/#custom-ranking-strategies","title":"Custom Ranking Strategies","text":"<p>Create a custom ranking strategy by combining weights:</p> YAML<pre><code>ranking:\n  algorithm: custom\n  custom_weights:\n    keyword_match: 0.40    # Emphasize keyword relevance\n    path_relevance: 0.15   # De-emphasize path matching\n    import_graph: 0.15     # Moderate dependency weight\n    git_activity: 0.10     # Low git signal weight\n    file_type: 0.10        # File type matching\n    complexity: 0.10       # Code complexity\n</code></pre>"},{"location":"CONFIG/#multi-environment-setup","title":"Multi-Environment Setup","text":"<p>Create environment-specific configs:</p> Bash<pre><code># Development\ncp .tenets.yml .tenets.dev.yml\n# Edit for dev settings\n\n# Production analysis\ncp .tenets.yml .tenets.prod.yml\n# Edit for production settings\n\n# Use specific config\ntenets --config .tenets.dev.yml distill \"query\"\n</code></pre>"},{"location":"CONFIG/#integration-with-cicd","title":"Integration with CI/CD","text":"YAML<pre><code># .tenets.ci.yml - Optimized for CI\nmax_tokens: 50000\nquiet: true\nscanner:\n  max_files: 5000\n  workers: 2\nranking:\n  algorithm: fast\n  threshold: 0.10\ncache:\n  enabled: false  # Fresh analysis each run\noutput:\n  default_format: json  # Machine-readable\n</code></pre>"},{"location":"CONFIG/#see-also","title":"See Also","text":"<ul> <li>CLI Reference - Complete command documentation</li> <li>API Reference - Python API documentation</li> <li>Architecture - System design details</li> </ul>"},{"location":"CONTRIBUTING/","title":"Contributing to Tenets","text":"<p>Thanks for your interest in improving Tenets! Contributions of all kinds are welcome: bug reports, docs, tests, features, performance improvements, refactors, and feedback.</p>"},{"location":"CONTRIBUTING/#quick-start-tldr","title":"Quick Start (TL;DR)","text":"Bash<pre><code># Fork / clone\n git clone https://github.com/jddunn/tenets.git\n cd tenets\n\n# Create a virtual environment (or use pyenv / conda)\n python -m venv .venv &amp;&amp; source .venv/bin/activate  # Windows: .venv\\Scripts\\activate\n\n# Install core + dev extras\n pip install -e .[dev]\n # (or: make dev)\n\n# Run tests\n pytest -q\n\n# Lint &amp; type check\n ruff check .\n mypy tenets\n\n# Format\n black .\n\n# Run a sample command\n tenets distill \"hello world\" --stats\n</code></pre>"},{"location":"CONTRIBUTING/#project-philosophy","title":"Project Philosophy","text":"<p>Tenets is: - Local-first, privacy-preserving - Fast with graceful scalability (analyze only as deep as necessary) - Extensible without forcing heavyweight ML (opt-in extras) - Transparent in ranking decisions (explanations where reasonable)</p>"},{"location":"CONTRIBUTING/#issue-tracking","title":"Issue Tracking","text":"<p>Before filing: 1. Search existing issues (open + closed) 2. For questions / ideas, consider starting a GitHub Discussion (if enabled) or Discord 3. Provide reproduction steps and environment info (OS, Python version, extras installed)</p> <p>Good bug report template: Text Only<pre><code>### Description\nClear, concise description of the problem.\n\n### Reproduction\nCommands or code snippet that reproduces the issue.\n\n### Expected vs Actual\nWhat you expected / what happened.\n\n### Environment\nOS / Python / tenets version / installed extras.\n</code></pre></p>"},{"location":"CONTRIBUTING/#branch--commit-conventions","title":"Branch &amp; Commit Conventions","text":"<ul> <li>Create feature branches off <code>dev</code> (default contribution branch)</li> <li>Keep PRs narrowly scoped when possible</li> <li>Conventional Commit prefixes (enforced via commitizen config):</li> <li>feat: new user-facing feature</li> <li>fix: bug fix</li> <li>refactor: code change without feature/bug semantics</li> <li>perf: performance improvement</li> <li>docs: docs only changes</li> <li>test: add or improve tests</li> <li>chore: tooling / infra / build</li> </ul> <p>Example: Text Only<pre><code>feat(ranking): add parallel TF-IDF corpus prepass\n</code></pre></p> <p>Use <code>cz commit</code> if you have commitizen installed.</p>"},{"location":"CONTRIBUTING/#code-style--tooling","title":"Code Style &amp; Tooling","text":"Tool Purpose Command black Formatting <code>black .</code> ruff Linting (multi-plugin) <code>ruff check .</code> mypy Static typing <code>mypy tenets</code> pytest Tests + coverage <code>pytest -q</code> coverage HTML / XML reports <code>pytest --cov</code> commitizen Conventional versioning <code>cz bump</code> <p>Pre-commit hooks (optional): Bash<pre><code>pip install pre-commit\npre-commit install\n</code></pre></p>"},{"location":"CONTRIBUTING/#tests","title":"Tests","text":"<p>Guidelines: - Place tests under <code>tests/</code> mirroring module paths - Use <code>pytest</code> fixtures; prefer explicit data over deep mocks - Mark slow tests with <code>@pytest.mark.slow</code> - Keep unit tests fast (&lt;300ms ideally) - Add at least one failing test before a bug fix</p> <p>Run selectively: Bash<pre><code>pytest tests/core/analysis -k python_analyzer\npytest -m \"not slow\"\n</code></pre></p>"},{"location":"CONTRIBUTING/#type-hints","title":"Type Hints","text":"<ul> <li>New/modified public functions must be fully typed</li> <li>Avoid <code>Any</code> unless absolutely necessary; justify in a comment</li> <li>mypy config is strict\u2014fix or silence with narrow <code># type: ignore[...]</code></li> </ul>"},{"location":"CONTRIBUTING/#documentation","title":"Documentation","text":"<p>User docs live in <code>docs/</code> (MkDocs Material). For changes affecting users: - Update <code>README.md</code> - Update or create relevant page under <code>docs/</code> - Add examples (<code>quickstart.md</code>) if CLI/API behavior changes - Link new pages in <code>mkdocs.yml</code></p> <p>Serve docs locally: Bash<pre><code>mkdocs serve\n</code></pre></p>"},{"location":"CONTRIBUTING/#adding-a-language-analyzer","title":"Adding a Language Analyzer","text":"<ol> <li>Create <code>&lt;language&gt;_analyzer.py</code> under <code>tenets/core/analysis/implementations/</code></li> <li>Subclass <code>LanguageAnalyzer</code></li> <li>Implement <code>match(path)</code> and <code>analyze(content)</code></li> <li>Add tests under <code>tests/core/analysis/implementations/</code></li> <li>Update <code>supported-languages.md</code></li> </ol>"},{"location":"CONTRIBUTING/#ranking-extensions","title":"Ranking Extensions","text":"<ul> <li>Register custom rankers via provided registration API (see <code>tenets/core/ranking/ranker.py</code>)</li> <li>Provide deterministic output; avoid network calls in ranking stage</li> <li>Document new algorithm flags in <code>CONFIG.md</code></li> </ul>"},{"location":"CONTRIBUTING/#performance-considerations","title":"Performance Considerations","text":"<ul> <li>Avoid O(n^2) scans over file lists when possible</li> <li>Cache expensive analysis (see existing caching layer)</li> <li>Add benchmarks if adding heavy operations (future / optional)</li> </ul>"},{"location":"CONTRIBUTING/#security--privacy","title":"Security / Privacy","text":"<ul> <li>Never exfiltrate code or send network requests without explicit user config</li> <li>Keep default extras minimal</li> </ul>"},{"location":"CONTRIBUTING/#release-process-maintainers","title":"Release Process (Maintainers)","text":"<ol> <li>Ensure <code>dev</code> is green (CI + coverage)</li> <li>Bump version: <code>cz bump</code> (updates <code>pyproject.toml</code>, tag, CHANGELOG)</li> <li>Build: <code>make build</code> (or <code>python -m build</code>)</li> <li>Publish: <code>twine upload dist/*</code></li> <li>Merge <code>dev</code> -&gt; <code>master</code> and push tags</li> </ol>"},{"location":"CONTRIBUTING/#code-of-conduct","title":"Code of Conduct","text":"<p>This project follows the Code of Conduct. By participating you agree to uphold it.</p>"},{"location":"CONTRIBUTING/#license","title":"License","text":"<p>By contributing you agree your contributions are licensed under the MIT License.</p> <p>Questions? Open an issue or reach out via Discord.</p>"},{"location":"DEPLOYMENT/","title":"Deployment Guide","text":"<p>This guide outlines the process for releasing new versions of Tenets to PyPI and deploying documentation.</p>"},{"location":"DEPLOYMENT/#release-process-automated","title":"Release Process (Automated)","text":"<p>Standard path: merge conventional commits into <code>main</code>; automation versions &amp; publishes.</p>"},{"location":"DEPLOYMENT/#how-it-works","title":"How It Works","text":"<ol> <li>Merge PR \u2192 <code>version-bump.yml</code> runs</li> <li>Determines bump size (major / minor / patch / skip) from commit messages</li> <li>Updates <code>pyproject.toml</code> + appends grouped section to <code>CHANGELOG.md</code></li> <li>Commits <code>chore(release): vX.Y.Z</code> and tags <code>vX.Y.Z</code></li> <li>Tag triggers <code>release.yml</code>: build, publish to PyPI, (future) Docker, docs deploy</li> <li>Release notes composed from changelog / draft config</li> </ol>"},{"location":"DEPLOYMENT/#bump-rules-summary","title":"Bump Rules (Summary)","text":"Commit Types Seen Result BREAKING CHANGE / <code>!</code> Major feat / perf Minor fix / refactor / chore Patch (unless higher trigger present) Only docs / test / style Skip"},{"location":"DEPLOYMENT/#manual-overrides-rare","title":"Manual Overrides (Rare)","text":"<p>If automation blocked (workflow infra outage): Bash<pre><code>git checkout main &amp;&amp; git pull\ncz bump --increment PATCH  # or MINOR / MAJOR\ngit push &amp;&amp; git push --tags\n</code></pre> Resume automation next merge.</p>"},{"location":"DEPLOYMENT/#first-release-bootstrap-v010","title":"First Release Bootstrap (v0.1.0)","text":"<p>For the initial v0.1.0 release, follow this manual process:</p> <ol> <li>Update CHANGELOG.md with v0.1.0 entries (on dev branch)</li> <li>Commit and push to dev: <code>git commit -m \"docs: update CHANGELOG for v0.1.0\"</code></li> <li>Merge dev \u2192 master</li> <li>From master, create and push tag: Bash<pre><code>git checkout master &amp;&amp; git pull\ngit tag -a v0.1.0 -m \"Release v0.1.0 - Initial public release\"\ngit push origin v0.1.0  # This triggers everything!\n</code></pre></li> <li>The tag push automatically triggers:</li> <li>GitHub Release creation with artifacts</li> <li>PyPI package publishing (if PYPI_API_TOKEN is set)</li> <li>Documentation deployment to GitHub Pages</li> </ol> <p>After v0.1.0: Automation takes over - commits trigger version bumps based on conventional commit messages.</p>"},{"location":"DEPLOYMENT/#verification-checklist","title":"Verification Checklist","text":"Step Command / Action Install published wheel <code>pip install --no-cache-dir tenets==X.Y.Z</code> CLI version matches <code>tenets --version</code> Release notes present Check GitHub Release page Docs updated Visit docs site / gh-pages commit"},{"location":"DEPLOYMENT/#troubleshooting","title":"Troubleshooting","text":"Issue Cause Resolution No tag created Only docs/test/style commits Land a fix/feat/perf commit Wrong bump size Mis-typed commit message Amend &amp; force push before merge; or follow-up commit PyPI publish failed Missing PyPI token / trust approval pending Add <code>PYPI_API_TOKEN</code> or approve trusted publisher Duplicate releases Manual tag + automated tag Avoid manual tagging unless emergency"},{"location":"DEPLOYMENT/#documentation-deployment","title":"Documentation Deployment","text":"<p>Docs are (a) built in CI on PR for validation; (b) deployed on release tag push by <code>release.yml</code> (or dedicated docs deploy step on main). GitHub Pages serves from <code>gh-pages</code>.</p>"},{"location":"DEPLOYMENT/#required--optional-secrets","title":"Required / Optional Secrets","text":"Secret Required Purpose Notes <code>PYPI_API_TOKEN</code> Yes* PyPI publish in <code>release.yml</code> *Omit if using Trusted Publishing (approve first build). <code>CODECOV_TOKEN</code> Public: often no / Private: yes Coverage uploads Set to be explicit. <code>GOOGLE_ANALYTICS_ID</code> Optional GA4 measurement ID for docs analytics Used by MkDocs Material via <code>!ENV</code> in <code>mkdocs.yml</code> (e.g., <code>G-XXXXXXXXXX</code>). If unset/empty, analytics are disabled. <code>DOCKER_USERNAME</code> / <code>DOCKER_TOKEN</code> Optional Future Docker image publishing Not required yet. <code>GH_PAT</code> No Cross-repo automation (not standard) Avoid storing if unused. <p>Environment (optional): <code>TENETS_DEBUG</code>, <code>TENETS_CACHE_DIRECTORY</code>.</p>"},{"location":"DEPLOYMENT/#google-analytics-optional","title":"Google Analytics (optional)","text":"<p>MkDocs Material analytics are wired to an environment variable:</p> <ul> <li>In <code>mkdocs.yml</code>: <code>extra.analytics.property: !ENV [GOOGLE_ANALYTICS_ID, \"\"]</code></li> <li>Provide a GA4 Measurement ID (format <code>G-XXXXXXXXXX</code>). If the variable is unset or empty, analytics are disabled automatically.</li> </ul> <p>Local usage</p> Bash<pre><code># bash / Git Bash / WSL\nexport GOOGLE_ANALYTICS_ID=G-XXXXXXXXXX\nmkdocs serve\n</code></pre> PowerShell<pre><code># PowerShell\n$env:GOOGLE_ANALYTICS_ID = 'G-XXXXXXXXXX'\nmkdocs serve\n</code></pre> <p>GitHub Actions (recommended)</p> YAML<pre><code>jobs:\n   docs:\n      runs-on: ubuntu-latest\n      env:\n         GOOGLE_ANALYTICS_ID: ${{ secrets.GOOGLE_ANALYTICS_ID }}\n      steps:\n         - uses: actions/checkout@v4\n         - uses: actions/setup-python@v5\n            with:\n               python-version: '3.12'\n         - run: pip install -e '.[docs]'\n         - run: mkdocs build --clean\n</code></pre> <p>Store your GA4 Measurement ID as a repository secret named <code>GOOGLE_ANALYTICS_ID</code>. The docs build will inject it at build time; if not present, analytics are off.</p>"},{"location":"DEPLOYMENT/#with-specific-features","title":"With specific features","text":"<p>pip install tenets[ml]  # ML features pip install tenets[viz]  # Visualization pip install tenets[all]  # Everything Text Only<pre><code>### 2. Development Installation\n\n```bash\n# From source\ngit clone https://github.com/jddunn/tenets.git\ncd tenets\npip install -e \".[dev]\"\n</code></pre></p>"},{"location":"DEPLOYMENT/#3-docker-container","title":"3. Docker Container","text":"Bash<pre><code># Pull from Docker Hub\ndocker pull tenets/tenets:latest\n\n# Run command\ndocker run --rm -v $(pwd):/workspace tenets/tenets make-context \"query\" .\n\n# Interactive shell\ndocker run -it --rm -v $(pwd):/workspace tenets/tenets bash\n</code></pre>"},{"location":"DEPLOYMENT/#4-standalone-binary","title":"4. Standalone Binary","text":"<p>Download from GitHub Releases:</p> Bash<pre><code># Linux/macOS\ncurl -L https://github.com/jddunn/tenets/releases/latest/download/tenets-linux -o tenets\nchmod +x tenets\n./tenets --version\n\n# Windows\n# Download tenets-windows.exe from releases page\n</code></pre>"},{"location":"DEPLOYMENT/#pypi-publishing","title":"PyPI Publishing","text":""},{"location":"DEPLOYMENT/#first-time-setup","title":"First-Time Setup","text":"<ol> <li>Create PyPI account:</li> <li>Register at pypi.org</li> <li> <p>Enable 2FA (required)</p> </li> <li> <p>Configure trusted publishing:</p> </li> <li>Go to your project settings on PyPI</li> <li>Add GitHub Actions as trusted publisher:<ul> <li>Owner: <code>jddunn</code></li> <li>Repository: <code>tenets</code></li> <li>Workflow: <code>release.yml</code></li> <li>Environment: <code>pypi</code></li> </ul> </li> </ol>"},{"location":"DEPLOYMENT/#manual-publishing-emergency-only","title":"Manual Publishing (Emergency Only)","text":"Bash<pre><code># Build distribution\npython -m build\n\n# Check package\ntwine check dist/*\n\n# Upload to TestPyPI first\ntwine upload --repository testpypi dist/*\n\n# Test installation\npip install --index-url https://test.pypi.org/simple/ tenets\n\n# Upload to PyPI\ntwine upload dist/*\n</code></pre>"},{"location":"DEPLOYMENT/#docker-deployment","title":"Docker Deployment","text":""},{"location":"DEPLOYMENT/#building-images","title":"Building Images","text":"Docker<pre><code># Dockerfile\nFROM python:3.11-slim\n\n# Install system dependencies\nRUN apt-get update &amp;&amp; apt-get install -y \\\n    git \\\n    &amp;&amp; rm -rf /var/lib/apt/lists/*\n\n# Create non-root user\nRUN useradd -m -s /bin/bash tenets\n\n# Set working directory\nWORKDIR /app\n\n# Install tenets\nCOPY requirements.txt .\nRUN pip install --no-cache-dir -r requirements.txt\n\nCOPY . .\nRUN pip install --no-cache-dir -e .\n\n# Switch to non-root user\nUSER tenets\n\n# Set entrypoint\nENTRYPOINT [\"tenets\"]\n</code></pre>"},{"location":"DEPLOYMENT/#multi-architecture-build","title":"Multi-Architecture Build","text":"Bash<pre><code># Setup buildx\ndocker buildx create --use\n\n# Build for multiple platforms\ndocker buildx build \\\n  --platform linux/amd64,linux/arm64 \\\n  --tag tenets/tenets:latest \\\n  --tag tenets/tenets:v0.1.0 \\\n  --push .\n</code></pre>"},{"location":"DEPLOYMENT/#docker-compose","title":"Docker Compose","text":"YAML<pre><code># docker-compose.yml\nversion: '3.8'\n\nservices:\n  tenets:\n    image: tenets/tenets:latest\n    volumes:\n      - .:/workspace\n      - ~/.tenets:/home/tenets/.tenets\n    working_dir: /workspace\n    environment:\n      - TENETS_LOG_LEVEL=INFO\n    command: make-context \"implement feature\" .\n</code></pre>"},{"location":"DEPLOYMENT/#binary-distribution","title":"Binary Distribution","text":""},{"location":"DEPLOYMENT/#building-binaries","title":"Building Binaries","text":"Bash<pre><code># Install PyInstaller\npip install pyinstaller\n\n# Build for current platform\npyinstaller \\\n  --onefile \\\n  --name tenets \\\n  --add-data \"tenets:tenets\" \\\n  --hidden-import tenets.core \\\n  --hidden-import tenets.models \\\n  --hidden-import tenets.utils \\\n  tenets/__main__.py\n\n# Output in dist/tenets\n</code></pre>"},{"location":"DEPLOYMENT/#cross-platform-building","title":"Cross-Platform Building","text":"<p>Use GitHub Actions for multi-platform builds: - Linux: Ubuntu runner - macOS: macOS runner - Windows: Windows runner</p>"},{"location":"DEPLOYMENT/#code-signing-optional","title":"Code Signing (Optional)","text":"Bash<pre><code># macOS\ncodesign --deep --force --verify --verbose \\\n  --sign \"Developer ID Application: Your Name\" \\\n  dist/tenets\n\n# Windows (using signtool)\nsigntool sign /t http://timestamp.digicert.com dist/tenets.exe\n</code></pre>"},{"location":"DEPLOYMENT/#documentation-deployment_1","title":"Documentation Deployment","text":""},{"location":"DEPLOYMENT/#building-documentation","title":"Building Documentation","text":"Bash<pre><code># Install dependencies\npip install -e \".[docs]\"\n\n# Build docs\nmkdocs build\n\n# Test locally\nmkdocs serve\n</code></pre>"},{"location":"DEPLOYMENT/#versioned-documentation","title":"Versioned Documentation","text":"Bash<pre><code># Deploy new version\nmike deploy --push --update-aliases 0.1.0 latest\n\n# Deploy development docs\nmike deploy --push dev\n\n# Set default version\nmike set-default --push latest\n</code></pre>"},{"location":"DEPLOYMENT/#github-pages-setup","title":"GitHub Pages Setup","text":"<ol> <li>Enable GitHub Pages in repository settings</li> <li>Set source to <code>gh-pages</code> branch</li> <li>Documentation auto-deploys on release</li> </ol>"},{"location":"DEPLOYMENT/#security-considerations","title":"Security Considerations","text":""},{"location":"DEPLOYMENT/#release-security","title":"Release Security","text":"<ol> <li> <p>Sign commits and tags:    Bash<pre><code>git config --global commit.gpgsign true\ngit config --global tag.gpgsign true\n</code></pre></p> </li> <li> <p>Verify dependencies:    Bash<pre><code># Check for vulnerabilities\nsafety check\n\n# Audit dependencies\npip-audit\n</code></pre></p> </li> <li> <p>Scan for secrets:    Bash<pre><code># Pre-release scan\ndetect-secrets scan --all-files\n</code></pre></p> </li> </ol>"},{"location":"DEPLOYMENT/#deployment-security","title":"Deployment Security","text":"<ol> <li> <p>Use minimal base images:    Docker<pre><code>FROM python:3.11-slim  # Not full python image\n</code></pre></p> </li> <li> <p>Run as non-root:    Docker<pre><code>USER nobody\n</code></pre></p> </li> <li> <p>Scan images:    Bash<pre><code># Scan for vulnerabilities\ndocker scan tenets/tenets:latest\n</code></pre></p> </li> </ol>"},{"location":"DEPLOYMENT/#monitoring--maintenance","title":"Monitoring &amp; Maintenance","text":""},{"location":"DEPLOYMENT/#release-monitoring","title":"Release Monitoring","text":"<ol> <li>PyPI Statistics:</li> <li>Check download stats</li> <li> <p>Monitor for unusual activity</p> </li> <li> <p>GitHub Insights:</p> </li> <li>Track clone/download metrics</li> <li> <p>Monitor issue trends</p> </li> <li> <p>Error Tracking:</p> </li> <li>Set up Sentry (optional)</li> <li>Monitor GitHub issues</li> </ol>"},{"location":"DEPLOYMENT/#maintenance-tasks","title":"Maintenance Tasks","text":""},{"location":"DEPLOYMENT/#weekly","title":"Weekly","text":"<ul> <li>Review and triage issues</li> <li>Check for security advisories</li> <li>Update dependencies</li> </ul>"},{"location":"DEPLOYMENT/#monthly","title":"Monthly","text":"<ul> <li>Review performance metrics</li> <li>Update documentation</li> <li>Clean up old releases</li> </ul>"},{"location":"DEPLOYMENT/#quarterly","title":"Quarterly","text":"<ul> <li>Major dependency updates</li> <li>Security audit</li> <li>Performance benchmarking</li> </ul>"},{"location":"DEPLOYMENT/#rollback-procedure","title":"Rollback Procedure","text":"<p>If a release has critical issues:</p> <ol> <li> <p>Yank from PyPI (last resort):    Bash<pre><code># This prevents new installations\n# Existing installations continue to work\ntwine yank tenets==0.1.0\n</code></pre></p> </li> <li> <p>Create hotfix:    Bash<pre><code>git checkout -b hotfix/critical-bug\n# Fix issue\ngit commit -m \"fix: critical bug in analyzer\"\ncz bump --increment PATCH\ngit push origin hotfix/critical-bug\n</code></pre></p> </li> <li> <p>Fast-track release:</p> </li> <li>Create PR with hotfix</li> <li>Bypass normal review (emergency)</li> <li>Merge and tag immediately</li> </ol>"},{"location":"DEPLOYMENT/#deployment-environments","title":"Deployment Environments","text":""},{"location":"DEPLOYMENT/#development","title":"Development","text":"Bash<pre><code>pip install -e \".[dev]\"\nexport TENETS_ENV=development\n</code></pre>"},{"location":"DEPLOYMENT/#staging","title":"Staging","text":"Bash<pre><code>pip install tenets==0.1.0rc1  # Release candidate\nexport TENETS_ENV=staging\n</code></pre>"},{"location":"DEPLOYMENT/#production","title":"Production","text":"Bash<pre><code>pip install tenets==0.1.0\nexport TENETS_ENV=production\n</code></pre>"},{"location":"DEPLOYMENT/#troubleshooting_1","title":"Troubleshooting","text":""},{"location":"DEPLOYMENT/#common-issues","title":"Common Issues","text":"<ol> <li>PyPI upload fails:</li> <li>Check PyPI status</li> <li>Verify credentials</li> <li> <p>Ensure version doesn't exist</p> </li> <li> <p>Docker build fails:</p> </li> <li>Clear builder cache</li> <li>Check Docker Hub limits</li> <li> <p>Verify multi-arch support</p> </li> <li> <p>Documentation not updating:</p> </li> <li>Check GitHub Pages settings</li> <li>Verify mike configuration</li> <li>Clear browser cache</li> </ol>"},{"location":"DEPLOYMENT/#getting-help","title":"Getting Help","text":"<ul> <li>GitHub Issues for bugs</li> <li>Discussions for questions</li> <li>team@tenets.dev for security issues</li> </ul> <p>Remember: Every release should make developers' lives easier. \ud83d\ude80</p>"},{"location":"DEVELOPMENT/","title":"Development Guide","text":"<p>This guide provides instructions for setting up your development environment, running tests, and contributing to the Tenets project.</p>"},{"location":"DEVELOPMENT/#1-initial-setup","title":"1. Initial Setup","text":""},{"location":"DEVELOPMENT/#prerequisites","title":"Prerequisites","text":"<ul> <li>Python 3.9+</li> <li>Git</li> <li>An activated Python virtual environment (e.g., <code>venv</code>, <code>conda</code>).</li> </ul>"},{"location":"DEVELOPMENT/#fork-and-clone","title":"Fork and Clone","text":"<ol> <li>Fork the repository on GitHub.</li> <li>Clone your fork locally:    Bash<pre><code>git clone https://github.com/jddunn/tenets.git\ncd tenets\n</code></pre></li> </ol>"},{"location":"DEVELOPMENT/#install-dependencies","title":"Install Dependencies","text":"<p>Install the project in \"editable\" mode along with all development dependencies. This allows you to modify the source code and have the changes immediately reflected.</p> <p>Bash<pre><code>pip install -e \".[all,dev]\"\n</code></pre> This command installs everything needed for development, including core dependencies, optional features (<code>all</code>), and development tools (<code>dev</code>).</p>"},{"location":"DEVELOPMENT/#set-up-pre-commit-hooks","title":"Set up Pre-Commit Hooks","text":"<p>This project uses <code>pre-commit</code> to automatically run linters and formatters before each commit.</p> Bash<pre><code>pre-commit install\n</code></pre>"},{"location":"DEVELOPMENT/#alternative-installs","title":"Alternative Installs","text":"<p>If you only need core + dev tooling (faster): Bash<pre><code>pip install -e \".[dev]\"\n</code></pre> If you need a minimal footprint for quick iteration (no optional extras): Bash<pre><code>pip install -e .\n</code></pre></p>"},{"location":"DEVELOPMENT/#verifying-the-cli","title":"Verifying the CLI","text":"Bash<pre><code>tenets --version\ntenets --help | head\n</code></pre> <p>If the command is not found, ensure your virtualenv is activated and that the <code>scripts</code> (Windows) or <code>bin</code> (Unix) directory is on PATH.</p>"},{"location":"DEVELOPMENT/#11-building-distribution-artifacts-optional","title":"1.1 Building Distribution Artifacts (Optional)","text":"<p>You typically do NOT need to build wheels / sdists for day\u2011to\u2011day development; the editable install auto-reflects code edits. Build only when testing packaging or release steps.</p> Bash<pre><code>python -m build               # creates dist/*.whl and dist/*.tar.gz\npip install --force-reinstall dist/tenets-*.whl  # sanity check install\n</code></pre> <p>To inspect what went into the wheel: Bash<pre><code>unzip -l dist/tenets-*.whl | grep analysis/implementations | head\n</code></pre></p>"},{"location":"DEVELOPMENT/#12-clean-environment-tasks","title":"1.2 Clean Environment Tasks","text":"Bash<pre><code>pip cache purge        # optional: clear wheel cache\nfind . -name \"__pycache__\" -exec rm -rf {} +\nrm -rf .pytest_cache .ruff_cache .mypy_cache build dist *.egg-info\n</code></pre>"},{"location":"DEVELOPMENT/#13-using-poetry-instead-of-pip-optional","title":"1.3 Using Poetry Instead of pip (Optional)","text":"<p>Poetry can manage the virtual environment and extras if you prefer: Bash<pre><code>poetry install -E all -E dev   # full feature + dev toolchain\npoetry run pytest              # run tests\npoetry run tenets --help       # invoke CLI\n</code></pre> Update dependencies: Bash<pre><code>poetry update\n</code></pre> Add a new optional dependency (example): Bash<pre><code>poetry add --optional rich\n</code></pre> Text Only<pre><code>## 2. Running Tests\n\nThe test suite uses `pytest`. We have a comprehensive configuration in `pytest.ini` that handles most settings automatically.\n\n### Running All Tests\nTo run the entire test suite:\n```bash\npytest\n</code></pre></p>"},{"location":"DEVELOPMENT/#running-tests-with-coverage","title":"Running Tests with Coverage","text":"<p>To generate a test coverage report: Bash<pre><code>pytest --cov\n</code></pre> This command is configured in <code>pytest.ini</code> to: - Measure coverage for the <code>tenets</code> package. - Generate reports in the terminal, as XML (<code>coverage.xml</code>), and as a detailed HTML report (<code>htmlcov/</code>). - Fail the build if coverage drops below 70%.</p> <p>To view the interactive HTML report: Bash<pre><code># On macOS\nopen htmlcov/index.html\n\n# On Windows\nstart htmlcov/index.html\n\n# On Linux\nxdg-open htmlcov/index.html\n</code></pre></p>"},{"location":"DEVELOPMENT/#3-required--optional-secrets","title":"3. Required / Optional Secrets","text":"<p>Configure these in GitHub: Settings \u2192 Secrets and variables \u2192 Actions.</p> Secret Required? Purpose Notes <code>PYPI_API_TOKEN</code> Yes* Upload package in <code>release.yml</code> *If using PyPI Trusted Publishing you can omit and approve first publication manually. Keep token while bootstrapping. <code>CODECOV_TOKEN</code> Yes (private repo) / No (public) Coverage uploads in CI Public repos sometimes auto-detect; set to be explicit. <code>DOCKER_USERNAME</code> Optional Auth for Docker image push (if enabled) Only needed if/when container publishing is turned on. <code>DOCKER_TOKEN</code> Optional Password / token for Docker Hub Pair with username. <code>GH_PAT</code> No Only for advanced workflows (e.g. cross\u2011repo automation) Not needed for standard release pipeline. <p>Additional environment driven configs (rarely needed): | Variable | Effect | |----------|-------| | <code>TENETS_CACHE_DIRECTORY</code> | Override default cache directory | | <code>TENETS_DEBUG</code> | Enables verbose debug logging when <code>true</code> |</p> <p>Security tips: - Grant least privilege (PyPI token scoped to project if possible) - Rotate any credentials annually or on role changes - Prefer Trusted Publishing over long\u2011lived API tokens once stable</p>"},{"location":"DEVELOPMENT/#4-code-style-and-linting","title":"4. Code Style and Linting","text":"<p>We use <code>ruff</code> for linting and formatting. The pre-commit hook runs it automatically, but you can also run it manually:</p> Bash<pre><code># Check for linting errors\nruff check .\n\n# Automatically fix linting errors\nruff check . --fix\n\n# Format the code\nruff format .\n</code></pre>"},{"location":"DEVELOPMENT/#5-building-documentation","title":"5. Building Documentation","text":"<p>The documentation is built using MkDocs with the Material theme.</p>"},{"location":"DEVELOPMENT/#installing-documentation-dependencies","title":"Installing Documentation Dependencies","text":"Bash<pre><code># Install MkDocs and theme\npip install mkdocs mkdocs-material\n\n# Or if you installed with dev dependencies, it's already included:\npip install -e \".[dev]\"\n</code></pre>"},{"location":"DEVELOPMENT/#serving-documentation-locally","title":"Serving Documentation Locally","text":""},{"location":"DEVELOPMENT/#fast-development-mode-recommended-for-editing-docs","title":"FAST Development Mode (Recommended for editing docs)","text":"Bash<pre><code># Use the lightweight dev config with dirty reload for FASTEST iteration\nmkdocs serve -f mkdocs.dev.yml --dirtyreload\n\n# Without dirty reload (still faster than full build)\nmkdocs serve -f mkdocs.dev.yml\n</code></pre> <p>mkdocs.dev.yml differences: - Disables heavy plugins: No API generation, no mkdocstrings, no minification - Faster rebuilds: Skips expensive operations - Dirty reload: Only rebuilds changed pages (not entire site) - Perfect for: Writing/editing documentation content</p>"},{"location":"DEVELOPMENT/#full-production-mode-for-testing-final-output","title":"Full Production Mode (for testing final output)","text":"Bash<pre><code># Full build with all features including API docs generation\nmkdocs serve\n\n# Serve on a different port\nmkdocs serve -a localhost:8080\n\n# Serve with verbose output for debugging\nmkdocs serve --verbose\n\n# With clean rebuild\nmkdocs serve --clean\n</code></pre> <p>The development server includes: - Live reload: Changes to docs files automatically refresh the browser - API docs generation: Auto-generates from Python docstrings - Full theme features: All navigation and search features enabled</p>"},{"location":"DEVELOPMENT/#building-static-documentation","title":"Building Static Documentation","text":"Bash<pre><code># Build the static site to site/ directory\nmkdocs build\n\n# Build with strict mode (fails on warnings)\nmkdocs build --strict\n\n# Build with verbose output\nmkdocs build --verbose\n\n# Clean build (removes old files first)\nmkdocs build --clean\n</code></pre>"},{"location":"DEVELOPMENT/#documentation-structure","title":"Documentation Structure","text":"Text Only<pre><code>docs/\n\u251c\u2500\u2500 index.md           # Homepage\n\u251c\u2500\u2500 overrides/        # Custom HTML templates\n\u2502   \u2514\u2500\u2500 home.html     # Custom homepage\n\u251c\u2500\u2500 styles/           # Custom CSS\n\u2502   \u251c\u2500\u2500 main.css\n\u2502   \u251c\u2500\u2500 search.css\n\u2502   \u2514\u2500\u2500 ...\n\u251c\u2500\u2500 assets/           # Images and screenshots\n\u2502   \u2514\u2500\u2500 images/\n\u2514\u2500\u2500 *.md             # Documentation pages\n</code></pre>"},{"location":"DEVELOPMENT/#api-documentation-generation","title":"API Documentation Generation","text":"<p>The API documentation is auto-generated from Python docstrings using <code>mkdocstrings</code> and <code>gen-files</code> plugins.</p>"},{"location":"DEVELOPMENT/#how-it-works","title":"How it works:","text":"<ol> <li><code>docs/gen_api.py</code> script runs during build:</li> <li>Scans all Python modules in <code>tenets/</code></li> <li>Generates markdown files with <code>:::</code> mkdocstrings syntax</li> <li> <p>Creates navigation structure in <code>api/</code> directory</p> </li> <li> <p><code>mkdocstrings</code> plugin processes the generated files:</p> </li> <li>Extracts docstrings from Python code</li> <li>Renders them as formatted documentation</li> <li>Includes type hints, parameters, returns, examples</li> </ol>"},{"location":"DEVELOPMENT/#regenerating-api-docs","title":"Regenerating API docs:","text":"Bash<pre><code># Full build with API generation (automatic)\nmkdocs build\n\n# Or serve with API generation\nmkdocs serve  # Uses mkdocs.yml which has gen-files enabled\n\n# Skip API generation for faster dev\nmkdocs serve -f mkdocs.dev.yml --dirtyreload\n</code></pre>"},{"location":"DEVELOPMENT/#writing-good-docstrings-for-api-docs","title":"Writing Good Docstrings for API docs:","text":"Python<pre><code>def example_function(param1: str, param2: int = 0) -&gt; bool:\n    \"\"\"Short summary of what this function does.\n\n    Longer description with more details about the function's\n    behavior, use cases, and any important notes.\n\n    Args:\n        param1: Description of first parameter\n        param2: Description of second parameter (default: 0)\n\n    Returns:\n        Description of return value\n\n    Raises:\n        ValueError: When something goes wrong\n\n    Example:\n        &gt;&gt;&gt; example_function(\"test\", 42)\n        True\n    \"\"\"\n</code></pre>"},{"location":"DEVELOPMENT/#making-documentation-changes","title":"Making Documentation Changes","text":"<ol> <li>For content/markdown: Edit files in <code>docs/</code> directory</li> <li>For API docs: Update docstrings in Python source files</li> <li>Preview changes:</li> <li>Fast: <code>mkdocs serve -f mkdocs.dev.yml --dirtyreload</code></li> <li>Full: <code>mkdocs serve</code></li> <li>Test the build: <code>mkdocs build --strict</code></li> <li>Check for broken links in the browser console</li> </ol>"},{"location":"DEVELOPMENT/#deploying-documentation","title":"Deploying Documentation","text":"Bash<pre><code># Deploy to GitHub Pages (requires push permissions)\nmkdocs gh-deploy\n\n# Deploy with custom commit message\nmkdocs gh-deploy -m \"Update documentation\"\n\n# Deploy without pushing (dry run)\nmkdocs gh-deploy --no-push\n</code></pre> <p>The site will be available at <code>https://[username].github.io/tenets/</code>.</p>"},{"location":"DEVELOPMENT/#2-making-changes","title":"2. Making Changes","text":"<p>Follow the coding standards: - Write clean, readable code - Add comprehensive docstrings (Google style) - Include type hints for all functions - Write tests for new functionality</p>"},{"location":"DEVELOPMENT/#3-committing-changes","title":"3. Committing Changes","text":"<p>We use Conventional Commits:</p> Bash<pre><code># Interactive commit\nmake commit  # or: cz commit\n\n# Manual commit (must follow format)\ngit commit -m \"feat(analyzer): add support for Rust AST parsing\"\n</code></pre> <p>Commit types: - <code>feat</code>: New feature - <code>fix</code>: Bug fix - <code>docs</code>: Documentation changes - <code>style</code>: Code style changes (formatting) - <code>refactor</code>: Code refactoring - <code>perf</code>: Performance improvements - <code>test</code>: Test additions or changes - <code>chore</code>: Maintenance tasks</p>"},{"location":"DEVELOPMENT/#4-running-tests","title":"4. Running Tests","text":"Bash<pre><code># Run all tests\nmake test\n\n# Run fast tests only\nmake test-fast\n\n# Run specific test file\npytest tests/test_analyzer.py\n\n# Run with coverage\npytest --cov=tenets --cov-report=html\n</code></pre>"},{"location":"DEVELOPMENT/#5-code-quality-checks","title":"5. Code Quality Checks","text":"Bash<pre><code># Run all checks\nmake lint\n\n# Auto-format code\nmake format\n\n# Individual tools\nblack .\nisort .\nruff check .\nmypy tenets --strict\nbandit -r tenets\n</code></pre>"},{"location":"DEVELOPMENT/#6-pushing-changes","title":"6. Pushing Changes","text":"Bash<pre><code># Pre-commit hooks will run automatically\ngit push origin feature/your-feature-name\n</code></pre>"},{"location":"DEVELOPMENT/#7-creating-a-pull-request","title":"7. Creating a Pull Request","text":"<ol> <li>Go to GitHub and create a PR</li> <li>Fill out the PR template</li> <li>Ensure all CI checks pass</li> <li>Request review from maintainers</li> </ol>"},{"location":"DEVELOPMENT/#testing","title":"Testing","text":""},{"location":"DEVELOPMENT/#test-structure","title":"Test Structure","text":"Text Only<pre><code>tests/\n\u251c\u2500\u2500 unit/              # Unit tests\n\u2502   \u251c\u2500\u2500 test_analyzer.py\n\u2502   \u251c\u2500\u2500 test_nlp.py\n\u2502   \u2514\u2500\u2500 test_scanner.py\n\u251c\u2500\u2500 integration/       # Integration tests\n\u2502   \u251c\u2500\u2500 test_cli.py\n\u2502   \u2514\u2500\u2500 test_workflow.py\n\u251c\u2500\u2500 fixtures/         # Test data\n\u2502   \u2514\u2500\u2500 sample_repo/\n\u2514\u2500\u2500 conftest.py      # Pytest configuration\n</code></pre>"},{"location":"DEVELOPMENT/#writing-tests","title":"Writing Tests","text":"Python<pre><code>\"\"\"Test module for analyzer functionality.\"\"\"\n\nimport pytest\nfrom tenets.core.analysis import CodeAnalyzer\n\n\nclass TestCodeAnalyzer:\n    \"\"\"Test suite for CodeAnalyzer.\"\"\"\n\n    @pytest.fixture\n    def analyzer(self):\n        \"\"\"Create analyzer instance.\"\"\"\n        return CodeAnalyzer()\n\n    def test_analyze_python_file(self, analyzer, tmp_path):\n        \"\"\"Test Python file analysis.\"\"\"\n        # Create test file\n        test_file = tmp_path / \"test.py\"\n        test_file.write_text(\"def hello():\\n    return 'world'\")\n\n        # Analyze\n        result = analyzer.analyze_file(test_file)\n\n        # Assertions\n        assert result.language == \"python\"\n        assert len(result.functions) == 1\n        assert result.functions[0][\"name\"] == \"hello\"\n</code></pre>"},{"location":"DEVELOPMENT/#test-markers","title":"Test Markers","text":"Bash<pre><code># Run only unit tests\npytest -m unit\n\n# Skip slow tests\npytest -m \"not slow\"\n\n# Run tests requiring git\npytest -m requires_git\n</code></pre>"},{"location":"DEVELOPMENT/#code-quality","title":"Code Quality","text":""},{"location":"DEVELOPMENT/#style-guide","title":"Style Guide","text":"<p>We follow PEP 8 with these modifications: - Line length: 100 characters - Use Black for formatting - Use Google-style docstrings</p>"},{"location":"DEVELOPMENT/#type-hints","title":"Type Hints","text":"<p>All functions must have type hints:</p> Python<pre><code>from typing import List, Optional, Dict, Any\n\n\ndef analyze_files(\n    paths: List[Path],\n    deep: bool = False,\n    max_workers: Optional[int] = None\n) -&gt; Dict[str, Any]:\n    \"\"\"\n    Analyze multiple files in parallel.\n\n    Args:\n        paths: List of file paths to analyze\n        deep: Whether to perform deep analysis\n        max_workers: Maximum number of parallel workers\n\n    Returns:\n        Dictionary containing analysis results\n    \"\"\"\n    ...\n</code></pre>"},{"location":"DEVELOPMENT/#docstrings","title":"Docstrings","text":"<p>Use Google-style docstrings:</p> Python<pre><code>def calculate_relevance(\n    file: FileAnalysis,\n    prompt: PromptContext,\n    algorithm: str = \"balanced\"\n) -&gt; float:\n    \"\"\"\n    Calculate relevance score for a file.\n\n    Uses multi-factor scoring to determine how relevant a file is\n    to the given prompt context.\n\n    Args:\n        file: Analyzed file data\n        prompt: Parsed prompt context\n        algorithm: Ranking algorithm to use\n\n    Returns:\n        Relevance score between 0.0 and 1.0\n\n    Raises:\n        ValueError: If algorithm is not recognized\n\n    Example:\n        &gt;&gt;&gt; relevance = calculate_relevance(file, prompt, \"thorough\")\n        &gt;&gt;&gt; print(f\"Relevance: {relevance:.2f}\")\n        0.85\n    \"\"\"\n    ...\n</code></pre>"},{"location":"DEVELOPMENT/#documentation","title":"Documentation","text":""},{"location":"DEVELOPMENT/#building-documentation","title":"Building Documentation","text":"Bash<pre><code># Build docs\nmake docs\n\n# Serve locally\nmake serve-docs\n# Visit http://localhost:8000\n</code></pre>"},{"location":"DEVELOPMENT/#writing-documentation","title":"Writing Documentation","text":"<ol> <li>API Documentation: Auto-generated from docstrings</li> <li>User Guides: Written in Markdown in <code>docs/</code></li> <li>Examples: Include code examples in docstrings</li> </ol>"},{"location":"DEVELOPMENT/#documentation-standards","title":"Documentation Standards","text":"<ul> <li>Use clear, concise language</li> <li>Include code examples</li> <li>Add diagrams where helpful</li> <li>Keep it up-to-date with code changes</li> </ul>"},{"location":"DEVELOPMENT/#debugging","title":"Debugging","text":""},{"location":"DEVELOPMENT/#debug-mode","title":"Debug Mode","text":"Bash<pre><code># Enable debug logging\nexport TENETS_DEBUG=true\ntenets make-context \"test\" . --verbose\n\n# Or in code\nimport logging\nlogging.basicConfig(level=logging.DEBUG)\n</code></pre>"},{"location":"DEVELOPMENT/#using-vs-code","title":"Using VS Code","text":"<p><code>.vscode/launch.json</code>: JSON<pre><code>{\n    \"version\": \"0.2.0\",\n    \"configurations\": [\n        {\n            \"name\": \"Debug tenets CLI\",\n            \"type\": \"python\",\n            \"request\": \"launch\",\n            \"module\": \"tenets.cli.main\",\n            \"args\": [\"make-context\", \"test query\", \".\"],\n            \"console\": \"integratedTerminal\"\n        }\n    ]\n}\n</code></pre></p>"},{"location":"DEVELOPMENT/#common-issues","title":"Common Issues","text":"<ol> <li>Import errors: Ensure you've installed in development mode (<code>pip install -e .</code>)</li> <li>Type errors: Run <code>mypy</code> to catch type issues</li> <li>Test failures: Check if you need to install optional dependencies</li> </ol>"},{"location":"DEVELOPMENT/#contributing-guidelines","title":"Contributing Guidelines","text":""},{"location":"DEVELOPMENT/#before-you-start","title":"Before You Start","text":"<ol> <li>Check existing issues and PRs</li> <li>Open an issue to discuss large changes</li> <li>Read the architecture documentation</li> </ol>"},{"location":"DEVELOPMENT/#code-review-checklist","title":"Code Review Checklist","text":"<ul> <li> Tests pass locally</li> <li> Code is formatted (black, isort)</li> <li> Type hints are present</li> <li> Docstrings are complete</li> <li> Tests cover new functionality</li> <li> Documentation is updated</li> <li> Commit messages follow convention</li> <li> No security issues (bandit)</li> </ul>"},{"location":"DEVELOPMENT/#getting-help","title":"Getting Help","text":"<ul> <li>Open an issue for bugs</li> <li>Start a discussion for features</li> <li>Join our Discord (coming soon)</li> <li>Email: team@tenets.dev</li> </ul>"},{"location":"DEVELOPMENT/#release--versioning","title":"Release &amp; Versioning","text":"<p>Releases are automated. Merging conventional commits into <code>main</code> (from PRs) is all you normally do.</p>"},{"location":"DEVELOPMENT/#branch-model","title":"Branch Model","text":"Branch Purpose <code>dev</code> (or feature branches) Integration / iterative work <code>main</code> Always releasable; auto-versioned on merge"},{"location":"DEVELOPMENT/#workflows-high-level","title":"Workflows (high level)","text":"<ol> <li>PR merged into <code>main</code>.</li> <li><code>version-bump.yml</code> runs:<ul> <li>Collects commits since last tag</li> <li>Determines next version:</li> <li>Major: commit body contains <code>BREAKING CHANGE:</code> or type suffixed with <code>!</code></li> <li>Minor: at least one <code>feat:</code> or <code>perf:</code> commit (performance treated as minor to signal impact)</li> <li>Patch: any <code>fix</code>, <code>refactor</code>, <code>chore</code> (unless a higher bump already chosen)</li> <li>Skip: only docs / test / style commits (no release)</li> <li>Updates <code>pyproject.toml</code></li> <li>Appends a section to <code>CHANGELOG.md</code> grouping commits (Features / Performance / Fixes / Refactoring / Chore)</li> <li>Commits with message <code>chore(release): vX.Y.Z</code> and creates annotated tag <code>vX.Y.Z</code></li> </ul> </li> <li>Tag push triggers <code>release.yml</code>:<ul> <li>Builds wheel + sdist</li> <li>Publishes to PyPI (token or Trusted Publishing)</li> <li>(Optional) Builds &amp; publishes Docker image (future enablement)</li> <li>Deploys docs (if configured) / updates site</li> </ul> </li> <li><code>release-drafter</code> (config) ensures GitHub Release notes reflect categorized changes (either via draft or final publish depending on config state).</li> </ol> <p>You do NOT run <code>cz bump</code> manually during normal flow; the workflow handles versioning.</p>"},{"location":"DEVELOPMENT/#conventional-commit-expectations","title":"Conventional Commit Expectations","text":"<p>Use clear scopes where possible: Text Only<pre><code>feat(ranking): add semantic similarity signal\nfix(cli): prevent crash on empty directory\nperf(analyzer): cache parsed ASTs\nrefactor(config): simplify loading logic\ndocs: update quickstart for --copy flag\n</code></pre></p> <p>Edge cases: - Multiple commit types: highest precedence decides (major &gt; minor &gt; patch) - Mixed docs + fix: still releases (fix wins) - Only docs/test/style: skipped; no tag produced</p>"},{"location":"DEVELOPMENT/#first-release-bootstrap","title":"First Release (Bootstrap)","text":"<p>If no existing tag: 1. Merge initial feature set into <code>main</code> 2. Push a commit with <code>feat: initial release</code> (or similar) 3. Workflow sets version to <code>0.1.0</code> (or bump logic starting point defined in workflow)</p> <p>If you need a different starting version (e.g. <code>0.3.0</code>): create an annotated tag manually once, then subsequent merges resume automation.</p>"},{"location":"DEVELOPMENT/#manual--emergency-release","title":"Manual / Emergency Release","text":"<p>Only when automation is blocked: Bash<pre><code>git checkout main &amp;&amp; git pull\ncz bump --increment PATCH  # or MINOR / MAJOR\ngit push &amp;&amp; git push --tags\n</code></pre> Monitor <code>release.yml</code>. After resolution, revert to automated flow.</p>"},{"location":"DEVELOPMENT/#verifying-a-release","title":"Verifying a Release","text":"<p>After automation completes: Bash<pre><code>pip install --no-cache-dir tenets==&lt;new_version&gt;\ntenets --version\n</code></pre> Smoke test a core command: Bash<pre><code>tenets distill \"smoke\" --max-tokens 2000 --mode fast --stats || true\n</code></pre></p>"},{"location":"DEVELOPMENT/#troubleshooting","title":"Troubleshooting","text":"Symptom Likely Cause Fix No new tag after merge Only docs/test/style commits Land a non-skipped commit (e.g. fix) Wrong bump size Commit type misclassified Amend / add corrective commit (e.g. feat) PyPI publish failed Missing / invalid <code>PYPI_API_TOKEN</code> or Trusted Publishing not approved yet Add token or approve in PyPI UI Changelog missing section Commit type not in allowed list Ensure conventional type used Duplicate release notes Manual tag + automated tag Avoid manual tagging except emergencies"},{"location":"DEVELOPMENT/#philosophy","title":"Philosophy","text":"<p>Keep <code>main</code> always shippable. Small, frequent releases reduce risk and keep context fresh for users.</p>"},{"location":"DEVELOPMENT/#advanced-topics","title":"Advanced Topics","text":""},{"location":"DEVELOPMENT/#adding-a-new-language-analyzer","title":"Adding a New Language Analyzer","text":"<ol> <li> <p>Create analyzer in <code>tenets/core/analysis/</code>:    Python<pre><code>class RustAnalyzer(LanguageAnalyzer):\n    language_name = \"rust\"\n\n    def extract_imports(self, content: str) -&gt; List[Import]:\n        # Implementation\n        ...\n</code></pre></p> </li> <li> <p>Register in <code>analysis/analyzer.py</code>:    Python<pre><code>analyzers['.rs'] = RustAnalyzer()\n</code></pre></p> </li> <li> <p>Add tests in <code>tests/unit/test_rust_analyzer.py</code></p> </li> </ol>"},{"location":"DEVELOPMENT/#creating-custom-ranking-algorithms","title":"Creating Custom Ranking Algorithms","text":"<ol> <li> <p>Implement algorithm:    Python<pre><code>class SecurityRanking:\n    def score_file(self, file, prompt):\n        # Custom scoring logic\n        ...\n</code></pre></p> </li> <li> <p>Register algorithm:    Python<pre><code>@register_algorithm(\"security\")\nclass SecurityRanking:\n    ...\n</code></pre></p> </li> <li> <p>Document usage in <code>docs/api.md</code></p> </li> </ol> <p>Happy coding! \ud83d\ude80 Remember: context is everything.</p>"},{"location":"SECURITY/","title":"Security Policy","text":""},{"location":"SECURITY/#supported-versions","title":"Supported Versions","text":"<p>The project is pre-1.0; security fixes are applied to the latest released version. Older versions may not receive backports.</p>"},{"location":"SECURITY/#reporting-a-vulnerability","title":"Reporting a Vulnerability","text":"<p>Email: team@tenets.dev (or team@manic.agency if unreachable)</p> <p>Please include: - Description of the issue - Steps to reproduce / proof-of-concept - Potential impact / affected components - Your environment (OS, Python, tenets version)</p> <p>We aim to acknowledge within 3 business days and provide a remediation ETA after triage.</p>"},{"location":"SECURITY/#responsible-disclosure","title":"Responsible Disclosure","text":"<p>Do not open public issues for exploitable vulnerabilities. Use the private email above. We will coordinate disclosure and credit (if desired) after a fix is released.</p>"},{"location":"SECURITY/#scope","title":"Scope","text":"<p>Tenets runs locally. Primary concerns: - Arbitrary code execution via file parsing - Directory traversal / path injection - Insecure temporary file handling - Leakage of private repository data beyond intended output</p> <p>Out of scope: - Issues requiring malicious local user privilege escalation - Vulnerabilities in optional third-party dependencies (report upstream)</p>"},{"location":"SECURITY/#security-best-practices-users","title":"Security Best Practices (Users)","text":"<ul> <li>Pin versions in production workflows</li> <li>Run latest patch release</li> <li>Review output before sharing externally</li> <li>Avoid running against untrusted repositories without isolation (use containers)</li> </ul>"},{"location":"SECURITY/#patching-process","title":"Patching Process","text":"<ol> <li>Triage &amp; reproduce</li> <li>Develop fix in private branch</li> <li>Add regression tests</li> <li>Coordinate release (patch version bump)</li> <li>Publish advisory in CHANGELOG / release notes</li> </ol>"},{"location":"SECURITY/#contact","title":"Contact","text":"<p>team@tenets.dev // team@manic.agency</p>"},{"location":"TESTING/","title":"Testing","text":""},{"location":"TESTING/#quick-start","title":"Quick Start","text":"Bash<pre><code># One-liner (editable install + test deps + coverage helpers)\npip install -e '.[test]' pytest pytest-cov\n\n# Run all tests (quiet)\npytest -q\n\n# Run with coverage + fail if below threshold (adjust as policy evolves)\npytest --cov=tenets --cov-report=term-missing --cov-fail-under=70\n\n# Generate XML (CI) + HTML\npytest --cov=tenets --cov-report=xml --cov-report=html\n\n# Open HTML (macOS/Linux)\nopen htmlcov/index.html || xdg-open htmlcov/index.html || true\n\n# Specific test file / test\npytest tests/core/analysis/test_analyzer.py::test_basic_python_analysis -q\n\n# Pattern match\npytest -k analyzer -q\n\n# Parallel (if pytest-xdist installed)\npytest -n auto\n</code></pre> <p>Optional feature extras (install before running related tests): Bash<pre><code>pip install -e '.[light]'   # BM25 / TF-IDF / YAKE ranking tests\npip install -e '.[viz]'     # Visualization tests\npip install -e '.[ml]'      # Embedding / semantic tests (heavy)\n</code></pre></p>"},{"location":"TESTING/#test-structure","title":"Test Structure","text":"Text Only<pre><code>tests/\n\u251c\u2500\u2500 conftest.py              # Shared fixtures\n\u251c\u2500\u2500 test_config.py           # Config tests\n\u251c\u2500\u2500 test_tenets.py           # Main module tests\n\u251c\u2500\u2500 core/\n\u2502   \u251c\u2500\u2500 analysis/           # Code analysis tests\n\u2502   \u251c\u2500\u2500 distiller/          # Context distillation tests\n\u2502   \u251c\u2500\u2500 git/                # Git integration tests\n\u2502   \u251c\u2500\u2500 prompt/             # Prompt parsing tests\n\u2502   \u251c\u2500\u2500 ranker/             # File ranking tests\n\u2502   \u251c\u2500\u2500 session/            # Session management tests\n\u2502   \u2514\u2500\u2500 summarizer/         # Summarization tests\n\u251c\u2500\u2500 storage/\n\u2502   \u251c\u2500\u2500 test_cache.py       # Caching system tests\n\u2502   \u251c\u2500\u2500 test_session_db.py  # Session persistence tests\n\u2502   \u2514\u2500\u2500 test_sqlite.py      # SQLite utilities tests\n\u2514\u2500\u2500 utils/\n    \u251c\u2500\u2500 test_scanner.py     # File scanning tests\n    \u251c\u2500\u2500 test_tokens.py      # Token counting tests\n    \u2514\u2500\u2500 test_logger.py      # Logging tests\n</code></pre>"},{"location":"TESTING/#running-tests","title":"Running Tests","text":""},{"location":"TESTING/#by-category","title":"By Category","text":"Bash<pre><code># Unit tests only\npytest -m unit\n\n# Integration tests\npytest -m integration\n\n# Skip slow tests\npytest -m \"not slow\"\n\n# Tests requiring git\npytest -m requires_git\n\n# Tests requiring ML dependencies\npytest -m requires_ml\n</code></pre>"},{"location":"TESTING/#coverage-reports","title":"Coverage Reports","text":"Bash<pre><code># Terminal report\npytest --cov=tenets --cov-report=term-missing\n\n# Enforce minimum (CI/local gate)\npytest --cov=tenets --cov-report=term-missing --cov-fail-under=80\n\n# HTML report\npytest --cov=tenets --cov-report=html\n\n# XML for CI services (Codecov)\npytest --cov=tenets --cov-report=xml\n</code></pre>"},{"location":"TESTING/#debug-mode","title":"Debug Mode","text":"Bash<pre><code># Show print statements\npytest -s\n\n# Stop on first failure\npytest -x\n\n# Drop into debugger on failure\npytest --pdb\n\n# Verbose output\npytest -vv\n</code></pre>"},{"location":"TESTING/#writing-tests","title":"Writing Tests","text":""},{"location":"TESTING/#basic-test","title":"Basic Test","text":"Python<pre><code>def test_feature(config, analyzer):\n    \"\"\"Test feature description.\"\"\"\n    result = analyzer.analyze_file(Path(\"test.py\"))\n    assert result.language == \"python\"\n</code></pre>"},{"location":"TESTING/#using-fixtures","title":"Using Fixtures","text":"Python<pre><code>@pytest.fixture\ndef temp_project(tmp_path):\n    \"\"\"Create temporary project structure.\"\"\"\n    (tmp_path / \"src\").mkdir()\n    (tmp_path / \"src/main.py\").write_text(\"print('hello')\")\n    return tmp_path\n\ndef test_with_project(temp_project):\n    files = list(temp_project.glob(\"**/*.py\"))\n    assert len(files) == 1\n</code></pre>"},{"location":"TESTING/#mocking","title":"Mocking","text":"Python<pre><code>from unittest.mock import Mock, patch\n\ndef test_with_mock():\n    with patch('tenets.utils.tokens.count_tokens') as mock_count:\n        mock_count.return_value = 100\n        # test code\n</code></pre>"},{"location":"TESTING/#parametrized-tests","title":"Parametrized Tests","text":"Python<pre><code>@pytest.mark.parametrize(\"input,expected\", [\n    (\"test.py\", \"python\"),\n    (\"test.js\", \"javascript\"),\n    (\"test.go\", \"go\"),\n])\ndef test_language_detection(analyzer, input, expected):\n    assert analyzer._detect_language(Path(input)) == expected\n</code></pre>"},{"location":"TESTING/#test-markers","title":"Test Markers","text":"<p>Add to test functions:</p> Python<pre><code>@pytest.mark.slow\ndef test_heavy_operation():\n    pass\n\n@pytest.mark.requires_git\ndef test_git_features():\n    pass\n\n@pytest.mark.skipif(not HAS_TIKTOKEN, reason=\"tiktoken not installed\")\ndef test_token_counting():\n    pass\n</code></pre>"},{"location":"TESTING/#ci-integration","title":"CI Integration","text":"YAML<pre><code># .github/workflows/test.yml\n- name: Run tests\n  run: |\n    pytest --cov=tenets --cov-report=xml\n\n- name: Upload coverage\n  uses: codecov/codecov-action@v3\n  with:\n    file: ./coverage.xml\n</code></pre>"},{"location":"TESTING/#pre-commit-hook","title":"Pre-commit Hook","text":"YAML<pre><code># .pre-commit-config.yaml\n- repo: local\n  hooks:\n    - id: tests\n      name: tests\n      entry: pytest\n      language: system\n      pass_filenames: false\n      always_run: true\n</code></pre>"},{"location":"TESTING/#release-test-checklist","title":"Release Test Checklist","text":"<p>Before tagging a release:</p> Bash<pre><code># 1. Clean environment\nrm -rf .venv dist build *.egg-info &amp;&amp; python -m venv .venv &amp;&amp; source .venv/bin/activate\n\n# 2. Install with all needed extras for full test surface\npip install -e '.[all,test]' pytest pytest-cov\n\n# 3. Lint / type (if tools configured)\n# ruff check .\n# mypy tenets\n\n# 4. Run tests with coverage gate\npytest --cov=tenets --cov-report=term-missing --cov-fail-under=80\n\n# 5. Spot-check critical CLI commands\nfor cmd in \\\n  \"distill 'smoke test' --stats\" \\\n  \"instill 'example tenet'\" \\\n  \"session create release-smoke\" \\\n  \"config cache-stats\"; do\n  echo \"tenets $cmd\"; tenets $cmd || exit 1; done\n\n# 6. Build sdist/wheel\npython -m build\n\n# 7. Install built artifact in fresh venv &amp; re-smoke\npython -m venv verify &amp;&amp; source verify/bin/activate &amp;&amp; pip install dist/*.whl &amp;&amp; tenets version\n</code></pre> <p>Minimal CHANGELOG update + version bump in <code>tenets/__init__.py</code> must precede tagging.</p>"},{"location":"TESTING/#performance-testing","title":"Performance Testing","text":"Bash<pre><code># Benchmark tests\npytest tests/performance/ --benchmark-only\n\n# Profile slow tests\npytest --durations=10\n</code></pre>"},{"location":"TESTING/#troubleshooting","title":"Troubleshooting","text":""},{"location":"TESTING/#common-issues","title":"Common Issues","text":"<p>Import errors: Ensure package is installed with test extras: Bash<pre><code>pip install -e \".[test]\"\n</code></pre></p> <p>Slow tests: Use parallel execution: Bash<pre><code>pytest -n auto\n</code></pre></p> <p>Flaky tests: Re-run failures: Bash<pre><code>pytest --reruns 3\n</code></pre></p> <p>Memory issues: Run tests in chunks: Bash<pre><code>pytest tests/core/\npytest tests/storage/\npytest tests/utils/\n</code></pre></p>"},{"location":"TESTING/#coverage-goals","title":"Coverage Goals","text":"<ul> <li>Overall: &gt;80%</li> <li>Core logic: &gt;90%</li> <li>Error paths: &gt;70%</li> <li>Utils: &gt;85%</li> </ul> <p>Check current coverage: Bash<pre><code>pytest --cov=tenets --cov-report=term-missing | grep TOTAL\n</code></pre></p>"},{"location":"VIZ_CHEATSHEET/","title":"Tenets Viz Deps Command Cheat Sheet","text":""},{"location":"VIZ_CHEATSHEET/#installation","title":"Installation","text":"Bash<pre><code>pip install tenets[viz]  # Install visualization dependencies\n</code></pre>"},{"location":"VIZ_CHEATSHEET/#basic-commands","title":"Basic Commands","text":""},{"location":"VIZ_CHEATSHEET/#simple-usage","title":"Simple Usage","text":"Bash<pre><code>tenets viz deps                     # Auto-detect project, show ASCII tree\ntenets viz deps .                   # Analyze current directory\ntenets viz deps src/                # Analyze specific directory\n</code></pre>"},{"location":"VIZ_CHEATSHEET/#output-formats","title":"Output Formats","text":"Bash<pre><code>tenets viz deps --format ascii      # Terminal tree (default)\ntenets viz deps --format svg --output arch.svg     # Scalable vector graphics\ntenets viz deps --format png --output arch.png     # PNG image\ntenets viz deps --format html --output deps.html   # Interactive HTML\ntenets viz deps --format dot --output graph.dot    # Graphviz DOT\ntenets viz deps --format json --output data.json   # Raw JSON data\n</code></pre>"},{"location":"VIZ_CHEATSHEET/#aggregation-levels","title":"Aggregation Levels","text":"Bash<pre><code>tenets viz deps --level file        # Individual file dependencies (detailed)\ntenets viz deps --level module      # Module-level aggregation (recommended)\ntenets viz deps --level package     # Package-level view (high-level)\n</code></pre>"},{"location":"VIZ_CHEATSHEET/#clustering-options","title":"Clustering Options","text":"Bash<pre><code>tenets viz deps --cluster-by directory   # Group by directory structure\ntenets viz deps --cluster-by module      # Group by module\ntenets viz deps --cluster-by package     # Group by package\n</code></pre>"},{"location":"VIZ_CHEATSHEET/#layout-algorithms","title":"Layout Algorithms","text":"Bash<pre><code>tenets viz deps --layout hierarchical   # Tree-like layout (default)\ntenets viz deps --layout circular       # Circular/radial layout\ntenets viz deps --layout shell          # Concentric circles\ntenets viz deps --layout kamada         # Force-directed layout\n</code></pre>"},{"location":"VIZ_CHEATSHEET/#filtering","title":"Filtering","text":"Bash<pre><code># Include specific patterns\ntenets viz deps --include \"*.py\"                    # Only Python files\ntenets viz deps --include \"*.js,*.jsx\"              # JavaScript files\ntenets viz deps --include \"src/**/*.py\"             # Python in src/\n\n# Exclude patterns\ntenets viz deps --exclude \"*test*\"                  # No test files\ntenets viz deps --exclude \"*.min.js,node_modules\"   # Skip minified and deps\n\n# Combined\ntenets viz deps --include \"*.py\" --exclude \"*test*\"\n</code></pre>"},{"location":"VIZ_CHEATSHEET/#node-limiting","title":"Node Limiting","text":"Bash<pre><code>tenets viz deps --max-nodes 50      # Show only top 50 most connected nodes\ntenets viz deps --max-nodes 100     # Useful for large projects\n</code></pre>"},{"location":"VIZ_CHEATSHEET/#real-world-examples","title":"Real-World Examples","text":""},{"location":"VIZ_CHEATSHEET/#for-documentation","title":"For Documentation","text":"Bash<pre><code># Clean architecture diagram for docs\ntenets viz deps . --level package --format svg --output docs/architecture.svg\n\n# Module overview with clustering\ntenets viz deps . --level module --cluster-by directory --format png --output modules.png\n</code></pre>"},{"location":"VIZ_CHEATSHEET/#for-code-review","title":"For Code Review","text":"Bash<pre><code># Interactive exploration\ntenets viz deps . --level module --format html --output review.html\n\n# Focused on specific subsystem\ntenets viz deps src/api --include \"*.py\" --format svg --output api_deps.svg\n</code></pre>"},{"location":"VIZ_CHEATSHEET/#for-refactoring","title":"For Refactoring","text":"Bash<pre><code># Find circular dependencies\ntenets viz deps . --layout circular --format html --output circular_deps.html\n\n# Identify tightly coupled modules\ntenets viz deps . --level module --layout circular --max-nodes 50 --output coupling.svg\n</code></pre>"},{"location":"VIZ_CHEATSHEET/#for-large-projects","title":"For Large Projects","text":"Bash<pre><code># Top-level overview\ntenets viz deps . --level package --max-nodes 20 --format svg --output overview.svg\n\n# Most connected files\ntenets viz deps . --max-nodes 100 --format html --output top100.html\n\n# Specific subsystem deep dive\ntenets viz deps backend/ --level module --cluster-by module --format html -o backend.html\n</code></pre>"},{"location":"VIZ_CHEATSHEET/#project-type-auto-detection","title":"Project Type Auto-Detection","text":"<p>The command automatically detects: - Python: Packages, Django, Flask, FastAPI - JavaScript/TypeScript: Node.js, React, Vue, Angular - Java: Maven, Gradle, Spring - Go: Go modules - Rust: Cargo projects - Ruby: Rails, Gems - PHP: Laravel, Composer - And more...</p>"},{"location":"VIZ_CHEATSHEET/#tips","title":"Tips","text":"<ol> <li>Start Simple: Use <code>tenets viz deps</code> first to see what's detected</li> <li>Use Levels: Start with <code>--level package</code> for overview, drill down to <code>module</code> or <code>file</code></li> <li>Interactive HTML: Best for exploration, use <code>--format html</code></li> <li>Filter Noise: Use <code>--exclude \"*test*,*mock*\"</code> to focus on core code</li> <li>Save Time: Use <code>--max-nodes</code> for large codebases</li> <li>Documentation: SVG format scales well for docs</li> <li>Clustering: Helps organize complex graphs visually</li> </ol>"},{"location":"VIZ_CHEATSHEET/#troubleshooting","title":"Troubleshooting","text":"Bash<pre><code># Check if dependencies are installed\npython -c \"import networkx, matplotlib, graphviz, plotly\" 2&gt;/dev/null &amp;&amp; echo \"All deps OK\" || echo \"Run: pip install tenets[viz]\"\n\n# Debug mode\nTENETS_LOG_LEVEL=DEBUG tenets viz deps . 2&gt;&amp;1 | grep -E \"(Detected|Found|Analyzing)\"\n\n# If graph is too large\ntenets viz deps . --max-nodes 50 --level module  # Reduce nodes and aggregate\n</code></pre>"},{"location":"VIZ_CHEATSHEET/#output-examples","title":"Output Examples","text":""},{"location":"VIZ_CHEATSHEET/#ascii-tree-default","title":"ASCII Tree (default)","text":"Text Only<pre><code>Dependency Graph:\n==================================================\n\nmain.py\n  \u2514\u2500&gt; utils.py\n  \u2514\u2500&gt; config.py\n  \u2514\u2500&gt; models.py\n\nutils.py\n  \u2514\u2500&gt; config.py\n\nmodels.py\n  \u2514\u2500&gt; utils.py\n</code></pre>"},{"location":"VIZ_CHEATSHEET/#what-you-get","title":"What You Get","text":"<ul> <li>Project Info: Auto-detected type, languages, frameworks</li> <li>Entry Points: Identified main files (main.py, index.js, etc.)</li> <li>Dependency Graph: Visual representation of code relationships</li> <li>Multiple Views: File, module, or package level perspectives</li> </ul>"},{"location":"api/","title":"API Reference","text":"<p>This section contains auto-generated API documentation for the Tenets package.</p> <p>The documentation is generated automatically from Python docstrings during the build process using mkdocstrings.</p>"},{"location":"api/#navigation","title":"Navigation","text":"<p>Use the sidebar to browse through the modules. Each module page shows:</p> <ul> <li>Classes and their methods</li> <li>Functions with parameters and return types</li> <li>Module-level variables and constants</li> <li>Docstrings with examples when available</li> </ul>"},{"location":"api/#main-modules","title":"Main Modules","text":"<ul> <li>tenets - Core package and main exports</li> <li>tenets.core - Core functionality including analysis, ranking, and session management</li> <li>tenets.cli - Command-line interface and commands</li> <li>tenets.models - Data models and structures</li> <li>tenets.utils - Utility functions and helpers</li> </ul> <p>Auto-generated Documentation</p> <p>This documentation is generated directly from the source code.  Any changes to docstrings in the code will be reflected here after rebuilding.</p>"},{"location":"best-practices/","title":"Best Practices","text":""},{"location":"best-practices/#repository-setup","title":"Repository Setup","text":""},{"location":"best-practices/#clean-working-directory","title":"Clean Working Directory","text":"<p>Always run Tenets on a clean working directory for accurate results: Bash<pre><code>git status  # Ensure no uncommitted changes\ntenets examine\n</code></pre></p>"},{"location":"best-practices/#gitignore-configuration","title":"Gitignore Configuration","text":"<p>Ensure your <code>.gitignore</code> is properly configured to exclude: - Build artifacts - Node modules - Virtual environments - Temporary files</p>"},{"location":"best-practices/#command-usage","title":"Command Usage","text":""},{"location":"best-practices/#examine-command","title":"Examine Command","text":"<ul> <li>Use <code>--format</code> for different output formats</li> <li>Filter by language with <code>--language</code></li> <li>Focus on specific paths for targeted analysis</li> </ul>"},{"location":"best-practices/#chronicle-command","title":"Chronicle Command","text":"<ul> <li>Use time ranges appropriate to your project's activity</li> <li>Filter by author for team member contributions</li> <li>Combine with <code>--pattern</code> for specific file analysis</li> </ul>"},{"location":"best-practices/#distill-command","title":"Distill Command","text":"<ul> <li>Run after significant development milestones</li> <li>Use to generate weekly or monthly insights</li> <li>Combine with chronicle for historical context</li> </ul>"},{"location":"best-practices/#performance-optimization","title":"Performance Optimization","text":""},{"location":"best-practices/#large-repositories","title":"Large Repositories","text":"<p>For repositories with many files: Bash<pre><code># Focus on specific directories\ntenets examine src/ --depth 3\n\n# Exclude certain patterns\ntenets examine --exclude \"**/test/**\"\n</code></pre></p>"},{"location":"best-practices/#memory-management","title":"Memory Management","text":"<ul> <li>Use <code>--batch-size</code> for large analyses</li> <li>Enable streaming output with <code>--stream</code></li> </ul>"},{"location":"best-practices/#integration","title":"Integration","text":""},{"location":"best-practices/#cicd-pipeline","title":"CI/CD Pipeline","text":"<p>Add Tenets to your CI pipeline: YAML<pre><code>- name: Code Analysis\n  run: |\n    pip install tenets\n    tenets examine --format json &gt; analysis.json\n</code></pre></p>"},{"location":"best-practices/#pre-commit-hooks","title":"Pre-commit Hooks","text":"<p>Use Tenets in pre-commit hooks: YAML<pre><code>repos:\n  - repo: local\n    hooks:\n      - id: tenets-check\n        name: Tenets Analysis\n        entry: tenets examine --quick\n        language: system\n        pass_filenames: false\n</code></pre></p>"},{"location":"best-practices/#team-collaboration","title":"Team Collaboration","text":""},{"location":"best-practices/#sharing-reports","title":"Sharing Reports","text":"<ul> <li>Generate HTML reports for stakeholder review</li> <li>Export JSON for further processing</li> <li>Use visualizations for architecture discussions</li> </ul>"},{"location":"best-practices/#code-reviews","title":"Code Reviews","text":"<p>Use Tenets output to: - Identify complex areas needing review - Track ownership changes - Monitor technical debt</p>"},{"location":"best-practices/#next-steps","title":"Next Steps","text":"<ul> <li>See Examples for real-world scenarios</li> <li>Review CLI Reference for all options</li> <li>Check Configuration for customization</li> </ul>"},{"location":"docs/","title":"Documentation","text":"<p>Welcome to the Tenets documentation hub. Explore guides and references below.</p> <ul> <li>Quick Start: Get started fast</li> <li>Supported Languages: List</li> <li>CLI Reference: Commands</li> <li>Configuration: Config guide</li> <li> <p>Architecture: System overview</p> </li> <li> <p>API Reference: Browse API</p> </li> </ul> <p>If you were looking for the homepage, go to /.</p>"},{"location":"examples/","title":"Examples","text":""},{"location":"examples/#basic-analysis-examples","title":"Basic Analysis Examples","text":""},{"location":"examples/#analyzing-a-python-project","title":"Analyzing a Python Project","text":"Bash<pre><code># Basic examination\ntenets examine my_python_project/\n\n# With specific focus\ntenets examine my_python_project/ --language python --depth 3\n\n# Output to JSON\ntenets examine my_python_project/ --format json &gt; analysis.json\n</code></pre>"},{"location":"examples/#analyzing-a-javascripttypescript-project","title":"Analyzing a JavaScript/TypeScript Project","text":"Bash<pre><code># Examine with TypeScript support\ntenets examine frontend/ --language typescript\n\n# Exclude node_modules\ntenets examine frontend/ --exclude \"**/node_modules/**\"\n</code></pre>"},{"location":"examples/#chronicle-examples","title":"Chronicle Examples","text":""},{"location":"examples/#team-contribution-analysis","title":"Team Contribution Analysis","text":"Bash<pre><code># Last month's team activity\ntenets chronicle --days 30 --format table\n\n# Specific developer's contributions\ntenets chronicle --author \"Jane Doe\" --days 90\n\n# Focus on feature branch\ntenets chronicle --branch feature/new-ui --days 14\n</code></pre>"},{"location":"examples/#release-analysis","title":"Release Analysis","text":"Bash<pre><code># Changes between releases\ntenets chronicle --from v1.0.0 --to v2.0.0\n\n# Recent hotfixes\ntenets chronicle --pattern \"**/hotfix/**\" --days 7\n</code></pre>"},{"location":"examples/#distill-examples","title":"Distill Examples","text":""},{"location":"examples/#project-insights","title":"Project Insights","text":"Bash<pre><code># Generate comprehensive insights\ntenets distill --comprehensive\n\n# Quick summary\ntenets distill --quick\n\n# Export for reporting\ntenets distill --format markdown &gt; insights.md\n</code></pre>"},{"location":"examples/#visualization-examples","title":"Visualization Examples","text":""},{"location":"examples/#architecture-visualization","title":"Architecture Visualization","text":"Bash<pre><code># Interactive HTML graph\ntenets viz --output architecture.html\n\n# Include all relationships\ntenets viz --include-all --output full-graph.html\n\n# Focus on core modules\ntenets viz --filter \"core/**\" --output core-modules.html\n</code></pre>"},{"location":"examples/#momentum-tracking","title":"Momentum Tracking","text":""},{"location":"examples/#development-velocity","title":"Development Velocity","text":"Bash<pre><code># Weekly momentum report\ntenets momentum --period week\n\n# Monthly trends\ntenets momentum --period month --format chart\n\n# Team momentum\ntenets momentum --team --days 30\n</code></pre>"},{"location":"examples/#advanced-combinations","title":"Advanced Combinations","text":""},{"location":"examples/#pre-release-audit","title":"Pre-Release Audit","text":"Bash<pre><code># Full pre-release analysis\ntenets examine --comprehensive &gt; examine-report.txt\ntenets chronicle --days 30 &gt; chronicle-report.txt\ntenets distill --format json &gt; insights.json\ntenets viz --output release-architecture.html\n</code></pre>"},{"location":"examples/#technical-debt-assessment","title":"Technical Debt Assessment","text":"Bash<pre><code># Identify complex areas\ntenets examine --metric complexity --threshold high\n\n# Find stale code\ntenets chronicle --stale --days 180\n\n# Ownership gaps\ntenets examine --ownership --unowned\n</code></pre>"},{"location":"examples/#team-performance-review","title":"Team Performance Review","text":"Bash<pre><code># Individual contributions\nfor author in \"Alice\" \"Bob\" \"Charlie\"; do\n  tenets chronicle --author \"$author\" --days 90 &gt; \"$author-report.txt\"\ndone\n\n# Team visualization\ntenets viz --team --output team-collaboration.html\n</code></pre>"},{"location":"examples/#integration-examples","title":"Integration Examples","text":""},{"location":"examples/#github-actions","title":"GitHub Actions","text":"YAML<pre><code>name: Code Analysis\non: [push, pull_request]\n\njobs:\n  analyze:\n    runs-on: ubuntu-latest\n    steps:\n      - uses: actions/checkout@v2\n      - name: Install Tenets\n        run: pip install tenets\n      - name: Run Analysis\n        run: |\n          tenets examine --format json &gt; examine.json\n          tenets chronicle --days 7 --format json &gt; chronicle.json\n      - name: Upload Results\n        uses: actions/upload-artifact@v2\n        with:\n          name: analysis-results\n          path: |\n            examine.json\n            chronicle.json\n</code></pre>"},{"location":"examples/#pre-commit-hook","title":"Pre-commit Hook","text":"YAML<pre><code># .pre-commit-config.yaml\nrepos:\n  - repo: local\n    hooks:\n      - id: tenets-complexity\n        name: Check Code Complexity\n        entry: tenets examine --metric complexity --fail-on high\n        language: system\n        pass_filenames: false\n</code></pre>"},{"location":"examples/#next-steps","title":"Next Steps","text":"<ul> <li>Review Best Practices for optimal usage</li> <li>See CLI Reference for all available options</li> <li>Check Configuration for customization options</li> </ul>"},{"location":"installation/","title":"Installation","text":""},{"location":"installation/#requirements","title":"Requirements","text":"<ul> <li>Python 3.9 or higher</li> <li>Git</li> </ul>"},{"location":"installation/#install-from-pypi","title":"Install from PyPI","text":"Bash<pre><code>pip install tenets\n</code></pre>"},{"location":"installation/#install-from-source","title":"Install from Source","text":"Bash<pre><code>git clone https://github.com/yourusername/tenets.git\ncd tenets\npip install -e .\n</code></pre>"},{"location":"installation/#verify-installation","title":"Verify Installation","text":"Bash<pre><code>tenets --version\n</code></pre>"},{"location":"installation/#next-steps","title":"Next Steps","text":"<p>After installation, see Quick Start to get started with your first analysis.</p>"},{"location":"quickstart/","title":"Quickstart","text":""},{"location":"quickstart/#real-world-flow-system-instruction--tenets--sessions","title":"Real-world flow: System instruction + Tenets + Sessions","text":"Bash<pre><code># Create a working session\ntenets session create auth-refresh\n\n# Add guiding principles (tenets)\ntenets tenet add \"Prefer small, safe diffs\" --priority high --category style\ntenets tenet add \"Always validate user input\" --priority critical --category security\n\n# Apply tenets for this session\ntenets instill --session auth-refresh\n\n# Set a global system instruction\ntenets system-instruction set \"You are a senior engineer. Add tests and document trade-offs.\" --enable\n\n# Build context with transformations for token efficiency\ntenets distill \"add OAuth2 refresh tokens\" --session auth-refresh --remove-comments --condense\n\n# Pin files as you learn what matters\ntenets instill --session auth-refresh --add-file src/auth/service.py --add-folder src/auth/routes\ntenets instill --session auth-refresh --list-pinned\n</code></pre> <p>See also: CLI &gt; System Instruction Commands, Tenet Commands, and Instill.</p>"},{"location":"quickstart/#quick-start","title":"Quick Start","text":"<p>Get productive with Tenets in under 60 seconds.</p>"},{"location":"quickstart/#1-install","title":"1. Install","text":"Bash<pre><code>pip install tenets\n</code></pre>"},{"location":"quickstart/#2-generate-context-cli","title":"2. Generate Context (CLI)","text":"Bash<pre><code>tenets distill \"add optimistic locking to order updates\"\n</code></pre> <p>Copy straight to your clipboard:</p> Bash<pre><code>tenets distill \"refactor payment flow\" --copy\n</code></pre> <p>Or enable auto-copy in <code>tenets.toml</code>:</p> TOML<pre><code>[output]\ncopy_on_distill = true\n</code></pre>"},{"location":"quickstart/#3-refine","title":"3. Refine","text":"<p>Pin or force-include critical files:</p> Bash<pre><code># Build context for investigation\ntenets distill \"investigate cache stampede\"\n\n# Pin files are managed through instill command for sessions\ntenets instill --add-file cache/*.py --add-file config/settings.py\n</code></pre> <p>Exclude noise:</p> Bash<pre><code>tenets distill \"debug webhook\" --exclude \"**/migrations/**,**/tests/**\"\n</code></pre>"},{"location":"quickstart/#4-python-api","title":"4. Python API","text":"Python<pre><code>from tenets import Tenets\n\ntenets = Tenets()\nresult = tenets.distill(\n    prompt=\"implement bulk import\",\n    max_tokens=80_000,\n)\nprint(result.token_count, \"tokens\")\n# Copy is done via CLI flag --copy or config setting\n</code></pre>"},{"location":"quickstart/#5-sessions-iterate","title":"5. Sessions (Iterate)","text":"Python<pre><code>tenets = Tenets()\n# Sessions are managed through distill parameters\nfirst = tenets.distill(\"trace 500 errors in checkout\", session_name=\"checkout-fixes\")\nsecond = tenets.distill(\"add instrumentation around payment retries\", session_name=\"checkout-fixes\")\n</code></pre>"},{"location":"quickstart/#6-visualization--insight","title":"6. Visualization &amp; Insight","text":"Bash<pre><code># Complexity &amp; hotspots\ntenets examine . --show-details --hotspots\n\n# Dependency graph (Interactive HTML)\ntenets viz deps --format html --output deps.html\n</code></pre>"},{"location":"quickstart/#7-next","title":"7. Next","text":"<ul> <li>See full CLI options: CLI Reference</li> <li>Tune ranking &amp; tokens: Configuration</li> <li>Dive deeper: Architecture</li> </ul>"},{"location":"supported-languages/","title":"Supported Languages","text":"<p>Tenets ships with first-class analyzers for a broad set of ecosystems. Each analyzer extracts structural signals (definitions, imports, dependencies) that feed ranking.</p> Language / Tech Analyzer Class Extensions Notes Python PythonAnalyzer .py AST parsing, imports, class/function graph JavaScript / TypeScript* JavaScriptAnalyzer .js, .jsx, .ts, .tsx Lightweight regex/heuristic (TypeScript treated as JS for now) Java JavaAnalyzer .java Package &amp; import extraction Go GoAnalyzer .go Import graph, function signatures C# CSharpAnalyzer .cs Namespace &amp; using directives (great for Unity scripts) C / C++ CppAnalyzer .c, .h, .cpp, .hpp Include graph detection Rust RustAnalyzer .rs Module/use extraction Scala ScalaAnalyzer .scala Object/class/trait discovery Kotlin KotlinAnalyzer .kt, .kts Package &amp; import extraction Swift SwiftAnalyzer .swift Import/use lines PHP PhpAnalyzer .php Namespace/use detection Ruby RubyAnalyzer .rb Class/module defs Dart DartAnalyzer .dart Import and class/function capture GDScript (Godot) GDScriptAnalyzer .gd Signals + extends parsing HTML HTMLAnalyzer .html, .htm Link/script/style references CSS CSSAnalyzer .css @import and rule summarization Generic Text GenericAnalyzer * (fallback) Used when no specific analyzer matches <p>*TypeScript currently leverages the JavaScript analyzer (roadmap: richer TS-specific parsing).</p>"},{"location":"supported-languages/#detection-rules","title":"Detection Rules","text":"<p>File extension matching selects the analyzer. Unsupported files fall back to the generic analyzer supplying minimal term frequency and path heuristics.</p>"},{"location":"supported-languages/#adding-a-new-language","title":"Adding a New Language","text":"<ol> <li>Subclass <code>LanguageAnalyzer</code> in <code>tenets/core/analysis/implementations</code></li> <li>Implement <code>match(path)</code> and <code>analyze(content)</code></li> <li>Register in the analyzer registry (if dynamic) or import to ensure discovery</li> <li>Add tests under <code>tests/core/analysis/implementations</code></li> <li>Update this page</li> </ol>"},{"location":"supported-languages/#roadmap","title":"Roadmap","text":"<p>Planned enhancements:</p> <ul> <li>Deeper TypeScript semantic model</li> <li>SQL schema/introspection analyzer</li> <li>Proto / gRPC IDL support</li> <li>Framework-aware weighting (Django, Rails, Spring) optional modules</li> </ul> <p>Got a priority? Open an issue or PR.</p>"},{"location":"api/","title":"API Reference","text":"<p>Welcome to the Tenets API documentation. This section contains comprehensive documentation for all modules, classes, and functions in the Tenets package.</p>"},{"location":"api/#overview","title":"Overview","text":"<p>The API documentation is automatically generated from the source code docstrings using mkdocstrings. Each module page includes:</p> <ul> <li>Classes - With all methods, attributes, and detailed descriptions</li> <li>Functions - Including parameters, return types, and usage examples</li> <li>Type Hints - Full type annotations for better IDE support</li> <li>Examples - Code snippets demonstrating usage where available</li> </ul>"},{"location":"api/#main-package-structure","title":"Main Package Structure","text":""},{"location":"api/#core-package","title":"Core Package","text":"<p><code>tenets</code> - The main package containing core exports and initialization</p>"},{"location":"api/#core-modules","title":"Core Modules","text":"<p><code>tenets.core</code> - Core functionality powering tenets - Analysis engines for code understanding - Ranking algorithms for relevance scoring - Context aggregation and management - Session persistence and state management</p>"},{"location":"api/#command-line-interface","title":"Command-Line Interface","text":"<p><code>tenets.cli</code> - CLI application and commands - Main application entry point - Command implementations - Terminal output formatting</p>"},{"location":"api/#data-models","title":"Data Models","text":"<p><code>tenets.models</code> - Data structures and schemas - File and context models - Session and configuration models - Analysis result structures</p>"},{"location":"api/#utilities","title":"Utilities","text":"<p><code>tenets.utils</code> - Helper functions and utilities - File operations and scanning - Git integration helpers - Token counting and management</p>"},{"location":"api/#navigation","title":"Navigation","text":"<p>The full module documentation is auto-generated during the build process. Use the sidebar navigation to browse through all available modules and their documentation.</p> <p>Using the API</p> <p>To use Tenets programmatically in your Python code:</p> Python<pre><code>from tenets import Tenets\n\n# Initialize\ntenets = Tenets()\n\n# Build context\nresult = tenets.distill(\"implement user authentication\")\n</code></pre> <p>Auto-Generated Content</p> <p>This documentation is generated directly from the source code. Any updates to docstrings in the codebase will be reflected here after rebuilding the documentation.</p>"},{"location":"api/SUMMARY/","title":"SUMMARY","text":"<ul> <li>tenets<ul> <li>cli<ul> <li>app</li> <li>commands<ul> <li>_utils</li> <li>chronicle</li> <li>config</li> <li>distill</li> <li>examine</li> <li>instill</li> <li>momentum</li> <li>rank</li> <li>session</li> <li>system_instruction</li> <li>tenet</li> <li>viz</li> </ul> </li> </ul> </li> <li>config</li> <li>core<ul> <li>analysis<ul> <li>analyzer</li> <li>base</li> <li>implementations<ul> <li>cpp_analyzer</li> <li>csharp_analyzer</li> <li>css_analyzer</li> <li>dart_analyzer</li> <li>gdscript_analyzer</li> <li>generic_analyzer</li> <li>go_analyzer</li> <li>html_analyzer</li> <li>java_analyzer</li> <li>javascript_analyzer</li> <li>kotlin_analyzer</li> <li>php_analyzer</li> <li>python_analyzer</li> <li>ruby_analyzer</li> <li>rust_analyzer</li> <li>scala_analyzer</li> <li>swift_analyzer</li> </ul> </li> <li>project_detector</li> </ul> </li> <li>distiller<ul> <li>aggregator</li> <li>distiller</li> <li>formatter</li> <li>optimizer</li> <li>transform</li> </ul> </li> <li>examiner<ul> <li>complexity</li> <li>examiner</li> <li>hotspots</li> <li>metrics</li> <li>ownership</li> </ul> </li> <li>git<ul> <li>analyzer</li> <li>blame</li> <li>chronicle</li> <li>stats</li> </ul> </li> <li>instiller<ul> <li>injector</li> <li>instiller</li> <li>manager</li> </ul> </li> <li>momentum<ul> <li>metrics</li> <li>tracker</li> </ul> </li> <li>nlp<ul> <li>bm25</li> <li>cache</li> <li>embeddings</li> <li>keyword_extractor</li> <li>ml_utils</li> <li>programming_patterns</li> <li>similarity</li> <li>stopwords</li> <li>tfidf</li> <li>tokenizer</li> </ul> </li> <li>prompt<ul> <li>cache</li> <li>entity_recognizer</li> <li>external_sources</li> <li>intent_detector</li> <li>normalizer</li> <li>parser</li> <li>temporal_parser</li> </ul> </li> <li>ranking<ul> <li>factors</li> <li>ranker</li> <li>strategies</li> </ul> </li> <li>reporting<ul> <li>generator</li> <li>html_reporter</li> <li>markdown_reporter</li> <li>visualizer</li> </ul> </li> <li>session<ul> <li>session</li> </ul> </li> <li>summarizer<ul> <li>llm</li> <li>strategies</li> <li>summarizer</li> </ul> </li> </ul> </li> <li>models<ul> <li>analysis</li> <li>context</li> <li>llm</li> <li>summary</li> <li>tenet</li> </ul> </li> <li>storage<ul> <li>cache</li> <li>session_db</li> <li>sqlite</li> </ul> </li> <li>utils<ul> <li>external_sources</li> <li>logger</li> <li>multiprocessing</li> <li>scanner</li> <li>timing</li> <li>tokens</li> </ul> </li> <li>viz<ul> <li>base</li> <li>complexity</li> <li>contributors</li> <li>coupling</li> <li>dependencies</li> <li>displays</li> <li>graph_generator</li> <li>hotspots</li> <li>momentum</li> </ul> </li> </ul> </li> </ul>"},{"location":"api/tenets/","title":"Tenets","text":""},{"location":"api/tenets/#tenets","title":"tenets","text":"<p>Tenets - Context that feeds your prompts.</p> <p>Tenets is a code intelligence platform that analyzes codebases locally to surface relevant files, track development velocity, and build optimal context for both human understanding and AI pair programming - all without making any LLM API calls.</p> <p>This package provides:</p> Example <p>Basic usage for context extraction:</p> <p>from tenets import Tenets ten = Tenets() result = ten.distill(\"implement OAuth2 authentication\") print(result.context)</p> <p>With tenet system:</p> <p>ten.add_tenet(\"Always use type hints in Python\", priority=\"high\") ten.instill_tenets() result = ten.distill(\"add user model\")  # Context now includes tenets</p>"},{"location":"api/tenets/#tenets-classes","title":"Classes","text":""},{"location":"api/tenets/#tenets.TenetsConfig","title":"TenetsConfig  <code>dataclass</code>","text":"Python<pre><code>TenetsConfig(config_file: Optional[Path] = None, project_root: Optional[Path] = None, max_tokens: int = 100000, version: str = '0.1.0', debug: bool = False, quiet: bool = False, scanner: ScannerConfig = ScannerConfig(), ranking: RankingConfig = RankingConfig(), summarizer: SummarizerConfig = SummarizerConfig(), tenet: TenetConfig = TenetConfig(), cache: CacheConfig = CacheConfig(), output: OutputConfig = OutputConfig(), git: GitConfig = GitConfig(), llm: LLMConfig = LLMConfig(), nlp: NLPConfig = NLPConfig(), custom: Dict[str, Any] = dict())\n</code></pre> <p>Main configuration for the Tenets system with LLM and NLP support.</p> <p>This is the root configuration object that contains all subsystem configs and global settings. It handles loading from files, environment variables, and provides sensible defaults.</p> ATTRIBUTE DESCRIPTION <code>config_file</code> <p>Path to configuration file (if any)</p> <p> TYPE: <code>Optional[Path]</code> </p> <code>project_root</code> <p>Root directory of the project</p> <p> TYPE: <code>Optional[Path]</code> </p> <code>max_tokens</code> <p>Default maximum tokens for context</p> <p> TYPE: <code>int</code> </p> <code>version</code> <p>Tenets version (for compatibility checking)</p> <p> TYPE: <code>str</code> </p> <code>debug</code> <p>Enable debug mode</p> <p> TYPE: <code>bool</code> </p> <code>quiet</code> <p>Suppress non-essential output</p> <p> TYPE: <code>bool</code> </p> <code>scanner</code> <p>Scanner subsystem configuration</p> <p> TYPE: <code>ScannerConfig</code> </p> <code>ranking</code> <p>Ranking subsystem configuration</p> <p> TYPE: <code>RankingConfig</code> </p> <code>summarizer</code> <p>Summarizer subsystem configuration</p> <p> TYPE: <code>SummarizerConfig</code> </p> <code>tenet</code> <p>Tenet subsystem configuration</p> <p> TYPE: <code>TenetConfig</code> </p> <code>cache</code> <p>Cache subsystem configuration</p> <p> TYPE: <code>CacheConfig</code> </p> <code>output</code> <p>Output formatting configuration</p> <p> TYPE: <code>OutputConfig</code> </p> <code>git</code> <p>Git integration configuration</p> <p> TYPE: <code>GitConfig</code> </p> <code>llm</code> <p>LLM integration configuration</p> <p> TYPE: <code>LLMConfig</code> </p> <code>nlp</code> <p>NLP system configuration</p> <p> TYPE: <code>NLPConfig</code> </p> <code>custom</code> <p>Custom user configuration</p> <p> TYPE: <code>Dict[str, Any]</code> </p>"},{"location":"api/tenets/#tenets.TenetsConfig-attributes","title":"Attributes","text":""},{"location":"api/tenets/#tenets.TenetsConfig.exclude_minified","title":"exclude_minified  <code>property</code> <code>writable</code>","text":"Python<pre><code>exclude_minified: bool\n</code></pre> <p>Get exclude_minified setting from scanner config.</p>"},{"location":"api/tenets/#tenets.TenetsConfig.minified_patterns","title":"minified_patterns  <code>property</code> <code>writable</code>","text":"Python<pre><code>minified_patterns: List[str]\n</code></pre> <p>Get minified patterns from scanner config.</p>"},{"location":"api/tenets/#tenets.TenetsConfig.build_directory_patterns","title":"build_directory_patterns  <code>property</code> <code>writable</code>","text":"Python<pre><code>build_directory_patterns: List[str]\n</code></pre> <p>Get build directory patterns from scanner config.</p>"},{"location":"api/tenets/#tenets.TenetsConfig.cache_dir","title":"cache_dir  <code>property</code> <code>writable</code>","text":"Python<pre><code>cache_dir: Path\n</code></pre> <p>Get the cache directory path.</p>"},{"location":"api/tenets/#tenets.TenetsConfig.scanner_workers","title":"scanner_workers  <code>property</code>","text":"Python<pre><code>scanner_workers: int\n</code></pre> <p>Get number of scanner workers.</p>"},{"location":"api/tenets/#tenets.TenetsConfig.ranking_workers","title":"ranking_workers  <code>property</code>","text":"Python<pre><code>ranking_workers: int\n</code></pre> <p>Get number of ranking workers.</p>"},{"location":"api/tenets/#tenets.TenetsConfig.ranking_algorithm","title":"ranking_algorithm  <code>property</code>","text":"Python<pre><code>ranking_algorithm: str\n</code></pre> <p>Get the ranking algorithm.</p>"},{"location":"api/tenets/#tenets.TenetsConfig.summarizer_mode","title":"summarizer_mode  <code>property</code>","text":"Python<pre><code>summarizer_mode: str\n</code></pre> <p>Get the default summarizer mode.</p>"},{"location":"api/tenets/#tenets.TenetsConfig.summarizer_ratio","title":"summarizer_ratio  <code>property</code>","text":"Python<pre><code>summarizer_ratio: float\n</code></pre> <p>Get the default summarization target ratio.</p>"},{"location":"api/tenets/#tenets.TenetsConfig.respect_gitignore","title":"respect_gitignore  <code>property</code> <code>writable</code>","text":"Python<pre><code>respect_gitignore: bool\n</code></pre> <p>Whether to respect .gitignore files.</p>"},{"location":"api/tenets/#tenets.TenetsConfig.follow_symlinks","title":"follow_symlinks  <code>property</code> <code>writable</code>","text":"Python<pre><code>follow_symlinks: bool\n</code></pre> <p>Whether to follow symbolic links.</p>"},{"location":"api/tenets/#tenets.TenetsConfig.additional_ignore_patterns","title":"additional_ignore_patterns  <code>property</code> <code>writable</code>","text":"Python<pre><code>additional_ignore_patterns: List[str]\n</code></pre> <p>Get additional ignore patterns.</p>"},{"location":"api/tenets/#tenets.TenetsConfig.auto_instill_tenets","title":"auto_instill_tenets  <code>property</code> <code>writable</code>","text":"Python<pre><code>auto_instill_tenets: bool\n</code></pre> <p>Whether to automatically instill tenets.</p>"},{"location":"api/tenets/#tenets.TenetsConfig.max_tenets_per_context","title":"max_tenets_per_context  <code>property</code> <code>writable</code>","text":"Python<pre><code>max_tenets_per_context: int\n</code></pre> <p>Maximum tenets to inject per context.</p>"},{"location":"api/tenets/#tenets.TenetsConfig.tenet_injection_config","title":"tenet_injection_config  <code>property</code>","text":"Python<pre><code>tenet_injection_config: Dict[str, Any]\n</code></pre> <p>Get tenet injection configuration.</p>"},{"location":"api/tenets/#tenets.TenetsConfig.cache_ttl_days","title":"cache_ttl_days  <code>property</code> <code>writable</code>","text":"Python<pre><code>cache_ttl_days: int\n</code></pre> <p>Cache time-to-live in days.</p>"},{"location":"api/tenets/#tenets.TenetsConfig.max_cache_size_mb","title":"max_cache_size_mb  <code>property</code> <code>writable</code>","text":"Python<pre><code>max_cache_size_mb: int\n</code></pre> <p>Maximum cache size in megabytes.</p>"},{"location":"api/tenets/#tenets.TenetsConfig.llm_enabled","title":"llm_enabled  <code>property</code> <code>writable</code>","text":"Python<pre><code>llm_enabled: bool\n</code></pre> <p>Whether LLM features are enabled.</p>"},{"location":"api/tenets/#tenets.TenetsConfig.llm_provider","title":"llm_provider  <code>property</code> <code>writable</code>","text":"Python<pre><code>llm_provider: str\n</code></pre> <p>Get the current LLM provider.</p>"},{"location":"api/tenets/#tenets.TenetsConfig.nlp_enabled","title":"nlp_enabled  <code>property</code> <code>writable</code>","text":"Python<pre><code>nlp_enabled: bool\n</code></pre> <p>Whether NLP features are enabled.</p>"},{"location":"api/tenets/#tenets.TenetsConfig.nlp_embeddings_enabled","title":"nlp_embeddings_enabled  <code>property</code> <code>writable</code>","text":"Python<pre><code>nlp_embeddings_enabled: bool\n</code></pre> <p>Whether NLP embeddings are enabled.</p>"},{"location":"api/tenets/#tenets.TenetsConfig-functions","title":"Functions","text":""},{"location":"api/tenets/#tenets.TenetsConfig.to_dict","title":"to_dict","text":"Python<pre><code>to_dict() -&gt; Dict[str, Any]\n</code></pre> <p>Convert configuration to dictionary.</p> RETURNS DESCRIPTION <code>Dict[str, Any]</code> <p>Dictionary representation of configuration</p>"},{"location":"api/tenets/#tenets.TenetsConfig.save","title":"save","text":"Python<pre><code>save(path: Optional[Path] = None)\n</code></pre> <p>Save configuration to file.</p> PARAMETER DESCRIPTION <code>path</code> <p>Path to save to (uses config_file if not specified)</p> <p> TYPE: <code>Optional[Path]</code> DEFAULT: <code>None</code> </p> RAISES DESCRIPTION <code>ValueError</code> <p>If no path specified and config_file not set</p>"},{"location":"api/tenets/#tenets.TenetsConfig.get_llm_api_key","title":"get_llm_api_key","text":"Python<pre><code>get_llm_api_key(provider: Optional[str] = None) -&gt; Optional[str]\n</code></pre> <p>Get LLM API key for a provider.</p> PARAMETER DESCRIPTION <code>provider</code> <p>Provider name (uses default if not specified)</p> <p> TYPE: <code>Optional[str]</code> DEFAULT: <code>None</code> </p> RETURNS DESCRIPTION <code>Optional[str]</code> <p>API key or None</p>"},{"location":"api/tenets/#tenets.TenetsConfig.get_llm_model","title":"get_llm_model","text":"Python<pre><code>get_llm_model(task: str = 'default', provider: Optional[str] = None) -&gt; str\n</code></pre> <p>Get LLM model for a specific task.</p> PARAMETER DESCRIPTION <code>task</code> <p>Task type</p> <p> TYPE: <code>str</code> DEFAULT: <code>'default'</code> </p> <code>provider</code> <p>Provider name (uses default if not specified)</p> <p> TYPE: <code>Optional[str]</code> DEFAULT: <code>None</code> </p> RETURNS DESCRIPTION <code>str</code> <p>Model name</p>"},{"location":"api/tenets/#tenets.CodeAnalyzer","title":"CodeAnalyzer","text":"Python<pre><code>CodeAnalyzer(config: TenetsConfig)\n</code></pre> <p>Main code analysis orchestrator.</p> <p>Coordinates language-specific analyzers and provides a unified interface for analyzing source code files. Handles caching, parallel processing, analyzer selection, and fallback strategies.</p> ATTRIBUTE DESCRIPTION <code>config</code> <p>TenetsConfig instance for configuration</p> <p> </p> <code>logger</code> <p>Logger instance for logging</p> <p> </p> <code>cache</code> <p>AnalysisCache for caching analysis results</p> <p> </p> <code>analyzers</code> <p>Dictionary mapping file extensions to analyzer instances</p> <p> </p> <code>stats</code> <p>Analysis statistics and metrics</p> <p> </p> <p>Initialize the code analyzer.</p> PARAMETER DESCRIPTION <code>config</code> <p>Tenets configuration object</p> <p> TYPE: <code>TenetsConfig</code> </p>"},{"location":"api/tenets/#tenets.CodeAnalyzer-functions","title":"Functions","text":""},{"location":"api/tenets/#tenets.CodeAnalyzer.analyze_file","title":"analyze_file","text":"Python<pre><code>analyze_file(file_path: Path, deep: bool = False, extract_keywords: bool = True, use_cache: bool = True, progress_callback: Optional[Callable] = None) -&gt; FileAnalysis\n</code></pre> <p>Analyze a single file.</p> <p>Performs language-specific analysis on a file, extracting imports, structure, complexity metrics, and other relevant information.</p> PARAMETER DESCRIPTION <code>file_path</code> <p>Path to the file to analyze</p> <p> TYPE: <code>Path</code> </p> <code>deep</code> <p>Whether to perform deep analysis (AST parsing, etc.)</p> <p> TYPE: <code>bool</code> DEFAULT: <code>False</code> </p> <code>extract_keywords</code> <p>Whether to extract keywords from content</p> <p> TYPE: <code>bool</code> DEFAULT: <code>True</code> </p> <code>use_cache</code> <p>Whether to use cached results if available</p> <p> TYPE: <code>bool</code> DEFAULT: <code>True</code> </p> <code>progress_callback</code> <p>Optional callback for progress updates</p> <p> TYPE: <code>Optional[Callable]</code> DEFAULT: <code>None</code> </p> RETURNS DESCRIPTION <code>FileAnalysis</code> <p>FileAnalysis object with complete analysis results</p> RAISES DESCRIPTION <code>FileNotFoundError</code> <p>If file doesn't exist</p> <code>PermissionError</code> <p>If file cannot be read</p>"},{"location":"api/tenets/#tenets.CodeAnalyzer.analyze_files","title":"analyze_files","text":"Python<pre><code>analyze_files(file_paths: list[Path], deep: bool = False, parallel: bool = True, progress_callback: Optional[Callable] = None) -&gt; list[FileAnalysis]\n</code></pre> <p>Analyze multiple files.</p> PARAMETER DESCRIPTION <code>file_paths</code> <p>List of file paths to analyze</p> <p> TYPE: <code>list[Path]</code> </p> <code>deep</code> <p>Whether to perform deep analysis</p> <p> TYPE: <code>bool</code> DEFAULT: <code>False</code> </p> <code>parallel</code> <p>Whether to analyze files in parallel</p> <p> TYPE: <code>bool</code> DEFAULT: <code>True</code> </p> <code>progress_callback</code> <p>Optional callback for progress updates</p> <p> TYPE: <code>Optional[Callable]</code> DEFAULT: <code>None</code> </p> RETURNS DESCRIPTION <code>list[FileAnalysis]</code> <p>List of FileAnalysis objects</p>"},{"location":"api/tenets/#tenets.CodeAnalyzer.analyze_project","title":"analyze_project","text":"Python<pre><code>analyze_project(project_path: Path, patterns: Optional[list[str]] = None, exclude_patterns: Optional[list[str]] = None, deep: bool = True, parallel: bool = True, progress_callback: Optional[Callable] = None) -&gt; ProjectAnalysis\n</code></pre> <p>Analyze an entire project.</p> PARAMETER DESCRIPTION <code>project_path</code> <p>Path to the project root</p> <p> TYPE: <code>Path</code> </p> <code>patterns</code> <p>File patterns to include (e.g., ['.py', '.js'])</p> <p> TYPE: <code>Optional[list[str]]</code> DEFAULT: <code>None</code> </p> <code>exclude_patterns</code> <p>File patterns to exclude</p> <p> TYPE: <code>Optional[list[str]]</code> DEFAULT: <code>None</code> </p> <code>deep</code> <p>Whether to perform deep analysis</p> <p> TYPE: <code>bool</code> DEFAULT: <code>True</code> </p> <code>parallel</code> <p>Whether to analyze files in parallel</p> <p> TYPE: <code>bool</code> DEFAULT: <code>True</code> </p> <code>progress_callback</code> <p>Optional callback for progress updates</p> <p> TYPE: <code>Optional[Callable]</code> DEFAULT: <code>None</code> </p> RETURNS DESCRIPTION <code>ProjectAnalysis</code> <p>ProjectAnalysis object with complete project analysis</p>"},{"location":"api/tenets/#tenets.CodeAnalyzer.generate_report","title":"generate_report","text":"Python<pre><code>generate_report(analysis: Union[FileAnalysis, ProjectAnalysis, list[FileAnalysis]], format: str = 'json', output_path: Optional[Path] = None) -&gt; AnalysisReport\n</code></pre> <p>Generate an analysis report.</p> PARAMETER DESCRIPTION <code>analysis</code> <p>Analysis results to report on</p> <p> TYPE: <code>Union[FileAnalysis, ProjectAnalysis, list[FileAnalysis]]</code> </p> <code>format</code> <p>Report format ('json', 'html', 'markdown', 'csv')</p> <p> TYPE: <code>str</code> DEFAULT: <code>'json'</code> </p> <code>output_path</code> <p>Optional path to save the report</p> <p> TYPE: <code>Optional[Path]</code> DEFAULT: <code>None</code> </p> RETURNS DESCRIPTION <code>AnalysisReport</code> <p>AnalysisReport object</p>"},{"location":"api/tenets/#tenets.CodeAnalyzer.shutdown","title":"shutdown","text":"Python<pre><code>shutdown()\n</code></pre> <p>Shutdown the analyzer and clean up resources.</p>"},{"location":"api/tenets/#tenets.Distiller","title":"Distiller","text":"Python<pre><code>Distiller(config: TenetsConfig)\n</code></pre> <p>Orchestrates context extraction from codebases.</p> <p>The Distiller is the main engine that powers the 'distill' command. It coordinates all the components to extract the most relevant context based on a user's prompt.</p> <p>Initialize the distiller with configuration.</p> PARAMETER DESCRIPTION <code>config</code> <p>Tenets configuration</p> <p> TYPE: <code>TenetsConfig</code> </p>"},{"location":"api/tenets/#tenets.Distiller-functions","title":"Functions","text":""},{"location":"api/tenets/#tenets.Distiller.distill","title":"distill","text":"Python<pre><code>distill(prompt: str, paths: Optional[Union[str, Path, List[Path]]] = None, *, format: str = 'markdown', model: Optional[str] = None, max_tokens: Optional[int] = None, mode: str = 'balanced', include_git: bool = True, session_name: Optional[str] = None, include_patterns: Optional[List[str]] = None, exclude_patterns: Optional[List[str]] = None, full: bool = False, condense: bool = False, remove_comments: bool = False, pinned_files: Optional[List[Path]] = None, include_tests: Optional[bool] = None, docstring_weight: Optional[float] = None, summarize_imports: bool = True) -&gt; ContextResult\n</code></pre> <p>Distill relevant context from codebase based on prompt.</p> <p>This is the main method that extracts, ranks, and aggregates the most relevant files and information for a given prompt.</p> PARAMETER DESCRIPTION <code>prompt</code> <p>The user's query or task description</p> <p> TYPE: <code>str</code> </p> <code>paths</code> <p>Paths to analyze (default: current directory)</p> <p> TYPE: <code>Optional[Union[str, Path, List[Path]]]</code> DEFAULT: <code>None</code> </p> <code>format</code> <p>Output format (markdown, xml, json)</p> <p> TYPE: <code>str</code> DEFAULT: <code>'markdown'</code> </p> <code>model</code> <p>Target LLM model for token counting</p> <p> TYPE: <code>Optional[str]</code> DEFAULT: <code>None</code> </p> <code>max_tokens</code> <p>Maximum tokens for context</p> <p> TYPE: <code>Optional[int]</code> DEFAULT: <code>None</code> </p> <code>mode</code> <p>Analysis mode (fast, balanced, thorough)</p> <p> TYPE: <code>str</code> DEFAULT: <code>'balanced'</code> </p> <code>include_git</code> <p>Whether to include git context</p> <p> TYPE: <code>bool</code> DEFAULT: <code>True</code> </p> <code>session_name</code> <p>Session name for stateful context</p> <p> TYPE: <code>Optional[str]</code> DEFAULT: <code>None</code> </p> <code>include_patterns</code> <p>File patterns to include</p> <p> TYPE: <code>Optional[List[str]]</code> DEFAULT: <code>None</code> </p> <code>exclude_patterns</code> <p>File patterns to exclude</p> <p> TYPE: <code>Optional[List[str]]</code> DEFAULT: <code>None</code> </p> RETURNS DESCRIPTION <code>ContextResult</code> <p>ContextResult with the distilled context</p> Example <p>distiller = Distiller(config) result = distiller.distill( ...     \"implement OAuth2 authentication\", ...     paths=\"./src\", ...     mode=\"thorough\", ...     max_tokens=50000 ... ) print(result.context)</p>"},{"location":"api/tenets/#tenets.Instiller","title":"Instiller","text":"Python<pre><code>Instiller(config: TenetsConfig)\n</code></pre> <p>Main orchestrator for tenet instillation with smart injection.</p> <p>The Instiller manages the entire process of injecting tenets into context, including: - Tracking injection history per session - Analyzing context complexity - Determining optimal injection frequency - Selecting appropriate tenets - Applying injection strategies - Recording metrics and effectiveness</p> <p>It supports multiple injection modes: - Always: Inject into every context - Periodic: Inject every Nth distillation - Adaptive: Smart injection based on complexity and session - Manual: Only inject when explicitly requested</p> <p>Initialize the Instiller.</p> PARAMETER DESCRIPTION <code>config</code> <p>Configuration object</p> <p> TYPE: <code>TenetsConfig</code> </p>"},{"location":"api/tenets/#tenets.Instiller-functions","title":"Functions","text":""},{"location":"api/tenets/#tenets.Instiller.inject_system_instruction","title":"inject_system_instruction","text":"Python<pre><code>inject_system_instruction(content: str, format: str = 'markdown', session: Optional[str] = None) -&gt; Tuple[str, Dict[str, Any]]\n</code></pre> <p>Inject system instruction (system prompt) according to config.</p> <p>Behavior: - If system instruction is disabled or empty, return unchanged. - If session provided and once-per-session is enabled, inject only on first distill. - If no session, inject on every distill. - Placement controlled by system_instruction_position. - Formatting controlled by system_instruction_format.</p> <p>Returns modified content and metadata about injection.</p>"},{"location":"api/tenets/#tenets.Instiller.instill","title":"instill","text":"Python<pre><code>instill(context: Union[str, ContextResult], session: Optional[str] = None, force: bool = False, strategy: Optional[str] = None, max_tenets: Optional[int] = None, check_frequency: bool = True, inject_system_instruction: Optional[bool] = None) -&gt; Union[str, ContextResult]\n</code></pre> <p>Instill tenets into context with smart injection.</p> PARAMETER DESCRIPTION <code>context</code> <p>Context to inject tenets into</p> <p> TYPE: <code>Union[str, ContextResult]</code> </p> <code>session</code> <p>Session identifier for tracking</p> <p> TYPE: <code>Optional[str]</code> DEFAULT: <code>None</code> </p> <code>force</code> <p>Force injection regardless of frequency settings</p> <p> TYPE: <code>bool</code> DEFAULT: <code>False</code> </p> <code>strategy</code> <p>Override injection strategy</p> <p> TYPE: <code>Optional[str]</code> DEFAULT: <code>None</code> </p> <code>max_tenets</code> <p>Override maximum tenets</p> <p> TYPE: <code>Optional[int]</code> DEFAULT: <code>None</code> </p> <code>check_frequency</code> <p>Whether to check injection frequency</p> <p> TYPE: <code>bool</code> DEFAULT: <code>True</code> </p> RETURNS DESCRIPTION <code>Union[str, ContextResult]</code> <p>Modified context with tenets injected (if applicable)</p>"},{"location":"api/tenets/#tenets.Instiller.get_session_stats","title":"get_session_stats","text":"Python<pre><code>get_session_stats(session: str) -&gt; Dict[str, Any]\n</code></pre> <p>Get statistics for a specific session.</p> PARAMETER DESCRIPTION <code>session</code> <p>Session identifier</p> <p> TYPE: <code>str</code> </p> RETURNS DESCRIPTION <code>Dict[str, Any]</code> <p>Dictionary of session statistics</p>"},{"location":"api/tenets/#tenets.Instiller.get_all_session_stats","title":"get_all_session_stats","text":"Python<pre><code>get_all_session_stats() -&gt; Dict[str, Dict[str, Any]]\n</code></pre> <p>Get statistics for all sessions.</p> RETURNS DESCRIPTION <code>Dict[str, Dict[str, Any]]</code> <p>Dictionary mapping session IDs to stats</p>"},{"location":"api/tenets/#tenets.Instiller.analyze_effectiveness","title":"analyze_effectiveness","text":"Python<pre><code>analyze_effectiveness(session: Optional[str] = None) -&gt; Dict[str, Any]\n</code></pre> <p>Analyze the effectiveness of tenet instillation.</p> PARAMETER DESCRIPTION <code>session</code> <p>Optional session to analyze</p> <p> TYPE: <code>Optional[str]</code> DEFAULT: <code>None</code> </p> RETURNS DESCRIPTION <code>Dict[str, Any]</code> <p>Dictionary with analysis results and recommendations</p>"},{"location":"api/tenets/#tenets.Instiller.export_instillation_history","title":"export_instillation_history","text":"Python<pre><code>export_instillation_history(output_path: Path, format: str = 'json', session: Optional[str] = None) -&gt; None\n</code></pre> <p>Export instillation history to file.</p> PARAMETER DESCRIPTION <code>output_path</code> <p>Path to output file</p> <p> TYPE: <code>Path</code> </p> <code>format</code> <p>Export format (json or csv)</p> <p> TYPE: <code>str</code> DEFAULT: <code>'json'</code> </p> <code>session</code> <p>Optional session filter</p> <p> TYPE: <code>Optional[str]</code> DEFAULT: <code>None</code> </p> RAISES DESCRIPTION <code>ValueError</code> <p>If format is not supported</p>"},{"location":"api/tenets/#tenets.Instiller.reset_session_history","title":"reset_session_history","text":"Python<pre><code>reset_session_history(session: str) -&gt; bool\n</code></pre> <p>Reset injection history for a session.</p> PARAMETER DESCRIPTION <code>session</code> <p>Session identifier</p> <p> TYPE: <code>str</code> </p> RETURNS DESCRIPTION <code>bool</code> <p>True if reset, False if session not found</p>"},{"location":"api/tenets/#tenets.Instiller.clear_cache","title":"clear_cache","text":"Python<pre><code>clear_cache() -&gt; None\n</code></pre> <p>Clear the results cache.</p>"},{"location":"api/tenets/#tenets.TenetManager","title":"TenetManager","text":"Python<pre><code>TenetManager(config: TenetsConfig)\n</code></pre> <p>Manages tenets throughout their lifecycle.</p> <p>Initialize the tenet manager.</p> PARAMETER DESCRIPTION <code>config</code> <p>Tenets configuration</p> <p> TYPE: <code>TenetsConfig</code> </p>"},{"location":"api/tenets/#tenets.TenetManager-functions","title":"Functions","text":""},{"location":"api/tenets/#tenets.TenetManager.add_tenet","title":"add_tenet","text":"Python<pre><code>add_tenet(content: Union[str, Tenet], priority: Union[str, Priority] = 'medium', category: Optional[Union[str, TenetCategory]] = None, session: Optional[str] = None, author: Optional[str] = None) -&gt; Tenet\n</code></pre> <p>Add a new tenet.</p> PARAMETER DESCRIPTION <code>content</code> <p>The guiding principle text or a Tenet object</p> <p> TYPE: <code>Union[str, Tenet]</code> </p> <code>priority</code> <p>Priority level (low, medium, high, critical)</p> <p> TYPE: <code>Union[str, Priority]</code> DEFAULT: <code>'medium'</code> </p> <code>category</code> <p>Category for organization</p> <p> TYPE: <code>Optional[Union[str, TenetCategory]]</code> DEFAULT: <code>None</code> </p> <code>session</code> <p>Bind to specific session</p> <p> TYPE: <code>Optional[str]</code> DEFAULT: <code>None</code> </p> <code>author</code> <p>Who created the tenet</p> <p> TYPE: <code>Optional[str]</code> DEFAULT: <code>None</code> </p> RETURNS DESCRIPTION <code>Tenet</code> <p>The created Tenet</p>"},{"location":"api/tenets/#tenets.TenetManager.get_tenet","title":"get_tenet","text":"Python<pre><code>get_tenet(tenet_id: str) -&gt; Optional[Tenet]\n</code></pre> <p>Get a specific tenet by ID.</p> PARAMETER DESCRIPTION <code>tenet_id</code> <p>Tenet ID (can be partial)</p> <p> TYPE: <code>str</code> </p> RETURNS DESCRIPTION <code>Optional[Tenet]</code> <p>The Tenet or None if not found</p>"},{"location":"api/tenets/#tenets.TenetManager.list_tenets","title":"list_tenets","text":"Python<pre><code>list_tenets(pending_only: bool = False, instilled_only: bool = False, session: Optional[str] = None, category: Optional[Union[str, TenetCategory]] = None) -&gt; List[Dict[str, Any]]\n</code></pre> <p>List tenets with filtering.</p> PARAMETER DESCRIPTION <code>pending_only</code> <p>Only show pending tenets</p> <p> TYPE: <code>bool</code> DEFAULT: <code>False</code> </p> <code>instilled_only</code> <p>Only show instilled tenets</p> <p> TYPE: <code>bool</code> DEFAULT: <code>False</code> </p> <code>session</code> <p>Filter by session binding</p> <p> TYPE: <code>Optional[str]</code> DEFAULT: <code>None</code> </p> <code>category</code> <p>Filter by category</p> <p> TYPE: <code>Optional[Union[str, TenetCategory]]</code> DEFAULT: <code>None</code> </p> RETURNS DESCRIPTION <code>List[Dict[str, Any]]</code> <p>List of tenet dictionaries</p>"},{"location":"api/tenets/#tenets.TenetManager.get_pending_tenets","title":"get_pending_tenets","text":"Python<pre><code>get_pending_tenets(session: Optional[str] = None) -&gt; List[Tenet]\n</code></pre> <p>Get all pending tenets.</p> PARAMETER DESCRIPTION <code>session</code> <p>Filter by session</p> <p> TYPE: <code>Optional[str]</code> DEFAULT: <code>None</code> </p> RETURNS DESCRIPTION <code>List[Tenet]</code> <p>List of pending Tenet objects</p>"},{"location":"api/tenets/#tenets.TenetManager.remove_tenet","title":"remove_tenet","text":"Python<pre><code>remove_tenet(tenet_id: str) -&gt; bool\n</code></pre> <p>Remove a tenet.</p> PARAMETER DESCRIPTION <code>tenet_id</code> <p>Tenet ID (can be partial)</p> <p> TYPE: <code>str</code> </p> RETURNS DESCRIPTION <code>bool</code> <p>True if removed, False if not found</p>"},{"location":"api/tenets/#tenets.TenetManager.instill_tenets","title":"instill_tenets","text":"Python<pre><code>instill_tenets(session: Optional[str] = None, force: bool = False) -&gt; Dict[str, Any]\n</code></pre> <p>Instill pending tenets.</p> PARAMETER DESCRIPTION <code>session</code> <p>Target session</p> <p> TYPE: <code>Optional[str]</code> DEFAULT: <code>None</code> </p> <code>force</code> <p>Re-instill even if already instilled</p> <p> TYPE: <code>bool</code> DEFAULT: <code>False</code> </p> RETURNS DESCRIPTION <code>Dict[str, Any]</code> <p>Dictionary with results</p>"},{"location":"api/tenets/#tenets.TenetManager.get_tenets_for_injection","title":"get_tenets_for_injection","text":"Python<pre><code>get_tenets_for_injection(context_length: int, session: Optional[str] = None, max_tenets: int = 5) -&gt; List[Tenet]\n</code></pre> <p>Get tenets ready for injection into context.</p> PARAMETER DESCRIPTION <code>context_length</code> <p>Current context length in tokens</p> <p> TYPE: <code>int</code> </p> <code>session</code> <p>Current session</p> <p> TYPE: <code>Optional[str]</code> DEFAULT: <code>None</code> </p> <code>max_tenets</code> <p>Maximum number of tenets to return</p> <p> TYPE: <code>int</code> DEFAULT: <code>5</code> </p> RETURNS DESCRIPTION <code>List[Tenet]</code> <p>List of tenets to inject</p>"},{"location":"api/tenets/#tenets.TenetManager.export_tenets","title":"export_tenets","text":"Python<pre><code>export_tenets(format: str = 'yaml', session: Optional[str] = None, include_archived: bool = False) -&gt; str\n</code></pre> <p>Export tenets to YAML or JSON.</p> PARAMETER DESCRIPTION <code>format</code> <p>Export format (yaml or json)</p> <p> TYPE: <code>str</code> DEFAULT: <code>'yaml'</code> </p> <code>session</code> <p>Filter by session</p> <p> TYPE: <code>Optional[str]</code> DEFAULT: <code>None</code> </p> <code>include_archived</code> <p>Include archived tenets</p> <p> TYPE: <code>bool</code> DEFAULT: <code>False</code> </p> RETURNS DESCRIPTION <code>str</code> <p>Serialized tenets</p>"},{"location":"api/tenets/#tenets.TenetManager.import_tenets","title":"import_tenets","text":"Python<pre><code>import_tenets(file_path: Union[str, Path], session: Optional[str] = None, override_priority: Optional[Priority] = None) -&gt; int\n</code></pre> <p>Import tenets from file.</p> PARAMETER DESCRIPTION <code>file_path</code> <p>Path to import file</p> <p> TYPE: <code>Union[str, Path]</code> </p> <code>session</code> <p>Bind imported tenets to session</p> <p> TYPE: <code>Optional[str]</code> DEFAULT: <code>None</code> </p> <code>override_priority</code> <p>Override priority for all imported tenets</p> <p> TYPE: <code>Optional[Priority]</code> DEFAULT: <code>None</code> </p> RETURNS DESCRIPTION <code>int</code> <p>Number of tenets imported</p>"},{"location":"api/tenets/#tenets.TenetManager.create_collection","title":"create_collection","text":"Python<pre><code>create_collection(name: str, description: str = '', tenet_ids: Optional[List[str]] = None) -&gt; TenetCollection\n</code></pre> <p>Create a collection of related tenets.</p> PARAMETER DESCRIPTION <code>name</code> <p>Collection name</p> <p> TYPE: <code>str</code> </p> <code>description</code> <p>Collection description</p> <p> TYPE: <code>str</code> DEFAULT: <code>''</code> </p> <code>tenet_ids</code> <p>IDs of tenets to include</p> <p> TYPE: <code>Optional[List[str]]</code> DEFAULT: <code>None</code> </p> RETURNS DESCRIPTION <code>TenetCollection</code> <p>The created TenetCollection</p>"},{"location":"api/tenets/#tenets.TenetManager.analyze_tenet_effectiveness","title":"analyze_tenet_effectiveness","text":"Python<pre><code>analyze_tenet_effectiveness() -&gt; Dict[str, Any]\n</code></pre> <p>Analyze effectiveness of tenets.</p> RETURNS DESCRIPTION <code>Dict[str, Any]</code> <p>Analysis of tenet usage and effectiveness</p>"},{"location":"api/tenets/#tenets.ContextResult","title":"ContextResult  <code>dataclass</code>","text":"Python<pre><code>ContextResult(content: Optional[str] = None, context: Optional[str] = None, format: str = 'markdown', token_count: int = 0, files: list[str] = list(), files_included: list[str] = list(), files_summarized: list[str] = list(), metadata: dict[str, Any] = dict(), session_id: Optional[str] = None, timestamp: datetime = datetime.now(), statistics: dict[str, Any] = dict(), prompt_context: Optional[PromptContext] = None, cost_estimate: Optional[dict[str, float]] = None, warnings: list[str] = list(), errors: list[str] = list())\n</code></pre> <p>Result of context generation.</p> <p>Contains the generated context ready for consumption by LLMs or other tools. This is the final output of the distillation process.</p> ATTRIBUTE DESCRIPTION <code>content</code> <p>The generated context content (preferred alias)</p> <p> TYPE: <code>Optional[str]</code> </p> <code>context</code> <p>Backward-compatible alias for content</p> <p> TYPE: <code>Optional[str]</code> </p> <code>format</code> <p>Output format (markdown, xml, json)</p> <p> TYPE: <code>str</code> </p> <code>token_count</code> <p>Number of tokens in context</p> <p> TYPE: <code>int</code> </p> <code>files</code> <p>List of included file paths (preferred alias)</p> <p> TYPE: <code>list[str]</code> </p> <code>files_included</code> <p>Backward-compatible alias for files</p> <p> TYPE: <code>list[str]</code> </p> <code>files_summarized</code> <p>List of summarized file paths</p> <p> TYPE: <code>list[str]</code> </p> <code>metadata</code> <p>Additional metadata about generation, including: - timing: Dict with duration info (if timing enabled)     - duration: float seconds     - formatted_duration: Human-readable string (e.g. \"2.34s\")     - start_datetime: ISO format start time     - end_datetime: ISO format end time</p> <p> TYPE: <code>dict[str, Any]</code> </p> <code>session_id</code> <p>Session this belongs to</p> <p> TYPE: <code>Optional[str]</code> </p> <code>timestamp</code> <p>When context was generated</p> <p> TYPE: <code>datetime</code> </p> <code>statistics</code> <p>Generation statistics</p> <p> TYPE: <code>dict[str, Any]</code> </p> <code>prompt_context</code> <p>Original prompt context</p> <p> TYPE: <code>Optional[PromptContext]</code> </p> <code>cost_estimate</code> <p>Estimated cost for LLM usage</p> <p> TYPE: <code>Optional[dict[str, float]]</code> </p> <code>warnings</code> <p>Any warnings during generation</p> <p> TYPE: <code>list[str]</code> </p> <code>errors</code> <p>Any errors during generation</p> <p> TYPE: <code>list[str]</code> </p>"},{"location":"api/tenets/#tenets.ContextResult-functions","title":"Functions","text":""},{"location":"api/tenets/#tenets.ContextResult.add_warning","title":"add_warning","text":"Python<pre><code>add_warning(warning: str) -&gt; None\n</code></pre> <p>Add a warning message.</p>"},{"location":"api/tenets/#tenets.ContextResult.add_error","title":"add_error","text":"Python<pre><code>add_error(error: str) -&gt; None\n</code></pre> <p>Add an error message.</p>"},{"location":"api/tenets/#tenets.ContextResult.update_statistics","title":"update_statistics","text":"Python<pre><code>update_statistics(key: str, value: Any) -&gt; None\n</code></pre> <p>Update a statistic value.</p>"},{"location":"api/tenets/#tenets.ContextResult.to_dict","title":"to_dict","text":"Python<pre><code>to_dict() -&gt; dict[str, Any]\n</code></pre> <p>Convert to dictionary representation.</p>"},{"location":"api/tenets/#tenets.ContextResult.from_dict","title":"from_dict  <code>classmethod</code>","text":"Python<pre><code>from_dict(data: dict[str, Any]) -&gt; ContextResult\n</code></pre> <p>Create from dictionary.</p>"},{"location":"api/tenets/#tenets.ContextResult.save_to_file","title":"save_to_file","text":"Python<pre><code>save_to_file(path: Union[str, Path]) -&gt; None\n</code></pre> <p>Save context result to file.</p>"},{"location":"api/tenets/#tenets.ContextResult.get_summary","title":"get_summary","text":"Python<pre><code>get_summary() -&gt; str\n</code></pre> <p>Get a summary of the context result.</p>"},{"location":"api/tenets/#tenets.Priority","title":"Priority","text":"<p>               Bases: <code>Enum</code></p> <p>Tenet priority levels.</p>"},{"location":"api/tenets/#tenets.Priority-attributes","title":"Attributes","text":""},{"location":"api/tenets/#tenets.Priority.weight","title":"weight  <code>property</code>","text":"Python<pre><code>weight: float\n</code></pre> <p>Get numerical weight for priority.</p>"},{"location":"api/tenets/#tenets.Tenet","title":"Tenet  <code>dataclass</code>","text":"Python<pre><code>Tenet(id: str = (lambda: str(uuid.uuid4()))(), content: str = '', priority: Priority = Priority.MEDIUM, category: Optional[TenetCategory] = None, status: TenetStatus = TenetStatus.PENDING, created_at: datetime = datetime.now(), instilled_at: Optional[datetime] = None, updated_at: datetime = datetime.now(), session_bindings: list[str] = list(), author: Optional[str] = None, metrics: TenetMetrics = TenetMetrics(), injection_strategy: InjectionStrategy = InjectionStrategy(), metadata: dict[str, Any] = dict())\n</code></pre> <p>A guiding principle for code development.</p> <p>Tenets are persistent instructions that guide AI interactions to maintain consistency across multiple prompts and sessions.</p> ATTRIBUTE DESCRIPTION <code>id</code> <p>Unique identifier</p> <p> TYPE: <code>str</code> </p> <code>content</code> <p>The principle text</p> <p> TYPE: <code>str</code> </p> <code>priority</code> <p>Importance level</p> <p> TYPE: <code>Priority</code> </p> <code>category</code> <p>Classification category</p> <p> TYPE: <code>Optional[TenetCategory]</code> </p> <code>status</code> <p>Current status (pending, instilled, archived)</p> <p> TYPE: <code>TenetStatus</code> </p> <code>created_at</code> <p>When the tenet was created</p> <p> TYPE: <code>datetime</code> </p> <code>instilled_at</code> <p>When first instilled into context</p> <p> TYPE: <code>Optional[datetime]</code> </p> <code>updated_at</code> <p>Last modification time</p> <p> TYPE: <code>datetime</code> </p> <code>session_bindings</code> <p>Sessions this tenet applies to</p> <p> TYPE: <code>list[str]</code> </p> <code>author</code> <p>Who created the tenet</p> <p> TYPE: <code>Optional[str]</code> </p> <code>metrics</code> <p>Usage and effectiveness metrics</p> <p> TYPE: <code>TenetMetrics</code> </p> <code>injection_strategy</code> <p>How this tenet should be injected</p> <p> TYPE: <code>InjectionStrategy</code> </p> <code>metadata</code> <p>Additional custom data</p> <p> TYPE: <code>dict[str, Any]</code> </p> Example <p>tenet = Tenet( ...     content=\"Always use type hints in Python code\", ...     priority=Priority.HIGH, ...     category=TenetCategory.STYLE ... )</p>"},{"location":"api/tenets/#tenets.Tenet-functions","title":"Functions","text":""},{"location":"api/tenets/#tenets.Tenet.instill","title":"instill","text":"Python<pre><code>instill() -&gt; None\n</code></pre> <p>Mark tenet as instilled.</p>"},{"location":"api/tenets/#tenets.Tenet.archive","title":"archive","text":"Python<pre><code>archive() -&gt; None\n</code></pre> <p>Archive this tenet.</p>"},{"location":"api/tenets/#tenets.Tenet.bind_to_session","title":"bind_to_session","text":"Python<pre><code>bind_to_session(session_id: str) -&gt; None\n</code></pre> <p>Bind tenet to a specific session.</p>"},{"location":"api/tenets/#tenets.Tenet.unbind_from_session","title":"unbind_from_session","text":"Python<pre><code>unbind_from_session(session_id: str) -&gt; None\n</code></pre> <p>Remove session binding.</p>"},{"location":"api/tenets/#tenets.Tenet.applies_to_session","title":"applies_to_session","text":"Python<pre><code>applies_to_session(session_id: Optional[str]) -&gt; bool\n</code></pre> <p>Check if tenet applies to a session.</p>"},{"location":"api/tenets/#tenets.Tenet.should_inject","title":"should_inject","text":"Python<pre><code>should_inject(context_length: int, already_injected: int) -&gt; bool\n</code></pre> <p>Determine if this tenet should be injected.</p>"},{"location":"api/tenets/#tenets.Tenet.format_for_injection","title":"format_for_injection","text":"Python<pre><code>format_for_injection() -&gt; str\n</code></pre> <p>Format tenet content for injection into context.</p>"},{"location":"api/tenets/#tenets.Tenet.to_dict","title":"to_dict","text":"Python<pre><code>to_dict() -&gt; dict[str, Any]\n</code></pre> <p>Convert to dictionary representation.</p>"},{"location":"api/tenets/#tenets.Tenet.from_dict","title":"from_dict  <code>classmethod</code>","text":"Python<pre><code>from_dict(data: dict[str, Any]) -&gt; Tenet\n</code></pre> <p>Create Tenet from dictionary.</p>"},{"location":"api/tenets/#tenets.TenetCategory","title":"TenetCategory","text":"<p>               Bases: <code>Enum</code></p> <p>Common tenet categories.</p>"},{"location":"api/tenets/#tenets.Tenets","title":"Tenets","text":"Python<pre><code>Tenets(config: Optional[Union[TenetsConfig, dict[str, Any], Path]] = None)\n</code></pre> <p>Main API interface for the Tenets system.</p> <p>This is the primary class that users interact with to access all Tenets functionality. It coordinates between the various subsystems (distiller, instiller, analyzer, etc.) to provide a unified interface.</p> <p>The Tenets class can be used both programmatically through Python and via the CLI. It maintains configuration, manages sessions, and orchestrates the various analysis and context generation operations.</p> ATTRIBUTE DESCRIPTION <code>config</code> <p>TenetsConfig instance containing all configuration</p> <p> </p> <code>distiller</code> <p>Distiller instance for context extraction</p> <p> </p> <code>instiller</code> <p>Instiller instance for tenet management</p> <p> </p> <code>tenet_manager</code> <p>Direct access to TenetManager for advanced operations</p> <p> </p> <code>logger</code> <p>Logger instance for this class</p> <p> </p> <code>_session</code> <p>Current session name if any</p> <p> </p> <code>_cache</code> <p>Internal cache for results</p> <p> </p> Example <p>from tenets import Tenets from pathlib import Path</p> <p>Initialize Tenets with configuration.</p> PARAMETER DESCRIPTION <code>config</code> <p>Can be: - TenetsConfig instance - Dictionary of configuration values - Path to configuration file - None (uses default configuration)</p> <p> TYPE: <code>Optional[Union[TenetsConfig, dict[str, Any], Path]]</code> DEFAULT: <code>None</code> </p> RAISES DESCRIPTION <code>ValueError</code> <p>If config format is invalid</p> <code>FileNotFoundError</code> <p>If config file path doesn't exist</p>"},{"location":"api/tenets/#tenets.Tenets--initialize-with-default-config","title":"Initialize with default config","text":"<p>ten = Tenets()</p>"},{"location":"api/tenets/#tenets.Tenets--or-with-custom-config","title":"Or with custom config","text":"<p>from tenets.config import TenetsConfig config = TenetsConfig(max_tokens=150000, ranking_algorithm=\"thorough\") ten = Tenets(config=config)</p>"},{"location":"api/tenets/#tenets.Tenets--extract-context-uses-default-session-automatically","title":"Extract context (uses default session automatically)","text":"<p>result = ten.distill(\"implement user authentication\") print(f\"Generated {result.token_count} tokens of context\")</p>"},{"location":"api/tenets/#tenets.Tenets--generate-html-report","title":"Generate HTML report","text":"<p>result = ten.distill(\"review API endpoints\", format=\"html\") Path(\"api-review.html\").write_text(result.context)</p>"},{"location":"api/tenets/#tenets.Tenets--add-and-apply-tenets","title":"Add and apply tenets","text":"<p>ten.add_tenet(\"Use dependency injection\", priority=\"high\") ten.add_tenet(\"Follow RESTful conventions\", category=\"architecture\") ten.instill_tenets()</p>"},{"location":"api/tenets/#tenets.Tenets--pin-critical-files-for-priority-inclusion","title":"Pin critical files for priority inclusion","text":"<p>ten.pin_file(\"src/core/auth.py\") ten.pin_folder(\"src/api/endpoints\")</p>"},{"location":"api/tenets/#tenets.Tenets--work-with-named-sessions","title":"Work with named sessions","text":"<p>result = ten.distill( ...     \"implement OAuth2\", ...     session_name=\"oauth-feature\", ...     mode=\"thorough\" ... )</p>"},{"location":"api/tenets/#tenets.Tenets-attributes","title":"Attributes","text":""},{"location":"api/tenets/#tenets.Tenets.distiller","title":"distiller  <code>property</code>","text":"Python<pre><code>distiller\n</code></pre> <p>Lazy load distiller when needed.</p>"},{"location":"api/tenets/#tenets.Tenets.instiller","title":"instiller  <code>property</code>","text":"Python<pre><code>instiller\n</code></pre> <p>Lazy load instiller when needed.</p>"},{"location":"api/tenets/#tenets.Tenets.tenet_manager","title":"tenet_manager  <code>property</code>","text":"Python<pre><code>tenet_manager\n</code></pre> <p>Lazy load tenet manager when needed.</p>"},{"location":"api/tenets/#tenets.Tenets-functions","title":"Functions","text":""},{"location":"api/tenets/#tenets.Tenets.distill","title":"distill","text":"Python<pre><code>distill(prompt: str, files: Optional[Union[str, Path, list[Path]]] = None, *, format: str = 'markdown', model: Optional[str] = None, max_tokens: Optional[int] = None, mode: str = 'balanced', include_git: bool = True, session_name: Optional[str] = None, include_patterns: Optional[list[str]] = None, exclude_patterns: Optional[list[str]] = None, apply_tenets: Optional[bool] = None, full: bool = False, condense: bool = False, remove_comments: bool = False, include_tests: Optional[bool] = None, docstring_weight: Optional[float] = None, summarize_imports: bool = True) -&gt; ContextResult\n</code></pre> <p>Distill relevant context from codebase based on prompt.</p> <p>This is the main method for extracting context. It analyzes your codebase, finds relevant files, ranks them by importance, and aggregates them into an optimized context that fits within token limits.</p> PARAMETER DESCRIPTION <code>prompt</code> <p>Your query or task description. Can be plain text or a URL    to a GitHub issue, JIRA ticket, etc.</p> <p> TYPE: <code>str</code> </p> <code>files</code> <p>Paths to analyze. Can be a single path, list of paths, or None   to use current directory</p> <p> TYPE: <code>Optional[Union[str, Path, list[Path]]]</code> DEFAULT: <code>None</code> </p> <code>format</code> <p>Output format - 'markdown', 'xml' (Claude), 'json', or 'html' (interactive report)</p> <p> TYPE: <code>str</code> DEFAULT: <code>'markdown'</code> </p> <code>model</code> <p>Target LLM model for token counting (e.g., 'gpt-4o', 'claude-3-opus')</p> <p> TYPE: <code>Optional[str]</code> DEFAULT: <code>None</code> </p> <code>max_tokens</code> <p>Maximum tokens for context (overrides model default)</p> <p> TYPE: <code>Optional[int]</code> DEFAULT: <code>None</code> </p> <code>mode</code> <p>Analysis mode - 'fast', 'balanced', or 'thorough'</p> <p> TYPE: <code>str</code> DEFAULT: <code>'balanced'</code> </p> <code>include_git</code> <p>Whether to include git context (commits, contributors, etc.)</p> <p> TYPE: <code>bool</code> DEFAULT: <code>True</code> </p> <code>session_name</code> <p>Session name for stateful context building</p> <p> TYPE: <code>Optional[str]</code> DEFAULT: <code>None</code> </p> <code>include_patterns</code> <p>File patterns to include (e.g., ['.py', '.js'])</p> <p> TYPE: <code>Optional[list[str]]</code> DEFAULT: <code>None</code> </p> <code>exclude_patterns</code> <p>File patterns to exclude (e.g., ['test_', '.backup'])</p> <p> TYPE: <code>Optional[list[str]]</code> DEFAULT: <code>None</code> </p> <code>apply_tenets</code> <p>Whether to apply tenets (None = use config default)</p> <p> TYPE: <code>Optional[bool]</code> DEFAULT: <code>None</code> </p> RETURNS DESCRIPTION <code>ContextResult</code> <p>ContextResult containing the generated context, metadata, and statistics.</p> <code>ContextResult</code> <p>The metadata field includes timing information when available: metadata['timing'] = {     'duration': 2.34,  # seconds     'formatted_duration': '2.34s',  # Human-readable duration string     'start_datetime': '2024-01-15T10:30:45',     'end_datetime': '2024-01-15T10:30:47' }</p> RAISES DESCRIPTION <code>ValueError</code> <p>If prompt is empty or invalid</p> <code>FileNotFoundError</code> <p>If specified files don't exist</p> Example"},{"location":"api/tenets/#tenets.Tenets.distill--basic-usage-uses-default-session-automatically","title":"Basic usage (uses default session automatically)","text":"<p>result = tenets.distill(\"implement OAuth2 authentication\") print(result.context[:100])  # First 100 chars of context</p>"},{"location":"api/tenets/#tenets.Tenets.distill--with-specific-files-and-options","title":"With specific files and options","text":"<p>result = tenets.distill( ...     \"add caching layer\", ...     files=\"./src\", ...     mode=\"thorough\", ...     max_tokens=50000, ...     include_patterns=[\".py\"], ...     exclude_patterns=[\"test_.py\"] ... )</p>"},{"location":"api/tenets/#tenets.Tenets.distill--generate-html-report","title":"Generate HTML report","text":"<p>result = tenets.distill( ...     \"analyze authentication flow\", ...     format=\"html\" ... ) Path(\"report.html\").write_text(result.context)</p>"},{"location":"api/tenets/#tenets.Tenets.distill--with-session-management","title":"With session management","text":"<p>result = tenets.distill( ...     \"implement validation\", ...     session_name=\"validation-feature\" ... )</p>"},{"location":"api/tenets/#tenets.Tenets.distill--from-github-issue","title":"From GitHub issue","text":"<p>result = tenets.distill(\"https://github.com/org/repo/issues/123\")</p>"},{"location":"api/tenets/#tenets.Tenets.distill--access-timing-information","title":"Access timing information","text":"<p>result = tenets.distill(\"analyze performance\") if 'timing' in result.metadata: ...     print(f\"Analysis took {result.metadata['timing']['formatted_duration']}\") ...     # Output: \"Analysis took 2.34s\"</p>"},{"location":"api/tenets/#tenets.Tenets.rank_files","title":"rank_files","text":"Python<pre><code>rank_files(prompt: str, paths: Optional[Union[str, Path, List[Path]]] = None, *, mode: str = 'balanced', include_patterns: Optional[List[str]] = None, exclude_patterns: Optional[List[str]] = None, include_tests: Optional[bool] = None, exclude_tests: bool = False, explain: bool = False) -&gt; RankResult\n</code></pre> <p>Rank files by relevance without generating full context.</p> <p>This method uses the same sophisticated ranking pipeline as distill() but returns only the ranked files without aggregating content. Perfect for understanding which files are relevant or for automation.</p> PARAMETER DESCRIPTION <code>prompt</code> <p>Your query or task description</p> <p> TYPE: <code>str</code> </p> <code>paths</code> <p>Paths to analyze (default: current directory)</p> <p> TYPE: <code>Optional[Union[str, Path, List[Path]]]</code> DEFAULT: <code>None</code> </p> <code>mode</code> <p>Analysis mode - 'fast', 'balanced', or 'thorough'</p> <p> TYPE: <code>str</code> DEFAULT: <code>'balanced'</code> </p> <code>include_patterns</code> <p>File patterns to include</p> <p> TYPE: <code>Optional[List[str]]</code> DEFAULT: <code>None</code> </p> <code>exclude_patterns</code> <p>File patterns to exclude</p> <p> TYPE: <code>Optional[List[str]]</code> DEFAULT: <code>None</code> </p> <code>include_tests</code> <p>Whether to include test files</p> <p> TYPE: <code>Optional[bool]</code> DEFAULT: <code>None</code> </p> <code>exclude_tests</code> <p>Whether to exclude test files</p> <p> TYPE: <code>bool</code> DEFAULT: <code>False</code> </p> <code>explain</code> <p>Whether to include ranking factor explanations</p> <p> TYPE: <code>bool</code> DEFAULT: <code>False</code> </p> RETURNS DESCRIPTION <code>RankResult</code> <p>RankResult containing the ranked files and metadata</p> Example <p>result = ten.rank_files(\"fix summarizing truncation bug\") for file in result.files: ...     print(f\"{file.path}: {file.relevance_score:.3f}\")</p>"},{"location":"api/tenets/#tenets.Tenets.add_tenet","title":"add_tenet","text":"Python<pre><code>add_tenet(content: str, priority: Union[str, Priority] = 'medium', category: Optional[Union[str, TenetCategory]] = None, session: Optional[str] = None, author: Optional[str] = None) -&gt; Tenet\n</code></pre> <p>Add a new guiding principle (tenet).</p> <p>Tenets are persistent instructions that get strategically injected into generated context to maintain consistency across AI interactions. They help combat context drift and ensure important principles are followed.</p> PARAMETER DESCRIPTION <code>content</code> <p>The guiding principle text</p> <p> TYPE: <code>str</code> </p> <code>priority</code> <p>Priority level - 'low', 'medium', 'high', or 'critical'</p> <p> TYPE: <code>Union[str, Priority]</code> DEFAULT: <code>'medium'</code> </p> <code>category</code> <p>Optional category - 'architecture', 'security', 'style',      'performance', 'testing', 'documentation', etc.</p> <p> TYPE: <code>Optional[Union[str, TenetCategory]]</code> DEFAULT: <code>None</code> </p> <code>session</code> <p>Optional session to bind this tenet to</p> <p> TYPE: <code>Optional[str]</code> DEFAULT: <code>None</code> </p> <code>author</code> <p>Optional author identifier</p> <p> TYPE: <code>Optional[str]</code> DEFAULT: <code>None</code> </p> RETURNS DESCRIPTION <code>Tenet</code> <p>The created Tenet object</p> Example"},{"location":"api/tenets/#tenets.Tenets.add_tenet--add-a-high-priority-security-tenet","title":"Add a high-priority security tenet","text":"<p>tenet = ten.add_tenet( ...     \"Always validate and sanitize user input\", ...     priority=\"high\", ...     category=\"security\" ... )</p>"},{"location":"api/tenets/#tenets.Tenets.add_tenet--add-a-session-specific-tenet","title":"Add a session-specific tenet","text":"<p>ten.add_tenet( ...     \"Use async/await for all I/O operations\", ...     session=\"async-refactor\" ... )</p>"},{"location":"api/tenets/#tenets.Tenets.instill_tenets","title":"instill_tenets","text":"Python<pre><code>instill_tenets(session: Optional[str] = None, force: bool = False) -&gt; Dict[str, Any]\n</code></pre> <p>Instill pending tenets.</p> <p>This marks tenets as active and ready to be injected into future contexts. By default, only pending tenets are instilled, but you can force re-instillation of all tenets.</p> PARAMETER DESCRIPTION <code>session</code> <p>Optional session to instill tenets for</p> <p> TYPE: <code>Optional[str]</code> DEFAULT: <code>None</code> </p> <code>force</code> <p>If True, re-instill even already instilled tenets</p> <p> TYPE: <code>bool</code> DEFAULT: <code>False</code> </p> RETURNS DESCRIPTION <code>Dict[str, Any]</code> <p>Dictionary with instillation results including count and tenets</p> Example"},{"location":"api/tenets/#tenets.Tenets.instill_tenets--instill-all-pending-tenets","title":"Instill all pending tenets","text":"<p>result = ten.instill_tenets() print(f\"Instilled {result['count']} tenets\")</p>"},{"location":"api/tenets/#tenets.Tenets.instill_tenets--force-re-instillation","title":"Force re-instillation","text":"<p>ten.instill_tenets(force=True)</p>"},{"location":"api/tenets/#tenets.Tenets.add_file_to_session","title":"add_file_to_session","text":"Python<pre><code>add_file_to_session(file_path: Union[str, Path], session: Optional[str] = None) -&gt; bool\n</code></pre> <p>Pin a single file into a session so it is prioritized in future distill calls.</p> PARAMETER DESCRIPTION <code>file_path</code> <p>Path to file</p> <p> TYPE: <code>Union[str, Path]</code> </p> <code>session</code> <p>Optional session name</p> <p> TYPE: <code>Optional[str]</code> DEFAULT: <code>None</code> </p>"},{"location":"api/tenets/#tenets.Tenets.add_folder_to_session","title":"add_folder_to_session","text":"Python<pre><code>add_folder_to_session(folder_path: Union[str, Path], session: Optional[str] = None, include_patterns: Optional[list[str]] = None, exclude_patterns: Optional[list[str]] = None, respect_gitignore: bool = True, recursive: bool = True) -&gt; int\n</code></pre> <p>Pin all files in a folder (optionally filtered) into a session.</p> PARAMETER DESCRIPTION <code>folder_path</code> <p>Directory to scan</p> <p> TYPE: <code>Union[str, Path]</code> </p> <code>session</code> <p>Session name</p> <p> TYPE: <code>Optional[str]</code> DEFAULT: <code>None</code> </p> <code>include_patterns</code> <p>Include filter</p> <p> TYPE: <code>Optional[list[str]]</code> DEFAULT: <code>None</code> </p> <code>exclude_patterns</code> <p>Exclude filter</p> <p> TYPE: <code>Optional[list[str]]</code> DEFAULT: <code>None</code> </p> <code>respect_gitignore</code> <p>Respect .gitignore</p> <p> TYPE: <code>bool</code> DEFAULT: <code>True</code> </p> <code>recursive</code> <p>Recurse into subdirectories</p> <p> TYPE: <code>bool</code> DEFAULT: <code>True</code> </p>"},{"location":"api/tenets/#tenets.Tenets.list_tenets","title":"list_tenets","text":"Python<pre><code>list_tenets(pending_only: bool = False, instilled_only: bool = False, session: Optional[str] = None, category: Optional[Union[str, TenetCategory]] = None) -&gt; list[dict[str, Any]]\n</code></pre> <p>List tenets with optional filtering.</p> PARAMETER DESCRIPTION <code>pending_only</code> <p>Only show pending (not yet instilled) tenets</p> <p> TYPE: <code>bool</code> DEFAULT: <code>False</code> </p> <code>instilled_only</code> <p>Only show instilled tenets</p> <p> TYPE: <code>bool</code> DEFAULT: <code>False</code> </p> <code>session</code> <p>Filter by session binding</p> <p> TYPE: <code>Optional[str]</code> DEFAULT: <code>None</code> </p> <code>category</code> <p>Filter by category</p> <p> TYPE: <code>Optional[Union[str, TenetCategory]]</code> DEFAULT: <code>None</code> </p> RETURNS DESCRIPTION <code>list[dict[str, Any]]</code> <p>List of tenet dictionaries</p> Example"},{"location":"api/tenets/#tenets.Tenets.list_tenets--list-all-tenets","title":"List all tenets","text":"<p>all_tenets = ten.list_tenets()</p>"},{"location":"api/tenets/#tenets.Tenets.list_tenets--list-only-pending-security-tenets","title":"List only pending security tenets","text":"<p>pending_security = ten.list_tenets( ...     pending_only=True, ...     category=\"security\" ... )</p>"},{"location":"api/tenets/#tenets.Tenets.get_tenet","title":"get_tenet","text":"Python<pre><code>get_tenet(tenet_id: str) -&gt; Optional[Tenet]\n</code></pre> <p>Get a specific tenet by ID.</p> PARAMETER DESCRIPTION <code>tenet_id</code> <p>Tenet ID (can be partial)</p> <p> TYPE: <code>str</code> </p> RETURNS DESCRIPTION <code>Optional[Tenet]</code> <p>The Tenet object or None if not found</p>"},{"location":"api/tenets/#tenets.Tenets.remove_tenet","title":"remove_tenet","text":"Python<pre><code>remove_tenet(tenet_id: str) -&gt; bool\n</code></pre> <p>Remove (archive) a tenet.</p> PARAMETER DESCRIPTION <code>tenet_id</code> <p>Tenet ID (can be partial)</p> <p> TYPE: <code>str</code> </p> RETURNS DESCRIPTION <code>bool</code> <p>True if removed, False if not found</p>"},{"location":"api/tenets/#tenets.Tenets.get_pending_tenets","title":"get_pending_tenets","text":"Python<pre><code>get_pending_tenets(session: Optional[str] = None) -&gt; List[Tenet]\n</code></pre> <p>Get all pending tenets.</p> PARAMETER DESCRIPTION <code>session</code> <p>Optional session filter</p> <p> TYPE: <code>Optional[str]</code> DEFAULT: <code>None</code> </p> RETURNS DESCRIPTION <code>List[Tenet]</code> <p>List of pending Tenet objects</p>"},{"location":"api/tenets/#tenets.Tenets.export_tenets","title":"export_tenets","text":"Python<pre><code>export_tenets(format: str = 'yaml', session: Optional[str] = None) -&gt; str\n</code></pre> <p>Export tenets to YAML or JSON.</p> PARAMETER DESCRIPTION <code>format</code> <p>Export format - 'yaml' or 'json'</p> <p> TYPE: <code>str</code> DEFAULT: <code>'yaml'</code> </p> <code>session</code> <p>Optional session filter</p> <p> TYPE: <code>Optional[str]</code> DEFAULT: <code>None</code> </p> RETURNS DESCRIPTION <code>str</code> <p>Serialized tenets string</p>"},{"location":"api/tenets/#tenets.Tenets.import_tenets","title":"import_tenets","text":"Python<pre><code>import_tenets(file_path: Union[str, Path], session: Optional[str] = None) -&gt; int\n</code></pre> <p>Import tenets from file.</p> PARAMETER DESCRIPTION <code>file_path</code> <p>Path to import file (YAML or JSON)</p> <p> TYPE: <code>Union[str, Path]</code> </p> <code>session</code> <p>Optional session to bind imported tenets to</p> <p> TYPE: <code>Optional[str]</code> DEFAULT: <code>None</code> </p> RETURNS DESCRIPTION <code>int</code> <p>Number of tenets imported</p>"},{"location":"api/tenets/#tenets.Tenets.examine","title":"examine","text":"Python<pre><code>examine(path: Optional[Union[str, Path]] = None, deep: bool = False, include_git: bool = True, output_metadata: bool = False) -&gt; Any\n</code></pre> <p>Examine codebase structure and metrics.</p> <p>Provides detailed analysis of your code including file counts, language distribution, complexity metrics, and potential issues.</p> PARAMETER DESCRIPTION <code>path</code> <p>Path to examine (default: current directory)</p> <p> TYPE: <code>Optional[Union[str, Path]]</code> DEFAULT: <code>None</code> </p> <code>deep</code> <p>Perform deep analysis with AST parsing</p> <p> TYPE: <code>bool</code> DEFAULT: <code>False</code> </p> <code>include_git</code> <p>Include git statistics</p> <p> TYPE: <code>bool</code> DEFAULT: <code>True</code> </p> <code>output_metadata</code> <p>Include detailed metadata in result</p> <p> TYPE: <code>bool</code> DEFAULT: <code>False</code> </p> RETURNS DESCRIPTION <code>Any</code> <p>AnalysisResult object with comprehensive codebase analysis</p> Example"},{"location":"api/tenets/#tenets.Tenets.examine--basic-examination","title":"Basic examination","text":"<p>analysis = ten.examine() print(f\"Found {analysis.total_files} files\") print(f\"Languages: {', '.join(analysis.languages)}\")</p>"},{"location":"api/tenets/#tenets.Tenets.examine--deep-analysis-with-git","title":"Deep analysis with git","text":"<p>analysis = ten.examine(deep=True, include_git=True)</p>"},{"location":"api/tenets/#tenets.Tenets.track_changes","title":"track_changes","text":"Python<pre><code>track_changes(path: Optional[Union[str, Path]] = None, since: str = '1 week', author: Optional[str] = None, file_pattern: Optional[str] = None) -&gt; Dict[str, Any]\n</code></pre> <p>Track code changes over time.</p> PARAMETER DESCRIPTION <code>path</code> <p>Repository path (default: current directory)</p> <p> TYPE: <code>Optional[Union[str, Path]]</code> DEFAULT: <code>None</code> </p> <code>since</code> <p>Time period (e.g., '1 week', '3 days', 'yesterday')</p> <p> TYPE: <code>str</code> DEFAULT: <code>'1 week'</code> </p> <code>author</code> <p>Filter by author</p> <p> TYPE: <code>Optional[str]</code> DEFAULT: <code>None</code> </p> <code>file_pattern</code> <p>Filter by file pattern</p> <p> TYPE: <code>Optional[str]</code> DEFAULT: <code>None</code> </p> RETURNS DESCRIPTION <code>Dict[str, Any]</code> <p>Dictionary with change information</p>"},{"location":"api/tenets/#tenets.Tenets.momentum","title":"momentum","text":"Python<pre><code>momentum(path: Optional[Union[str, Path]] = None, since: str = 'last-month', team: bool = False, author: Optional[str] = None) -&gt; Dict[str, Any]\n</code></pre> <p>Track development momentum and velocity.</p> PARAMETER DESCRIPTION <code>path</code> <p>Repository path</p> <p> TYPE: <code>Optional[Union[str, Path]]</code> DEFAULT: <code>None</code> </p> <code>since</code> <p>Time period to analyze</p> <p> TYPE: <code>str</code> DEFAULT: <code>'last-month'</code> </p> <code>team</code> <p>Show team-wide statistics</p> <p> TYPE: <code>bool</code> DEFAULT: <code>False</code> </p> <code>author</code> <p>Show stats for specific author</p> <p> TYPE: <code>Optional[str]</code> DEFAULT: <code>None</code> </p> RETURNS DESCRIPTION <code>Dict[str, Any]</code> <p>Dictionary with momentum metrics</p>"},{"location":"api/tenets/#tenets.Tenets.estimate_cost","title":"estimate_cost","text":"Python<pre><code>estimate_cost(result: ContextResult, model: str) -&gt; Dict[str, Any]\n</code></pre> <p>Estimate the cost of using generated context with an LLM.</p> PARAMETER DESCRIPTION <code>result</code> <p>ContextResult from distill()</p> <p> TYPE: <code>ContextResult</code> </p> <code>model</code> <p>Target model name</p> <p> TYPE: <code>str</code> </p> RETURNS DESCRIPTION <code>Dict[str, Any]</code> <p>Dictionary with token counts and cost estimates</p>"},{"location":"api/tenets/#tenets.Tenets.set_system_instruction","title":"set_system_instruction","text":"Python<pre><code>set_system_instruction(instruction: str, enable: bool = True, position: str = 'top', format: str = 'markdown', save: bool = False) -&gt; None\n</code></pre> <p>Set the system instruction for AI interactions.</p> PARAMETER DESCRIPTION <code>instruction</code> <p>The system instruction text</p> <p> TYPE: <code>str</code> </p> <code>enable</code> <p>Whether to auto-inject</p> <p> TYPE: <code>bool</code> DEFAULT: <code>True</code> </p> <code>position</code> <p>Where to inject ('top', 'after_header', 'before_content')</p> <p> TYPE: <code>str</code> DEFAULT: <code>'top'</code> </p> <code>format</code> <p>Format type ('markdown', 'xml', 'comment', 'plain')</p> <p> TYPE: <code>str</code> DEFAULT: <code>'markdown'</code> </p> <code>save</code> <p>Whether to save to config file</p> <p> TYPE: <code>bool</code> DEFAULT: <code>False</code> </p>"},{"location":"api/tenets/#tenets.Tenets.get_system_instruction","title":"get_system_instruction","text":"Python<pre><code>get_system_instruction() -&gt; Optional[str]\n</code></pre> <p>Get the current system instruction.</p> RETURNS DESCRIPTION <code>Optional[str]</code> <p>The system instruction text or None</p>"},{"location":"api/tenets/#tenets.Tenets.clear_system_instruction","title":"clear_system_instruction","text":"Python<pre><code>clear_system_instruction(save: bool = False) -&gt; None\n</code></pre> <p>Clear the system instruction.</p> PARAMETER DESCRIPTION <code>save</code> <p>Whether to save to config file</p> <p> TYPE: <code>bool</code> DEFAULT: <code>False</code> </p>"},{"location":"api/tenets/#tenets-functions","title":"Functions","text":""},{"location":"api/tenets/#tenets.get_logger","title":"get_logger","text":"Python<pre><code>get_logger(name: Optional[str] = None, level: Optional[int] = None) -&gt; logging.Logger\n</code></pre> <p>Return a configured logger.</p> Environment variables <ul> <li>TENETS_LOG_LEVEL: DEBUG|INFO|WARNING|ERROR|CRITICAL</li> </ul>"},{"location":"api/tenets/config/","title":"Config","text":""},{"location":"api/tenets/config/#tenets.config","title":"tenets.config","text":"<p>Configuration management for Tenets with enhanced LLM and NLP support.</p> <p>This module handles all configuration for the Tenets system, including loading from files, environment variables, and providing defaults. Configuration can be specified at multiple levels with proper precedence.</p> <p>Configuration precedence (highest to lowest): 1. Runtime parameters (passed to methods) 2. Environment variables (TENETS_*) 3. Project config file (.tenets.yml in project) 4. User config file (~/.config/tenets/config.yml) 5. Default values</p> <p>The configuration system is designed to work with zero configuration (sensible defaults) while allowing full customization when needed.</p> <p>Enhanced with comprehensive LLM provider support for optional AI-powered features and centralized NLP configuration for all text processing operations.</p>"},{"location":"api/tenets/config/#tenets.config-classes","title":"Classes","text":""},{"location":"api/tenets/config/#tenets.config.NLPConfig","title":"NLPConfig  <code>dataclass</code>","text":"Python<pre><code>NLPConfig(enabled: bool = True, stopwords_enabled: bool = True, code_stopword_set: str = 'minimal', prompt_stopword_set: str = 'aggressive', custom_stopword_files: List[str] = list(), tokenization_mode: str = 'auto', preserve_original_tokens: bool = True, split_camelcase: bool = True, split_snakecase: bool = True, min_token_length: int = 2, keyword_extraction_method: str = 'auto', max_keywords: int = 30, ngram_size: int = 3, yake_dedup_threshold: float = 0.7, tfidf_use_sublinear: bool = True, tfidf_use_idf: bool = True, tfidf_norm: str = 'l2', bm25_k1: float = 1.2, bm25_b: float = 0.75, embeddings_enabled: bool = False, embeddings_model: str = 'all-MiniLM-L6-v2', embeddings_device: str = 'auto', embeddings_cache: bool = True, embeddings_batch_size: int = 32, similarity_metric: str = 'cosine', similarity_threshold: float = 0.7, cache_embeddings_ttl_days: int = 30, cache_tfidf_ttl_days: int = 7, cache_keywords_ttl_days: int = 7, multiprocessing_enabled: bool = True, multiprocessing_workers: Optional[int] = None, multiprocessing_chunk_size: int = 100)\n</code></pre> <p>Configuration for centralized NLP (Natural Language Processing) system.</p> <p>Controls all text processing operations including tokenization, keyword extraction, stopword filtering, embeddings, and similarity computation. All NLP operations are centralized in the tenets.core.nlp package.</p> ATTRIBUTE DESCRIPTION <code>enabled</code> <p>Whether NLP features are enabled globally</p> <p> TYPE: <code>bool</code> </p> <code>stopwords_enabled</code> <p>Whether to use stopword filtering</p> <p> TYPE: <code>bool</code> </p> <code>code_stopword_set</code> <p>Stopword set for code search (minimal)</p> <p> TYPE: <code>str</code> </p> <code>prompt_stopword_set</code> <p>Stopword set for prompt parsing (aggressive)</p> <p> TYPE: <code>str</code> </p> <code>custom_stopword_files</code> <p>Additional custom stopword files</p> <p> TYPE: <code>List[str]</code> </p> <code>tokenization_mode</code> <p>Tokenization mode ('code', 'text', 'auto')</p> <p> TYPE: <code>str</code> </p> <code>preserve_original_tokens</code> <p>Keep original tokens for exact matching</p> <p> TYPE: <code>bool</code> </p> <code>split_camelcase</code> <p>Split camelCase and PascalCase</p> <p> TYPE: <code>bool</code> </p> <code>split_snakecase</code> <p>Split snake_case</p> <p> TYPE: <code>bool</code> </p> <code>min_token_length</code> <p>Minimum token length to keep</p> <p> TYPE: <code>int</code> </p> <code>keyword_extraction_method</code> <p>Method for keyword extraction</p> <p> TYPE: <code>str</code> </p> <code>max_keywords</code> <p>Maximum keywords to extract</p> <p> TYPE: <code>int</code> </p> <code>ngram_size</code> <p>Maximum n-gram size for extraction</p> <p> TYPE: <code>int</code> </p> <code>yake_dedup_threshold</code> <p>YAKE deduplication threshold</p> <p> TYPE: <code>float</code> </p> <code>tfidf_use_sublinear</code> <p>Use log scaling for term frequency</p> <p> TYPE: <code>bool</code> </p> <code>tfidf_use_idf</code> <p>Use inverse document frequency</p> <p> TYPE: <code>bool</code> </p> <code>tfidf_norm</code> <p>Normalization method for TF-IDF</p> <p> TYPE: <code>str</code> </p> <code>bm25_k1</code> <p>BM25 term frequency saturation parameter</p> <p> TYPE: <code>float</code> </p> <code>bm25_b</code> <p>BM25 length normalization parameter</p> <p> TYPE: <code>float</code> </p> <code>embeddings_enabled</code> <p>Whether to use embeddings (requires ML)</p> <p> TYPE: <code>bool</code> </p> <code>embeddings_model</code> <p>Default embedding model</p> <p> TYPE: <code>str</code> </p> <code>embeddings_device</code> <p>Device for embeddings ('auto', 'cpu', 'cuda')</p> <p> TYPE: <code>str</code> </p> <code>embeddings_cache</code> <p>Whether to cache embeddings</p> <p> TYPE: <code>bool</code> </p> <code>embeddings_batch_size</code> <p>Batch size for embedding generation</p> <p> TYPE: <code>int</code> </p> <code>similarity_metric</code> <p>Default similarity metric</p> <p> TYPE: <code>str</code> </p> <code>similarity_threshold</code> <p>Default similarity threshold</p> <p> TYPE: <code>float</code> </p> <code>cache_embeddings_ttl_days</code> <p>TTL for embedding cache</p> <p> TYPE: <code>int</code> </p> <code>cache_tfidf_ttl_days</code> <p>TTL for TF-IDF cache</p> <p> TYPE: <code>int</code> </p> <code>cache_keywords_ttl_days</code> <p>TTL for keyword cache</p> <p> TYPE: <code>int</code> </p> <code>multiprocessing_enabled</code> <p>Enable multiprocessing for NLP operations</p> <p> TYPE: <code>bool</code> </p> <code>multiprocessing_workers</code> <p>Number of workers (None = cpu_count)</p> <p> TYPE: <code>Optional[int]</code> </p> <code>multiprocessing_chunk_size</code> <p>Chunk size for parallel processing</p> <p> TYPE: <code>int</code> </p>"},{"location":"api/tenets/config/#tenets.config.LLMConfig","title":"LLMConfig  <code>dataclass</code>","text":"Python<pre><code>LLMConfig(enabled: bool = False, provider: str = 'openai', fallback_providers: List[str] = (lambda: ['anthropic', 'openrouter'])(), api_keys: Dict[str, str] = (lambda: {'openai': '${OPENAI_API_KEY}', 'anthropic': '${ANTHROPIC_API_KEY}', 'openrouter': '${OPENROUTER_API_KEY}', 'cohere': '${COHERE_API_KEY}', 'together': '${TOGETHER_API_KEY}', 'huggingface': '${HUGGINGFACE_API_KEY}', 'replicate': '${REPLICATE_API_KEY}', 'ollama': ''})(), api_base_urls: Dict[str, str] = (lambda: {'openai': 'https://api.openai.com/v1', 'anthropic': 'https://api.anthropic.com/v1', 'openrouter': 'https://openrouter.ai/api/v1', 'ollama': 'http://localhost:11434'})(), models: Dict[str, str] = (lambda: {'default': 'gpt-4o-mini', 'summarization': 'gpt-3.5-turbo', 'analysis': 'gpt-4o', 'embeddings': 'text-embedding-3-small', 'code_generation': 'gpt-4o', 'semantic_search': 'text-embedding-3-small', 'anthropic_default': 'claude-3-haiku-20240307', 'anthropic_analysis': 'claude-3-sonnet-20240229', 'anthropic_code': 'claude-3-opus-20240229', 'ollama_default': 'llama2', 'ollama_code': 'codellama', 'ollama_embeddings': 'nomic-embed-text'})(), max_cost_per_run: float = 0.1, max_cost_per_day: float = 10.0, max_tokens_per_request: int = 4000, max_context_length: int = 100000, temperature: float = 0.3, top_p: float = 0.95, frequency_penalty: float = 0.0, presence_penalty: float = 0.0, requests_per_minute: int = 60, retry_on_error: bool = True, max_retries: int = 3, retry_delay: float = 1.0, retry_backoff: float = 2.0, timeout: int = 30, stream: bool = False, cache_responses: bool = True, cache_ttl_hours: int = 24, log_requests: bool = False, log_responses: bool = False, custom_headers: Dict[str, str] = dict(), organization_id: Optional[str] = None, project_id: Optional[str] = None)\n</code></pre> <p>Configuration for LLM (Large Language Model) integration.</p> <p>Supports multiple providers and models with comprehensive cost controls, rate limiting, and fallback strategies. All LLM features are optional and disabled by default.</p> ATTRIBUTE DESCRIPTION <code>enabled</code> <p>Whether LLM features are enabled globally</p> <p> TYPE: <code>bool</code> </p> <code>provider</code> <p>Primary LLM provider (openai, anthropic, openrouter, litellm, ollama)</p> <p> TYPE: <code>str</code> </p> <code>fallback_providers</code> <p>Ordered list of fallback providers if primary fails</p> <p> TYPE: <code>List[str]</code> </p> <code>api_keys</code> <p>Dictionary of provider -&gt; API key (can use env vars)</p> <p> TYPE: <code>Dict[str, str]</code> </p> <code>api_base_urls</code> <p>Custom API endpoints for providers (e.g., for proxies)</p> <p> TYPE: <code>Dict[str, str]</code> </p> <code>models</code> <p>Model selection for different tasks</p> <p> TYPE: <code>Dict[str, str]</code> </p> <code>max_cost_per_run</code> <p>Maximum cost in USD per execution run</p> <p> TYPE: <code>float</code> </p> <code>max_cost_per_day</code> <p>Maximum cost in USD per day</p> <p> TYPE: <code>float</code> </p> <code>max_tokens_per_request</code> <p>Maximum tokens per single request</p> <p> TYPE: <code>int</code> </p> <code>max_context_length</code> <p>Maximum context window to use</p> <p> TYPE: <code>int</code> </p> <code>temperature</code> <p>Sampling temperature (0.0-2.0, lower = more deterministic)</p> <p> TYPE: <code>float</code> </p> <code>top_p</code> <p>Nucleus sampling parameter</p> <p> TYPE: <code>float</code> </p> <code>frequency_penalty</code> <p>Frequency penalty for token repetition</p> <p> TYPE: <code>float</code> </p> <code>presence_penalty</code> <p>Presence penalty for topic repetition</p> <p> TYPE: <code>float</code> </p> <code>requests_per_minute</code> <p>Rate limit for API requests</p> <p> TYPE: <code>int</code> </p> <code>retry_on_error</code> <p>Whether to retry failed requests</p> <p> TYPE: <code>bool</code> </p> <code>max_retries</code> <p>Maximum number of retry attempts</p> <p> TYPE: <code>int</code> </p> <code>retry_delay</code> <p>Initial delay between retries in seconds</p> <p> TYPE: <code>float</code> </p> <code>retry_backoff</code> <p>Backoff multiplier for retry delays</p> <p> TYPE: <code>float</code> </p> <code>timeout</code> <p>Request timeout in seconds</p> <p> TYPE: <code>int</code> </p> <code>stream</code> <p>Whether to stream responses</p> <p> TYPE: <code>bool</code> </p> <code>cache_responses</code> <p>Whether to cache LLM responses</p> <p> TYPE: <code>bool</code> </p> <code>cache_ttl_hours</code> <p>Cache time-to-live in hours</p> <p> TYPE: <code>int</code> </p> <code>log_requests</code> <p>Whether to log all LLM requests</p> <p> TYPE: <code>bool</code> </p> <code>log_responses</code> <p>Whether to log all LLM responses</p> <p> TYPE: <code>bool</code> </p> <code>custom_headers</code> <p>Additional headers for API requests</p> <p> TYPE: <code>Dict[str, str]</code> </p> <code>organization_id</code> <p>Organization ID for providers that support it</p> <p> TYPE: <code>Optional[str]</code> </p> <code>project_id</code> <p>Project ID for providers that support it</p> <p> TYPE: <code>Optional[str]</code> </p>"},{"location":"api/tenets/config/#tenets.config.LLMConfig-functions","title":"Functions","text":""},{"location":"api/tenets/config/#tenets.config.LLMConfig.get_api_key","title":"get_api_key","text":"Python<pre><code>get_api_key(provider: Optional[str] = None) -&gt; Optional[str]\n</code></pre> <p>Get API key for a specific provider.</p> PARAMETER DESCRIPTION <code>provider</code> <p>Provider name (uses default if not specified)</p> <p> TYPE: <code>Optional[str]</code> DEFAULT: <code>None</code> </p> RETURNS DESCRIPTION <code>Optional[str]</code> <p>API key string or None if not configured</p>"},{"location":"api/tenets/config/#tenets.config.LLMConfig.get_model","title":"get_model","text":"Python<pre><code>get_model(task: str = 'default', provider: Optional[str] = None) -&gt; str\n</code></pre> <p>Get model name for a specific task and provider.</p> PARAMETER DESCRIPTION <code>task</code> <p>Task type (default, summarization, analysis, etc.)</p> <p> TYPE: <code>str</code> DEFAULT: <code>'default'</code> </p> <code>provider</code> <p>Provider name (uses default if not specified)</p> <p> TYPE: <code>Optional[str]</code> DEFAULT: <code>None</code> </p> RETURNS DESCRIPTION <code>str</code> <p>Model name string</p>"},{"location":"api/tenets/config/#tenets.config.LLMConfig.to_litellm_params","title":"to_litellm_params","text":"Python<pre><code>to_litellm_params() -&gt; Dict[str, Any]\n</code></pre> <p>Convert to parameters for LiteLLM library.</p> RETURNS DESCRIPTION <code>Dict[str, Any]</code> <p>Dictionary of parameters compatible with LiteLLM</p>"},{"location":"api/tenets/config/#tenets.config.ScannerConfig","title":"ScannerConfig  <code>dataclass</code>","text":"Python<pre><code>ScannerConfig(respect_gitignore: bool = True, follow_symlinks: bool = False, max_file_size: int = 5000000, max_files: int = 10000, binary_check: bool = True, encoding: str = 'utf-8', additional_ignore_patterns: List[str] = (lambda: ['*.pyc', '*.pyo', '__pycache__', '*.so', '*.dylib', '*.dll', '*.egg-info', '*.dist-info', '.tox', '.nox', '.coverage', '.hypothesis', '.pytest_cache', '.mypy_cache', '.ruff_cache'])(), additional_include_patterns: List[str] = list(), workers: int = 4, parallel_mode: str = 'auto', timeout: float = 5.0, exclude_minified: bool = True, minified_patterns: List[str] = (lambda: ['*.min.js', '*.min.css', 'bundle.js', '*.bundle.js', '*.bundle.css', '*.production.js', '*.prod.js', 'vendor.prod.js', '*.dist.js', '*.compiled.js', '*.minified.*', '*.uglified.*'])(), build_directory_patterns: List[str] = (lambda: ['dist/', 'build/', 'out/', 'output/', 'public/', 'static/generated/', '.next/', '_next/', 'node_modules/'])(), exclude_tests_by_default: bool = True, test_patterns: List[str] = (lambda: ['test_*.py', '*_test.py', 'test*.py', '*.test.js', '*.spec.js', '*.test.ts', '*.spec.ts', '*.test.jsx', '*.spec.jsx', '*.test.tsx', '*.spec.tsx', '*Test.java', '*Tests.java', '*TestCase.java', '*Test.cs', '*Tests.cs', '*TestCase.cs', '*_test.go', 'test_*.go', '*_test.rb', '*_spec.rb', 'test_*.rb', '*Test.php', '*_test.php', 'test_*.php', '*_test.rs', 'test_*.rs', '**/test/**', '**/tests/**', '**/*test*/**'])(), test_directories: List[str] = (lambda: ['test', 'tests', '__tests__', 'spec', 'specs', 'testing', 'test_*', '*_test', '*_tests', 'unit_tests', 'integration_tests', 'e2e', 'e2e_tests', 'functional_tests', 'acceptance_tests', 'regression_tests'])())\n</code></pre> <p>Configuration for file scanning subsystem.</p> <p>Controls how tenets discovers and filters files in a codebase.</p> ATTRIBUTE DESCRIPTION <code>respect_gitignore</code> <p>Whether to respect .gitignore files</p> <p> TYPE: <code>bool</code> </p> <code>follow_symlinks</code> <p>Whether to follow symbolic links</p> <p> TYPE: <code>bool</code> </p> <code>max_file_size</code> <p>Maximum file size in bytes to analyze</p> <p> TYPE: <code>int</code> </p> <code>max_files</code> <p>Maximum number of files to scan</p> <p> TYPE: <code>int</code> </p> <code>binary_check</code> <p>Whether to check for and skip binary files</p> <p> TYPE: <code>bool</code> </p> <code>encoding</code> <p>Default file encoding</p> <p> TYPE: <code>str</code> </p> <code>additional_ignore_patterns</code> <p>Extra patterns to ignore</p> <p> TYPE: <code>List[str]</code> </p> <code>additional_include_patterns</code> <p>Extra patterns to include</p> <p> TYPE: <code>List[str]</code> </p> <code>workers</code> <p>Number of parallel workers for scanning</p> <p> TYPE: <code>int</code> </p> <code>parallel_mode</code> <p>Parallel execution mode (\"thread\", \"process\", or \"auto\")</p> <p> TYPE: <code>str</code> </p> <code>timeout</code> <p>Per-file analysis timeout used in parallel execution (seconds)</p> <p> TYPE: <code>float</code> </p>"},{"location":"api/tenets/config/#tenets.config.RankingConfig","title":"RankingConfig  <code>dataclass</code>","text":"Python<pre><code>RankingConfig(algorithm: str = 'balanced', threshold: float = 0.1, text_similarity_algorithm: str = 'bm25', use_tfidf: bool = True, use_stopwords: bool = False, use_embeddings: bool = False, use_git: bool = True, use_ml: bool = False, embedding_model: str = 'all-MiniLM-L6-v2', custom_weights: Dict[str, float] = (lambda: {'keyword_match': 0.25, 'path_relevance': 0.2, 'import_graph': 0.2, 'git_activity': 0.15, 'file_type': 0.1, 'complexity': 0.1})(), workers: int = 2, parallel_mode: str = 'auto', batch_size: int = 100)\n</code></pre> <p>Configuration for relevance ranking system.</p> <p>Controls how files are scored and ranked for relevance to prompts. Uses centralized NLP components for all text processing.</p> ATTRIBUTE DESCRIPTION <code>algorithm</code> <p>Default ranking algorithm (fast, balanced, thorough, ml)</p> <p> TYPE: <code>str</code> </p> <code>threshold</code> <p>Minimum relevance score to include file</p> <p> TYPE: <code>float</code> </p> <code>text_similarity_algorithm</code> <p>Text similarity algorithm ('bm25' or 'tfidf', default: 'bm25')</p> <p> TYPE: <code>str</code> </p> <code>use_tfidf</code> <p>Whether to use TF-IDF for keyword matching (deprecated, use text_similarity_algorithm)</p> <p> TYPE: <code>bool</code> </p> <code>use_stopwords</code> <p>Whether to use stopwords filtering</p> <p> TYPE: <code>bool</code> </p> <code>use_embeddings</code> <p>Whether to use semantic embeddings (requires ML)</p> <p> TYPE: <code>bool</code> </p> <code>use_git</code> <p>Whether to include git signals in ranking</p> <p> TYPE: <code>bool</code> </p> <code>use_ml</code> <p>Whether to enable ML features (uses NLP embeddings)</p> <p> TYPE: <code>bool</code> </p> <code>embedding_model</code> <p>Which embedding model to use</p> <p> TYPE: <code>str</code> </p> <code>custom_weights</code> <p>Custom weights for ranking factors</p> <p> TYPE: <code>Dict[str, float]</code> </p> <code>workers</code> <p>Number of parallel workers for ranking</p> <p> TYPE: <code>int</code> </p> <code>parallel_mode</code> <p>Parallel execution mode (\"thread\", \"process\", or \"auto\")</p> <p> TYPE: <code>str</code> </p> <code>batch_size</code> <p>Batch size for ML operations</p> <p> TYPE: <code>int</code> </p>"},{"location":"api/tenets/config/#tenets.config.SummarizerConfig","title":"SummarizerConfig  <code>dataclass</code>","text":"Python<pre><code>SummarizerConfig(default_mode: str = 'auto', target_ratio: float = 0.3, enable_cache: bool = True, preserve_code_structure: bool = True, summarize_imports: bool = True, import_summary_threshold: int = 5, max_cache_size: int = 100, llm_provider: Optional[str] = None, llm_model: Optional[str] = None, llm_temperature: float = 0.3, llm_max_tokens: int = 500, enable_ml_strategies: bool = True, quality_threshold: str = 'medium', batch_size: int = 10, docs_context_aware: bool = True, docs_show_in_place_context: bool = True, docs_context_search_depth: int = 2, docs_context_min_confidence: float = 0.6, docs_context_max_sections: int = 10, docs_context_preserve_examples: bool = True, docstring_weight: float = 0.5, include_all_signatures: bool = True)\n</code></pre> <p>Configuration for content summarization system.</p> <p>Controls how text and code are compressed to fit within token limits.</p> ATTRIBUTE DESCRIPTION <code>default_mode</code> <p>Default summarization mode (extractive, compressive, textrank, transformer, llm, auto)</p> <p> TYPE: <code>str</code> </p> <code>target_ratio</code> <p>Default target compression ratio (0.3 = 30% of original)</p> <p> TYPE: <code>float</code> </p> <code>enable_cache</code> <p>Whether to cache summaries</p> <p> TYPE: <code>bool</code> </p> <code>preserve_code_structure</code> <p>Whether to preserve imports/signatures in code</p> <p> TYPE: <code>bool</code> </p> <code>summarize_imports</code> <p>Whether to condense imports into a summary (default: True)</p> <p> TYPE: <code>bool</code> </p> <code>import_summary_threshold</code> <p>Number of imports to trigger summarization (default: 5)</p> <p> TYPE: <code>int</code> </p> <code>max_cache_size</code> <p>Maximum number of cached summaries</p> <p> TYPE: <code>int</code> </p> <code>llm_provider</code> <p>LLM provider for LLM mode (uses global LLM config)</p> <p> TYPE: <code>Optional[str]</code> </p> <code>llm_model</code> <p>LLM model to use (uses global LLM config)</p> <p> TYPE: <code>Optional[str]</code> </p> <code>llm_temperature</code> <p>LLM sampling temperature</p> <p> TYPE: <code>float</code> </p> <code>llm_max_tokens</code> <p>Maximum tokens for LLM response</p> <p> TYPE: <code>int</code> </p> <code>enable_ml_strategies</code> <p>Whether to enable ML-based strategies</p> <p> TYPE: <code>bool</code> </p> <code>quality_threshold</code> <p>Quality threshold for auto mode selection</p> <p> TYPE: <code>str</code> </p> <code>batch_size</code> <p>Batch size for parallel processing</p> <p> TYPE: <code>int</code> </p> <code>docs_context_aware</code> <p>Whether to enable context-aware summarization for documentation files</p> <p> TYPE: <code>bool</code> </p> <code>docs_show_in_place_context</code> <p>When enabled, preserves and highlights relevant context in documentation summaries instead of generic structure</p> <p> TYPE: <code>bool</code> </p> <code>docs_context_search_depth</code> <p>How deep to search for contextual references (1=direct mentions, 2=semantic similarity, 3=deep analysis)</p> <p> TYPE: <code>int</code> </p> <code>docs_context_min_confidence</code> <p>Minimum confidence threshold for context relevance (0.0-1.0)</p> <p> TYPE: <code>float</code> </p> <code>docs_context_max_sections</code> <p>Maximum number of contextual sections to preserve per document</p> <p> TYPE: <code>int</code> </p> <code>docs_context_preserve_examples</code> <p>Whether to always preserve code examples and snippets in documentation</p> <p> TYPE: <code>bool</code> </p>"},{"location":"api/tenets/config/#tenets.config.TenetConfig","title":"TenetConfig  <code>dataclass</code>","text":"Python<pre><code>TenetConfig(auto_instill: bool = True, max_per_context: int = 5, reinforcement: bool = True, injection_strategy: str = 'strategic', min_distance_between: int = 1000, prefer_natural_breaks: bool = True, storage_path: Optional[Path] = None, collections_enabled: bool = True, injection_frequency: str = 'adaptive', injection_interval: int = 3, session_complexity_threshold: float = 0.7, min_session_length: int = 1, adaptive_injection: bool = True, track_injection_history: bool = True, decay_rate: float = 0.1, reinforcement_interval: int = 10, session_aware: bool = True, session_memory_limit: int = 100, persist_session_history: bool = True, complexity_weight: float = 0.5, priority_boost_critical: float = 2.0, priority_boost_high: float = 1.5, skip_low_priority_on_complex: bool = True, track_effectiveness: bool = True, effectiveness_window_days: int = 30, min_compliance_score: float = 0.6, system_instruction: Optional[str] = None, system_instruction_enabled: bool = False, system_instruction_position: str = 'top', system_instruction_format: str = 'markdown', system_instruction_once_per_session: bool = True)\n</code></pre> <p>Configuration for the tenet (guiding principles) system.</p> <p>Controls how tenets are managed and injected into context, including smart injection frequency, session tracking, and adaptive behavior.</p> ATTRIBUTE DESCRIPTION <code>auto_instill</code> <p>Whether to automatically apply tenets to context</p> <p> TYPE: <code>bool</code> </p> <code>max_per_context</code> <p>Maximum tenets to inject per context</p> <p> TYPE: <code>int</code> </p> <code>reinforcement</code> <p>Whether to reinforce critical tenets</p> <p> TYPE: <code>bool</code> </p> <code>injection_strategy</code> <p>Default injection strategy ('strategic', 'top', 'distributed')</p> <p> TYPE: <code>str</code> </p> <code>min_distance_between</code> <p>Minimum character distance between injections</p> <p> TYPE: <code>int</code> </p> <code>prefer_natural_breaks</code> <p>Whether to inject at natural break points</p> <p> TYPE: <code>bool</code> </p> <code>storage_path</code> <p>Where to store tenet database</p> <p> TYPE: <code>Optional[Path]</code> </p> <code>collections_enabled</code> <p>Whether to enable tenet collections</p> <p> TYPE: <code>bool</code> </p> <code>injection_frequency</code> <p>How often to inject tenets ('always', 'periodic', 'adaptive', 'manual')</p> <p> TYPE: <code>str</code> </p> <code>injection_interval</code> <p>Numeric interval for periodic injection (e.g., every 3<sup>rd</sup> distill)</p> <p> TYPE: <code>int</code> </p> <code>session_complexity_threshold</code> <p>Complexity threshold for smart injection (0-1)</p> <p> TYPE: <code>float</code> </p> <code>min_session_length</code> <p>Minimum session length before first injection</p> <p> TYPE: <code>int</code> </p> <code>adaptive_injection</code> <p>Enable adaptive injection based on context analysis</p> <p> TYPE: <code>bool</code> </p> <code>track_injection_history</code> <p>Track injection history per session for smarter decisions</p> <p> TYPE: <code>bool</code> </p> <code>decay_rate</code> <p>How quickly tenet importance decays (0-1, higher = faster decay)</p> <p> TYPE: <code>float</code> </p> <code>reinforcement_interval</code> <p>How often to reinforce critical tenets (every N injections)</p> <p> TYPE: <code>int</code> </p> <code>session_aware</code> <p>Enable session-aware injection patterns</p> <p> TYPE: <code>bool</code> </p> <code>session_memory_limit</code> <p>Max sessions to track in memory</p> <p> TYPE: <code>int</code> </p> <code>persist_session_history</code> <p>Save session histories to disk</p> <p> TYPE: <code>bool</code> </p> <code>complexity_weight</code> <p>Weight given to complexity in injection decisions (0-1)</p> <p> TYPE: <code>float</code> </p> <code>priority_boost_critical</code> <p>Boost factor for critical priority tenets</p> <p> TYPE: <code>float</code> </p> <code>priority_boost_high</code> <p>Boost factor for high priority tenets</p> <p> TYPE: <code>float</code> </p> <code>skip_low_priority_on_complex</code> <p>Skip low priority tenets when complexity &gt; threshold</p> <p> TYPE: <code>bool</code> </p> <code>track_effectiveness</code> <p>Track tenet effectiveness metrics</p> <p> TYPE: <code>bool</code> </p> <code>effectiveness_window_days</code> <p>Days to consider for effectiveness analysis</p> <p> TYPE: <code>int</code> </p> <code>min_compliance_score</code> <p>Minimum compliance score before reinforcement</p> <p> TYPE: <code>float</code> </p>"},{"location":"api/tenets/config/#tenets.config.TenetConfig--system-instruction-system-prompt-configuration","title":"System instruction (system prompt) configuration","text":"<p>system_instruction: Optional text to inject as foundational context system_instruction_enabled: Enable auto-injection when instruction exists system_instruction_position: Where to inject (top, after_header, before_content) system_instruction_format: Format of instruction (markdown, xml, comment, plain) system_instruction_once_per_session: Inject once per session; if no session, inject every distill</p>"},{"location":"api/tenets/config/#tenets.config.TenetConfig-attributes","title":"Attributes","text":""},{"location":"api/tenets/config/#tenets.config.TenetConfig.injection_config","title":"injection_config  <code>property</code>","text":"Python<pre><code>injection_config: Dict[str, Any]\n</code></pre> <p>Get injection configuration as dictionary for TenetInjector.</p>"},{"location":"api/tenets/config/#tenets.config.CacheConfig","title":"CacheConfig  <code>dataclass</code>","text":"Python<pre><code>CacheConfig(enabled: bool = True, directory: Optional[Path] = None, ttl_days: int = 7, max_size_mb: int = 500, compression: bool = False, memory_cache_size: int = 1000, sqlite_pragmas: Dict[str, str] = (lambda: {'journal_mode': 'WAL', 'synchronous': 'NORMAL', 'cache_size': '-64000', 'temp_store': 'MEMORY'})(), max_age_hours: int = 24, llm_cache_enabled: bool = True, llm_cache_ttl_hours: int = 24)\n</code></pre> <p>Configuration for caching system.</p> <p>Controls cache behavior for analysis results and other expensive operations.</p> ATTRIBUTE DESCRIPTION <code>enabled</code> <p>Whether caching is enabled</p> <p> TYPE: <code>bool</code> </p> <code>directory</code> <p>Cache directory path</p> <p> TYPE: <code>Optional[Path]</code> </p> <code>ttl_days</code> <p>Time-to-live for cache entries in days</p> <p> TYPE: <code>int</code> </p> <code>max_size_mb</code> <p>Maximum cache size in megabytes</p> <p> TYPE: <code>int</code> </p> <code>compression</code> <p>Whether to compress cached data</p> <p> TYPE: <code>bool</code> </p> <code>memory_cache_size</code> <p>Number of items in memory cache</p> <p> TYPE: <code>int</code> </p> <code>sqlite_pragmas</code> <p>SQLite performance settings</p> <p> TYPE: <code>Dict[str, str]</code> </p> <code>max_age_hours</code> <p>Max age for certain cached entries (used by analyzer)</p> <p> TYPE: <code>int</code> </p> <code>llm_cache_enabled</code> <p>Whether to cache LLM responses</p> <p> TYPE: <code>bool</code> </p> <code>llm_cache_ttl_hours</code> <p>TTL for LLM response cache</p> <p> TYPE: <code>int</code> </p>"},{"location":"api/tenets/config/#tenets.config.OutputConfig","title":"OutputConfig  <code>dataclass</code>","text":"Python<pre><code>OutputConfig(default_format: str = 'markdown', syntax_highlighting: bool = True, line_numbers: bool = False, max_line_length: int = 120, include_metadata: bool = True, compression_threshold: int = 10000, summary_ratio: float = 0.25, copy_on_distill: bool = False, show_token_usage: bool = True, show_cost_estimate: bool = True)\n</code></pre> <p>Configuration for output formatting.</p> <p>Controls how context and analysis results are formatted.</p> ATTRIBUTE DESCRIPTION <code>default_format</code> <p>Default output format (markdown, xml, json)</p> <p> TYPE: <code>str</code> </p> <code>syntax_highlighting</code> <p>Whether to enable syntax highlighting</p> <p> TYPE: <code>bool</code> </p> <code>line_numbers</code> <p>Whether to include line numbers</p> <p> TYPE: <code>bool</code> </p> <code>max_line_length</code> <p>Maximum line length before wrapping</p> <p> TYPE: <code>int</code> </p> <code>include_metadata</code> <p>Whether to include metadata in output</p> <p> TYPE: <code>bool</code> </p> <code>compression_threshold</code> <p>File size threshold for summarization</p> <p> TYPE: <code>int</code> </p> <code>summary_ratio</code> <p>Target compression ratio for summaries</p> <p> TYPE: <code>float</code> </p> <code>copy_on_distill</code> <p>Automatically copy distill output to clipboard when true</p> <p> TYPE: <code>bool</code> </p> <code>show_token_usage</code> <p>Whether to show token usage statistics</p> <p> TYPE: <code>bool</code> </p> <code>show_cost_estimate</code> <p>Whether to show cost estimates for LLM operations</p> <p> TYPE: <code>bool</code> </p>"},{"location":"api/tenets/config/#tenets.config.GitConfig","title":"GitConfig  <code>dataclass</code>","text":"Python<pre><code>GitConfig(enabled: bool = True, include_history: bool = True, history_limit: int = 100, include_blame: bool = False, include_stats: bool = True, ignore_authors: List[str] = (lambda: ['dependabot[bot]', 'github-actions[bot]', 'renovate[bot]'])(), main_branches: List[str] = (lambda: ['main', 'master', 'develop', 'trunk'])())\n</code></pre> <p>Configuration for git integration.</p> <p>Controls how git information is gathered and used.</p> ATTRIBUTE DESCRIPTION <code>enabled</code> <p>Whether git integration is enabled</p> <p> TYPE: <code>bool</code> </p> <code>include_history</code> <p>Whether to include commit history</p> <p> TYPE: <code>bool</code> </p> <code>history_limit</code> <p>Maximum number of commits to include</p> <p> TYPE: <code>int</code> </p> <code>include_blame</code> <p>Whether to include git blame info</p> <p> TYPE: <code>bool</code> </p> <code>include_stats</code> <p>Whether to include statistics</p> <p> TYPE: <code>bool</code> </p> <code>ignore_authors</code> <p>Authors to ignore in analysis</p> <p> TYPE: <code>List[str]</code> </p> <code>main_branches</code> <p>Branch names considered \"main\"</p> <p> TYPE: <code>List[str]</code> </p>"},{"location":"api/tenets/config/#tenets.config.TenetsConfig","title":"TenetsConfig  <code>dataclass</code>","text":"Python<pre><code>TenetsConfig(config_file: Optional[Path] = None, project_root: Optional[Path] = None, max_tokens: int = 100000, version: str = '0.1.0', debug: bool = False, quiet: bool = False, scanner: ScannerConfig = ScannerConfig(), ranking: RankingConfig = RankingConfig(), summarizer: SummarizerConfig = SummarizerConfig(), tenet: TenetConfig = TenetConfig(), cache: CacheConfig = CacheConfig(), output: OutputConfig = OutputConfig(), git: GitConfig = GitConfig(), llm: LLMConfig = LLMConfig(), nlp: NLPConfig = NLPConfig(), custom: Dict[str, Any] = dict())\n</code></pre> <p>Main configuration for the Tenets system with LLM and NLP support.</p> <p>This is the root configuration object that contains all subsystem configs and global settings. It handles loading from files, environment variables, and provides sensible defaults.</p> ATTRIBUTE DESCRIPTION <code>config_file</code> <p>Path to configuration file (if any)</p> <p> TYPE: <code>Optional[Path]</code> </p> <code>project_root</code> <p>Root directory of the project</p> <p> TYPE: <code>Optional[Path]</code> </p> <code>max_tokens</code> <p>Default maximum tokens for context</p> <p> TYPE: <code>int</code> </p> <code>version</code> <p>Tenets version (for compatibility checking)</p> <p> TYPE: <code>str</code> </p> <code>debug</code> <p>Enable debug mode</p> <p> TYPE: <code>bool</code> </p> <code>quiet</code> <p>Suppress non-essential output</p> <p> TYPE: <code>bool</code> </p> <code>scanner</code> <p>Scanner subsystem configuration</p> <p> TYPE: <code>ScannerConfig</code> </p> <code>ranking</code> <p>Ranking subsystem configuration</p> <p> TYPE: <code>RankingConfig</code> </p> <code>summarizer</code> <p>Summarizer subsystem configuration</p> <p> TYPE: <code>SummarizerConfig</code> </p> <code>tenet</code> <p>Tenet subsystem configuration</p> <p> TYPE: <code>TenetConfig</code> </p> <code>cache</code> <p>Cache subsystem configuration</p> <p> TYPE: <code>CacheConfig</code> </p> <code>output</code> <p>Output formatting configuration</p> <p> TYPE: <code>OutputConfig</code> </p> <code>git</code> <p>Git integration configuration</p> <p> TYPE: <code>GitConfig</code> </p> <code>llm</code> <p>LLM integration configuration</p> <p> TYPE: <code>LLMConfig</code> </p> <code>nlp</code> <p>NLP system configuration</p> <p> TYPE: <code>NLPConfig</code> </p> <code>custom</code> <p>Custom user configuration</p> <p> TYPE: <code>Dict[str, Any]</code> </p>"},{"location":"api/tenets/config/#tenets.config.TenetsConfig-attributes","title":"Attributes","text":""},{"location":"api/tenets/config/#tenets.config.TenetsConfig.exclude_minified","title":"exclude_minified  <code>property</code> <code>writable</code>","text":"Python<pre><code>exclude_minified: bool\n</code></pre> <p>Get exclude_minified setting from scanner config.</p>"},{"location":"api/tenets/config/#tenets.config.TenetsConfig.minified_patterns","title":"minified_patterns  <code>property</code> <code>writable</code>","text":"Python<pre><code>minified_patterns: List[str]\n</code></pre> <p>Get minified patterns from scanner config.</p>"},{"location":"api/tenets/config/#tenets.config.TenetsConfig.build_directory_patterns","title":"build_directory_patterns  <code>property</code> <code>writable</code>","text":"Python<pre><code>build_directory_patterns: List[str]\n</code></pre> <p>Get build directory patterns from scanner config.</p>"},{"location":"api/tenets/config/#tenets.config.TenetsConfig.cache_dir","title":"cache_dir  <code>property</code> <code>writable</code>","text":"Python<pre><code>cache_dir: Path\n</code></pre> <p>Get the cache directory path.</p>"},{"location":"api/tenets/config/#tenets.config.TenetsConfig.scanner_workers","title":"scanner_workers  <code>property</code>","text":"Python<pre><code>scanner_workers: int\n</code></pre> <p>Get number of scanner workers.</p>"},{"location":"api/tenets/config/#tenets.config.TenetsConfig.ranking_workers","title":"ranking_workers  <code>property</code>","text":"Python<pre><code>ranking_workers: int\n</code></pre> <p>Get number of ranking workers.</p>"},{"location":"api/tenets/config/#tenets.config.TenetsConfig.ranking_algorithm","title":"ranking_algorithm  <code>property</code>","text":"Python<pre><code>ranking_algorithm: str\n</code></pre> <p>Get the ranking algorithm.</p>"},{"location":"api/tenets/config/#tenets.config.TenetsConfig.summarizer_mode","title":"summarizer_mode  <code>property</code>","text":"Python<pre><code>summarizer_mode: str\n</code></pre> <p>Get the default summarizer mode.</p>"},{"location":"api/tenets/config/#tenets.config.TenetsConfig.summarizer_ratio","title":"summarizer_ratio  <code>property</code>","text":"Python<pre><code>summarizer_ratio: float\n</code></pre> <p>Get the default summarization target ratio.</p>"},{"location":"api/tenets/config/#tenets.config.TenetsConfig.respect_gitignore","title":"respect_gitignore  <code>property</code> <code>writable</code>","text":"Python<pre><code>respect_gitignore: bool\n</code></pre> <p>Whether to respect .gitignore files.</p>"},{"location":"api/tenets/config/#tenets.config.TenetsConfig.follow_symlinks","title":"follow_symlinks  <code>property</code> <code>writable</code>","text":"Python<pre><code>follow_symlinks: bool\n</code></pre> <p>Whether to follow symbolic links.</p>"},{"location":"api/tenets/config/#tenets.config.TenetsConfig.additional_ignore_patterns","title":"additional_ignore_patterns  <code>property</code> <code>writable</code>","text":"Python<pre><code>additional_ignore_patterns: List[str]\n</code></pre> <p>Get additional ignore patterns.</p>"},{"location":"api/tenets/config/#tenets.config.TenetsConfig.auto_instill_tenets","title":"auto_instill_tenets  <code>property</code> <code>writable</code>","text":"Python<pre><code>auto_instill_tenets: bool\n</code></pre> <p>Whether to automatically instill tenets.</p>"},{"location":"api/tenets/config/#tenets.config.TenetsConfig.max_tenets_per_context","title":"max_tenets_per_context  <code>property</code> <code>writable</code>","text":"Python<pre><code>max_tenets_per_context: int\n</code></pre> <p>Maximum tenets to inject per context.</p>"},{"location":"api/tenets/config/#tenets.config.TenetsConfig.tenet_injection_config","title":"tenet_injection_config  <code>property</code>","text":"Python<pre><code>tenet_injection_config: Dict[str, Any]\n</code></pre> <p>Get tenet injection configuration.</p>"},{"location":"api/tenets/config/#tenets.config.TenetsConfig.cache_ttl_days","title":"cache_ttl_days  <code>property</code> <code>writable</code>","text":"Python<pre><code>cache_ttl_days: int\n</code></pre> <p>Cache time-to-live in days.</p>"},{"location":"api/tenets/config/#tenets.config.TenetsConfig.max_cache_size_mb","title":"max_cache_size_mb  <code>property</code> <code>writable</code>","text":"Python<pre><code>max_cache_size_mb: int\n</code></pre> <p>Maximum cache size in megabytes.</p>"},{"location":"api/tenets/config/#tenets.config.TenetsConfig.llm_enabled","title":"llm_enabled  <code>property</code> <code>writable</code>","text":"Python<pre><code>llm_enabled: bool\n</code></pre> <p>Whether LLM features are enabled.</p>"},{"location":"api/tenets/config/#tenets.config.TenetsConfig.llm_provider","title":"llm_provider  <code>property</code> <code>writable</code>","text":"Python<pre><code>llm_provider: str\n</code></pre> <p>Get the current LLM provider.</p>"},{"location":"api/tenets/config/#tenets.config.TenetsConfig.nlp_enabled","title":"nlp_enabled  <code>property</code> <code>writable</code>","text":"Python<pre><code>nlp_enabled: bool\n</code></pre> <p>Whether NLP features are enabled.</p>"},{"location":"api/tenets/config/#tenets.config.TenetsConfig.nlp_embeddings_enabled","title":"nlp_embeddings_enabled  <code>property</code> <code>writable</code>","text":"Python<pre><code>nlp_embeddings_enabled: bool\n</code></pre> <p>Whether NLP embeddings are enabled.</p>"},{"location":"api/tenets/config/#tenets.config.TenetsConfig-functions","title":"Functions","text":""},{"location":"api/tenets/config/#tenets.config.TenetsConfig.to_dict","title":"to_dict","text":"Python<pre><code>to_dict() -&gt; Dict[str, Any]\n</code></pre> <p>Convert configuration to dictionary.</p> RETURNS DESCRIPTION <code>Dict[str, Any]</code> <p>Dictionary representation of configuration</p>"},{"location":"api/tenets/config/#tenets.config.TenetsConfig.save","title":"save","text":"Python<pre><code>save(path: Optional[Path] = None)\n</code></pre> <p>Save configuration to file.</p> PARAMETER DESCRIPTION <code>path</code> <p>Path to save to (uses config_file if not specified)</p> <p> TYPE: <code>Optional[Path]</code> DEFAULT: <code>None</code> </p> RAISES DESCRIPTION <code>ValueError</code> <p>If no path specified and config_file not set</p>"},{"location":"api/tenets/config/#tenets.config.TenetsConfig.get_llm_api_key","title":"get_llm_api_key","text":"Python<pre><code>get_llm_api_key(provider: Optional[str] = None) -&gt; Optional[str]\n</code></pre> <p>Get LLM API key for a provider.</p> PARAMETER DESCRIPTION <code>provider</code> <p>Provider name (uses default if not specified)</p> <p> TYPE: <code>Optional[str]</code> DEFAULT: <code>None</code> </p> RETURNS DESCRIPTION <code>Optional[str]</code> <p>API key or None</p>"},{"location":"api/tenets/config/#tenets.config.TenetsConfig.get_llm_model","title":"get_llm_model","text":"Python<pre><code>get_llm_model(task: str = 'default', provider: Optional[str] = None) -&gt; str\n</code></pre> <p>Get LLM model for a specific task.</p> PARAMETER DESCRIPTION <code>task</code> <p>Task type</p> <p> TYPE: <code>str</code> DEFAULT: <code>'default'</code> </p> <code>provider</code> <p>Provider name (uses default if not specified)</p> <p> TYPE: <code>Optional[str]</code> DEFAULT: <code>None</code> </p> RETURNS DESCRIPTION <code>str</code> <p>Model name</p>"},{"location":"api/tenets/cli/app/","title":"App","text":""},{"location":"api/tenets/cli/app/#tenets.cli.app","title":"tenets.cli.app","text":"<p>Tenets CLI application.</p>"},{"location":"api/tenets/cli/app/#tenets.cli.app-functions","title":"Functions","text":""},{"location":"api/tenets/cli/app/#tenets.cli.app.distill_placeholder","title":"distill_placeholder","text":"Python<pre><code>distill_placeholder(ctx: Context, prompt: str = typer.Argument(..., help='Query or task to build context for'))\n</code></pre> <p>Distill relevant context from codebase for AI prompts.</p>"},{"location":"api/tenets/cli/app/#tenets.cli.app.instill_placeholder","title":"instill_placeholder","text":"Python<pre><code>instill_placeholder(ctx: Context)\n</code></pre> <p>Apply tenets (guiding principles) to context.</p>"},{"location":"api/tenets/cli/app/#tenets.cli.app.version","title":"version","text":"Python<pre><code>version(verbose: bool = typer.Option(False, '--verbose', '-v', help='Show detailed version info'))\n</code></pre> <p>Show version information.</p>"},{"location":"api/tenets/cli/app/#tenets.cli.app.main_callback","title":"main_callback","text":"Python<pre><code>main_callback(ctx: Context, version: bool = typer.Option(False, '--version', help='Show version and exit'), verbose: bool = typer.Option(False, '--verbose', '-v', help='Enable verbose output'), quiet: bool = typer.Option(False, '--quiet', '-q', help='Suppress non-essential output'), silent: bool = typer.Option(False, '--silent', help='Only show errors'))\n</code></pre> <p>Tenets - Context that feeds your prompts.</p> <p>Distill relevant context from your codebase and instill guiding principles to maintain consistency across AI interactions.</p>"},{"location":"api/tenets/cli/app/#tenets.cli.app.run","title":"run","text":"Python<pre><code>run()\n</code></pre> <p>Run the CLI application.</p>"},{"location":"api/tenets/cli/commands/_utils/","title":"Utils","text":""},{"location":"api/tenets/cli/commands/_utils/#tenets.cli.commands._utils","title":"tenets.cli.commands._utils","text":"<p>Shared helpers for CLI command modules.</p>"},{"location":"api/tenets/cli/commands/_utils/#tenets.cli.commands._utils-functions","title":"Functions","text":""},{"location":"api/tenets/cli/commands/_utils/#tenets.cli.commands._utils.normalize_path","title":"normalize_path","text":"Python<pre><code>normalize_path(p: Union[str, Path]) -&gt; str\n</code></pre> <p>Return a normalized absolute path string for stable testing/logging.</p> <p>Ensures platform-appropriate formatting and avoids returning Path objects so that tests can compare against stringified call arguments consistently.</p>"},{"location":"api/tenets/cli/commands/chronicle/","title":"Chronicle","text":""},{"location":"api/tenets/cli/commands/chronicle/#tenets.cli.commands.chronicle","title":"tenets.cli.commands.chronicle","text":"<p>Chronicle command implementation.</p> <p>This command provides git history analysis and visualization of code evolution over time, including contribution patterns and change dynamics.</p>"},{"location":"api/tenets/cli/commands/chronicle/#tenets.cli.commands.chronicle-classes","title":"Classes","text":""},{"location":"api/tenets/cli/commands/chronicle/#tenets.cli.commands.chronicle-functions","title":"Functions","text":""},{"location":"api/tenets/cli/commands/chronicle/#tenets.cli.commands.chronicle.run","title":"run","text":"Python<pre><code>run(path: str = typer.Argument('.', help='Repository directory'), since: Optional[str] = typer.Option(None, '--since', '-s', help='Start date (YYYY-MM-DD or relative like \"3 months ago\")'), until: Optional[str] = typer.Option(None, '--until', '-u', help='End date (YYYY-MM-DD or relative like \"today\")'), output: Optional[str] = typer.Option(None, '--output', '-o', help='Output file for report'), format: str = typer.Option('terminal', '--format', '-f', help='Output format', case_sensitive=False), branch: str = typer.Option('main', '--branch', '-b', help='Git branch to analyze'), authors: Optional[List[str]] = typer.Option(None, '--authors', '-a', help='Filter by specific authors'), show_merges: bool = typer.Option(False, '--show-merges', help='Include merge commits'), show_contributors: bool = typer.Option(False, '--show-contributors', help='Show contributor analysis'), show_patterns: bool = typer.Option(False, '--show-patterns', help='Show change patterns'), limit: Optional[int] = typer.Option(None, '--limit', '-l', help='Limit number of commits to analyze'))\n</code></pre> <p>Chronicle the evolution of your codebase.</p> <p>This runs as the app callback so tests can invoke <code>chronicle</code> directly.</p>"},{"location":"api/tenets/cli/commands/config/","title":"Config","text":""},{"location":"api/tenets/cli/commands/config/#tenets.cli.commands.config","title":"tenets.cli.commands.config","text":"<p>Configuration management commands.</p> <p>This module implements the <code>tenets config</code> subcommands using Typer. It includes initialization, display, mutation (set), validation, cache utilities, and export/diff helpers. The <code>set</code> command is designed to be test-friendly by supporting MagicMock-based objects in unit tests when direct dict validation is unavailable.</p>"},{"location":"api/tenets/cli/commands/config/#tenets.cli.commands.config-classes","title":"Classes","text":""},{"location":"api/tenets/cli/commands/config/#tenets.cli.commands.config-functions","title":"Functions","text":""},{"location":"api/tenets/cli/commands/config/#tenets.cli.commands.config.config_init","title":"config_init","text":"Python<pre><code>config_init(force: bool = typer.Option(False, '--force', '-f', help='Overwrite existing config'))\n</code></pre> <p>Create a starter .tenets.yml configuration file.</p> <p>Examples:</p> <p>tenets config init tenets config init --force</p>"},{"location":"api/tenets/cli/commands/config/#tenets.cli.commands.config.config_show","title":"config_show","text":"Python<pre><code>config_show(key: Optional[str] = typer.Option(None, '--key', '-k', help='Specific key to show'), format: str = typer.Option('yaml', '--format', '-f', help='Output format: yaml, json'))\n</code></pre> <p>Show current configuration.</p> <p>Examples:</p> <p>tenets config show tenets config show --key summarizer tenets config show --key ranking.algorithm tenets config show --format json</p>"},{"location":"api/tenets/cli/commands/config/#tenets.cli.commands.config.config_set","title":"config_set","text":"Python<pre><code>config_set(key: str = typer.Argument(..., help='Configuration key (e.g., summarizer.target_ratio)'), value: str = typer.Argument(..., help='Value to set'), save: bool = typer.Option(False, '--save', '-s', help='Save to config file'))\n</code></pre> <p>Set a configuration value.</p> <p>Examples:</p> <p>tenets config set max_tokens 150000 tenets config set ranking.algorithm thorough tenets config set summarizer.default_mode extractive --save tenets config set summarizer.llm_model gpt-4 --save</p>"},{"location":"api/tenets/cli/commands/config/#tenets.cli.commands.config.config_validate","title":"config_validate","text":"Python<pre><code>config_validate(file: Optional[Path] = typer.Option(None, '--file', '-f', help='Config file to validate'))\n</code></pre> <p>Validate configuration file.</p> <p>Examples:</p> <p>tenets config validate tenets config validate --file custom-config.yml</p>"},{"location":"api/tenets/cli/commands/config/#tenets.cli.commands.config.config_clear_cache","title":"config_clear_cache","text":"Python<pre><code>config_clear_cache(confirm: bool = typer.Option(False, '--yes', '-y', help='Skip confirmation'))\n</code></pre> <p>Wipe all Tenets caches (analysis + general + summaries).</p>"},{"location":"api/tenets/cli/commands/config/#tenets.cli.commands.config.config_cleanup_cache","title":"config_cleanup_cache","text":"Python<pre><code>config_cleanup_cache()\n</code></pre> <p>Cleanup old / oversized cache entries respecting TTL and size policies.</p>"},{"location":"api/tenets/cli/commands/config/#tenets.cli.commands.config.config_cache_stats","title":"config_cache_stats","text":"Python<pre><code>config_cache_stats()\n</code></pre> <p>Show detailed cache statistics.</p>"},{"location":"api/tenets/cli/commands/config/#tenets.cli.commands.config.config_export","title":"config_export","text":"Python<pre><code>config_export(output: Path = typer.Argument(..., help='Output file path'), format: str = typer.Option('yaml', '--format', '-f', help='Output format: yaml, json'))\n</code></pre> <p>Export current configuration to file.</p> <p>Examples:</p> <p>tenets config export my-config.yml tenets config export config.json --format json</p>"},{"location":"api/tenets/cli/commands/config/#tenets.cli.commands.config.config_diff","title":"config_diff","text":"Python<pre><code>config_diff(file1: Optional[Path] = typer.Option(None, '--file1', help='First config file'), file2: Optional[Path] = typer.Option(None, '--file2', help='Second config file'))\n</code></pre> <p>Show differences between configurations.</p> <p>Examples:</p> <p>tenets config diff  # Compare current vs defaults tenets config diff --file1 old.yml --file2 new.yml</p>"},{"location":"api/tenets/cli/commands/distill/","title":"Distill","text":""},{"location":"api/tenets/cli/commands/distill/#tenets.cli.commands.distill","title":"tenets.cli.commands.distill","text":"<p>Distill command - extract relevant context from codebase.</p>"},{"location":"api/tenets/cli/commands/distill/#tenets.cli.commands.distill-classes","title":"Classes","text":""},{"location":"api/tenets/cli/commands/distill/#tenets.cli.commands.distill-functions","title":"Functions","text":""},{"location":"api/tenets/cli/commands/distill/#tenets.cli.commands.distill.distill","title":"distill","text":"Python<pre><code>distill(prompt: str = typer.Argument(..., help='Your query or task (can be text or URL to GitHub issue, etc.)'), path: Path = typer.Argument(Path(), help='Path to analyze (directory or files)'), format: str = typer.Option('markdown', '--format', '-f', help='Output format: markdown, xml, json, html'), output: Optional[Path] = typer.Option(None, '--output', '-o', help='Save output to file instead of stdout'), mode: str = typer.Option('balanced', '--mode', '-m', help='Analysis mode: fast (keywords only), balanced (default), thorough (deep analysis)'), model: Optional[str] = typer.Option(None, '--model', help='Target LLM model for token counting (e.g., gpt-4o, claude-3-opus)'), max_tokens: Optional[int] = typer.Option(None, '--max-tokens', help='Maximum tokens for context (overrides model default)'), include: Optional[str] = typer.Option(None, '--include', '-i', help=\"Include file patterns (e.g., '*.py,*.js')\"), exclude: Optional[str] = typer.Option(None, '--exclude', '-e', help=\"Exclude file patterns (e.g., 'test_*,*.backup')\"), include_tests: bool = typer.Option(False, '--include-tests', help='Include test files (overrides default exclusion)'), exclude_tests: bool = typer.Option(False, '--exclude-tests', help='Explicitly exclude test files (even for test-related prompts)'), include_minified: bool = typer.Option(False, '--include-minified', help='Include minified/built files (*.min.js, dist/, etc.) normally excluded'), no_git: bool = typer.Option(False, '--no-git', help='Disable git context inclusion'), full: bool = typer.Option(False, '--full', help='Include full content for all ranked files within token budget (no summarization)'), condense: bool = typer.Option(False, '--condense', help='Condense whitespace (collapse large blank runs, trim trailing spaces) before counting tokens'), remove_comments: bool = typer.Option(False, '--remove-comments', help='Strip comments (heuristic, language-aware) before counting tokens'), docstring_weight: Optional[float] = typer.Option(None, '--docstring-weight', min=0.0, max=1.0, help='Weight for including docstrings in summaries (0=never, 0.5=balanced, 1.0=always)'), no_summarize_imports: bool = typer.Option(False, '--no-summarize-imports', help='Disable import summarization (show all imports verbatim)'), session: Optional[str] = typer.Option(None, '--session', '-s', help='Use session for stateful context building'), estimate_cost: bool = typer.Option(False, '--estimate-cost', help='Show token usage and cost estimate'), show_stats: bool = typer.Option(False, '--stats', help='Show statistics about context generation'), verbose: bool = typer.Option(False, '--verbose', '-v', help='Show detailed debug information including keyword matching'), copy: bool = typer.Option(False, '--copy', help='Copy distilled context to clipboard (also enabled automatically if config.output.copy_on_distill)'))\n</code></pre> <p>Distill relevant context from your codebase for any prompt.</p> <p>This command extracts and aggregates the most relevant files, documentation, and git history based on your query, optimizing for LLM token limits.</p> <p>Examples:</p> Text Only<pre><code># Basic usage\ntenets distill \"implement OAuth2 authentication\"\n\n# From a GitHub issue\ntenets distill https://github.com/org/repo/issues/123\n\n# Specific path with options\ntenets distill \"add caching layer\" ./src --mode thorough --max-tokens 50000\n\n# Filter by file types\ntenets distill \"review API\" --include \"*.py,*.yaml\" --exclude \"test_*\"\n\n# Save to file with cost estimate\ntenets distill \"debug login\" -o context.md --model gpt-4o --estimate-cost\n</code></pre>"},{"location":"api/tenets/cli/commands/examine/","title":"Examine","text":""},{"location":"api/tenets/cli/commands/examine/#tenets.cli.commands.examine","title":"tenets.cli.commands.examine","text":"<p>Examine command implementation.</p> <p>This module provides a Typer-compatible <code>examine</code> app that performs comprehensive code examination including complexity analysis, metrics calculation, hotspot detection, ownership analysis, and multiple output formats. Tests import the exported <code>examine</code> symbol and invoke it directly using Typer's CliRunner, so we expose a Typer app via a callback rather than a bare Click command.</p>"},{"location":"api/tenets/cli/commands/examine/#tenets.cli.commands.examine-classes","title":"Classes","text":""},{"location":"api/tenets/cli/commands/examine/#tenets.cli.commands.examine-functions","title":"Functions","text":""},{"location":"api/tenets/cli/commands/examine/#tenets.cli.commands.examine.run","title":"run","text":"Python<pre><code>run(path: str = typer.Argument('.', help='Path to analyze'), output: Optional[str] = typer.Option(None, '--output', '-o', help='Output file for report'), output_format: str = typer.Option('terminal', '--format', '-f', help='Output format'), metrics: List[str] = typer.Option([], '--metrics', '-m', help='Specific metrics to calculate', show_default=False), threshold: int = typer.Option(10, '--threshold', '-t', help='Complexity threshold'), include: List[str] = typer.Option([], '--include', '-i', help='File patterns to include', show_default=False), exclude: List[str] = typer.Option([], '--exclude', '-e', help='File patterns to exclude', show_default=False), include_minified: bool = typer.Option(False, '--include-minified', help='Include minified/built files (*.min.js, dist/, etc.) normally excluded'), max_depth: int = typer.Option(5, '--max-depth', help='Maximum directory depth'), show_details: bool = typer.Option(False, '--show-details', help='Show details'), hotspots: bool = typer.Option(False, '--hotspots', help='Include hotspot analysis'), ownership: bool = typer.Option(False, '--ownership', help='Include ownership analysis'), complexity_trend: bool = typer.Option(False, '--complexity-trend', help='Include complexity trend hook in results (experimental)'))\n</code></pre> <p>Typer app callback for the examine command.</p> <p>This mirrors the legacy Click command interface while ensuring compatibility with Typer's testing harness.</p>"},{"location":"api/tenets/cli/commands/examine/#tenets.cli.commands.examine.generate_auto_filename","title":"generate_auto_filename","text":"Python<pre><code>generate_auto_filename(path: str, format: str, timestamp: Optional[datetime] = None) -&gt; str\n</code></pre> <p>Generate an automatic filename for reports.</p> PARAMETER DESCRIPTION <code>path</code> <p>The path that was examined</p> <p> TYPE: <code>str</code> </p> <code>format</code> <p>The output format (html, json, markdown, etc.)</p> <p> TYPE: <code>str</code> </p> <code>timestamp</code> <p>Optional timestamp to use (defaults to current time)</p> <p> TYPE: <code>Optional[datetime]</code> DEFAULT: <code>None</code> </p> RETURNS DESCRIPTION <code>str</code> <p>Generated filename like: tenets_report_{path}_{timestamp}.{format}</p>"},{"location":"api/tenets/cli/commands/instill/","title":"Instill","text":""},{"location":"api/tenets/cli/commands/instill/#tenets.cli.commands.instill","title":"tenets.cli.commands.instill","text":"<p>Instill command - Smart injection of guiding principles into context.</p> <p>This command provides comprehensive control over tenet injection including: - Multiple injection frequency modes (always, periodic, adaptive, manual) - Session-aware injection tracking - Complexity analysis for smart injection - History and statistics viewing - Export capabilities for analysis</p>"},{"location":"api/tenets/cli/commands/instill/#tenets.cli.commands.instill-classes","title":"Classes","text":""},{"location":"api/tenets/cli/commands/instill/#tenets.cli.commands.instill-functions","title":"Functions","text":""},{"location":"api/tenets/cli/commands/instill/#tenets.cli.commands.instill.instill","title":"instill","text":"Python<pre><code>instill(session: Optional[str] = typer.Option(None, '--session', '-s', help='Target session for instillation'), force: bool = typer.Option(False, '--force', '-f', help='Force injection regardless of frequency settings'), frequency: Optional[str] = typer.Option(None, '--frequency', help='Override injection frequency (always/periodic/adaptive/manual)'), interval: Optional[int] = typer.Option(None, '--interval', help='Override injection interval for periodic mode'), dry_run: bool = typer.Option(False, '--dry-run', help='Show what would be instilled without applying'), analyze: bool = typer.Option(False, '--analyze', help='Analyze injection patterns and effectiveness'), stats: bool = typer.Option(False, '--stats', help='Show injection statistics'), list_pending: bool = typer.Option(False, '--list-pending', help='List pending tenets and exit'), list_history: bool = typer.Option(False, '--list-history', help='Show injection history for session'), list_sessions: bool = typer.Option(False, '--list-sessions', help='List all tracked sessions'), add_file: Optional[list[str]] = typer.Option(None, '--add-file', '-F', help='Pin a file for future distill operations (can be passed multiple times)'), add_folder: Optional[list[str]] = typer.Option(None, '--add-folder', '-D', help='Pin all files in a folder (respects .gitignore)'), remove_file: Optional[list[str]] = typer.Option(None, '--remove-file', help='Unpin a file from the session'), list_pinned: bool = typer.Option(False, '--list-pinned', help='List pinned files for the session and exit'), reset_session: bool = typer.Option(False, '--reset-session', help='Reset injection history for the session'), clear_all_sessions: bool = typer.Option(False, '--clear-all-sessions', help='Clear all session histories (requires confirmation)'), export_history: Optional[Path] = typer.Option(None, '--export-history', help='Export injection history to file (JSON or CSV)'), export_format: str = typer.Option('json', '--export-format', help='Format for export (json/csv)'), set_frequency: Optional[str] = typer.Option(None, '--set-frequency', help='Set default injection frequency and save to config'), set_interval: Optional[int] = typer.Option(None, '--set-interval', help='Set default injection interval and save to config'), show_config: bool = typer.Option(False, '--show-config', help='Show current injection configuration'), ctx: Context = typer.Context)\n</code></pre> <p>Smart injection of guiding principles (tenets) into your context.</p> <p>This command manages the injection of tenets with intelligent frequency control, session tracking, and complexity-aware adaptation. Tenets are strategically placed to maintain consistent coding principles across AI interactions.</p> INJECTION MODES <p>always   - Inject into every distilled context periodic - Inject every Nth distillation adaptive - Smart injection based on complexity manual   - Only inject when forced</p> Text Only<pre><code># Standard injection (uses configured frequency)\ntenets instill\n\n# Force injection regardless of frequency\ntenets instill --force\n\n# Session-specific injection\ntenets instill --session oauth-work\n\n# Set injection to every 5th distill\ntenets instill --set-frequency periodic --set-interval 5\n\n# View injection statistics\ntenets instill --stats --session oauth-work\n\n# Analyze effectiveness\ntenets instill --analyze\n\n# Pin files for guaranteed inclusion\ntenets instill --add-file src/core.py --session main\n\n# Export history for analysis\ntenets instill --export-history analysis.json\n\n# Reset session tracking\ntenets instill --reset-session --session oauth-work\n</code></pre>"},{"location":"api/tenets/cli/commands/momentum/","title":"Momentum","text":""},{"location":"api/tenets/cli/commands/momentum/#tenets.cli.commands.momentum","title":"tenets.cli.commands.momentum","text":"<p>Momentum command implementation.</p> <p>This command tracks and visualizes development velocity and team momentum metrics over time.</p>"},{"location":"api/tenets/cli/commands/momentum/#tenets.cli.commands.momentum-classes","title":"Classes","text":""},{"location":"api/tenets/cli/commands/momentum/#tenets.cli.commands.momentum-functions","title":"Functions","text":""},{"location":"api/tenets/cli/commands/momentum/#tenets.cli.commands.momentum.run","title":"run","text":"Python<pre><code>run(path: str = typer.Argument('.', help='Repository directory'), period: str = typer.Option('week', '--period', '-p', help='Time period (day, week, sprint, month)'), duration: int = typer.Option(12, '--duration', '-d', help='Number of periods to analyze'), sprint_length: int = typer.Option(14, '--sprint-length', help='Sprint length in days'), since: Optional[str] = typer.Option(None, '--since', '-s', help='Start date (YYYY-MM-DD, relative like \"3 weeks ago\", or keyword like \"sprint-start\")'), until: Optional[str] = typer.Option(None, '--until', '-u', help='End date (YYYY-MM-DD, relative like \"today\"/\"now\")'), output: Optional[str] = typer.Option(None, '--output', '-o', help='Output file for report'), output_format: str = typer.Option('terminal', '--format', '-f', help='Output format'), metrics: List[str] = typer.Option([], '--metrics', '-m', help='Metrics to track', show_default=False), team: bool = typer.Option(False, '--team', help='Show team metrics'), burndown: bool = typer.Option(False, '--burndown', help='Show burndown chart'), forecast: bool = typer.Option(False, '--forecast', help='Include velocity forecast'))\n</code></pre> <p>Track development momentum and velocity.</p> <p>Analyzes repository activity to measure development velocity, team productivity, and momentum trends over time.</p> <p>Examples:</p> <p>tenets momentum tenets momentum --period=sprint --duration=6 tenets momentum --burndown --team tenets momentum --forecast --format=html --output=velocity.html</p>"},{"location":"api/tenets/cli/commands/rank/","title":"Rank","text":""},{"location":"api/tenets/cli/commands/rank/#tenets.cli.commands.rank","title":"tenets.cli.commands.rank","text":"<p>Rank command - show ranked files without content.</p> <p>This module provides the rank command for the tenets CLI, which allows users to see which files are most relevant to their query without displaying the actual content of those files. This is useful for previewing what would be included in a full distill operation or for generating file lists for automation.</p>"},{"location":"api/tenets/cli/commands/rank/#tenets.cli.commands.rank-classes","title":"Classes","text":""},{"location":"api/tenets/cli/commands/rank/#tenets.cli.commands.rank-functions","title":"Functions","text":""},{"location":"api/tenets/cli/commands/rank/#tenets.cli.commands.rank.rank","title":"rank","text":"Python<pre><code>rank(prompt: str = typer.Argument(..., help='Your query or task to rank files against'), path: Path = typer.Argument(Path(), help='Path to analyze (directory or files)'), format: str = typer.Option('markdown', '--format', '-f', help='Output format: markdown, json, xml, html, tree'), output: Optional[Path] = typer.Option(None, '--output', '-o', help='Save output to file instead of stdout'), mode: str = typer.Option('balanced', '--mode', '-m', help='Ranking mode: fast (keyword only), balanced (TF-IDF + structure), thorough (deep analysis)'), top: Optional[int] = typer.Option(None, '--top', '-t', help='Show only top N files'), min_score: Optional[float] = typer.Option(None, '--min-score', help='Minimum relevance score (0.0-1.0)'), max_files: Optional[int] = typer.Option(None, '--max-files', help='Maximum number of files to show'), tree_view: bool = typer.Option(False, '--tree', help='Show results as directory tree'), show_scores: bool = typer.Option(True, '--scores/--no-scores', help='Show relevance scores'), show_factors: bool = typer.Option(False, '--factors', help='Show ranking factor breakdown'), show_path: str = typer.Option('relative', '--path-style', help='Path display: relative, absolute, name'), include: Optional[str] = typer.Option(None, '--include', '-i', help=\"Include file patterns (e.g., '*.py,*.js')\"), exclude: Optional[str] = typer.Option(None, '--exclude', '-e', help=\"Exclude file patterns (e.g., 'test_*,*.backup')\"), include_tests: bool = typer.Option(False, '--include-tests', help='Include test files'), exclude_tests: bool = typer.Option(False, '--exclude-tests', help='Explicitly exclude test files'), no_git: bool = typer.Option(False, '--no-git', help='Disable git signals in ranking'), session: Optional[str] = typer.Option(None, '--session', '-s', help='Use session for stateful ranking'), show_stats: bool = typer.Option(False, '--stats', help='Show ranking statistics'), verbose: bool = typer.Option(False, '--verbose', '-v', help='Show detailed debug information'), copy: bool = typer.Option(False, '--copy', help='Copy file list to clipboard')) -&gt; None\n</code></pre> <p>Rank files by relevance without showing their content.</p> <p>This command runs the same intelligent ranking as 'distill' but only shows the list of relevant files, their scores, and optionally the ranking factors. Useful for understanding what files would be included in context or for feeding file lists to other tools.</p> PARAMETER DESCRIPTION <code>prompt</code> <p>The query or task to rank files against.</p> <p> TYPE: <code>str</code> DEFAULT: <code>Argument(..., help='Your query or task to rank files against')</code> </p> <code>path</code> <p>Path to analyze (directory or files).</p> <p> TYPE: <code>Path</code> DEFAULT: <code>Argument(Path(), help='Path to analyze (directory or files)')</code> </p> <code>format</code> <p>Output format (markdown, json, xml, html, tree).</p> <p> TYPE: <code>str</code> DEFAULT: <code>Option('markdown', '--format', '-f', help='Output format: markdown, json, xml, html, tree')</code> </p> <code>output</code> <p>Optional file path to save output.</p> <p> TYPE: <code>Optional[Path]</code> DEFAULT: <code>Option(None, '--output', '-o', help='Save output to file instead of stdout')</code> </p> <code>mode</code> <p>Ranking algorithm mode (fast, balanced, thorough).</p> <p> TYPE: <code>str</code> DEFAULT: <code>Option('balanced', '--mode', '-m', help='Ranking mode: fast (keyword only), balanced (TF-IDF + structure), thorough (deep analysis)')</code> </p> <code>top</code> <p>Show only top N files.</p> <p> TYPE: <code>Optional[int]</code> DEFAULT: <code>Option(None, '--top', '-t', help='Show only top N files')</code> </p> <code>min_score</code> <p>Minimum relevance score threshold (0.0-1.0).</p> <p> TYPE: <code>Optional[float]</code> DEFAULT: <code>Option(None, '--min-score', help='Minimum relevance score (0.0-1.0)')</code> </p> <code>max_files</code> <p>Maximum number of files to display.</p> <p> TYPE: <code>Optional[int]</code> DEFAULT: <code>Option(None, '--max-files', help='Maximum number of files to show')</code> </p> <code>tree_view</code> <p>Whether to show results as directory tree.</p> <p> TYPE: <code>bool</code> DEFAULT: <code>Option(False, '--tree', help='Show results as directory tree')</code> </p> <code>show_scores</code> <p>Whether to display relevance scores.</p> <p> TYPE: <code>bool</code> DEFAULT: <code>Option(True, '--scores/--no-scores', help='Show relevance scores')</code> </p> <code>show_factors</code> <p>Whether to show ranking factor breakdown.</p> <p> TYPE: <code>bool</code> DEFAULT: <code>Option(False, '--factors', help='Show ranking factor breakdown')</code> </p> <code>show_path</code> <p>Path display style (relative, absolute, name).</p> <p> TYPE: <code>str</code> DEFAULT: <code>Option('relative', '--path-style', help='Path display: relative, absolute, name')</code> </p> <code>include</code> <p>Include file patterns (comma-separated).</p> <p> TYPE: <code>Optional[str]</code> DEFAULT: <code>Option(None, '--include', '-i', help=\"Include file patterns (e.g., '*.py,*.js')\")</code> </p> <code>exclude</code> <p>Exclude file patterns (comma-separated).</p> <p> TYPE: <code>Optional[str]</code> DEFAULT: <code>Option(None, '--exclude', '-e', help=\"Exclude file patterns (e.g., 'test_*,*.backup')\")</code> </p> <code>include_tests</code> <p>Whether to include test files.</p> <p> TYPE: <code>bool</code> DEFAULT: <code>Option(False, '--include-tests', help='Include test files')</code> </p> <code>exclude_tests</code> <p>Whether to explicitly exclude test files.</p> <p> TYPE: <code>bool</code> DEFAULT: <code>Option(False, '--exclude-tests', help='Explicitly exclude test files')</code> </p> <code>no_git</code> <p>Whether to disable git signals in ranking.</p> <p> TYPE: <code>bool</code> DEFAULT: <code>Option(False, '--no-git', help='Disable git signals in ranking')</code> </p> <code>session</code> <p>Optional session name for stateful ranking.</p> <p> TYPE: <code>Optional[str]</code> DEFAULT: <code>Option(None, '--session', '-s', help='Use session for stateful ranking')</code> </p> <code>show_stats</code> <p>Whether to show ranking statistics.</p> <p> TYPE: <code>bool</code> DEFAULT: <code>Option(False, '--stats', help='Show ranking statistics')</code> </p> <code>verbose</code> <p>Whether to show detailed debug information.</p> <p> TYPE: <code>bool</code> DEFAULT: <code>Option(False, '--verbose', '-v', help='Show detailed debug information')</code> </p> <code>copy</code> <p>Whether to copy file list to clipboard.</p> <p> TYPE: <code>bool</code> DEFAULT: <code>Option(False, '--copy', help='Copy file list to clipboard')</code> </p> RETURNS DESCRIPTION <code>None</code> <p>None</p> RAISES DESCRIPTION <code>SystemExit</code> <p>On error with exit code 1.</p> <p>Examples:</p>"},{"location":"api/tenets/cli/commands/rank/#tenets.cli.commands.rank.rank--show-top-10-most-relevant-files","title":"Show top 10 most relevant files","text":"<p>tenets rank \"implement OAuth2\" --top 10</p>"},{"location":"api/tenets/cli/commands/rank/#tenets.cli.commands.rank.rank--show-files-above-a-score-threshold","title":"Show files above a score threshold","text":"<p>tenets rank \"fix bug\" . --min-score 0.3</p>"},{"location":"api/tenets/cli/commands/rank/#tenets.cli.commands.rank.rank--tree-view-with-ranking-factors","title":"Tree view with ranking factors","text":"<p>tenets rank \"add caching\" --tree --factors</p>"},{"location":"api/tenets/cli/commands/rank/#tenets.cli.commands.rank.rank--export-as-json-for-automation","title":"Export as JSON for automation","text":"<p>tenets rank \"review API\" --format json -o ranked_files.json</p>"},{"location":"api/tenets/cli/commands/rank/#tenets.cli.commands.rank.rank--quick-file-list-to-clipboard","title":"Quick file list to clipboard","text":"<p>tenets rank \"database queries\" --top 20 --copy --no-scores</p>"},{"location":"api/tenets/cli/commands/session/","title":"Session","text":""},{"location":"api/tenets/cli/commands/session/#tenets.cli.commands.session","title":"tenets.cli.commands.session","text":"<p>Session management commands.</p>"},{"location":"api/tenets/cli/commands/session/#tenets.cli.commands.session-classes","title":"Classes","text":""},{"location":"api/tenets/cli/commands/session/#tenets.cli.commands.session-functions","title":"Functions","text":""},{"location":"api/tenets/cli/commands/session/#tenets.cli.commands.session.create","title":"create","text":"Python<pre><code>create(name: str = typer.Argument(..., help='Session name'))\n</code></pre> <p>Create a new session or activate it if it already exists.</p>"},{"location":"api/tenets/cli/commands/session/#tenets.cli.commands.session.start","title":"start","text":"Python<pre><code>start(name: str = typer.Argument(..., help='Session name'))\n</code></pre> <p>Start (create or activate) a session (alias of create).</p>"},{"location":"api/tenets/cli/commands/session/#tenets.cli.commands.session.list_cmd","title":"list_cmd","text":"Python<pre><code>list_cmd()\n</code></pre> <p>List sessions.</p>"},{"location":"api/tenets/cli/commands/session/#tenets.cli.commands.session.show","title":"show","text":"Python<pre><code>show(name: str = typer.Argument(..., help='Session name'))\n</code></pre> <p>Show session details.</p>"},{"location":"api/tenets/cli/commands/session/#tenets.cli.commands.session.delete","title":"delete","text":"Python<pre><code>delete(name: str = typer.Argument(..., help='Session name'), keep_context: bool = typer.Option(False, '--keep-context', help='Do not delete stored context artifacts'))\n</code></pre> <p>Delete a session (and its stored context unless --keep-context).</p>"},{"location":"api/tenets/cli/commands/session/#tenets.cli.commands.session.clear_all","title":"clear_all","text":"Python<pre><code>clear_all(keep_context: bool = typer.Option(False, '--keep-context', help='Keep artifacts'))\n</code></pre> <p>Delete ALL sessions (optionally keep artifacts).</p>"},{"location":"api/tenets/cli/commands/session/#tenets.cli.commands.session.add_context","title":"add_context","text":"Python<pre><code>add_context(name: str = typer.Argument(..., help='Session name'), kind: str = typer.Argument(..., help='Content kind tag (e.g. note, context_result)'), file: FileText = typer.Argument(..., help='File whose content to attach'))\n</code></pre> <p>Attach arbitrary content file to a session (stored as text).</p>"},{"location":"api/tenets/cli/commands/session/#tenets.cli.commands.session.reset_session","title":"reset_session","text":"Python<pre><code>reset_session(name: str = typer.Argument(..., help='Session name'))\n</code></pre> <p>Reset (delete and recreate) a session and purge its context.</p>"},{"location":"api/tenets/cli/commands/session/#tenets.cli.commands.session.resume","title":"resume","text":"Python<pre><code>resume(name: Optional[str] = typer.Argument(None, help='Session name (optional)'))\n</code></pre> <p>Mark a session as active (load/resume existing session).</p> <p>If NAME is omitted, resumes the most recently active session.</p>"},{"location":"api/tenets/cli/commands/session/#tenets.cli.commands.session.exit_session","title":"exit_session","text":"Python<pre><code>exit_session(name: Optional[str] = typer.Argument(None, help='Session name (optional)'))\n</code></pre> <p>Mark a session as inactive (exit/end session).</p> <p>If NAME is omitted, exits the current active session.</p>"},{"location":"api/tenets/cli/commands/session/#tenets.cli.commands.session.save_session","title":"save_session","text":"Python<pre><code>save_session(new_name: str = typer.Argument(..., help='New name for the session'), from_session: Optional[str] = typer.Option(None, '--from', '-f', help='Source session to save from (default: current/default session)'), delete_source: bool = typer.Option(False, '--delete-source', help='Delete the source session after saving'))\n</code></pre> <p>Save a session with a new name (useful for saving default/temporary sessions).</p> <p>This command copies an existing session (including all its metadata, pinned files, tenets, and context) to a new session with the specified name.</p> <p>Examples:</p>"},{"location":"api/tenets/cli/commands/session/#tenets.cli.commands.session.save_session--save-the-default-session-with-a-custom-name","title":"Save the default session with a custom name","text":"<p>tenets session save my-feature</p>"},{"location":"api/tenets/cli/commands/session/#tenets.cli.commands.session.save_session--save-a-specific-session-with-a-new-name","title":"Save a specific session with a new name","text":"<p>tenets session save production-fix --from debug-session</p>"},{"location":"api/tenets/cli/commands/session/#tenets.cli.commands.session.save_session--save-and-clean-up-the-original","title":"Save and clean up the original","text":"<p>tenets session save final-version --from default --delete-source</p>"},{"location":"api/tenets/cli/commands/system_instruction/","title":"System Instruction","text":""},{"location":"api/tenets/cli/commands/system_instruction/#tenets.cli.commands.system_instruction","title":"tenets.cli.commands.system_instruction","text":"<p>System instruction command - Manage the system instruction/prompt.</p>"},{"location":"api/tenets/cli/commands/system_instruction/#tenets.cli.commands.system_instruction-classes","title":"Classes","text":""},{"location":"api/tenets/cli/commands/system_instruction/#tenets.cli.commands.system_instruction-functions","title":"Functions","text":""},{"location":"api/tenets/cli/commands/system_instruction/#tenets.cli.commands.system_instruction.set_instruction","title":"set_instruction","text":"Python<pre><code>set_instruction(instruction: Optional[str] = typer.Argument(None, help='System instruction text'), file: Optional[Path] = typer.Option(None, '--file', '-f', help='Read from file'), enable: bool = typer.Option(True, '--enable/--disable', help='Enable auto-injection'), position: Optional[str] = typer.Option(None, '--position', help='Injection position'), format: Optional[str] = typer.Option(None, '--format', help='Format type'), save: bool = typer.Option(True, '--save/--no-save', help='Save to config'))\n</code></pre> <p>Set the system instruction that will be injected at session start.</p> <p>Examples:</p>"},{"location":"api/tenets/cli/commands/system_instruction/#tenets.cli.commands.system_instruction.set_instruction--set-directly","title":"Set directly","text":"<p>tenets system-instruction set \"You are a helpful coding assistant\"</p>"},{"location":"api/tenets/cli/commands/system_instruction/#tenets.cli.commands.system_instruction.set_instruction--set-from-file","title":"Set from file","text":"<p>tenets system-instruction set --file system_prompt.md</p>"},{"location":"api/tenets/cli/commands/system_instruction/#tenets.cli.commands.system_instruction.set_instruction--set-with-options","title":"Set with options","text":"<p>tenets system-instruction set \"Context here\" --position after_header --format xml</p>"},{"location":"api/tenets/cli/commands/system_instruction/#tenets.cli.commands.system_instruction.set_instruction--disable-auto-injection","title":"Disable auto-injection","text":"<p>tenets system-instruction set --disable</p>"},{"location":"api/tenets/cli/commands/system_instruction/#tenets.cli.commands.system_instruction.show_instruction","title":"show_instruction","text":"Python<pre><code>show_instruction(raw: bool = typer.Option(False, '--raw', help='Show raw text without formatting'))\n</code></pre> <p>Show the current system instruction.</p> <p>Examples:</p> <p>tenets system-instruction show tenets system-instruction show --raw</p>"},{"location":"api/tenets/cli/commands/system_instruction/#tenets.cli.commands.system_instruction.clear_instruction","title":"clear_instruction","text":"Python<pre><code>clear_instruction(confirm: bool = typer.Option(False, '--yes', '-y', help='Skip confirmation'))\n</code></pre> <p>Clear the system instruction.</p> <p>Examples:</p> <p>tenets system-instruction clear tenets system-instruction clear --yes</p>"},{"location":"api/tenets/cli/commands/system_instruction/#tenets.cli.commands.system_instruction.export_instruction","title":"export_instruction","text":"Python<pre><code>export_instruction(output: Path = typer.Argument(..., help='Output file path'))\n</code></pre> <p>Export system instruction to file.</p> <p>Examples:</p> <p>tenets system-instruction export system_prompt.txt tenets system-instruction export prompts/main.md</p>"},{"location":"api/tenets/cli/commands/system_instruction/#tenets.cli.commands.system_instruction.validate_instruction","title":"validate_instruction","text":"Python<pre><code>validate_instruction(check_tokens: bool = typer.Option(False, '--tokens', help='Check token count'), max_tokens: int = typer.Option(1000, '--max-tokens', help='Maximum allowed tokens'))\n</code></pre> <p>Validate the current system instruction.</p> <p>Examples:</p> <p>tenets system-instruction validate tenets system-instruction validate --tokens --max-tokens 500</p>"},{"location":"api/tenets/cli/commands/system_instruction/#tenets.cli.commands.system_instruction.edit_instruction","title":"edit_instruction","text":"Python<pre><code>edit_instruction(editor: Optional[str] = typer.Option(None, '--editor', '-e', help='Editor to use'))\n</code></pre> <p>Open system instruction in editor for editing.</p> <p>Examples:</p> <p>tenets system-instruction edit tenets system-instruction edit --editor vim tenets system-instruction edit -e nano</p>"},{"location":"api/tenets/cli/commands/tenet/","title":"Tenet","text":""},{"location":"api/tenets/cli/commands/tenet/#tenets.cli.commands.tenet","title":"tenets.cli.commands.tenet","text":"<p>Tenet management commands.</p>"},{"location":"api/tenets/cli/commands/tenet/#tenets.cli.commands.tenet-functions","title":"Functions","text":""},{"location":"api/tenets/cli/commands/tenet/#tenets.cli.commands.tenet.get_tenet_manager","title":"get_tenet_manager","text":"Python<pre><code>get_tenet_manager()\n</code></pre> <p>Get or create a lightweight tenet manager without loading heavy ML dependencies.</p>"},{"location":"api/tenets/cli/commands/tenet/#tenets.cli.commands.tenet.add_tenet","title":"add_tenet","text":"Python<pre><code>add_tenet(content: str = typer.Argument(..., help='The guiding principle to add'), priority: str = typer.Option('medium', '--priority', '-p', help='Priority level: low, medium, high, critical'), category: Optional[str] = typer.Option(None, '--category', '-c', help='Category: architecture, security, style, performance, testing, etc.'), session: Optional[str] = typer.Option(None, '--session', '-s', help='Bind to specific session'))\n</code></pre> <p>Add a new guiding principle (tenet).</p> <p>Examples:</p> <p>tenets tenet add \"Always use type hints in Python\"</p> <p>tenets tenet add \"Validate all user inputs\" --priority high --category security</p> <p>tenets tenet add \"Use async/await for I/O\" --session feature-x</p>"},{"location":"api/tenets/cli/commands/tenet/#tenets.cli.commands.tenet.list_tenets","title":"list_tenets","text":"Python<pre><code>list_tenets(pending: bool = typer.Option(False, '--pending', help='Show only pending tenets'), instilled: bool = typer.Option(False, '--instilled', help='Show only instilled tenets'), session: Optional[str] = typer.Option(None, '--session', '-s', help='Filter by session'), category: Optional[str] = typer.Option(None, '--category', '-c', help='Filter by category'), verbose: bool = typer.Option(False, '--verbose', '-v', help='Show full content'))\n</code></pre> <p>List all tenets (guiding principles).</p> <p>Examples:</p> <p>tenets tenet list                    # All tenets tenets tenet list --pending          # Only pending tenets tenet list --session oauth    # Session specific tenets tenet list --category security --verbose</p>"},{"location":"api/tenets/cli/commands/tenet/#tenets.cli.commands.tenet.remove_tenet","title":"remove_tenet","text":"Python<pre><code>remove_tenet(id: str = typer.Argument(..., help='Tenet ID to remove (can be partial)'), force: bool = typer.Option(False, '--force', '-f', help='Skip confirmation'))\n</code></pre> <p>Remove a tenet.</p> <p>Examples:</p> <p>tenets tenet remove abc123 tenets tenet remove abc123 --force</p>"},{"location":"api/tenets/cli/commands/tenet/#tenets.cli.commands.tenet.show_tenet","title":"show_tenet","text":"Python<pre><code>show_tenet(id: str = typer.Argument(..., help='Tenet ID to show (can be partial)'))\n</code></pre> <p>Show details of a specific tenet.</p> <p>Examples:</p> <p>tenets tenet show abc123</p>"},{"location":"api/tenets/cli/commands/tenet/#tenets.cli.commands.tenet.export_tenets","title":"export_tenets","text":"Python<pre><code>export_tenets(output: Optional[Path] = typer.Option(None, '--output', '-o', help='Output file'), format: str = typer.Option('yaml', '--format', '-f', help='Format: yaml or json'), session: Optional[str] = typer.Option(None, '--session', '-s', help='Export session-specific tenets'), include_archived: bool = typer.Option(False, '--include-archived', help='Include archived tenets'))\n</code></pre> <p>Export tenets to a file.</p> <p>Examples:</p> <p>tenets tenet export                           # To stdout tenets tenet export -o my-tenets.yml          # To file tenets tenet export --format json --session oauth</p>"},{"location":"api/tenets/cli/commands/tenet/#tenets.cli.commands.tenet.import_tenets","title":"import_tenets","text":"Python<pre><code>import_tenets(file: Path = typer.Argument(..., help='File to import tenets from'), session: Optional[str] = typer.Option(None, '--session', '-s', help='Import into specific session'), dry_run: bool = typer.Option(False, '--dry-run', help='Preview what would be imported'))\n</code></pre> <p>Import tenets from a file.</p> <p>Examples:</p> <p>tenets tenet import my-tenets.yml tenets tenet import team-principles.json --session feature-x tenets tenet import standards.yml --dry-run</p>"},{"location":"api/tenets/cli/commands/viz/","title":"Viz","text":""},{"location":"api/tenets/cli/commands/viz/#tenets.cli.commands.viz","title":"tenets.cli.commands.viz","text":"<p>Viz command implementation.</p> <p>This command provides visualization capabilities for codebase analysis, including dependency graphs, complexity visualizations, and more.</p>"},{"location":"api/tenets/cli/commands/viz/#tenets.cli.commands.viz-classes","title":"Classes","text":""},{"location":"api/tenets/cli/commands/viz/#tenets.cli.commands.viz-functions","title":"Functions","text":""},{"location":"api/tenets/cli/commands/viz/#tenets.cli.commands.viz.setup_verbose_logging","title":"setup_verbose_logging","text":"Python<pre><code>setup_verbose_logging(verbose: bool, command_name: str = '') -&gt; bool\n</code></pre> <p>Setup verbose logging, checking both command flag and global context.</p> RETURNS DESCRIPTION <code>bool</code> <p>True if verbose mode is enabled</p>"},{"location":"api/tenets/cli/commands/viz/#tenets.cli.commands.viz.deps","title":"deps","text":"Python<pre><code>deps(path: str = typer.Argument('.', help='Path to analyze (use quotes for globs, e.g., **/*.py)'), output: Optional[str] = typer.Option(None, '--output', '-o', help='Output file (e.g., architecture.svg)'), format: str = typer.Option('ascii', '--format', '-f', help='Output format (ascii, svg, png, html, json, dot)'), level: str = typer.Option('file', '--level', '-l', help='Dependency level (file, module, package)'), cluster_by: Optional[str] = typer.Option(None, '--cluster-by', help='Cluster nodes by (directory, module, package)'), max_nodes: Optional[int] = typer.Option(None, '--max-nodes', help='Maximum number of nodes to display'), include: Optional[str] = typer.Option(None, '--include', '-i', help='Include file patterns'), exclude: Optional[str] = typer.Option(None, '--exclude', '-e', help='Exclude file patterns'), layout: str = typer.Option('hierarchical', '--layout', help='Graph layout (hierarchical, circular, shell, kamada)'), include_minified: bool = typer.Option(False, '--include-minified', help='Include minified files'), verbose: bool = typer.Option(False, '--verbose', '-v', help='Enable verbose/debug output'))\n</code></pre> <p>Visualize dependencies between files and modules.</p> <p>Automatically detects project type (Python, Node.js, Java, Go, etc.) and generates dependency graphs in multiple formats.</p> <p>Examples:</p> <p>tenets viz deps                              # Auto-detect and show ASCII tree tenets viz deps . --output arch.svg          # Generate SVG dependency graph tenets viz deps --format html -o deps.html   # Interactive HTML visualization tenets viz deps --level module                # Module-level dependencies tenets viz deps --level package --cluster-by package  # Package architecture tenets viz deps --layout circular --max-nodes 50      # Circular layout tenets viz deps src/ --include \".py\" --exclude \"*test\"  # Filter files</p> Install visualization libraries <p>pip install tenets[viz]  # For SVG, PNG, HTML support</p>"},{"location":"api/tenets/cli/commands/viz/#tenets.cli.commands.viz.complexity","title":"complexity","text":"Python<pre><code>complexity(path: str = typer.Argument('.', help='Path to analyze'), output: Optional[str] = typer.Option(None, '--output', '-o', help='Output file'), format: str = typer.Option('ascii', '--format', '-f', help='Output format (ascii, svg, png, html)'), threshold: Optional[int] = typer.Option(None, '--threshold', help='Minimum complexity threshold'), hotspots: bool = typer.Option(False, '--hotspots', help='Show only hotspot files'), include: Optional[str] = typer.Option(None, '--include', '-i', help='Include file patterns'), exclude: Optional[str] = typer.Option(None, '--exclude', '-e', help='Exclude file patterns'), include_minified: bool = typer.Option(False, '--include-minified', help='Include minified/built files (*.min.js, dist/, etc.) normally excluded'), verbose: bool = typer.Option(False, '--verbose', '-v', help='Enable verbose/debug output'))\n</code></pre> <p>Visualize code complexity metrics.</p> <p>Examples:</p> <p>tenets viz complexity              # ASCII bar chart tenets viz complexity --threshold 10 --hotspots  # High complexity only tenets viz complexity --output complexity.png    # Save as image</p>"},{"location":"api/tenets/cli/commands/viz/#tenets.cli.commands.viz.data","title":"data","text":"Python<pre><code>data(input_file: str = typer.Argument(help='Data file to visualize (JSON/CSV)'), chart: Optional[str] = typer.Option(None, '--chart', '-c', help='Chart type'), output: Optional[str] = typer.Option(None, '--output', '-o', help='Output file'), format: str = typer.Option('terminal', '--format', '-f', help='Output format'), title: Optional[str] = typer.Option(None, '--title', help='Chart title'), verbose: bool = typer.Option(False, '--verbose', '-v', help='Enable verbose/debug output'))\n</code></pre> <p>Create visualizations from data files.</p> <p>This command generates visualizations from pre-analyzed data files without needing to re-run analysis.</p>"},{"location":"api/tenets/cli/commands/viz/#tenets.cli.commands.viz.aggregate_dependencies","title":"aggregate_dependencies","text":"Python<pre><code>aggregate_dependencies(dependency_graph: Dict[str, List[str]], level: str, project_info: Dict) -&gt; Dict[str, List[str]]\n</code></pre> <p>Aggregate file-level dependencies to module or package level.</p> PARAMETER DESCRIPTION <code>dependency_graph</code> <p>File-level dependency graph</p> <p> TYPE: <code>Dict[str, List[str]]</code> </p> <code>level</code> <p>Aggregation level (module or package)</p> <p> TYPE: <code>str</code> </p> <code>project_info</code> <p>Project detection information</p> <p> TYPE: <code>Dict</code> </p> RETURNS DESCRIPTION <code>Dict[str, List[str]]</code> <p>Aggregated dependency graph</p>"},{"location":"api/tenets/cli/commands/viz/#tenets.cli.commands.viz.get_aggregate_key","title":"get_aggregate_key","text":"Python<pre><code>get_aggregate_key(path_str: str, level: str, project_info: Dict) -&gt; str\n</code></pre> <p>Get the aggregate key for a path based on the specified level.</p> PARAMETER DESCRIPTION <code>path_str</code> <p>File path or module name</p> <p> TYPE: <code>str</code> </p> <code>level</code> <p>Aggregation level (module or package)</p> <p> TYPE: <code>str</code> </p> <code>project_info</code> <p>Project information for context</p> <p> TYPE: <code>Dict</code> </p> RETURNS DESCRIPTION <code>str</code> <p>Aggregate key string</p>"},{"location":"api/tenets/core/analysis/analyzer/","title":"Analyzer","text":""},{"location":"api/tenets/core/analysis/analyzer/#tenets.core.analysis.analyzer","title":"tenets.core.analysis.analyzer","text":"<p>Main code analyzer orchestrator for Tenets.</p> <p>This module coordinates language-specific analyzers and provides a unified interface for analyzing source code files. It handles analyzer selection, caching, parallel processing, and fallback strategies.</p>"},{"location":"api/tenets/core/analysis/analyzer/#tenets.core.analysis.analyzer-classes","title":"Classes","text":""},{"location":"api/tenets/core/analysis/analyzer/#tenets.core.analysis.analyzer.CodeAnalyzer","title":"CodeAnalyzer","text":"Python<pre><code>CodeAnalyzer(config: TenetsConfig)\n</code></pre> <p>Main code analysis orchestrator.</p> <p>Coordinates language-specific analyzers and provides a unified interface for analyzing source code files. Handles caching, parallel processing, analyzer selection, and fallback strategies.</p> ATTRIBUTE DESCRIPTION <code>config</code> <p>TenetsConfig instance for configuration</p> <p> </p> <code>logger</code> <p>Logger instance for logging</p> <p> </p> <code>cache</code> <p>AnalysisCache for caching analysis results</p> <p> </p> <code>analyzers</code> <p>Dictionary mapping file extensions to analyzer instances</p> <p> </p> <code>stats</code> <p>Analysis statistics and metrics</p> <p> </p> <p>Initialize the code analyzer.</p> PARAMETER DESCRIPTION <code>config</code> <p>Tenets configuration object</p> <p> TYPE: <code>TenetsConfig</code> </p>"},{"location":"api/tenets/core/analysis/analyzer/#tenets.core.analysis.analyzer.CodeAnalyzer-functions","title":"Functions","text":""},{"location":"api/tenets/core/analysis/analyzer/#tenets.core.analysis.analyzer.CodeAnalyzer.analyze_file","title":"analyze_file","text":"Python<pre><code>analyze_file(file_path: Path, deep: bool = False, extract_keywords: bool = True, use_cache: bool = True, progress_callback: Optional[Callable] = None) -&gt; FileAnalysis\n</code></pre> <p>Analyze a single file.</p> <p>Performs language-specific analysis on a file, extracting imports, structure, complexity metrics, and other relevant information.</p> PARAMETER DESCRIPTION <code>file_path</code> <p>Path to the file to analyze</p> <p> TYPE: <code>Path</code> </p> <code>deep</code> <p>Whether to perform deep analysis (AST parsing, etc.)</p> <p> TYPE: <code>bool</code> DEFAULT: <code>False</code> </p> <code>extract_keywords</code> <p>Whether to extract keywords from content</p> <p> TYPE: <code>bool</code> DEFAULT: <code>True</code> </p> <code>use_cache</code> <p>Whether to use cached results if available</p> <p> TYPE: <code>bool</code> DEFAULT: <code>True</code> </p> <code>progress_callback</code> <p>Optional callback for progress updates</p> <p> TYPE: <code>Optional[Callable]</code> DEFAULT: <code>None</code> </p> RETURNS DESCRIPTION <code>FileAnalysis</code> <p>FileAnalysis object with complete analysis results</p> RAISES DESCRIPTION <code>FileNotFoundError</code> <p>If file doesn't exist</p> <code>PermissionError</code> <p>If file cannot be read</p>"},{"location":"api/tenets/core/analysis/analyzer/#tenets.core.analysis.analyzer.CodeAnalyzer.analyze_files","title":"analyze_files","text":"Python<pre><code>analyze_files(file_paths: list[Path], deep: bool = False, parallel: bool = True, progress_callback: Optional[Callable] = None) -&gt; list[FileAnalysis]\n</code></pre> <p>Analyze multiple files.</p> PARAMETER DESCRIPTION <code>file_paths</code> <p>List of file paths to analyze</p> <p> TYPE: <code>list[Path]</code> </p> <code>deep</code> <p>Whether to perform deep analysis</p> <p> TYPE: <code>bool</code> DEFAULT: <code>False</code> </p> <code>parallel</code> <p>Whether to analyze files in parallel</p> <p> TYPE: <code>bool</code> DEFAULT: <code>True</code> </p> <code>progress_callback</code> <p>Optional callback for progress updates</p> <p> TYPE: <code>Optional[Callable]</code> DEFAULT: <code>None</code> </p> RETURNS DESCRIPTION <code>list[FileAnalysis]</code> <p>List of FileAnalysis objects</p>"},{"location":"api/tenets/core/analysis/analyzer/#tenets.core.analysis.analyzer.CodeAnalyzer.analyze_project","title":"analyze_project","text":"Python<pre><code>analyze_project(project_path: Path, patterns: Optional[list[str]] = None, exclude_patterns: Optional[list[str]] = None, deep: bool = True, parallel: bool = True, progress_callback: Optional[Callable] = None) -&gt; ProjectAnalysis\n</code></pre> <p>Analyze an entire project.</p> PARAMETER DESCRIPTION <code>project_path</code> <p>Path to the project root</p> <p> TYPE: <code>Path</code> </p> <code>patterns</code> <p>File patterns to include (e.g., ['.py', '.js'])</p> <p> TYPE: <code>Optional[list[str]]</code> DEFAULT: <code>None</code> </p> <code>exclude_patterns</code> <p>File patterns to exclude</p> <p> TYPE: <code>Optional[list[str]]</code> DEFAULT: <code>None</code> </p> <code>deep</code> <p>Whether to perform deep analysis</p> <p> TYPE: <code>bool</code> DEFAULT: <code>True</code> </p> <code>parallel</code> <p>Whether to analyze files in parallel</p> <p> TYPE: <code>bool</code> DEFAULT: <code>True</code> </p> <code>progress_callback</code> <p>Optional callback for progress updates</p> <p> TYPE: <code>Optional[Callable]</code> DEFAULT: <code>None</code> </p> RETURNS DESCRIPTION <code>ProjectAnalysis</code> <p>ProjectAnalysis object with complete project analysis</p>"},{"location":"api/tenets/core/analysis/analyzer/#tenets.core.analysis.analyzer.CodeAnalyzer.generate_report","title":"generate_report","text":"Python<pre><code>generate_report(analysis: Union[FileAnalysis, ProjectAnalysis, list[FileAnalysis]], format: str = 'json', output_path: Optional[Path] = None) -&gt; AnalysisReport\n</code></pre> <p>Generate an analysis report.</p> PARAMETER DESCRIPTION <code>analysis</code> <p>Analysis results to report on</p> <p> TYPE: <code>Union[FileAnalysis, ProjectAnalysis, list[FileAnalysis]]</code> </p> <code>format</code> <p>Report format ('json', 'html', 'markdown', 'csv')</p> <p> TYPE: <code>str</code> DEFAULT: <code>'json'</code> </p> <code>output_path</code> <p>Optional path to save the report</p> <p> TYPE: <code>Optional[Path]</code> DEFAULT: <code>None</code> </p> RETURNS DESCRIPTION <code>AnalysisReport</code> <p>AnalysisReport object</p>"},{"location":"api/tenets/core/analysis/analyzer/#tenets.core.analysis.analyzer.CodeAnalyzer.shutdown","title":"shutdown","text":"Python<pre><code>shutdown()\n</code></pre> <p>Shutdown the analyzer and clean up resources.</p>"},{"location":"api/tenets/core/analysis/analyzer/#tenets.core.analysis.analyzer-functions","title":"Functions","text":""},{"location":"api/tenets/core/analysis/base/","title":"Base","text":""},{"location":"api/tenets/core/analysis/base/#tenets.core.analysis.base","title":"tenets.core.analysis.base","text":"<p>Base abstract class for language-specific code analyzers.</p> <p>This module provides the abstract base class that all language-specific analyzers must implement. It defines the common interface for extracting imports, exports, structure, and calculating complexity metrics.</p>"},{"location":"api/tenets/core/analysis/base/#tenets.core.analysis.base-classes","title":"Classes","text":""},{"location":"api/tenets/core/analysis/base/#tenets.core.analysis.base.LanguageAnalyzer","title":"LanguageAnalyzer","text":"<p>               Bases: <code>ABC</code></p> <p>Abstract base class for language-specific analyzers.</p> <p>Each language analyzer must implement this interface to provide language-specific analysis capabilities. This ensures a consistent API across all language analyzers while allowing for language-specific implementation details.</p> ATTRIBUTE DESCRIPTION <code>language_name</code> <p>Name of the programming language</p> <p> TYPE: <code>str</code> </p> <code>file_extensions</code> <p>List of file extensions this analyzer handles</p> <p> TYPE: <code>List[str]</code> </p> <code>entry_points</code> <p>Common entry point filenames for this language</p> <p> TYPE: <code>List[str]</code> </p> <code>project_indicators</code> <p>Framework/project type indicators</p> <p> TYPE: <code>Dict[str, List[str]]</code> </p>"},{"location":"api/tenets/core/analysis/base/#tenets.core.analysis.base.LanguageAnalyzer-functions","title":"Functions","text":""},{"location":"api/tenets/core/analysis/base/#tenets.core.analysis.base.LanguageAnalyzer.extract_imports","title":"extract_imports  <code>abstractmethod</code>","text":"Python<pre><code>extract_imports(content: str, file_path: Path) -&gt; List[ImportInfo]\n</code></pre> <p>Extract import statements from source code.</p> <p>This method should identify and extract all import/include/require statements from the source code, including their type, location, and whether they are relative imports.</p> PARAMETER DESCRIPTION <code>content</code> <p>Source code content as string</p> <p> TYPE: <code>str</code> </p> <code>file_path</code> <p>Path to the file being analyzed</p> <p> TYPE: <code>Path</code> </p> RETURNS DESCRIPTION <code>List[ImportInfo]</code> <p>List of ImportInfo objects containing: - module: The imported module/package name - alias: Any alias assigned to the import - line: Line number of the import - type: Type of import (e.g., 'import', 'from', 'require') - is_relative: Whether this is a relative import - Additional language-specific fields</p> <p>Examples:</p>"},{"location":"api/tenets/core/analysis/base/#tenets.core.analysis.base.LanguageAnalyzer.extract_exports","title":"extract_exports  <code>abstractmethod</code>","text":"Python<pre><code>extract_exports(content: str, file_path: Path) -&gt; List[Dict[str, Any]]\n</code></pre> <p>Extract exported symbols from source code.</p> <p>This method should identify all symbols (functions, classes, variables) that are exported from the module and available for use by other modules.</p> PARAMETER DESCRIPTION <code>content</code> <p>Source code content as string</p> <p> TYPE: <code>str</code> </p> <code>file_path</code> <p>Path to the file being analyzed</p> <p> TYPE: <code>Path</code> </p> RETURNS DESCRIPTION <code>List[Dict[str, Any]]</code> <p>List of dictionaries containing: - name: Name of the exported symbol - type: Type of export (e.g., 'function', 'class', 'variable') - line: Line number where the export is defined - Additional language-specific metadata</p> <p>Examples:</p>"},{"location":"api/tenets/core/analysis/base/#tenets.core.analysis.base.LanguageAnalyzer.extract_structure","title":"extract_structure  <code>abstractmethod</code>","text":"Python<pre><code>extract_structure(content: str, file_path: Path) -&gt; CodeStructure\n</code></pre> <p>Extract code structure from source file.</p> <p>This method should parse the source code and extract structural elements like classes, functions, methods, variables, constants, and other language-specific constructs.</p> PARAMETER DESCRIPTION <code>content</code> <p>Source code content as string</p> <p> TYPE: <code>str</code> </p> <code>file_path</code> <p>Path to the file being analyzed</p> <p> TYPE: <code>Path</code> </p> RETURNS DESCRIPTION <code>CodeStructure</code> <p>CodeStructure object containing: - classes: List of ClassInfo objects - functions: List of FunctionInfo objects - variables: List of variable definitions - constants: List of constant definitions - interfaces: List of interface definitions (if applicable) - Additional language-specific structures</p> Note <p>The depth of extraction depends on the language's parsing capabilities. AST-based parsing provides more detail than regex-based parsing.</p>"},{"location":"api/tenets/core/analysis/base/#tenets.core.analysis.base.LanguageAnalyzer.calculate_complexity","title":"calculate_complexity  <code>abstractmethod</code>","text":"Python<pre><code>calculate_complexity(content: str, file_path: Path) -&gt; ComplexityMetrics\n</code></pre> <p>Calculate complexity metrics for the source code.</p> <p>This method should calculate various complexity metrics including cyclomatic complexity, cognitive complexity, and other relevant metrics for understanding code complexity and maintainability.</p> PARAMETER DESCRIPTION <code>content</code> <p>Source code content as string</p> <p> TYPE: <code>str</code> </p> <code>file_path</code> <p>Path to the file being analyzed</p> <p> TYPE: <code>Path</code> </p> RETURNS DESCRIPTION <code>ComplexityMetrics</code> <p>ComplexityMetrics object containing: - cyclomatic: McCabe cyclomatic complexity - cognitive: Cognitive complexity score - halstead: Halstead complexity metrics (if calculated) - line_count: Total number of lines - function_count: Number of functions/methods - class_count: Number of classes - max_depth: Maximum nesting depth - maintainability_index: Maintainability index score - Additional language-specific metrics</p> Complexity Calculation"},{"location":"api/tenets/core/analysis/base/#tenets.core.analysis.base.LanguageAnalyzer.analyze","title":"analyze","text":"Python<pre><code>analyze(content: str, file_path: Path) -&gt; Dict[str, Any]\n</code></pre> <p>Run complete analysis on source file.</p> <p>This method orchestrates all analysis methods to provide a complete analysis of the source file. It can be overridden by specific analyzers if they need custom orchestration logic.</p> PARAMETER DESCRIPTION <code>content</code> <p>Source code content as string</p> <p> TYPE: <code>str</code> </p> <code>file_path</code> <p>Path to the file being analyzed</p> <p> TYPE: <code>Path</code> </p> RETURNS DESCRIPTION <code>Dict[str, Any]</code> <p>Dictionary containing all analysis results: - imports: List of ImportInfo objects - exports: List of export dictionaries - structure: CodeStructure object - complexity: ComplexityMetrics object - Additional analysis results</p> Note <p>Subclasses can override this method to add language-specific analysis steps or modify the analysis pipeline.</p>"},{"location":"api/tenets/core/analysis/base/#tenets.core.analysis.base.LanguageAnalyzer.supports_file","title":"supports_file","text":"Python<pre><code>supports_file(file_path: Path) -&gt; bool\n</code></pre> <p>Check if this analyzer supports the given file.</p> PARAMETER DESCRIPTION <code>file_path</code> <p>Path to the file to check</p> <p> TYPE: <code>Path</code> </p> RETURNS DESCRIPTION <code>bool</code> <p>True if this analyzer can handle the file, False otherwise</p>"},{"location":"api/tenets/core/analysis/base/#tenets.core.analysis.base.LanguageAnalyzer.get_language_info","title":"get_language_info","text":"Python<pre><code>get_language_info() -&gt; Dict[str, Any]\n</code></pre> <p>Get information about the language this analyzer supports.</p> RETURNS DESCRIPTION <code>Dict[str, Any]</code> <p>Dictionary containing: - name: Language name - extensions: Supported file extensions - features: List of supported analysis features</p>"},{"location":"api/tenets/core/analysis/project_detector/","title":"Project Detector","text":""},{"location":"api/tenets/core/analysis/project_detector/#tenets.core.analysis.project_detector","title":"tenets.core.analysis.project_detector","text":"<p>Project type detection and entry point discovery.</p> <p>This module provides intelligent detection of project types, main entry points, and project structure based on language analyzers and file patterns.</p>"},{"location":"api/tenets/core/analysis/project_detector/#tenets.core.analysis.project_detector-classes","title":"Classes","text":""},{"location":"api/tenets/core/analysis/project_detector/#tenets.core.analysis.project_detector.ProjectDetector","title":"ProjectDetector","text":"Python<pre><code>ProjectDetector()\n</code></pre> <p>Detects project type and structure using language analyzers.</p> <p>This class leverages the language-specific analyzers to detect project types and entry points, avoiding duplication of language-specific knowledge.</p> <p>Initialize project detector with language analyzers.</p>"},{"location":"api/tenets/core/analysis/project_detector/#tenets.core.analysis.project_detector.ProjectDetector-functions","title":"Functions","text":""},{"location":"api/tenets/core/analysis/project_detector/#tenets.core.analysis.project_detector.ProjectDetector.detect_project_type","title":"detect_project_type","text":"Python<pre><code>detect_project_type(path: Path) -&gt; Dict[str, any]\n</code></pre> <p>Detect project type and main entry points.</p> PARAMETER DESCRIPTION <code>path</code> <p>Root directory to analyze</p> <p> TYPE: <code>Path</code> </p> RETURNS DESCRIPTION <code>Dict[str, any]</code> <p>Dictionary containing: - type: Primary project type - languages: List of detected languages - frameworks: List of detected frameworks - entry_points: List of likely entry point files - confidence: Confidence score (0-1)</p>"},{"location":"api/tenets/core/analysis/project_detector/#tenets.core.analysis.project_detector.ProjectDetector.find_main_file","title":"find_main_file","text":"Python<pre><code>find_main_file(path: Path) -&gt; Optional[Path]\n</code></pre> <p>Find the most likely main/entry file in a project.</p> PARAMETER DESCRIPTION <code>path</code> <p>Directory to search in</p> <p> TYPE: <code>Path</code> </p> RETURNS DESCRIPTION <code>Optional[Path]</code> <p>Path to the main file, or None if not found</p>"},{"location":"api/tenets/core/analysis/project_detector/#tenets.core.analysis.project_detector-functions","title":"Functions","text":""},{"location":"api/tenets/core/analysis/implementations/cpp_analyzer/","title":"Cpp Analyzer","text":""},{"location":"api/tenets/core/analysis/implementations/cpp_analyzer/#tenets.core.analysis.implementations.cpp_analyzer","title":"tenets.core.analysis.implementations.cpp_analyzer","text":"<p>C/C++ code analyzer.</p> <p>This module provides comprehensive analysis for C and C++ source files, including headers, templates, and modern C++ features.</p>"},{"location":"api/tenets/core/analysis/implementations/cpp_analyzer/#tenets.core.analysis.implementations.cpp_analyzer-classes","title":"Classes","text":""},{"location":"api/tenets/core/analysis/implementations/cpp_analyzer/#tenets.core.analysis.implementations.cpp_analyzer.CppAnalyzer","title":"CppAnalyzer","text":"Python<pre><code>CppAnalyzer()\n</code></pre> <p>               Bases: <code>LanguageAnalyzer</code></p> <p>C/C++ code analyzer.</p> <p>Provides analysis for C and C++ files including: - Include directive analysis (system and local) - Class, struct, and union extraction - Template analysis - Function and method extraction - Namespace handling - Macro and preprocessor directive analysis - Modern C++ features (auto, lambdas, smart pointers) - STL usage detection - Memory management patterns</p> <p>Supports both C and C++ with appropriate feature detection.</p> <p>Initialize the C++ analyzer with logger.</p>"},{"location":"api/tenets/core/analysis/implementations/cpp_analyzer/#tenets.core.analysis.implementations.cpp_analyzer.CppAnalyzer-functions","title":"Functions","text":""},{"location":"api/tenets/core/analysis/implementations/cpp_analyzer/#tenets.core.analysis.implementations.cpp_analyzer.CppAnalyzer.extract_imports","title":"extract_imports","text":"Python<pre><code>extract_imports(content: str, file_path: Path) -&gt; List[ImportInfo]\n</code></pre> <p>Extract includes from C/C++ code.</p> <p>Handles: - System includes: #include  - Local includes: #include \"myheader.h\" - Conditional includes with #ifdef - Include guards PARAMETER DESCRIPTION <code>content</code> <p>C/C++ source code</p> <p> TYPE: <code>str</code> </p> <code>file_path</code> <p>Path to the file being analyzed</p> <p> TYPE: <code>Path</code> </p> RETURNS DESCRIPTION <code>List[ImportInfo]</code> <p>List of ImportInfo objects representing includes</p>"},{"location":"api/tenets/core/analysis/implementations/cpp_analyzer/#tenets.core.analysis.implementations.cpp_analyzer.CppAnalyzer.extract_exports","title":"extract_exports","text":"Python<pre><code>extract_exports(content: str, file_path: Path) -&gt; List[Dict[str, Any]]\n</code></pre> <p>Extract exported symbols from C/C++ code.</p> <p>In C/C++, symbols are exported by default unless static. For headers, we extract declarations. For source files, we extract non-static definitions.</p> PARAMETER DESCRIPTION <code>content</code> <p>C/C++ source code</p> <p> TYPE: <code>str</code> </p> <code>file_path</code> <p>Path to the file being analyzed</p> <p> TYPE: <code>Path</code> </p> RETURNS DESCRIPTION <code>List[Dict[str, Any]]</code> <p>List of exported symbols</p>"},{"location":"api/tenets/core/analysis/implementations/cpp_analyzer/#tenets.core.analysis.implementations.cpp_analyzer.CppAnalyzer.extract_structure","title":"extract_structure","text":"Python<pre><code>extract_structure(content: str, file_path: Path) -&gt; CodeStructure\n</code></pre> <p>Extract code structure from C/C++ file.</p> <p>Extracts: - Namespaces - Classes and structs with inheritance - Functions and methods - Templates - Macros and preprocessor directives - Global variables - Operator overloads</p> PARAMETER DESCRIPTION <code>content</code> <p>C/C++ source code</p> <p> TYPE: <code>str</code> </p> <code>file_path</code> <p>Path to the file being analyzed</p> <p> TYPE: <code>Path</code> </p> RETURNS DESCRIPTION <code>CodeStructure</code> <p>CodeStructure object with extracted elements</p>"},{"location":"api/tenets/core/analysis/implementations/cpp_analyzer/#tenets.core.analysis.implementations.cpp_analyzer.CppAnalyzer.calculate_complexity","title":"calculate_complexity","text":"Python<pre><code>calculate_complexity(content: str, file_path: Path) -&gt; ComplexityMetrics\n</code></pre> <p>Calculate complexity metrics for C/C++ code.</p> <p>Calculates: - Cyclomatic complexity - Cognitive complexity - Preprocessor complexity - Template complexity - Memory management complexity</p> PARAMETER DESCRIPTION <code>content</code> <p>C/C++ source code</p> <p> TYPE: <code>str</code> </p> <code>file_path</code> <p>Path to the file being analyzed</p> <p> TYPE: <code>Path</code> </p> RETURNS DESCRIPTION <code>ComplexityMetrics</code> <p>ComplexityMetrics object with calculated metrics</p>"},{"location":"api/tenets/core/analysis/implementations/cpp_analyzer/#tenets.core.analysis.implementations.cpp_analyzer-functions","title":"Functions","text":""},{"location":"api/tenets/core/analysis/implementations/csharp_analyzer/","title":"Csharp Analyzer","text":""},{"location":"api/tenets/core/analysis/implementations/csharp_analyzer/#tenets.core.analysis.implementations.csharp_analyzer","title":"tenets.core.analysis.implementations.csharp_analyzer","text":"<p>C# code analyzer with Unity3D support.</p> <p>This module provides comprehensive analysis for C# source files, including support for modern C# features, .NET patterns, and Unity3D specific constructs like MonoBehaviours, Coroutines, and Unity attributes.</p>"},{"location":"api/tenets/core/analysis/implementations/csharp_analyzer/#tenets.core.analysis.implementations.csharp_analyzer-classes","title":"Classes","text":""},{"location":"api/tenets/core/analysis/implementations/csharp_analyzer/#tenets.core.analysis.implementations.csharp_analyzer.CSharpAnalyzer","title":"CSharpAnalyzer","text":"Python<pre><code>CSharpAnalyzer()\n</code></pre> <p>               Bases: <code>LanguageAnalyzer</code></p> <p>C# code analyzer with Unity3D support.</p> <p>Provides comprehensive analysis for C# files including: - Using directives and namespace analysis - Class, interface, struct, enum, and record extraction - Property and event analysis - Async/await and Task-based patterns - LINQ query detection - Attribute processing - Unity3D specific patterns (MonoBehaviour, Coroutines, etc.) - .NET Framework/Core detection - Nullable reference types (C# 8+) - Pattern matching (C# 7+)</p> <p>Supports modern C# features and Unity3D development patterns.</p> <p>Initialize the C# analyzer with logger.</p>"},{"location":"api/tenets/core/analysis/implementations/csharp_analyzer/#tenets.core.analysis.implementations.csharp_analyzer.CSharpAnalyzer-functions","title":"Functions","text":""},{"location":"api/tenets/core/analysis/implementations/csharp_analyzer/#tenets.core.analysis.implementations.csharp_analyzer.CSharpAnalyzer.extract_imports","title":"extract_imports","text":"Python<pre><code>extract_imports(content: str, file_path: Path) -&gt; List[ImportInfo]\n</code></pre> <p>Extract using directives from C# code.</p> <p>Handles: - using statements: using System.Collections.Generic; - using static: using static System.Math; - using aliases: using Project = PC.MyCompany.Project; - global using (C# 10+): global using System.Text; - Unity-specific usings</p> PARAMETER DESCRIPTION <code>content</code> <p>C# source code</p> <p> TYPE: <code>str</code> </p> <code>file_path</code> <p>Path to the file being analyzed</p> <p> TYPE: <code>Path</code> </p> RETURNS DESCRIPTION <code>List[ImportInfo]</code> <p>List of ImportInfo objects with import details</p>"},{"location":"api/tenets/core/analysis/implementations/csharp_analyzer/#tenets.core.analysis.implementations.csharp_analyzer.CSharpAnalyzer.extract_exports","title":"extract_exports","text":"Python<pre><code>extract_exports(content: str, file_path: Path) -&gt; List[Dict[str, Any]]\n</code></pre> <p>Extract public members from C# code.</p> <p>In C#, public members are accessible from other assemblies. This includes public classes, interfaces, structs, enums, delegates, etc.</p> PARAMETER DESCRIPTION <code>content</code> <p>C# source code</p> <p> TYPE: <code>str</code> </p> <code>file_path</code> <p>Path to the file being analyzed</p> <p> TYPE: <code>Path</code> </p> RETURNS DESCRIPTION <code>List[Dict[str, Any]]</code> <p>List of exported (public) symbols</p>"},{"location":"api/tenets/core/analysis/implementations/csharp_analyzer/#tenets.core.analysis.implementations.csharp_analyzer.CSharpAnalyzer.extract_structure","title":"extract_structure","text":"Python<pre><code>extract_structure(content: str, file_path: Path) -&gt; CodeStructure\n</code></pre> <p>Extract code structure from C# file.</p> <p>Extracts: - Namespace declarations - Classes with inheritance and interfaces - Properties with getters/setters - Methods including async methods - Events and delegates - Unity-specific components (MonoBehaviours, Coroutines) - LINQ queries - Attributes</p> PARAMETER DESCRIPTION <code>content</code> <p>C# source code</p> <p> TYPE: <code>str</code> </p> <code>file_path</code> <p>Path to the file being analyzed</p> <p> TYPE: <code>Path</code> </p> RETURNS DESCRIPTION <code>CodeStructure</code> <p>CodeStructure object with extracted elements</p>"},{"location":"api/tenets/core/analysis/implementations/csharp_analyzer/#tenets.core.analysis.implementations.csharp_analyzer.CSharpAnalyzer.calculate_complexity","title":"calculate_complexity","text":"Python<pre><code>calculate_complexity(content: str, file_path: Path) -&gt; ComplexityMetrics\n</code></pre> <p>Calculate complexity metrics for C# code.</p> <p>Calculates: - Cyclomatic complexity - Cognitive complexity - Unity-specific complexity (Coroutines, Update methods) - Async/await complexity - LINQ complexity - Exception handling complexity</p> PARAMETER DESCRIPTION <code>content</code> <p>C# source code</p> <p> TYPE: <code>str</code> </p> <code>file_path</code> <p>Path to the file being analyzed</p> <p> TYPE: <code>Path</code> </p> RETURNS DESCRIPTION <code>ComplexityMetrics</code> <p>ComplexityMetrics object with calculated metrics</p>"},{"location":"api/tenets/core/analysis/implementations/csharp_analyzer/#tenets.core.analysis.implementations.csharp_analyzer-functions","title":"Functions","text":""},{"location":"api/tenets/core/analysis/implementations/css_analyzer/","title":"Css Analyzer","text":""},{"location":"api/tenets/core/analysis/implementations/css_analyzer/#tenets.core.analysis.implementations.css_analyzer","title":"tenets.core.analysis.implementations.css_analyzer","text":"<p>CSS code analyzer with preprocessor and framework support.</p> <p>This module provides comprehensive analysis for CSS files, including support for CSS3, SCSS/Sass, Less, PostCSS, Tailwind CSS, UnoCSS, and other modern CSS frameworks.</p>"},{"location":"api/tenets/core/analysis/implementations/css_analyzer/#tenets.core.analysis.implementations.css_analyzer-classes","title":"Classes","text":""},{"location":"api/tenets/core/analysis/implementations/css_analyzer/#tenets.core.analysis.implementations.css_analyzer.CSSParser","title":"CSSParser","text":"Python<pre><code>CSSParser(content: str, is_scss: bool = False)\n</code></pre> <p>Custom CSS parser for detailed analysis.</p>"},{"location":"api/tenets/core/analysis/implementations/css_analyzer/#tenets.core.analysis.implementations.css_analyzer.CSSParser-functions","title":"Functions","text":""},{"location":"api/tenets/core/analysis/implementations/css_analyzer/#tenets.core.analysis.implementations.css_analyzer.CSSParser.parse","title":"parse","text":"Python<pre><code>parse()\n</code></pre> <p>Parse CSS/SCSS content.</p>"},{"location":"api/tenets/core/analysis/implementations/css_analyzer/#tenets.core.analysis.implementations.css_analyzer.CSSAnalyzer","title":"CSSAnalyzer","text":"Python<pre><code>CSSAnalyzer()\n</code></pre> <p>               Bases: <code>LanguageAnalyzer</code></p> <p>CSS code analyzer with preprocessor and framework support.</p> <p>Provides comprehensive analysis for CSS files including: - CSS3 features and properties - SCSS/Sass preprocessor features - Less preprocessor features - PostCSS plugins and features - Tailwind CSS utility classes - UnoCSS atomic CSS - CSS-in-JS patterns - CSS Modules - BEM, OOCSS, SMACSS methodologies - Performance metrics - Browser compatibility - Accessibility considerations - Design system patterns</p> <p>Supports modern CSS development practices and frameworks.</p> <p>Initialize the CSS analyzer with logger.</p>"},{"location":"api/tenets/core/analysis/implementations/css_analyzer/#tenets.core.analysis.implementations.css_analyzer.CSSAnalyzer-functions","title":"Functions","text":""},{"location":"api/tenets/core/analysis/implementations/css_analyzer/#tenets.core.analysis.implementations.css_analyzer.CSSAnalyzer.extract_imports","title":"extract_imports","text":"Python<pre><code>extract_imports(content: str, file_path: Path) -&gt; List[ImportInfo]\n</code></pre> <p>Extract import statements from CSS.</p> <p>Handles: - @import statements - @use (Sass) - @forward (Sass) - url() functions - CSS Modules composes</p> PARAMETER DESCRIPTION <code>content</code> <p>CSS source code</p> <p> TYPE: <code>str</code> </p> <code>file_path</code> <p>Path to the file being analyzed</p> <p> TYPE: <code>Path</code> </p> RETURNS DESCRIPTION <code>List[ImportInfo]</code> <p>List of ImportInfo objects with import details</p>"},{"location":"api/tenets/core/analysis/implementations/css_analyzer/#tenets.core.analysis.implementations.css_analyzer.CSSAnalyzer.extract_exports","title":"extract_exports","text":"Python<pre><code>extract_exports(content: str, file_path: Path) -&gt; List[Dict[str, Any]]\n</code></pre> <p>Extract exported elements from CSS.</p> <p>In CSS context, exports are: - Classes that can be used by HTML - IDs - Custom properties (CSS variables) - Mixins (SCSS/Less) - Functions (SCSS) - Keyframe animations - Utility classes (Tailwind/UnoCSS)</p> PARAMETER DESCRIPTION <code>content</code> <p>CSS source code</p> <p> TYPE: <code>str</code> </p> <code>file_path</code> <p>Path to the file being analyzed</p> <p> TYPE: <code>Path</code> </p> RETURNS DESCRIPTION <code>List[Dict[str, Any]]</code> <p>List of exported elements</p>"},{"location":"api/tenets/core/analysis/implementations/css_analyzer/#tenets.core.analysis.implementations.css_analyzer.CSSAnalyzer.extract_structure","title":"extract_structure","text":"Python<pre><code>extract_structure(content: str, file_path: Path) -&gt; CodeStructure\n</code></pre> <p>Extract CSS document structure.</p> <p>Extracts: - Rules and selectors - Media queries - CSS architecture patterns - Framework usage - Design tokens - Component structure</p> PARAMETER DESCRIPTION <code>content</code> <p>CSS source code</p> <p> TYPE: <code>str</code> </p> <code>file_path</code> <p>Path to the file being analyzed</p> <p> TYPE: <code>Path</code> </p> RETURNS DESCRIPTION <code>CodeStructure</code> <p>CodeStructure object with extracted elements</p>"},{"location":"api/tenets/core/analysis/implementations/css_analyzer/#tenets.core.analysis.implementations.css_analyzer.CSSAnalyzer.calculate_complexity","title":"calculate_complexity","text":"Python<pre><code>calculate_complexity(content: str, file_path: Path) -&gt; ComplexityMetrics\n</code></pre> <p>Calculate complexity metrics for CSS.</p> <p>Calculates: - Selector complexity - Specificity metrics - Rule complexity - Nesting depth - Framework complexity - Performance score - Maintainability index</p> PARAMETER DESCRIPTION <code>content</code> <p>CSS source code</p> <p> TYPE: <code>str</code> </p> <code>file_path</code> <p>Path to the file being analyzed</p> <p> TYPE: <code>Path</code> </p> RETURNS DESCRIPTION <code>ComplexityMetrics</code> <p>ComplexityMetrics object with calculated metrics</p>"},{"location":"api/tenets/core/analysis/implementations/css_analyzer/#tenets.core.analysis.implementations.css_analyzer-functions","title":"Functions","text":""},{"location":"api/tenets/core/analysis/implementations/dart_analyzer/","title":"Dart Analyzer","text":""},{"location":"api/tenets/core/analysis/implementations/dart_analyzer/#tenets.core.analysis.implementations.dart_analyzer","title":"tenets.core.analysis.implementations.dart_analyzer","text":"<p>Dart code analyzer with Flutter support.</p> <p>This module provides comprehensive analysis for Dart source files, including support for Flutter-specific patterns, null safety, async programming, and modern Dart features.</p>"},{"location":"api/tenets/core/analysis/implementations/dart_analyzer/#tenets.core.analysis.implementations.dart_analyzer-classes","title":"Classes","text":""},{"location":"api/tenets/core/analysis/implementations/dart_analyzer/#tenets.core.analysis.implementations.dart_analyzer.DartAnalyzer","title":"DartAnalyzer","text":"Python<pre><code>DartAnalyzer()\n</code></pre> <p>               Bases: <code>LanguageAnalyzer</code></p> <p>Dart code analyzer with Flutter support.</p> <p>Provides comprehensive analysis for Dart files including: - Import and export directives - Part and library declarations - Classes with mixins and extensions - Null safety features (?, !, late) - Async/await, Future, and Stream handling - Flutter widgets and lifecycle methods - Factory and named constructors - Extension methods - Annotations and metadata - Generics and type parameters</p> <p>Supports Dart 2.x with null safety and Flutter framework patterns.</p> <p>Initialize the Dart analyzer with logger.</p>"},{"location":"api/tenets/core/analysis/implementations/dart_analyzer/#tenets.core.analysis.implementations.dart_analyzer.DartAnalyzer-functions","title":"Functions","text":""},{"location":"api/tenets/core/analysis/implementations/dart_analyzer/#tenets.core.analysis.implementations.dart_analyzer.DartAnalyzer.extract_imports","title":"extract_imports","text":"Python<pre><code>extract_imports(content: str, file_path: Path) -&gt; List[ImportInfo]\n</code></pre> <p>Extract import, export, part, and library directives from Dart code.</p> <p>Handles: - import statements: import 'package:flutter/material.dart'; - export statements: export 'src/widget.dart'; - part statements: part 'implementation.dart'; - part of statements: part of 'library.dart'; - library declarations: library my_library; - Conditional imports: import 'stub.dart' if (dart.library.io) 'io.dart'; - Show/hide clauses: import 'dart:math' show Random hide PI; - Deferred imports: import 'big_lib.dart' deferred as big;</p> PARAMETER DESCRIPTION <code>content</code> <p>Dart source code</p> <p> TYPE: <code>str</code> </p> <code>file_path</code> <p>Path to the file being analyzed</p> <p> TYPE: <code>Path</code> </p> RETURNS DESCRIPTION <code>List[ImportInfo]</code> <p>List of ImportInfo objects with import details</p>"},{"location":"api/tenets/core/analysis/implementations/dart_analyzer/#tenets.core.analysis.implementations.dart_analyzer.DartAnalyzer.extract_exports","title":"extract_exports","text":"Python<pre><code>extract_exports(content: str, file_path: Path) -&gt; List[Dict[str, Any]]\n</code></pre> <p>Extract exported symbols from Dart code.</p> <p>In Dart, exports include: - Public classes (not prefixed with _) - Public functions - Public variables and constants - Public typedefs - Public enums - Extension methods</p> PARAMETER DESCRIPTION <code>content</code> <p>Dart source code</p> <p> TYPE: <code>str</code> </p> <code>file_path</code> <p>Path to the file being analyzed</p> <p> TYPE: <code>Path</code> </p> RETURNS DESCRIPTION <code>List[Dict[str, Any]]</code> <p>List of exported symbols</p>"},{"location":"api/tenets/core/analysis/implementations/dart_analyzer/#tenets.core.analysis.implementations.dart_analyzer.DartAnalyzer.extract_structure","title":"extract_structure","text":"Python<pre><code>extract_structure(content: str, file_path: Path) -&gt; CodeStructure\n</code></pre> <p>Extract code structure from Dart file.</p> <p>Extracts: - Classes with inheritance, mixins, and interfaces - Constructors (default, named, factory) - Methods and getters/setters - Flutter widgets and lifecycle methods - Async functions and streams - Extension methods - Null safety features - Annotations</p> PARAMETER DESCRIPTION <code>content</code> <p>Dart source code</p> <p> TYPE: <code>str</code> </p> <code>file_path</code> <p>Path to the file being analyzed</p> <p> TYPE: <code>Path</code> </p> RETURNS DESCRIPTION <code>CodeStructure</code> <p>CodeStructure object with extracted elements</p>"},{"location":"api/tenets/core/analysis/implementations/dart_analyzer/#tenets.core.analysis.implementations.dart_analyzer.DartAnalyzer.calculate_complexity","title":"calculate_complexity","text":"Python<pre><code>calculate_complexity(content: str, file_path: Path) -&gt; ComplexityMetrics\n</code></pre> <p>Calculate complexity metrics for Dart code.</p> <p>Calculates: - Cyclomatic complexity - Cognitive complexity - Null safety complexity - Async complexity - Flutter-specific complexity - Class hierarchy depth</p> PARAMETER DESCRIPTION <code>content</code> <p>Dart source code</p> <p> TYPE: <code>str</code> </p> <code>file_path</code> <p>Path to the file being analyzed</p> <p> TYPE: <code>Path</code> </p> RETURNS DESCRIPTION <code>ComplexityMetrics</code> <p>ComplexityMetrics object with calculated metrics</p>"},{"location":"api/tenets/core/analysis/implementations/dart_analyzer/#tenets.core.analysis.implementations.dart_analyzer-functions","title":"Functions","text":""},{"location":"api/tenets/core/analysis/implementations/gdscript_analyzer/","title":"Gdscript Analyzer","text":""},{"location":"api/tenets/core/analysis/implementations/gdscript_analyzer/#tenets.core.analysis.implementations.gdscript_analyzer","title":"tenets.core.analysis.implementations.gdscript_analyzer","text":"<p>GDScript code analyzer for Godot game development.</p> <p>This module provides comprehensive analysis for GDScript source files, including support for Godot-specific features like signals, exports, node references, and engine lifecycle methods.</p>"},{"location":"api/tenets/core/analysis/implementations/gdscript_analyzer/#tenets.core.analysis.implementations.gdscript_analyzer-classes","title":"Classes","text":""},{"location":"api/tenets/core/analysis/implementations/gdscript_analyzer/#tenets.core.analysis.implementations.gdscript_analyzer.GDScriptAnalyzer","title":"GDScriptAnalyzer","text":"Python<pre><code>GDScriptAnalyzer()\n</code></pre> <p>               Bases: <code>LanguageAnalyzer</code></p> <p>GDScript code analyzer for Godot development.</p> <p>Provides comprehensive analysis for GDScript files including: - Preload and load statements - Class inheritance (extends) - Signal declarations and connections - Export variable declarations - Onready variables and node references - Godot lifecycle methods (_ready, _process, etc.) - Tool scripts and custom resources - Typed GDScript (static typing) - Inner classes - Setget properties - Remote and master/puppet keywords (networking)</p> <p>Supports Godot 3.x and 4.x GDScript syntax.</p> <p>Initialize the GDScript analyzer with logger.</p>"},{"location":"api/tenets/core/analysis/implementations/gdscript_analyzer/#tenets.core.analysis.implementations.gdscript_analyzer.GDScriptAnalyzer-functions","title":"Functions","text":""},{"location":"api/tenets/core/analysis/implementations/gdscript_analyzer/#tenets.core.analysis.implementations.gdscript_analyzer.GDScriptAnalyzer.extract_imports","title":"extract_imports","text":"Python<pre><code>extract_imports(content: str, file_path: Path) -&gt; List[ImportInfo]\n</code></pre> <p>Extract preload, load, and class references from GDScript code.</p> <p>Handles: - preload statements: preload(\"res://path/to/script.gd\") - load statements: load(\"res://path/to/resource.tres\") - const preloads: const MyClass = preload(\"res://MyClass.gd\") - class_name declarations (Godot 3.1+) - Tool script declarations</p> PARAMETER DESCRIPTION <code>content</code> <p>GDScript source code</p> <p> TYPE: <code>str</code> </p> <code>file_path</code> <p>Path to the file being analyzed</p> <p> TYPE: <code>Path</code> </p> RETURNS DESCRIPTION <code>List[ImportInfo]</code> <p>List of ImportInfo objects with import details</p>"},{"location":"api/tenets/core/analysis/implementations/gdscript_analyzer/#tenets.core.analysis.implementations.gdscript_analyzer.GDScriptAnalyzer.extract_exports","title":"extract_exports","text":"Python<pre><code>extract_exports(content: str, file_path: Path) -&gt; List[Dict[str, Any]]\n</code></pre> <p>Extract exported symbols from GDScript code.</p> <p>In GDScript, exports include: - class_name declarations (global classes) - export variables - signals - Public functions (by convention, non-underscore prefixed)</p> PARAMETER DESCRIPTION <code>content</code> <p>GDScript source code</p> <p> TYPE: <code>str</code> </p> <code>file_path</code> <p>Path to the file being analyzed</p> <p> TYPE: <code>Path</code> </p> RETURNS DESCRIPTION <code>List[Dict[str, Any]]</code> <p>List of exported symbols</p>"},{"location":"api/tenets/core/analysis/implementations/gdscript_analyzer/#tenets.core.analysis.implementations.gdscript_analyzer.GDScriptAnalyzer.extract_structure","title":"extract_structure","text":"Python<pre><code>extract_structure(content: str, file_path: Path) -&gt; CodeStructure\n</code></pre> <p>Extract code structure from GDScript file.</p> <p>Extracts: - Class inheritance and structure - Inner classes - Functions with type hints - Godot lifecycle methods - Signals and their connections - Export variables - Onready variables - Node references - Setget properties - Enums and constants</p> PARAMETER DESCRIPTION <code>content</code> <p>GDScript source code</p> <p> TYPE: <code>str</code> </p> <code>file_path</code> <p>Path to the file being analyzed</p> <p> TYPE: <code>Path</code> </p> RETURNS DESCRIPTION <code>CodeStructure</code> <p>CodeStructure object with extracted elements</p>"},{"location":"api/tenets/core/analysis/implementations/gdscript_analyzer/#tenets.core.analysis.implementations.gdscript_analyzer.GDScriptAnalyzer.calculate_complexity","title":"calculate_complexity","text":"Python<pre><code>calculate_complexity(content: str, file_path: Path) -&gt; ComplexityMetrics\n</code></pre> <p>Calculate complexity metrics for GDScript code.</p> <p>Calculates: - Cyclomatic complexity - Cognitive complexity - Godot-specific complexity (signals, exports, node references) - Nesting depth - Function count and complexity distribution</p> PARAMETER DESCRIPTION <code>content</code> <p>GDScript source code</p> <p> TYPE: <code>str</code> </p> <code>file_path</code> <p>Path to the file being analyzed</p> <p> TYPE: <code>Path</code> </p> RETURNS DESCRIPTION <code>ComplexityMetrics</code> <p>ComplexityMetrics object with calculated metrics</p>"},{"location":"api/tenets/core/analysis/implementations/gdscript_analyzer/#tenets.core.analysis.implementations.gdscript_analyzer-functions","title":"Functions","text":""},{"location":"api/tenets/core/analysis/implementations/generic_analyzer/","title":"Generic Analyzer","text":""},{"location":"api/tenets/core/analysis/implementations/generic_analyzer/#tenets.core.analysis.implementations.generic_analyzer","title":"tenets.core.analysis.implementations.generic_analyzer","text":"<p>Generic code analyzer for unsupported file types.</p> <p>This module provides basic analysis capabilities for files that don't have a specific language analyzer. It performs text-based analysis and pattern matching to extract basic information. Enhanced with context-aware documentation analysis for smart summarization based on prompt/query relevance.</p>"},{"location":"api/tenets/core/analysis/implementations/generic_analyzer/#tenets.core.analysis.implementations.generic_analyzer-classes","title":"Classes","text":""},{"location":"api/tenets/core/analysis/implementations/generic_analyzer/#tenets.core.analysis.implementations.generic_analyzer.GenericAnalyzer","title":"GenericAnalyzer","text":"Python<pre><code>GenericAnalyzer()\n</code></pre> <p>               Bases: <code>LanguageAnalyzer</code></p> <p>Generic analyzer for unsupported file types.</p> <p>Provides basic analysis for text-based files including: - Line and character counting - Basic pattern matching for imports/includes - Simple complexity estimation - Keyword extraction - Configuration file parsing (JSON, YAML, XML, etc.)</p> <p>This analyzer serves as a fallback for files without specific language support and can handle various text formats.</p> <p>Initialize the generic analyzer with logger.</p>"},{"location":"api/tenets/core/analysis/implementations/generic_analyzer/#tenets.core.analysis.implementations.generic_analyzer.GenericAnalyzer-functions","title":"Functions","text":""},{"location":"api/tenets/core/analysis/implementations/generic_analyzer/#tenets.core.analysis.implementations.generic_analyzer.GenericAnalyzer.extract_imports","title":"extract_imports","text":"Python<pre><code>extract_imports(content: str, file_path: Path) -&gt; List[ImportInfo]\n</code></pre> <p>Extract potential imports/includes from generic text.</p> <p>Looks for common import patterns across various languages and configuration files.</p> PARAMETER DESCRIPTION <code>content</code> <p>File content</p> <p> TYPE: <code>str</code> </p> <code>file_path</code> <p>Path to the file being analyzed</p> <p> TYPE: <code>Path</code> </p> RETURNS DESCRIPTION <code>List[ImportInfo]</code> <p>List of ImportInfo objects with detected imports</p>"},{"location":"api/tenets/core/analysis/implementations/generic_analyzer/#tenets.core.analysis.implementations.generic_analyzer.GenericAnalyzer.extract_exports","title":"extract_exports","text":"Python<pre><code>extract_exports(content: str, file_path: Path) -&gt; List[Dict[str, Any]]\n</code></pre> <p>Extract potential exports from generic text.</p> <p>Looks for common export patterns and definitions.</p> PARAMETER DESCRIPTION <code>content</code> <p>File content</p> <p> TYPE: <code>str</code> </p> <code>file_path</code> <p>Path to the file being analyzed</p> <p> TYPE: <code>Path</code> </p> RETURNS DESCRIPTION <code>List[Dict[str, Any]]</code> <p>List of potential exported symbols</p>"},{"location":"api/tenets/core/analysis/implementations/generic_analyzer/#tenets.core.analysis.implementations.generic_analyzer.GenericAnalyzer.calculate_complexity","title":"calculate_complexity","text":"Python<pre><code>calculate_complexity(content: str, file_path: Path) -&gt; ComplexityMetrics\n</code></pre> <p>Calculate basic complexity metrics for generic text.</p> <p>Provides simplified complexity estimation based on: - Line count and length - Nesting depth (indentation/braces) - Decision keywords - File type specific metrics</p> PARAMETER DESCRIPTION <code>content</code> <p>File content</p> <p> TYPE: <code>str</code> </p> <code>file_path</code> <p>Path to the file being analyzed</p> <p> TYPE: <code>Path</code> </p> RETURNS DESCRIPTION <code>ComplexityMetrics</code> <p>ComplexityMetrics object with basic metrics</p>"},{"location":"api/tenets/core/analysis/implementations/generic_analyzer/#tenets.core.analysis.implementations.generic_analyzer.GenericAnalyzer.extract_structure","title":"extract_structure","text":"Python<pre><code>extract_structure(content: str, file_path: Path) -&gt; CodeStructure\n</code></pre> <p>Extract basic structure from generic text.</p> <p>Attempts to identify structural elements using pattern matching and indentation analysis.</p> PARAMETER DESCRIPTION <code>content</code> <p>File content</p> <p> TYPE: <code>str</code> </p> <code>file_path</code> <p>Path to the file being analyzed</p> <p> TYPE: <code>Path</code> </p> RETURNS DESCRIPTION <code>CodeStructure</code> <p>CodeStructure object with detected elements</p>"},{"location":"api/tenets/core/analysis/implementations/generic_analyzer/#tenets.core.analysis.implementations.generic_analyzer.GenericAnalyzer.extract_context_relevant_sections","title":"extract_context_relevant_sections","text":"Python<pre><code>extract_context_relevant_sections(content: str, file_path: Path, prompt_keywords: List[str], search_depth: int = 2, min_confidence: float = 0.6, max_sections: int = 10) -&gt; Dict[str, Any]\n</code></pre> <p>Extract sections of documentation that reference prompt keywords/concepts.</p> <p>This method identifies and extracts the most relevant parts of documentation files based on direct references and semantic similarity to prompt keywords.</p> PARAMETER DESCRIPTION <code>content</code> <p>File content</p> <p> TYPE: <code>str</code> </p> <code>file_path</code> <p>Path to the file being analyzed</p> <p> TYPE: <code>Path</code> </p> <code>prompt_keywords</code> <p>Keywords/phrases from the user's prompt</p> <p> TYPE: <code>List[str]</code> </p> <code>search_depth</code> <p>How deep to search (1=direct, 2=semantic, 3=deep analysis)</p> <p> TYPE: <code>int</code> DEFAULT: <code>2</code> </p> <code>min_confidence</code> <p>Minimum confidence threshold for relevance (0.0-1.0)</p> <p> TYPE: <code>float</code> DEFAULT: <code>0.6</code> </p> <code>max_sections</code> <p>Maximum number of contextual sections to preserve</p> <p> TYPE: <code>int</code> DEFAULT: <code>10</code> </p> RETURNS DESCRIPTION <code>Dict[str, Any]</code> <p>Dictionary containing relevant sections with metadata</p>"},{"location":"api/tenets/core/analysis/implementations/generic_analyzer/#tenets.core.analysis.implementations.generic_analyzer-functions","title":"Functions","text":""},{"location":"api/tenets/core/analysis/implementations/go_analyzer/","title":"Go Analyzer","text":""},{"location":"api/tenets/core/analysis/implementations/go_analyzer/#tenets.core.analysis.implementations.go_analyzer","title":"tenets.core.analysis.implementations.go_analyzer","text":"<p>Go language code analyzer.</p> <p>This module provides comprehensive analysis for Go source files, including package management, goroutines, channels, and Go-specific patterns.</p>"},{"location":"api/tenets/core/analysis/implementations/go_analyzer/#tenets.core.analysis.implementations.go_analyzer-classes","title":"Classes","text":""},{"location":"api/tenets/core/analysis/implementations/go_analyzer/#tenets.core.analysis.implementations.go_analyzer.GoAnalyzer","title":"GoAnalyzer","text":"Python<pre><code>GoAnalyzer()\n</code></pre> <p>               Bases: <code>LanguageAnalyzer</code></p> <p>Go code analyzer.</p> <p>Provides comprehensive analysis for Go files including: - Import analysis with vendored and internal imports - Function, method and interface extraction - Struct analysis with embedded types - Goroutine and channel detection - Error handling patterns - Defer statement tracking - Package-level analysis - Go module support</p> <p>Go's export mechanism is based on capitalization - identifiers starting with uppercase letters are exported.</p> <p>Initialize the Go analyzer with logger.</p>"},{"location":"api/tenets/core/analysis/implementations/go_analyzer/#tenets.core.analysis.implementations.go_analyzer.GoAnalyzer-functions","title":"Functions","text":""},{"location":"api/tenets/core/analysis/implementations/go_analyzer/#tenets.core.analysis.implementations.go_analyzer.GoAnalyzer.extract_imports","title":"extract_imports","text":"Python<pre><code>extract_imports(content: str, file_path: Path) -&gt; List[ImportInfo]\n</code></pre> <p>Extract imports from Go code.</p> <p>Handles: - Single imports: import \"fmt\" - Grouped imports: import ( \"fmt\" \"strings\" ) - Aliased imports: import f \"fmt\" - Dot imports: import . \"fmt\" - Blank imports: import _ \"database/sql\" - Vendored imports - Internal packages</p> PARAMETER DESCRIPTION <code>content</code> <p>Go source code</p> <p> TYPE: <code>str</code> </p> <code>file_path</code> <p>Path to the file being analyzed</p> <p> TYPE: <code>Path</code> </p> RETURNS DESCRIPTION <code>List[ImportInfo]</code> <p>List of ImportInfo objects with import details</p>"},{"location":"api/tenets/core/analysis/implementations/go_analyzer/#tenets.core.analysis.implementations.go_analyzer.GoAnalyzer.extract_exports","title":"extract_exports","text":"Python<pre><code>extract_exports(content: str, file_path: Path) -&gt; List[Dict[str, Any]]\n</code></pre> <p>Extract exported symbols from Go code.</p> <p>In Go, exported identifiers start with an uppercase letter. This includes functions, types, constants, and variables.</p> PARAMETER DESCRIPTION <code>content</code> <p>Go source code</p> <p> TYPE: <code>str</code> </p> <code>file_path</code> <p>Path to the file being analyzed</p> <p> TYPE: <code>Path</code> </p> RETURNS DESCRIPTION <code>List[Dict[str, Any]]</code> <p>List of exported symbols with metadata</p>"},{"location":"api/tenets/core/analysis/implementations/go_analyzer/#tenets.core.analysis.implementations.go_analyzer.GoAnalyzer.extract_structure","title":"extract_structure","text":"Python<pre><code>extract_structure(content: str, file_path: Path) -&gt; CodeStructure\n</code></pre> <p>Extract code structure from Go file.</p> <p>Extracts: - Package declaration - Functions and methods - Structs (treated as classes) - Interfaces - Type aliases - Constants and variables - Goroutines and channels - Init functions</p> PARAMETER DESCRIPTION <code>content</code> <p>Go source code</p> <p> TYPE: <code>str</code> </p> <code>file_path</code> <p>Path to the file being analyzed</p> <p> TYPE: <code>Path</code> </p> RETURNS DESCRIPTION <code>CodeStructure</code> <p>CodeStructure object with extracted elements</p>"},{"location":"api/tenets/core/analysis/implementations/go_analyzer/#tenets.core.analysis.implementations.go_analyzer.GoAnalyzer.calculate_complexity","title":"calculate_complexity","text":"Python<pre><code>calculate_complexity(content: str, file_path: Path) -&gt; ComplexityMetrics\n</code></pre> <p>Calculate complexity metrics for Go code.</p> <p>Calculates: - Cyclomatic complexity - Cognitive complexity - Error handling complexity - Concurrency complexity - Test coverage indicators</p> PARAMETER DESCRIPTION <code>content</code> <p>Go source code</p> <p> TYPE: <code>str</code> </p> <code>file_path</code> <p>Path to the file being analyzed</p> <p> TYPE: <code>Path</code> </p> RETURNS DESCRIPTION <code>ComplexityMetrics</code> <p>ComplexityMetrics object with calculated metrics</p>"},{"location":"api/tenets/core/analysis/implementations/go_analyzer/#tenets.core.analysis.implementations.go_analyzer-functions","title":"Functions","text":""},{"location":"api/tenets/core/analysis/implementations/html_analyzer/","title":"Html Analyzer","text":""},{"location":"api/tenets/core/analysis/implementations/html_analyzer/#tenets.core.analysis.implementations.html_analyzer","title":"tenets.core.analysis.implementations.html_analyzer","text":"<p>HTML code analyzer with modern web framework support.</p> <p>This module provides comprehensive analysis for HTML files, including support for HTML5, accessibility features, web components, and modern framework patterns.</p>"},{"location":"api/tenets/core/analysis/implementations/html_analyzer/#tenets.core.analysis.implementations.html_analyzer-classes","title":"Classes","text":""},{"location":"api/tenets/core/analysis/implementations/html_analyzer/#tenets.core.analysis.implementations.html_analyzer.HTMLStructureParser","title":"HTMLStructureParser","text":"Python<pre><code>HTMLStructureParser()\n</code></pre> <p>               Bases: <code>HTMLParser</code></p> <p>Custom HTML parser to extract structure information.</p>"},{"location":"api/tenets/core/analysis/implementations/html_analyzer/#tenets.core.analysis.implementations.html_analyzer.HTMLStructureParser-functions","title":"Functions","text":""},{"location":"api/tenets/core/analysis/implementations/html_analyzer/#tenets.core.analysis.implementations.html_analyzer.HTMLStructureParser.handle_starttag","title":"handle_starttag","text":"Python<pre><code>handle_starttag(tag, attrs)\n</code></pre> <p>Handle opening tags.</p>"},{"location":"api/tenets/core/analysis/implementations/html_analyzer/#tenets.core.analysis.implementations.html_analyzer.HTMLStructureParser.handle_endtag","title":"handle_endtag","text":"Python<pre><code>handle_endtag(tag)\n</code></pre> <p>Handle closing tags.</p>"},{"location":"api/tenets/core/analysis/implementations/html_analyzer/#tenets.core.analysis.implementations.html_analyzer.HTMLStructureParser.handle_data","title":"handle_data","text":"Python<pre><code>handle_data(data)\n</code></pre> <p>Handle text content.</p>"},{"location":"api/tenets/core/analysis/implementations/html_analyzer/#tenets.core.analysis.implementations.html_analyzer.HTMLAnalyzer","title":"HTMLAnalyzer","text":"Python<pre><code>HTMLAnalyzer()\n</code></pre> <p>               Bases: <code>LanguageAnalyzer</code></p> <p>HTML code analyzer with modern web framework support.</p> <p>Provides comprehensive analysis for HTML files including: - HTML5 semantic elements - CSS and JavaScript imports - Meta tags and SEO elements - Forms and input validation - Accessibility features (ARIA, alt text, etc.) - Web components and custom elements - Framework-specific patterns (React, Vue, Angular) - Microdata and structured data - DOM complexity and nesting depth - Performance hints (lazy loading, async/defer scripts) - Security considerations (CSP, integrity checks)</p> <p>Supports HTML5 and modern web development practices.</p> <p>Initialize the HTML analyzer with logger.</p>"},{"location":"api/tenets/core/analysis/implementations/html_analyzer/#tenets.core.analysis.implementations.html_analyzer.HTMLAnalyzer-functions","title":"Functions","text":""},{"location":"api/tenets/core/analysis/implementations/html_analyzer/#tenets.core.analysis.implementations.html_analyzer.HTMLAnalyzer.extract_imports","title":"extract_imports","text":"Python<pre><code>extract_imports(content: str, file_path: Path) -&gt; List[ImportInfo]\n</code></pre> <p>Extract external resource imports from HTML.</p> <p>Handles: -  tags for CSS -"},{"location":"api/tenets/core/analysis/implementations/java_analyzer/","title":"Java Analyzer","text":""},{"location":"api/tenets/core/analysis/implementations/java_analyzer/#tenets.core.analysis.implementations.java_analyzer","title":"tenets.core.analysis.implementations.java_analyzer","text":"<p>Java code analyzer.</p> <p>This module provides comprehensive analysis for Java source files, including support for modern Java features, annotations, and frameworks.</p>"},{"location":"api/tenets/core/analysis/implementations/java_analyzer/#tenets.core.analysis.implementations.java_analyzer-classes","title":"Classes","text":""},{"location":"api/tenets/core/analysis/implementations/java_analyzer/#tenets.core.analysis.implementations.java_analyzer.JavaAnalyzer","title":"JavaAnalyzer","text":"Python<pre><code>JavaAnalyzer()\n</code></pre> <p>               Bases: <code>LanguageAnalyzer</code></p> <p>Java code analyzer.</p> <p>Provides comprehensive analysis for Java files including: - Import analysis with static and wildcard imports - Package structure analysis - Class, interface, enum, and record extraction - Annotation processing - Generic type analysis - Method and field extraction with modifiers - Inner and anonymous class detection - Lambda expression support - Framework detection (Spring, JUnit, etc.)</p> <p>Supports modern Java features including records, sealed classes, pattern matching, and text blocks.</p> <p>Initialize the Java analyzer with logger.</p>"},{"location":"api/tenets/core/analysis/implementations/java_analyzer/#tenets.core.analysis.implementations.java_analyzer.JavaAnalyzer-functions","title":"Functions","text":""},{"location":"api/tenets/core/analysis/implementations/java_analyzer/#tenets.core.analysis.implementations.java_analyzer.JavaAnalyzer.extract_imports","title":"extract_imports","text":"Python<pre><code>extract_imports(content: str, file_path: Path) -&gt; List[ImportInfo]\n</code></pre> <p>Extract imports from Java code.</p> <p>Handles: - Standard imports: import java.util.List; - Static imports: import static java.lang.Math.PI; - Wildcard imports: import java.util.; - Static wildcard: import static org.junit.Assert.;</p> PARAMETER DESCRIPTION <code>content</code> <p>Java source code</p> <p> TYPE: <code>str</code> </p> <code>file_path</code> <p>Path to the file being analyzed</p> <p> TYPE: <code>Path</code> </p> RETURNS DESCRIPTION <code>List[ImportInfo]</code> <p>List of ImportInfo objects with import details</p>"},{"location":"api/tenets/core/analysis/implementations/java_analyzer/#tenets.core.analysis.implementations.java_analyzer.JavaAnalyzer.extract_exports","title":"extract_exports","text":"Python<pre><code>extract_exports(content: str, file_path: Path) -&gt; List[Dict[str, Any]]\n</code></pre> <p>Extract public members from Java code.</p> <p>In Java, public members are exported from a class/package. This includes public classes, interfaces, enums, methods, and fields.</p> PARAMETER DESCRIPTION <code>content</code> <p>Java source code</p> <p> TYPE: <code>str</code> </p> <code>file_path</code> <p>Path to the file being analyzed</p> <p> TYPE: <code>Path</code> </p> RETURNS DESCRIPTION <code>List[Dict[str, Any]]</code> <p>List of exported (public) symbols with metadata</p>"},{"location":"api/tenets/core/analysis/implementations/java_analyzer/#tenets.core.analysis.implementations.java_analyzer.JavaAnalyzer.extract_structure","title":"extract_structure","text":"Python<pre><code>extract_structure(content: str, file_path: Path) -&gt; CodeStructure\n</code></pre> <p>Extract code structure from Java file.</p> <p>Extracts: - Package declaration - Classes with inheritance and interfaces - Interfaces with extension - Enums with values - Records (Java 14+) - Methods with full signatures - Fields with types - Annotations - Inner classes - Lambda expressions</p> PARAMETER DESCRIPTION <code>content</code> <p>Java source code</p> <p> TYPE: <code>str</code> </p> <code>file_path</code> <p>Path to the file being analyzed</p> <p> TYPE: <code>Path</code> </p> RETURNS DESCRIPTION <code>CodeStructure</code> <p>CodeStructure object with extracted elements</p>"},{"location":"api/tenets/core/analysis/implementations/java_analyzer/#tenets.core.analysis.implementations.java_analyzer.JavaAnalyzer.calculate_complexity","title":"calculate_complexity","text":"Python<pre><code>calculate_complexity(content: str, file_path: Path) -&gt; ComplexityMetrics\n</code></pre> <p>Calculate complexity metrics for Java code.</p> <p>Calculates: - Cyclomatic complexity - Cognitive complexity - Class coupling - Inheritance depth indicators - Exception handling complexity</p> PARAMETER DESCRIPTION <code>content</code> <p>Java source code</p> <p> TYPE: <code>str</code> </p> <code>file_path</code> <p>Path to the file being analyzed</p> <p> TYPE: <code>Path</code> </p> RETURNS DESCRIPTION <code>ComplexityMetrics</code> <p>ComplexityMetrics object with calculated metrics</p>"},{"location":"api/tenets/core/analysis/implementations/java_analyzer/#tenets.core.analysis.implementations.java_analyzer-functions","title":"Functions","text":""},{"location":"api/tenets/core/analysis/implementations/javascript_analyzer/","title":"Javascript Analyzer","text":""},{"location":"api/tenets/core/analysis/implementations/javascript_analyzer/#tenets.core.analysis.implementations.javascript_analyzer","title":"tenets.core.analysis.implementations.javascript_analyzer","text":"<p>JavaScript and TypeScript code analyzer.</p> <p>This module provides comprehensive analysis for JavaScript and TypeScript files, including ES6+ features, JSX, CommonJS, and TypeScript-specific constructs.</p>"},{"location":"api/tenets/core/analysis/implementations/javascript_analyzer/#tenets.core.analysis.implementations.javascript_analyzer-classes","title":"Classes","text":""},{"location":"api/tenets/core/analysis/implementations/javascript_analyzer/#tenets.core.analysis.implementations.javascript_analyzer.JavaScriptAnalyzer","title":"JavaScriptAnalyzer","text":"Python<pre><code>JavaScriptAnalyzer()\n</code></pre> <p>               Bases: <code>LanguageAnalyzer</code></p> <p>JavaScript/TypeScript code analyzer.</p> <p>Provides analysis for JavaScript and TypeScript files including: - Import/export analysis (ES6 modules and CommonJS) - Function and class extraction (including arrow functions) - React component detection - TypeScript interface and type analysis - Complexity metrics for JS/TS code - Framework detection (React, Vue, Angular) - JSX/TSX support</p> <p>This analyzer uses regex-based parsing optimized for JavaScript's flexible syntax and various module systems.</p> <p>Initialize the JavaScript analyzer with logger.</p>"},{"location":"api/tenets/core/analysis/implementations/javascript_analyzer/#tenets.core.analysis.implementations.javascript_analyzer.JavaScriptAnalyzer-functions","title":"Functions","text":""},{"location":"api/tenets/core/analysis/implementations/javascript_analyzer/#tenets.core.analysis.implementations.javascript_analyzer.JavaScriptAnalyzer.extract_imports","title":"extract_imports","text":"Python<pre><code>extract_imports(content: str, file_path: Path) -&gt; List[ImportInfo]\n</code></pre> <p>Extract imports from JavaScript/TypeScript code.</p> <p>Handles multiple import styles: - ES6 imports: import x from 'module' - Named imports: import { x, y } from 'module' - Namespace imports: import * as x from 'module' - Side-effect imports: import 'module' - Dynamic imports: import('module') - CommonJS: require('module') - TypeScript type imports: import type { X } from 'module'</p> PARAMETER DESCRIPTION <code>content</code> <p>JavaScript/TypeScript source code</p> <p> TYPE: <code>str</code> </p> <code>file_path</code> <p>Path to the file being analyzed</p> <p> TYPE: <code>Path</code> </p> RETURNS DESCRIPTION <code>List[ImportInfo]</code> <p>List of ImportInfo objects with import details</p>"},{"location":"api/tenets/core/analysis/implementations/javascript_analyzer/#tenets.core.analysis.implementations.javascript_analyzer.JavaScriptAnalyzer.extract_exports","title":"extract_exports","text":"Python<pre><code>extract_exports(content: str, file_path: Path) -&gt; List[Dict[str, Any]]\n</code></pre> <p>Extract exports from JavaScript/TypeScript code.</p> <p>Handles multiple export styles: - ES6 default exports - ES6 named exports - ES6 export from - CommonJS module.exports - CommonJS exports.x - TypeScript type exports</p> PARAMETER DESCRIPTION <code>content</code> <p>JavaScript/TypeScript source code</p> <p> TYPE: <code>str</code> </p> <code>file_path</code> <p>Path to the file being analyzed</p> <p> TYPE: <code>Path</code> </p> RETURNS DESCRIPTION <code>List[Dict[str, Any]]</code> <p>List of exported symbols with metadata</p>"},{"location":"api/tenets/core/analysis/implementations/javascript_analyzer/#tenets.core.analysis.implementations.javascript_analyzer.JavaScriptAnalyzer.extract_structure","title":"extract_structure","text":"Python<pre><code>extract_structure(content: str, file_path: Path) -&gt; CodeStructure\n</code></pre> <p>Extract code structure from JavaScript/TypeScript file.</p> <p>Extracts: - Functions (regular, arrow, async, generator) - Classes (ES6 classes with inheritance) - Methods and properties - React components (class and functional) - TypeScript interfaces and types - Constants and variables</p> PARAMETER DESCRIPTION <code>content</code> <p>JavaScript/TypeScript source code</p> <p> TYPE: <code>str</code> </p> <code>file_path</code> <p>Path to the file being analyzed</p> <p> TYPE: <code>Path</code> </p> RETURNS DESCRIPTION <code>CodeStructure</code> <p>CodeStructure object with extracted elements</p>"},{"location":"api/tenets/core/analysis/implementations/javascript_analyzer/#tenets.core.analysis.implementations.javascript_analyzer.JavaScriptAnalyzer.calculate_complexity","title":"calculate_complexity","text":"Python<pre><code>calculate_complexity(content: str, file_path: Path) -&gt; ComplexityMetrics\n</code></pre> <p>Calculate complexity metrics for JavaScript/TypeScript code.</p> <p>Calculates: - Cyclomatic complexity - Cognitive complexity - Nesting depth - Function and class counts - Comment ratio</p> PARAMETER DESCRIPTION <code>content</code> <p>JavaScript/TypeScript source code</p> <p> TYPE: <code>str</code> </p> <code>file_path</code> <p>Path to the file being analyzed</p> <p> TYPE: <code>Path</code> </p> RETURNS DESCRIPTION <code>ComplexityMetrics</code> <p>ComplexityMetrics object with calculated metrics</p>"},{"location":"api/tenets/core/analysis/implementations/javascript_analyzer/#tenets.core.analysis.implementations.javascript_analyzer-functions","title":"Functions","text":""},{"location":"api/tenets/core/analysis/implementations/kotlin_analyzer/","title":"Kotlin Analyzer","text":""},{"location":"api/tenets/core/analysis/implementations/kotlin_analyzer/#tenets.core.analysis.implementations.kotlin_analyzer","title":"tenets.core.analysis.implementations.kotlin_analyzer","text":"<p>Kotlin code analyzer with Android and multiplatform support.</p> <p>This module provides comprehensive analysis for Kotlin source files, including support for Android development, coroutines, null safety, and Kotlin Multiplatform features.</p>"},{"location":"api/tenets/core/analysis/implementations/kotlin_analyzer/#tenets.core.analysis.implementations.kotlin_analyzer-classes","title":"Classes","text":""},{"location":"api/tenets/core/analysis/implementations/kotlin_analyzer/#tenets.core.analysis.implementations.kotlin_analyzer.KotlinAnalyzer","title":"KotlinAnalyzer","text":"Python<pre><code>KotlinAnalyzer()\n</code></pre> <p>               Bases: <code>LanguageAnalyzer</code></p> <p>Kotlin code analyzer with Android and multiplatform support.</p> <p>Provides comprehensive analysis for Kotlin files including: - Import statements with aliases - Package declarations - Classes, interfaces, objects, data classes - Sealed classes and interfaces - Extension functions and properties - Coroutines and suspend functions - Null safety features - Inline and reified functions - Companion objects - Delegation patterns - Android-specific patterns (Activities, Fragments, ViewModels) - Kotlin Multiplatform declarations</p> <p>Supports modern Kotlin features and Android development patterns.</p> <p>Initialize the Kotlin analyzer with logger.</p>"},{"location":"api/tenets/core/analysis/implementations/kotlin_analyzer/#tenets.core.analysis.implementations.kotlin_analyzer.KotlinAnalyzer-functions","title":"Functions","text":""},{"location":"api/tenets/core/analysis/implementations/kotlin_analyzer/#tenets.core.analysis.implementations.kotlin_analyzer.KotlinAnalyzer.extract_imports","title":"extract_imports","text":"Python<pre><code>extract_imports(content: str, file_path: Path) -&gt; List[ImportInfo]\n</code></pre> <p>Extract import statements from Kotlin code.</p> <p>Handles: - import statements: import kotlin.collections.List - Wildcard imports: import java.util.* - Aliased imports: import java.util.List as JList - Package declarations - Static imports (companion object members)</p> PARAMETER DESCRIPTION <code>content</code> <p>Kotlin source code</p> <p> TYPE: <code>str</code> </p> <code>file_path</code> <p>Path to the file being analyzed</p> <p> TYPE: <code>Path</code> </p> RETURNS DESCRIPTION <code>List[ImportInfo]</code> <p>List of ImportInfo objects with import details</p>"},{"location":"api/tenets/core/analysis/implementations/kotlin_analyzer/#tenets.core.analysis.implementations.kotlin_analyzer.KotlinAnalyzer.extract_exports","title":"extract_exports","text":"Python<pre><code>extract_exports(content: str, file_path: Path) -&gt; List[Dict[str, Any]]\n</code></pre> <p>Extract exported symbols from Kotlin code.</p> <p>In Kotlin, exports include: - Public classes, interfaces, and objects - Public functions (including extension functions) - Public properties (including extension properties) - Public type aliases - Sealed class hierarchies - Enum classes - Annotations</p> PARAMETER DESCRIPTION <code>content</code> <p>Kotlin source code</p> <p> TYPE: <code>str</code> </p> <code>file_path</code> <p>Path to the file being analyzed</p> <p> TYPE: <code>Path</code> </p> RETURNS DESCRIPTION <code>List[Dict[str, Any]]</code> <p>List of exported symbols</p>"},{"location":"api/tenets/core/analysis/implementations/kotlin_analyzer/#tenets.core.analysis.implementations.kotlin_analyzer.KotlinAnalyzer.extract_structure","title":"extract_structure","text":"Python<pre><code>extract_structure(content: str, file_path: Path) -&gt; CodeStructure\n</code></pre> <p>Extract code structure from Kotlin file.</p> <p>Extracts: - Classes with inheritance and interfaces - Data classes and sealed hierarchies - Functions with parameters and return types - Extension functions and properties - Coroutines and suspend functions - Companion objects - Android components (Activities, Fragments, ViewModels) - Delegation patterns - Inline classes/value classes</p> PARAMETER DESCRIPTION <code>content</code> <p>Kotlin source code</p> <p> TYPE: <code>str</code> </p> <code>file_path</code> <p>Path to the file being analyzed</p> <p> TYPE: <code>Path</code> </p> RETURNS DESCRIPTION <code>CodeStructure</code> <p>CodeStructure object with extracted elements</p>"},{"location":"api/tenets/core/analysis/implementations/kotlin_analyzer/#tenets.core.analysis.implementations.kotlin_analyzer.KotlinAnalyzer.calculate_complexity","title":"calculate_complexity","text":"Python<pre><code>calculate_complexity(content: str, file_path: Path) -&gt; ComplexityMetrics\n</code></pre> <p>Calculate complexity metrics for Kotlin code.</p> <p>Calculates: - Cyclomatic complexity - Cognitive complexity - Null safety complexity - Coroutine complexity - Android-specific complexity - Functional programming complexity</p> PARAMETER DESCRIPTION <code>content</code> <p>Kotlin source code</p> <p> TYPE: <code>str</code> </p> <code>file_path</code> <p>Path to the file being analyzed</p> <p> TYPE: <code>Path</code> </p> RETURNS DESCRIPTION <code>ComplexityMetrics</code> <p>ComplexityMetrics object with calculated metrics</p>"},{"location":"api/tenets/core/analysis/implementations/kotlin_analyzer/#tenets.core.analysis.implementations.kotlin_analyzer-functions","title":"Functions","text":""},{"location":"api/tenets/core/analysis/implementations/php_analyzer/","title":"Php Analyzer","text":""},{"location":"api/tenets/core/analysis/implementations/php_analyzer/#tenets.core.analysis.implementations.php_analyzer","title":"tenets.core.analysis.implementations.php_analyzer","text":"<p>PHP code analyzer.</p> <p>This module provides comprehensive analysis for PHP source files, including support for modern PHP features, namespaces, and frameworks.</p>"},{"location":"api/tenets/core/analysis/implementations/php_analyzer/#tenets.core.analysis.implementations.php_analyzer-classes","title":"Classes","text":""},{"location":"api/tenets/core/analysis/implementations/php_analyzer/#tenets.core.analysis.implementations.php_analyzer.PhpAnalyzer","title":"PhpAnalyzer","text":"Python<pre><code>PhpAnalyzer()\n</code></pre> <p>               Bases: <code>LanguageAnalyzer</code></p> <p>PHP code analyzer.</p> <p>Provides analysis for PHP files including: - Include/require analysis with variations - Namespace and use statement handling - Class, trait, and interface extraction - Function and method analysis with type hints - Property analysis with visibility - PHP 7+ features (typed properties, return types) - PHP 8+ features (attributes, union types, enums) - Framework detection (Laravel, Symfony, WordPress) - Composer dependency analysis</p> <p>Handles both procedural and object-oriented PHP code.</p> <p>Initialize the PHP analyzer with logger.</p>"},{"location":"api/tenets/core/analysis/implementations/php_analyzer/#tenets.core.analysis.implementations.php_analyzer.PhpAnalyzer-functions","title":"Functions","text":""},{"location":"api/tenets/core/analysis/implementations/php_analyzer/#tenets.core.analysis.implementations.php_analyzer.PhpAnalyzer.extract_imports","title":"extract_imports","text":"Python<pre><code>extract_imports(content: str, file_path: Path) -&gt; List[ImportInfo]\n</code></pre> <p>Extract imports from PHP code.</p> <p>Handles: - use statements (classes, functions, constants) - include/require statements - include_once/require_once - Composer autoload - Namespace imports</p> PARAMETER DESCRIPTION <code>content</code> <p>PHP source code</p> <p> TYPE: <code>str</code> </p> <code>file_path</code> <p>Path to the file being analyzed</p> <p> TYPE: <code>Path</code> </p> RETURNS DESCRIPTION <code>List[ImportInfo]</code> <p>List of ImportInfo objects with import details</p>"},{"location":"api/tenets/core/analysis/implementations/php_analyzer/#tenets.core.analysis.implementations.php_analyzer.PhpAnalyzer.extract_exports","title":"extract_exports","text":"Python<pre><code>extract_exports(content: str, file_path: Path) -&gt; List[Dict[str, Any]]\n</code></pre> <p>Extract public members from PHP code.</p> <p>PHP doesn't have explicit exports, but public classes, functions, and constants are accessible from other files.</p> PARAMETER DESCRIPTION <code>content</code> <p>PHP source code</p> <p> TYPE: <code>str</code> </p> <code>file_path</code> <p>Path to the file being analyzed</p> <p> TYPE: <code>Path</code> </p> RETURNS DESCRIPTION <code>List[Dict[str, Any]]</code> <p>List of exported (public) symbols</p>"},{"location":"api/tenets/core/analysis/implementations/php_analyzer/#tenets.core.analysis.implementations.php_analyzer.PhpAnalyzer.extract_structure","title":"extract_structure","text":"Python<pre><code>extract_structure(content: str, file_path: Path) -&gt; CodeStructure\n</code></pre> <p>Extract code structure from PHP file.</p> <p>Extracts: - Namespace declaration - Classes with inheritance and traits - Interfaces with extension - Traits with composition - Enums (PHP 8.1+) - Functions with type hints - Properties with visibility and types - Methods with return types - PHP attributes/annotations</p> PARAMETER DESCRIPTION <code>content</code> <p>PHP source code</p> <p> TYPE: <code>str</code> </p> <code>file_path</code> <p>Path to the file being analyzed</p> <p> TYPE: <code>Path</code> </p> RETURNS DESCRIPTION <code>CodeStructure</code> <p>CodeStructure object with extracted elements</p>"},{"location":"api/tenets/core/analysis/implementations/php_analyzer/#tenets.core.analysis.implementations.php_analyzer.PhpAnalyzer.calculate_complexity","title":"calculate_complexity","text":"Python<pre><code>calculate_complexity(content: str, file_path: Path) -&gt; ComplexityMetrics\n</code></pre> <p>Calculate complexity metrics for PHP code.</p> <p>Calculates: - Cyclomatic complexity - Cognitive complexity - Nesting depth - Class coupling - PHP-specific metrics</p> PARAMETER DESCRIPTION <code>content</code> <p>PHP source code</p> <p> TYPE: <code>str</code> </p> <code>file_path</code> <p>Path to the file being analyzed</p> <p> TYPE: <code>Path</code> </p> RETURNS DESCRIPTION <code>ComplexityMetrics</code> <p>ComplexityMetrics object with calculated metrics</p>"},{"location":"api/tenets/core/analysis/implementations/php_analyzer/#tenets.core.analysis.implementations.php_analyzer-functions","title":"Functions","text":""},{"location":"api/tenets/core/analysis/implementations/python_analyzer/","title":"Python Analyzer","text":""},{"location":"api/tenets/core/analysis/implementations/python_analyzer/#tenets.core.analysis.implementations.python_analyzer","title":"tenets.core.analysis.implementations.python_analyzer","text":"<p>Python-specific code analyzer using AST.</p> <p>This module provides comprehensive analysis of Python source code using the Abstract Syntax Tree (AST) module for accurate parsing. It extracts imports, exports, code structure, and calculates various complexity metrics.</p>"},{"location":"api/tenets/core/analysis/implementations/python_analyzer/#tenets.core.analysis.implementations.python_analyzer-classes","title":"Classes","text":""},{"location":"api/tenets/core/analysis/implementations/python_analyzer/#tenets.core.analysis.implementations.python_analyzer.PythonAnalyzer","title":"PythonAnalyzer","text":"Python<pre><code>PythonAnalyzer()\n</code></pre> <p>               Bases: <code>LanguageAnalyzer</code></p> <p>Python-specific code analyzer using AST.</p> <p>Provides deep analysis of Python code including: - Import analysis with tracking of relative imports - Function and class extraction with signatures - Decorator detection - Complexity metrics (cyclomatic, cognitive, Halstead) - Type hint analysis - Docstring extraction - Async function detection</p> <p>This analyzer uses Python's built-in AST module for accurate parsing, falling back to regex-based extraction when AST parsing fails.</p> <p>Initialize the Python analyzer with logger.</p>"},{"location":"api/tenets/core/analysis/implementations/python_analyzer/#tenets.core.analysis.implementations.python_analyzer.PythonAnalyzer-functions","title":"Functions","text":""},{"location":"api/tenets/core/analysis/implementations/python_analyzer/#tenets.core.analysis.implementations.python_analyzer.PythonAnalyzer.extract_imports","title":"extract_imports","text":"Python<pre><code>extract_imports(content: str, file_path: Path) -&gt; List[ImportInfo]\n</code></pre> <p>Extract imports from Python code using AST.</p> <p>Identifies all import statements including: - Standard imports: import os, import sys - From imports: from datetime import datetime - Relative imports: from . import module - Aliased imports: import numpy as np</p> PARAMETER DESCRIPTION <code>content</code> <p>Python source code</p> <p> TYPE: <code>str</code> </p> <code>file_path</code> <p>Path to the file being analyzed</p> <p> TYPE: <code>Path</code> </p> RETURNS DESCRIPTION <code>List[ImportInfo]</code> <p>List of ImportInfo objects with details about each import</p>"},{"location":"api/tenets/core/analysis/implementations/python_analyzer/#tenets.core.analysis.implementations.python_analyzer.PythonAnalyzer.extract_exports","title":"extract_exports","text":"Python<pre><code>extract_exports(content: str, file_path: Path) -&gt; List[Dict[str, Any]]\n</code></pre> <p>Extract exported symbols from Python code.</p> <p>Python exports are determined by: 1. Explicit all definition 2. Public symbols (not starting with underscore)</p> PARAMETER DESCRIPTION <code>content</code> <p>Python source code</p> <p> TYPE: <code>str</code> </p> <code>file_path</code> <p>Path to the file being analyzed</p> <p> TYPE: <code>Path</code> </p> RETURNS DESCRIPTION <code>List[Dict[str, Any]]</code> <p>List of exported symbols with their metadata</p>"},{"location":"api/tenets/core/analysis/implementations/python_analyzer/#tenets.core.analysis.implementations.python_analyzer.PythonAnalyzer.extract_structure","title":"extract_structure","text":"Python<pre><code>extract_structure(content: str, file_path: Path) -&gt; CodeStructure\n</code></pre> <p>Extract comprehensive code structure from Python file.</p> <p>Parses the AST to extract: - Classes with inheritance, methods, and docstrings - Functions with signatures, decorators, and complexity - Global variables and constants - Nested functions and classes</p> PARAMETER DESCRIPTION <code>content</code> <p>Python source code</p> <p> TYPE: <code>str</code> </p> <code>file_path</code> <p>Path to the file being analyzed</p> <p> TYPE: <code>Path</code> </p> RETURNS DESCRIPTION <code>CodeStructure</code> <p>CodeStructure object with complete structural information</p>"},{"location":"api/tenets/core/analysis/implementations/python_analyzer/#tenets.core.analysis.implementations.python_analyzer.PythonAnalyzer.calculate_complexity","title":"calculate_complexity","text":"Python<pre><code>calculate_complexity(content: str, file_path: Path) -&gt; ComplexityMetrics\n</code></pre> <p>Calculate comprehensive complexity metrics for Python code.</p> <p>Calculates: - Cyclomatic complexity (McCabe) - Cognitive complexity - Halstead metrics - Maintainability index - Maximum nesting depth - Lines of code metrics</p> PARAMETER DESCRIPTION <code>content</code> <p>Python source code</p> <p> TYPE: <code>str</code> </p> <code>file_path</code> <p>Path to the file being analyzed</p> <p> TYPE: <code>Path</code> </p> RETURNS DESCRIPTION <code>ComplexityMetrics</code> <p>ComplexityMetrics object with all calculated metrics</p>"},{"location":"api/tenets/core/analysis/implementations/python_analyzer/#tenets.core.analysis.implementations.python_analyzer-functions","title":"Functions","text":""},{"location":"api/tenets/core/analysis/implementations/ruby_analyzer/","title":"Ruby Analyzer","text":""},{"location":"api/tenets/core/analysis/implementations/ruby_analyzer/#tenets.core.analysis.implementations.ruby_analyzer","title":"tenets.core.analysis.implementations.ruby_analyzer","text":"<p>Ruby code analyzer.</p> <p>This module provides comprehensive analysis for Ruby source files, including support for Ruby's dynamic features, metaprogramming, and DSLs.</p>"},{"location":"api/tenets/core/analysis/implementations/ruby_analyzer/#tenets.core.analysis.implementations.ruby_analyzer-classes","title":"Classes","text":""},{"location":"api/tenets/core/analysis/implementations/ruby_analyzer/#tenets.core.analysis.implementations.ruby_analyzer.RubyAnalyzer","title":"RubyAnalyzer","text":"Python<pre><code>RubyAnalyzer()\n</code></pre> <p>               Bases: <code>LanguageAnalyzer</code></p> <p>Ruby code analyzer.</p> <p>Provides analysis for Ruby files including: - Require and gem dependency analysis - Class and module extraction with inheritance - Method analysis with visibility and metaprogramming - Block, proc, and lambda detection - DSL pattern recognition - Attribute accessors and metaprogramming - Ruby-specific patterns (symbols, instance variables) - Framework detection (Rails, Sinatra, RSpec)</p> <p>Handles Ruby's dynamic nature and metaprogramming features.</p> <p>Initialize the Ruby analyzer with logger.</p>"},{"location":"api/tenets/core/analysis/implementations/ruby_analyzer/#tenets.core.analysis.implementations.ruby_analyzer.RubyAnalyzer-functions","title":"Functions","text":""},{"location":"api/tenets/core/analysis/implementations/ruby_analyzer/#tenets.core.analysis.implementations.ruby_analyzer.RubyAnalyzer.extract_imports","title":"extract_imports","text":"Python<pre><code>extract_imports(content: str, file_path: Path) -&gt; List[ImportInfo]\n</code></pre> <p>Extract requires and gems from Ruby code.</p> <p>Handles: - require 'library' - require_relative 'file' - load 'file.rb' - gem 'gemname' - autoload :Module, 'file' - Bundler.require - conditional requires (require 'x' if ... / unless ...)</p>"},{"location":"api/tenets/core/analysis/implementations/ruby_analyzer/#tenets.core.analysis.implementations.ruby_analyzer.RubyAnalyzer.extract_exports","title":"extract_exports","text":"Python<pre><code>extract_exports(content: str, file_path: Path) -&gt; List[Dict[str, Any]]\n</code></pre> <p>Extract public methods and classes from Ruby code.</p> <p>In Ruby, everything is public by default unless specified otherwise. Module and class definitions are the primary exports.</p> PARAMETER DESCRIPTION <code>content</code> <p>Ruby source code</p> <p> TYPE: <code>str</code> </p> <code>file_path</code> <p>Path to the file being analyzed</p> <p> TYPE: <code>Path</code> </p> RETURNS DESCRIPTION <code>List[Dict[str, Any]]</code> <p>List of exported symbols with metadata</p>"},{"location":"api/tenets/core/analysis/implementations/ruby_analyzer/#tenets.core.analysis.implementations.ruby_analyzer.RubyAnalyzer.extract_structure","title":"extract_structure","text":"Python<pre><code>extract_structure(content: str, file_path: Path) -&gt; CodeStructure\n</code></pre> <p>Extract code structure from Ruby file.</p> <p>Extracts: - Classes with inheritance and included modules - Modules with included/extended modules - Methods with visibility and type - Instance and class variables - Constants - Blocks, procs, and lambdas - Attribute accessors - Aliases</p> PARAMETER DESCRIPTION <code>content</code> <p>Ruby source code</p> <p> TYPE: <code>str</code> </p> <code>file_path</code> <p>Path to the file being analyzed</p> <p> TYPE: <code>Path</code> </p> RETURNS DESCRIPTION <code>CodeStructure</code> <p>CodeStructure object with extracted elements</p>"},{"location":"api/tenets/core/analysis/implementations/ruby_analyzer/#tenets.core.analysis.implementations.ruby_analyzer.RubyAnalyzer.calculate_complexity","title":"calculate_complexity","text":"Python<pre><code>calculate_complexity(content: str, file_path: Path) -&gt; ComplexityMetrics\n</code></pre> <p>Calculate complexity metrics for Ruby code.</p> <p>Calculates: - Cyclomatic complexity - Cognitive complexity - ABC metrics (Assignment, Branch, Condition) - Method complexity - Metaprogramming complexity</p> PARAMETER DESCRIPTION <code>content</code> <p>Ruby source code</p> <p> TYPE: <code>str</code> </p> <code>file_path</code> <p>Path to the file being analyzed</p> <p> TYPE: <code>Path</code> </p> RETURNS DESCRIPTION <code>ComplexityMetrics</code> <p>ComplexityMetrics object with calculated metrics</p>"},{"location":"api/tenets/core/analysis/implementations/ruby_analyzer/#tenets.core.analysis.implementations.ruby_analyzer-functions","title":"Functions","text":""},{"location":"api/tenets/core/analysis/implementations/rust_analyzer/","title":"Rust Analyzer","text":""},{"location":"api/tenets/core/analysis/implementations/rust_analyzer/#tenets.core.analysis.implementations.rust_analyzer","title":"tenets.core.analysis.implementations.rust_analyzer","text":"<p>Rust code analyzer.</p> <p>This module provides comprehensive analysis for Rust source files, including support for Rust's ownership system, traits, and modern features.</p>"},{"location":"api/tenets/core/analysis/implementations/rust_analyzer/#tenets.core.analysis.implementations.rust_analyzer-classes","title":"Classes","text":""},{"location":"api/tenets/core/analysis/implementations/rust_analyzer/#tenets.core.analysis.implementations.rust_analyzer.RustAnalyzer","title":"RustAnalyzer","text":"Python<pre><code>RustAnalyzer()\n</code></pre> <p>               Bases: <code>LanguageAnalyzer</code></p> <p>Rust code analyzer.</p> <p>Provides comprehensive analysis for Rust files including: - Use statement and module analysis - Struct and enum extraction with generics - Trait definition and implementation - Function analysis with lifetimes and generics - Macro usage and definition - Ownership and borrowing patterns - Async/await support - Unsafe code detection - Cargo dependency analysis</p> <p>Handles Rust's unique features like ownership, lifetimes, and traits.</p> <p>Initialize the Rust analyzer with logger.</p>"},{"location":"api/tenets/core/analysis/implementations/rust_analyzer/#tenets.core.analysis.implementations.rust_analyzer.RustAnalyzer-functions","title":"Functions","text":""},{"location":"api/tenets/core/analysis/implementations/rust_analyzer/#tenets.core.analysis.implementations.rust_analyzer.RustAnalyzer.extract_imports","title":"extract_imports","text":"Python<pre><code>extract_imports(content: str, file_path: Path) -&gt; List[ImportInfo]\n</code></pre> <p>Extract imports from Rust code.</p> <p>Handles: - use statements with paths - use statements with glob imports - use statements with aliases - use statements with nested imports - extern crate declarations - mod declarations</p> PARAMETER DESCRIPTION <code>content</code> <p>Rust source code</p> <p> TYPE: <code>str</code> </p> <code>file_path</code> <p>Path to the file being analyzed</p> <p> TYPE: <code>Path</code> </p> RETURNS DESCRIPTION <code>List[ImportInfo]</code> <p>List of ImportInfo objects with import details</p>"},{"location":"api/tenets/core/analysis/implementations/rust_analyzer/#tenets.core.analysis.implementations.rust_analyzer.RustAnalyzer.extract_exports","title":"extract_exports","text":"Python<pre><code>extract_exports(content: str, file_path: Path) -&gt; List[Dict[str, Any]]\n</code></pre> <p>Extract public items from Rust code.</p> <p>In Rust, items marked with 'pub' are exported.</p> PARAMETER DESCRIPTION <code>content</code> <p>Rust source code</p> <p> TYPE: <code>str</code> </p> <code>file_path</code> <p>Path to the file being analyzed</p> <p> TYPE: <code>Path</code> </p> RETURNS DESCRIPTION <code>List[Dict[str, Any]]</code> <p>List of exported (public) symbols</p>"},{"location":"api/tenets/core/analysis/implementations/rust_analyzer/#tenets.core.analysis.implementations.rust_analyzer.RustAnalyzer.extract_structure","title":"extract_structure","text":"Python<pre><code>extract_structure(content: str, file_path: Path) -&gt; CodeStructure\n</code></pre> <p>Extract code structure from Rust file.</p> <p>Extracts: - Structs with fields and generics - Enums with variants - Traits with methods - Implementations (impl blocks) - Functions with signatures - Modules - Type aliases - Constants and statics - Macros</p> PARAMETER DESCRIPTION <code>content</code> <p>Rust source code</p> <p> TYPE: <code>str</code> </p> <code>file_path</code> <p>Path to the file being analyzed</p> <p> TYPE: <code>Path</code> </p> RETURNS DESCRIPTION <code>CodeStructure</code> <p>CodeStructure object with extracted elements</p>"},{"location":"api/tenets/core/analysis/implementations/rust_analyzer/#tenets.core.analysis.implementations.rust_analyzer.RustAnalyzer.calculate_complexity","title":"calculate_complexity","text":"Python<pre><code>calculate_complexity(content: str, file_path: Path) -&gt; ComplexityMetrics\n</code></pre> <p>Calculate complexity metrics for Rust code.</p> <p>Calculates: - Cyclomatic complexity - Cognitive complexity - Unsafe code metrics - Lifetime complexity - Generic complexity - Pattern matching complexity</p> PARAMETER DESCRIPTION <code>content</code> <p>Rust source code</p> <p> TYPE: <code>str</code> </p> <code>file_path</code> <p>Path to the file being analyzed</p> <p> TYPE: <code>Path</code> </p> RETURNS DESCRIPTION <code>ComplexityMetrics</code> <p>ComplexityMetrics object with calculated metrics</p>"},{"location":"api/tenets/core/analysis/implementations/rust_analyzer/#tenets.core.analysis.implementations.rust_analyzer-functions","title":"Functions","text":""},{"location":"api/tenets/core/analysis/implementations/scala_analyzer/","title":"Scala Analyzer","text":""},{"location":"api/tenets/core/analysis/implementations/scala_analyzer/#tenets.core.analysis.implementations.scala_analyzer","title":"tenets.core.analysis.implementations.scala_analyzer","text":"<p>Scala code analyzer with functional programming support.</p> <p>This module provides comprehensive analysis for Scala source files, including support for object-oriented and functional programming paradigms, pattern matching, implicits, and modern Scala 3 features.</p>"},{"location":"api/tenets/core/analysis/implementations/scala_analyzer/#tenets.core.analysis.implementations.scala_analyzer-classes","title":"Classes","text":""},{"location":"api/tenets/core/analysis/implementations/scala_analyzer/#tenets.core.analysis.implementations.scala_analyzer.ScalaAnalyzer","title":"ScalaAnalyzer","text":"Python<pre><code>ScalaAnalyzer()\n</code></pre> <p>               Bases: <code>LanguageAnalyzer</code></p> <p>Scala code analyzer with functional programming support.</p> <p>Provides comprehensive analysis for Scala files including: - Import statements with wildcards and renames - Package declarations and package objects - Classes, traits, objects, case classes - Implicit definitions and conversions - Pattern matching and case statements - For comprehensions and monadic operations - Higher-order functions and currying - Type parameters with variance annotations - Lazy vals and by-name parameters - Sealed traits and algebraic data types - Companion objects - Scala 3 features (given/using, extension methods, etc.)</p> <p>Supports both Scala 2.x and Scala 3.x syntax.</p> <p>Initialize the Scala analyzer with logger.</p>"},{"location":"api/tenets/core/analysis/implementations/scala_analyzer/#tenets.core.analysis.implementations.scala_analyzer.ScalaAnalyzer-functions","title":"Functions","text":""},{"location":"api/tenets/core/analysis/implementations/scala_analyzer/#tenets.core.analysis.implementations.scala_analyzer.ScalaAnalyzer.extract_imports","title":"extract_imports","text":"Python<pre><code>extract_imports(content: str, file_path: Path) -&gt; List[ImportInfo]\n</code></pre> <p>Extract import statements from Scala code.</p> <p>Handles: - import statements: import scala.collection.mutable - Wildcard imports: import java.util._ - Multiple imports: import java.util.{List, Map} - Renamed imports: import java.util.{List =&gt; JList} - Import all and hide: import java.util.{_, List =&gt; _} - Package declarations - Scala 3 given imports: import cats.implicits.given</p> PARAMETER DESCRIPTION <code>content</code> <p>Scala source code</p> <p> TYPE: <code>str</code> </p> <code>file_path</code> <p>Path to the file being analyzed</p> <p> TYPE: <code>Path</code> </p> RETURNS DESCRIPTION <code>List[ImportInfo]</code> <p>List of ImportInfo objects with import details</p>"},{"location":"api/tenets/core/analysis/implementations/scala_analyzer/#tenets.core.analysis.implementations.scala_analyzer.ScalaAnalyzer.extract_exports","title":"extract_exports","text":"Python<pre><code>extract_exports(content: str, file_path: Path) -&gt; List[Dict[str, Any]]\n</code></pre> <p>Extract exported symbols from Scala code.</p> <p>In Scala, exports include: - Public classes and case classes - Public traits - Public objects (including companion objects) - Public defs (methods/functions) - Public vals and vars - Public type definitions - Implicit definitions - Given instances (Scala 3)</p> PARAMETER DESCRIPTION <code>content</code> <p>Scala source code</p> <p> TYPE: <code>str</code> </p> <code>file_path</code> <p>Path to the file being analyzed</p> <p> TYPE: <code>Path</code> </p> RETURNS DESCRIPTION <code>List[Dict[str, Any]]</code> <p>List of exported symbols</p>"},{"location":"api/tenets/core/analysis/implementations/scala_analyzer/#tenets.core.analysis.implementations.scala_analyzer.ScalaAnalyzer.extract_structure","title":"extract_structure","text":"Python<pre><code>extract_structure(content: str, file_path: Path) -&gt; CodeStructure\n</code></pre> <p>Extract code structure from Scala file.</p> <p>Extracts: - Classes, traits, and objects - Case classes and algebraic data types - Methods with type parameters - Pattern matching constructs - For comprehensions - Implicit definitions - Companion objects - Extension methods (Scala 3) - Given/using (Scala 3)</p> PARAMETER DESCRIPTION <code>content</code> <p>Scala source code</p> <p> TYPE: <code>str</code> </p> <code>file_path</code> <p>Path to the file being analyzed</p> <p> TYPE: <code>Path</code> </p> RETURNS DESCRIPTION <code>CodeStructure</code> <p>CodeStructure object with extracted elements</p>"},{"location":"api/tenets/core/analysis/implementations/scala_analyzer/#tenets.core.analysis.implementations.scala_analyzer.ScalaAnalyzer.calculate_complexity","title":"calculate_complexity","text":"Python<pre><code>calculate_complexity(content: str, file_path: Path) -&gt; ComplexityMetrics\n</code></pre> <p>Calculate complexity metrics for Scala code.</p> <p>Calculates: - Cyclomatic complexity - Cognitive complexity - Pattern matching complexity - Functional programming complexity - Type complexity - Implicit complexity</p> PARAMETER DESCRIPTION <code>content</code> <p>Scala source code</p> <p> TYPE: <code>str</code> </p> <code>file_path</code> <p>Path to the file being analyzed</p> <p> TYPE: <code>Path</code> </p> RETURNS DESCRIPTION <code>ComplexityMetrics</code> <p>ComplexityMetrics object with calculated metrics</p>"},{"location":"api/tenets/core/analysis/implementations/scala_analyzer/#tenets.core.analysis.implementations.scala_analyzer-functions","title":"Functions","text":""},{"location":"api/tenets/core/analysis/implementations/swift_analyzer/","title":"Swift Analyzer","text":""},{"location":"api/tenets/core/analysis/implementations/swift_analyzer/#tenets.core.analysis.implementations.swift_analyzer","title":"tenets.core.analysis.implementations.swift_analyzer","text":"<p>Swift code analyzer with iOS/macOS and SwiftUI support.</p> <p>This module provides comprehensive analysis for Swift source files, including support for iOS/macOS development, SwiftUI, UIKit, async/await, and modern Swift features.</p>"},{"location":"api/tenets/core/analysis/implementations/swift_analyzer/#tenets.core.analysis.implementations.swift_analyzer-classes","title":"Classes","text":""},{"location":"api/tenets/core/analysis/implementations/swift_analyzer/#tenets.core.analysis.implementations.swift_analyzer.SwiftAnalyzer","title":"SwiftAnalyzer","text":"Python<pre><code>SwiftAnalyzer()\n</code></pre> <p>               Bases: <code>LanguageAnalyzer</code></p> <p>Swift code analyzer with iOS/macOS and SwiftUI support.</p> <p>Provides comprehensive analysis for Swift files including: - Import statements - Classes, structs, enums, protocols - Extensions and protocol conformance - Optionals and optional chaining - Guard statements and if-let bindings - Async/await and actors - Property wrappers (@State, @Published, etc.) - Result builders (@ViewBuilder, etc.) - SwiftUI views and modifiers - UIKit components - Combine framework usage - Access control levels - Generics and associated types</p> <p>Supports Swift 5.x features and Apple platform development.</p> <p>Initialize the Swift analyzer with logger.</p>"},{"location":"api/tenets/core/analysis/implementations/swift_analyzer/#tenets.core.analysis.implementations.swift_analyzer.SwiftAnalyzer-functions","title":"Functions","text":""},{"location":"api/tenets/core/analysis/implementations/swift_analyzer/#tenets.core.analysis.implementations.swift_analyzer.SwiftAnalyzer.extract_imports","title":"extract_imports","text":"Python<pre><code>extract_imports(content: str, file_path: Path) -&gt; List[ImportInfo]\n</code></pre> <p>Extract import statements from Swift code.</p> <p>Handles: - import statements: import Foundation - Targeted imports: import struct Swift.Array - Conditional imports: @_exported import, @testable import - Module aliasing (limited in Swift)</p> PARAMETER DESCRIPTION <code>content</code> <p>Swift source code</p> <p> TYPE: <code>str</code> </p> <code>file_path</code> <p>Path to the file being analyzed</p> <p> TYPE: <code>Path</code> </p> RETURNS DESCRIPTION <code>List[ImportInfo]</code> <p>List of ImportInfo objects with import details</p>"},{"location":"api/tenets/core/analysis/implementations/swift_analyzer/#tenets.core.analysis.implementations.swift_analyzer.SwiftAnalyzer.extract_exports","title":"extract_exports","text":"Python<pre><code>extract_exports(content: str, file_path: Path) -&gt; List[Dict[str, Any]]\n</code></pre> <p>Extract exported symbols from Swift code.</p> <p>In Swift, exports are determined by access control: - public: Accessible from any module - open: Subclassable from any module (classes only) - internal: Default, accessible within module - fileprivate: Accessible within file - private: Accessible within scope</p> PARAMETER DESCRIPTION <code>content</code> <p>Swift source code</p> <p> TYPE: <code>str</code> </p> <code>file_path</code> <p>Path to the file being analyzed</p> <p> TYPE: <code>Path</code> </p> RETURNS DESCRIPTION <code>List[Dict[str, Any]]</code> <p>List of exported symbols (public/open declarations)</p>"},{"location":"api/tenets/core/analysis/implementations/swift_analyzer/#tenets.core.analysis.implementations.swift_analyzer.SwiftAnalyzer.extract_structure","title":"extract_structure","text":"Python<pre><code>extract_structure(content: str, file_path: Path) -&gt; CodeStructure\n</code></pre> <p>Extract code structure from Swift file.</p> <p>Extracts: - Classes, structs, enums, protocols, actors - Methods and properties - Extensions and protocol conformance - SwiftUI views and modifiers - UIKit components - Async/await patterns - Property wrappers - Computed properties and property observers</p> PARAMETER DESCRIPTION <code>content</code> <p>Swift source code</p> <p> TYPE: <code>str</code> </p> <code>file_path</code> <p>Path to the file being analyzed</p> <p> TYPE: <code>Path</code> </p> RETURNS DESCRIPTION <code>CodeStructure</code> <p>CodeStructure object with extracted elements</p>"},{"location":"api/tenets/core/analysis/implementations/swift_analyzer/#tenets.core.analysis.implementations.swift_analyzer.SwiftAnalyzer.calculate_complexity","title":"calculate_complexity","text":"Python<pre><code>calculate_complexity(content: str, file_path: Path) -&gt; ComplexityMetrics\n</code></pre> <p>Calculate complexity metrics for Swift code.</p> <p>Calculates: - Cyclomatic complexity - Cognitive complexity - Optional handling complexity - Async/await complexity - SwiftUI/UIKit specific complexity - Protocol-oriented complexity</p> PARAMETER DESCRIPTION <code>content</code> <p>Swift source code</p> <p> TYPE: <code>str</code> </p> <code>file_path</code> <p>Path to the file being analyzed</p> <p> TYPE: <code>Path</code> </p> RETURNS DESCRIPTION <code>ComplexityMetrics</code> <p>ComplexityMetrics object with calculated metrics</p>"},{"location":"api/tenets/core/analysis/implementations/swift_analyzer/#tenets.core.analysis.implementations.swift_analyzer-functions","title":"Functions","text":""},{"location":"api/tenets/core/distiller/aggregator/","title":"Aggregator","text":""},{"location":"api/tenets/core/distiller/aggregator/#tenets.core.distiller.aggregator","title":"tenets.core.distiller.aggregator","text":"<p>Context aggregation - intelligently combine files within token limits.</p> <p>The aggregator is responsible for selecting and combining files in a way that maximizes relevance while staying within token constraints.</p>"},{"location":"api/tenets/core/distiller/aggregator/#tenets.core.distiller.aggregator-classes","title":"Classes","text":""},{"location":"api/tenets/core/distiller/aggregator/#tenets.core.distiller.aggregator.AggregationStrategy","title":"AggregationStrategy  <code>dataclass</code>","text":"Python<pre><code>AggregationStrategy(name: str, max_full_files: int = 10, summarize_threshold: float = 0.7, min_relevance: float = 0.3, preserve_structure: bool = True)\n</code></pre> <p>Strategy for how to aggregate files.</p>"},{"location":"api/tenets/core/distiller/aggregator/#tenets.core.distiller.aggregator.ContextAggregator","title":"ContextAggregator","text":"Python<pre><code>ContextAggregator(config: TenetsConfig)\n</code></pre> <p>Aggregates files intelligently within token constraints.</p> <p>Initialize the aggregator.</p> PARAMETER DESCRIPTION <code>config</code> <p>Tenets configuration</p> <p> TYPE: <code>TenetsConfig</code> </p>"},{"location":"api/tenets/core/distiller/aggregator/#tenets.core.distiller.aggregator.ContextAggregator-attributes","title":"Attributes","text":""},{"location":"api/tenets/core/distiller/aggregator/#tenets.core.distiller.aggregator.ContextAggregator.summarizer","title":"summarizer  <code>property</code>","text":"Python<pre><code>summarizer\n</code></pre> <p>Lazy load summarizer when needed.</p>"},{"location":"api/tenets/core/distiller/aggregator/#tenets.core.distiller.aggregator.ContextAggregator-functions","title":"Functions","text":""},{"location":"api/tenets/core/distiller/aggregator/#tenets.core.distiller.aggregator.ContextAggregator.aggregate","title":"aggregate","text":"Python<pre><code>aggregate(files: List[FileAnalysis], prompt_context: PromptContext, max_tokens: int, model: Optional[str] = None, git_context: Optional[Dict[str, Any]] = None, strategy: str = 'balanced', full: bool = False, condense: bool = False, remove_comments: bool = False, docstring_weight: Optional[float] = None, summarize_imports: bool = True) -&gt; Dict[str, Any]\n</code></pre> <p>Aggregate files within token budget.</p> PARAMETER DESCRIPTION <code>files</code> <p>Ranked files to aggregate</p> <p> TYPE: <code>List[FileAnalysis]</code> </p> <code>prompt_context</code> <p>Context about the prompt</p> <p> TYPE: <code>PromptContext</code> </p> <code>max_tokens</code> <p>Maximum token budget</p> <p> TYPE: <code>int</code> </p> <code>model</code> <p>Target model for token counting</p> <p> TYPE: <code>Optional[str]</code> DEFAULT: <code>None</code> </p> <code>git_context</code> <p>Optional git context to include</p> <p> TYPE: <code>Optional[Dict[str, Any]]</code> DEFAULT: <code>None</code> </p> <code>strategy</code> <p>Aggregation strategy to use</p> <p> TYPE: <code>str</code> DEFAULT: <code>'balanced'</code> </p> RETURNS DESCRIPTION <code>Dict[str, Any]</code> <p>Dictionary with aggregated content and metadata</p>"},{"location":"api/tenets/core/distiller/aggregator/#tenets.core.distiller.aggregator.ContextAggregator.optimize_packing","title":"optimize_packing","text":"Python<pre><code>optimize_packing(files: List[FileAnalysis], max_tokens: int, model: Optional[str] = None) -&gt; List[Tuple[FileAnalysis, bool]]\n</code></pre> <p>Optimize file packing using dynamic programming.</p> <p>This is a more sophisticated packing algorithm that tries to maximize total relevance score within token constraints.</p> PARAMETER DESCRIPTION <code>files</code> <p>Files to pack</p> <p> TYPE: <code>List[FileAnalysis]</code> </p> <code>max_tokens</code> <p>Token budget</p> <p> TYPE: <code>int</code> </p> <code>model</code> <p>Model for token counting</p> <p> TYPE: <code>Optional[str]</code> DEFAULT: <code>None</code> </p> RETURNS DESCRIPTION <code>List[Tuple[FileAnalysis, bool]]</code> <p>List of (file, should_summarize) tuples</p>"},{"location":"api/tenets/core/distiller/aggregator/#tenets.core.distiller.aggregator-functions","title":"Functions","text":""},{"location":"api/tenets/core/distiller/distiller/","title":"Distiller","text":""},{"location":"api/tenets/core/distiller/distiller/#tenets.core.distiller.distiller","title":"tenets.core.distiller.distiller","text":"<p>Main distiller orchestration.</p> <p>The Distiller coordinates the entire context extraction process, from understanding the prompt to delivering optimized context.</p>"},{"location":"api/tenets/core/distiller/distiller/#tenets.core.distiller.distiller-classes","title":"Classes","text":""},{"location":"api/tenets/core/distiller/distiller/#tenets.core.distiller.distiller.Distiller","title":"Distiller","text":"Python<pre><code>Distiller(config: TenetsConfig)\n</code></pre> <p>Orchestrates context extraction from codebases.</p> <p>The Distiller is the main engine that powers the 'distill' command. It coordinates all the components to extract the most relevant context based on a user's prompt.</p> <p>Initialize the distiller with configuration.</p> PARAMETER DESCRIPTION <code>config</code> <p>Tenets configuration</p> <p> TYPE: <code>TenetsConfig</code> </p>"},{"location":"api/tenets/core/distiller/distiller/#tenets.core.distiller.distiller.Distiller-functions","title":"Functions","text":""},{"location":"api/tenets/core/distiller/distiller/#tenets.core.distiller.distiller.Distiller.distill","title":"distill","text":"Python<pre><code>distill(prompt: str, paths: Optional[Union[str, Path, List[Path]]] = None, *, format: str = 'markdown', model: Optional[str] = None, max_tokens: Optional[int] = None, mode: str = 'balanced', include_git: bool = True, session_name: Optional[str] = None, include_patterns: Optional[List[str]] = None, exclude_patterns: Optional[List[str]] = None, full: bool = False, condense: bool = False, remove_comments: bool = False, pinned_files: Optional[List[Path]] = None, include_tests: Optional[bool] = None, docstring_weight: Optional[float] = None, summarize_imports: bool = True) -&gt; ContextResult\n</code></pre> <p>Distill relevant context from codebase based on prompt.</p> <p>This is the main method that extracts, ranks, and aggregates the most relevant files and information for a given prompt.</p> PARAMETER DESCRIPTION <code>prompt</code> <p>The user's query or task description</p> <p> TYPE: <code>str</code> </p> <code>paths</code> <p>Paths to analyze (default: current directory)</p> <p> TYPE: <code>Optional[Union[str, Path, List[Path]]]</code> DEFAULT: <code>None</code> </p> <code>format</code> <p>Output format (markdown, xml, json)</p> <p> TYPE: <code>str</code> DEFAULT: <code>'markdown'</code> </p> <code>model</code> <p>Target LLM model for token counting</p> <p> TYPE: <code>Optional[str]</code> DEFAULT: <code>None</code> </p> <code>max_tokens</code> <p>Maximum tokens for context</p> <p> TYPE: <code>Optional[int]</code> DEFAULT: <code>None</code> </p> <code>mode</code> <p>Analysis mode (fast, balanced, thorough)</p> <p> TYPE: <code>str</code> DEFAULT: <code>'balanced'</code> </p> <code>include_git</code> <p>Whether to include git context</p> <p> TYPE: <code>bool</code> DEFAULT: <code>True</code> </p> <code>session_name</code> <p>Session name for stateful context</p> <p> TYPE: <code>Optional[str]</code> DEFAULT: <code>None</code> </p> <code>include_patterns</code> <p>File patterns to include</p> <p> TYPE: <code>Optional[List[str]]</code> DEFAULT: <code>None</code> </p> <code>exclude_patterns</code> <p>File patterns to exclude</p> <p> TYPE: <code>Optional[List[str]]</code> DEFAULT: <code>None</code> </p> RETURNS DESCRIPTION <code>ContextResult</code> <p>ContextResult with the distilled context</p> Example <p>distiller = Distiller(config) result = distiller.distill( ...     \"implement OAuth2 authentication\", ...     paths=\"./src\", ...     mode=\"thorough\", ...     max_tokens=50000 ... ) print(result.context)</p>"},{"location":"api/tenets/core/distiller/distiller/#tenets.core.distiller.distiller-functions","title":"Functions","text":""},{"location":"api/tenets/core/distiller/formatter/","title":"Formatter","text":""},{"location":"api/tenets/core/distiller/formatter/#tenets.core.distiller.formatter","title":"tenets.core.distiller.formatter","text":"<p>Context formatting for different output formats.</p> <p>The formatter takes aggregated context and formats it for consumption by LLMs or humans in various formats (markdown, XML, JSON).</p>"},{"location":"api/tenets/core/distiller/formatter/#tenets.core.distiller.formatter-classes","title":"Classes","text":""},{"location":"api/tenets/core/distiller/formatter/#tenets.core.distiller.formatter.ContextFormatter","title":"ContextFormatter","text":"Python<pre><code>ContextFormatter(config: TenetsConfig)\n</code></pre> <p>Formats aggregated context for output.</p> <p>Initialize the formatter.</p> PARAMETER DESCRIPTION <code>config</code> <p>Tenets configuration</p> <p> TYPE: <code>TenetsConfig</code> </p>"},{"location":"api/tenets/core/distiller/formatter/#tenets.core.distiller.formatter.ContextFormatter-functions","title":"Functions","text":""},{"location":"api/tenets/core/distiller/formatter/#tenets.core.distiller.formatter.ContextFormatter.format","title":"format","text":"Python<pre><code>format(aggregated: Dict[str, Any], format: str, prompt_context: PromptContext, session_name: Optional[str] = None) -&gt; str\n</code></pre> <p>Format aggregated context for output.</p> PARAMETER DESCRIPTION <code>aggregated</code> <p>Aggregated context data containing files and statistics.</p> <p> TYPE: <code>Dict[str, Any]</code> </p> <code>format</code> <p>Output format (markdown, xml, json, html).</p> <p> TYPE: <code>str</code> </p> <code>prompt_context</code> <p>Original prompt context with task analysis.</p> <p> TYPE: <code>PromptContext</code> </p> <code>session_name</code> <p>Optional session name for context tracking.</p> <p> TYPE: <code>Optional[str]</code> DEFAULT: <code>None</code> </p> RETURNS DESCRIPTION <code>str</code> <p>Formatted context string in the requested format.</p> RAISES DESCRIPTION <code>ValueError</code> <p>If format is not supported.</p>"},{"location":"api/tenets/core/distiller/formatter/#tenets.core.distiller.formatter-functions","title":"Functions","text":""},{"location":"api/tenets/core/distiller/optimizer/","title":"Optimizer","text":""},{"location":"api/tenets/core/distiller/optimizer/#tenets.core.distiller.optimizer","title":"tenets.core.distiller.optimizer","text":"<p>Token optimization for context generation.</p> <p>The optimizer ensures we make the best use of available tokens by intelligently selecting what to include and what to summarize.</p>"},{"location":"api/tenets/core/distiller/optimizer/#tenets.core.distiller.optimizer-classes","title":"Classes","text":""},{"location":"api/tenets/core/distiller/optimizer/#tenets.core.distiller.optimizer.TokenBudget","title":"TokenBudget  <code>dataclass</code>","text":"Python<pre><code>TokenBudget(total_limit: int, model: Optional[str] = None, prompt_tokens: int = 0, response_reserve: int = 4000, structure_tokens: int = 1000, git_tokens: int = 0, tenet_tokens: int = 0, _available_override: Optional[int] = None)\n</code></pre> <p>Manages token allocation for context building.</p> ATTRIBUTE DESCRIPTION <code>total_limit</code> <p>Total token budget available.</p> <p> TYPE: <code>int</code> </p> <code>model</code> <p>Optional target model name.</p> <p> TYPE: <code>Optional[str]</code> </p> <code>prompt_tokens</code> <p>Tokens consumed by the prompt/instructions.</p> <p> TYPE: <code>int</code> </p> <code>response_reserve</code> <p>Reserved tokens for model output.</p> <p> TYPE: <code>int</code> </p> <code>structure_tokens</code> <p>Reserved tokens for headers/formatting.</p> <p> TYPE: <code>int</code> </p> <code>git_tokens</code> <p>Reserved tokens for git metadata.</p> <p> TYPE: <code>int</code> </p> <code>tenet_tokens</code> <p>Reserved tokens for tenet injection.</p> <p> TYPE: <code>int</code> </p>"},{"location":"api/tenets/core/distiller/optimizer/#tenets.core.distiller.optimizer.TokenBudget-attributes","title":"Attributes","text":""},{"location":"api/tenets/core/distiller/optimizer/#tenets.core.distiller.optimizer.TokenBudget.available_for_files","title":"available_for_files  <code>property</code> <code>writable</code>","text":"Python<pre><code>available_for_files: int\n</code></pre> <p>Calculate tokens available for file content.</p>"},{"location":"api/tenets/core/distiller/optimizer/#tenets.core.distiller.optimizer.TokenBudget.utilization","title":"utilization  <code>property</code>","text":"Python<pre><code>utilization: float\n</code></pre> <p>Calculate budget utilization percentage.</p>"},{"location":"api/tenets/core/distiller/optimizer/#tenets.core.distiller.optimizer.TokenOptimizer","title":"TokenOptimizer","text":"Python<pre><code>TokenOptimizer(config: TenetsConfig)\n</code></pre> <p>Optimizes token usage for maximum context value.</p> <p>Initialize the optimizer.</p> PARAMETER DESCRIPTION <code>config</code> <p>Tenets configuration</p> <p> TYPE: <code>TenetsConfig</code> </p>"},{"location":"api/tenets/core/distiller/optimizer/#tenets.core.distiller.optimizer.TokenOptimizer-functions","title":"Functions","text":""},{"location":"api/tenets/core/distiller/optimizer/#tenets.core.distiller.optimizer.TokenOptimizer.create_budget","title":"create_budget","text":"Python<pre><code>create_budget(model: Optional[str], max_tokens: Optional[int], prompt_tokens: int, has_git_context: bool = False, has_tenets: bool = False) -&gt; TokenBudget\n</code></pre> <p>Create a token budget for context generation.</p> PARAMETER DESCRIPTION <code>model</code> <p>Target model name.</p> <p> TYPE: <code>Optional[str]</code> </p> <code>max_tokens</code> <p>Optional hard cap on total tokens; overrides model default.</p> <p> TYPE: <code>Optional[int]</code> </p> <code>prompt_tokens</code> <p>Tokens used by the prompt/instructions.</p> <p> TYPE: <code>int</code> </p> <code>has_git_context</code> <p>Whether git context will be included.</p> <p> TYPE: <code>bool</code> DEFAULT: <code>False</code> </p> <code>has_tenets</code> <p>Whether tenets will be injected.</p> <p> TYPE: <code>bool</code> DEFAULT: <code>False</code> </p> RETURNS DESCRIPTION <code>TokenBudget</code> <p>Configured budget with reserves.</p> <p> TYPE: <code>TokenBudget</code> </p>"},{"location":"api/tenets/core/distiller/optimizer/#tenets.core.distiller.optimizer.TokenOptimizer.optimize_file_selection","title":"optimize_file_selection","text":"Python<pre><code>optimize_file_selection(files: List[FileAnalysis], budget: TokenBudget, strategy: str = 'balanced') -&gt; List[Tuple[FileAnalysis, str]]\n</code></pre> <p>Optimize file selection within budget.</p> <p>Uses different strategies to select which files to include and whether to summarize them.</p> PARAMETER DESCRIPTION <code>files</code> <p>Ranked files to consider</p> <p> TYPE: <code>List[FileAnalysis]</code> </p> <code>budget</code> <p>Token budget to work within</p> <p> TYPE: <code>TokenBudget</code> </p> <code>strategy</code> <p>Selection strategy (greedy, balanced, diverse)</p> <p> TYPE: <code>str</code> DEFAULT: <code>'balanced'</code> </p> RETURNS DESCRIPTION <code>List[Tuple[FileAnalysis, str]]</code> <p>List of (file, action) tuples where action is 'full' or 'summary'</p>"},{"location":"api/tenets/core/distiller/optimizer/#tenets.core.distiller.optimizer.TokenOptimizer.estimate_tokens_for_git","title":"estimate_tokens_for_git","text":"Python<pre><code>estimate_tokens_for_git(git_context: Optional[Dict[str, Any]]) -&gt; int\n</code></pre> <p>Estimate tokens needed for git context.</p>"},{"location":"api/tenets/core/distiller/optimizer/#tenets.core.distiller.optimizer.TokenOptimizer.estimate_tokens_for_tenets","title":"estimate_tokens_for_tenets","text":"Python<pre><code>estimate_tokens_for_tenets(tenet_count: int, with_reinforcement: bool = False) -&gt; int\n</code></pre> <p>Estimate tokens needed for tenet injection.</p>"},{"location":"api/tenets/core/distiller/optimizer/#tenets.core.distiller.optimizer-functions","title":"Functions","text":""},{"location":"api/tenets/core/distiller/transform/","title":"Transform","text":""},{"location":"api/tenets/core/distiller/transform/#tenets.core.distiller.transform","title":"tenets.core.distiller.transform","text":"<p>Content transformation utilities for distillation.</p> <p>Provides reusable helpers for optional modes: - full mode (handled outside here) - remove-comments - condense whitespace</p> <p>The functions here are intentionally conservative: they aim to reduce noise and token usage without breaking code structure. Comment stripping is heuristic and language-aware at a shallow level; if an operation would remove an excessive proportion of non-empty lines (&gt;60%), the original content is returned to avoid accidental destruction of meaning.</p>"},{"location":"api/tenets/core/distiller/transform/#tenets.core.distiller.transform-functions","title":"Functions","text":""},{"location":"api/tenets/core/distiller/transform/#tenets.core.distiller.transform.detect_language_from_extension","title":"detect_language_from_extension","text":"Python<pre><code>detect_language_from_extension(path: str) -&gt; str\n</code></pre> <p>Best-effort language detection from file extension.</p> PARAMETER DESCRIPTION <code>path</code> <p>File path.</p> <p> TYPE: <code>str</code> </p>"},{"location":"api/tenets/core/distiller/transform/#tenets.core.distiller.transform.strip_comments","title":"strip_comments","text":"Python<pre><code>strip_comments(content: str, language: str) -&gt; str\n</code></pre> <p>Strip comments from source content.</p> <p>Heuristic removal; skips removal if more than 60% of non-empty lines would disappear.</p> PARAMETER DESCRIPTION <code>content</code> <p>Original file content.</p> <p> TYPE: <code>str</code> </p> <code>language</code> <p>Detected language key.</p> <p> TYPE: <code>str</code> </p>"},{"location":"api/tenets/core/distiller/transform/#tenets.core.distiller.transform.condense_whitespace","title":"condense_whitespace","text":"Python<pre><code>condense_whitespace(content: str) -&gt; str\n</code></pre> <p>Condense extraneous whitespace while preserving code structure.</p> Operations <ul> <li>Collapse runs of &gt;=3 blank lines to a single blank line.</li> <li>Trim trailing spaces.</li> <li>Ensure single final newline.</li> </ul> PARAMETER DESCRIPTION <code>content</code> <p>File content.</p> <p> TYPE: <code>str</code> </p>"},{"location":"api/tenets/core/distiller/transform/#tenets.core.distiller.transform.apply_transformations","title":"apply_transformations","text":"Python<pre><code>apply_transformations(content: str, language: str, *, remove_comments: bool, condense: bool) -&gt; Tuple[str, dict]\n</code></pre> <p>Apply selected transformations.</p> PARAMETER DESCRIPTION <code>content</code> <p>Original content.</p> <p> TYPE: <code>str</code> </p> <code>language</code> <p>Language key.</p> <p> TYPE: <code>str</code> </p> <code>remove_comments</code> <p>Whether to strip comments.</p> <p> TYPE: <code>bool</code> </p> <code>condense</code> <p>Whether to condense whitespace.</p> <p> TYPE: <code>bool</code> </p>"},{"location":"api/tenets/core/examiner/complexity/","title":"Complexity","text":""},{"location":"api/tenets/core/examiner/complexity/#tenets.core.examiner.complexity","title":"tenets.core.examiner.complexity","text":"<p>Complexity analysis module for code examination.</p> <p>This module provides deep complexity analysis for codebases, calculating various complexity metrics including cyclomatic complexity, cognitive complexity, and Halstead metrics. It identifies complex areas that may need refactoring and tracks complexity trends.</p> <p>The complexity analyzer works with the examination system to provide detailed insights into code maintainability and potential problem areas.</p>"},{"location":"api/tenets/core/examiner/complexity/#tenets.core.examiner.complexity-classes","title":"Classes","text":""},{"location":"api/tenets/core/examiner/complexity/#tenets.core.examiner.complexity.ComplexityMetrics","title":"ComplexityMetrics  <code>dataclass</code>","text":"Python<pre><code>ComplexityMetrics(cyclomatic: int = 1, cognitive: int = 0, halstead_volume: float = 0.0, halstead_difficulty: float = 0.0, halstead_effort: float = 0.0, maintainability_index: float = 100.0, nesting_depth: int = 0, parameter_count: int = 0, line_count: int = 0, token_count: int = 0, operator_count: int = 0, operand_count: int = 0)\n</code></pre> <p>Detailed complexity metrics for a code element.</p> <p>Captures various complexity measurements for functions, classes, or files, providing a comprehensive view of code complexity.</p> ATTRIBUTE DESCRIPTION <code>cyclomatic</code> <p>McCabe's cyclomatic complexity</p> <p> TYPE: <code>int</code> </p> <code>cognitive</code> <p>Cognitive complexity (how hard to understand)</p> <p> TYPE: <code>int</code> </p> <code>halstead_volume</code> <p>Halstead volume metric</p> <p> TYPE: <code>float</code> </p> <code>halstead_difficulty</code> <p>Halstead difficulty metric</p> <p> TYPE: <code>float</code> </p> <code>halstead_effort</code> <p>Halstead effort metric</p> <p> TYPE: <code>float</code> </p> <code>maintainability_index</code> <p>Maintainability index (0-100)</p> <p> TYPE: <code>float</code> </p> <code>nesting_depth</code> <p>Maximum nesting depth</p> <p> TYPE: <code>int</code> </p> <code>parameter_count</code> <p>Number of parameters (for functions)</p> <p> TYPE: <code>int</code> </p> <code>line_count</code> <p>Number of lines</p> <p> TYPE: <code>int</code> </p> <code>token_count</code> <p>Number of tokens</p> <p> TYPE: <code>int</code> </p> <code>operator_count</code> <p>Number of unique operators</p> <p> TYPE: <code>int</code> </p> <code>operand_count</code> <p>Number of unique operands</p> <p> TYPE: <code>int</code> </p>"},{"location":"api/tenets/core/examiner/complexity/#tenets.core.examiner.complexity.ComplexityMetrics-attributes","title":"Attributes","text":""},{"location":"api/tenets/core/examiner/complexity/#tenets.core.examiner.complexity.ComplexityMetrics.complexity_per_line","title":"complexity_per_line  <code>property</code>","text":"Python<pre><code>complexity_per_line: float\n</code></pre> <p>Calculate complexity per line of code.</p> RETURNS DESCRIPTION <code>float</code> <p>Cyclomatic complexity divided by lines</p> <p> TYPE: <code>float</code> </p>"},{"location":"api/tenets/core/examiner/complexity/#tenets.core.examiner.complexity.ComplexityMetrics.risk_level","title":"risk_level  <code>property</code>","text":"Python<pre><code>risk_level: str\n</code></pre> <p>Determine risk level based on cyclomatic complexity.</p> <p>Uses industry-standard thresholds to categorize risk.</p> RETURNS DESCRIPTION <code>str</code> <p>Risk level (low, medium, high, very high)</p> <p> TYPE: <code>str</code> </p>"},{"location":"api/tenets/core/examiner/complexity/#tenets.core.examiner.complexity.ComplexityMetrics.cognitive_risk_level","title":"cognitive_risk_level  <code>property</code>","text":"Python<pre><code>cognitive_risk_level: str\n</code></pre> <p>Determine risk level based on cognitive complexity.</p> RETURNS DESCRIPTION <code>str</code> <p>Cognitive risk level</p> <p> TYPE: <code>str</code> </p>"},{"location":"api/tenets/core/examiner/complexity/#tenets.core.examiner.complexity.FunctionComplexity","title":"FunctionComplexity  <code>dataclass</code>","text":"Python<pre><code>FunctionComplexity(name: str, full_name: str, file_path: str, line_start: int, line_end: int, metrics: ComplexityMetrics = ComplexityMetrics(), calls: Set[str] = set(), called_by: Set[str] = set(), is_recursive: bool = False, is_generator: bool = False, is_async: bool = False, has_decorator: bool = False, docstring: Optional[str] = None)\n</code></pre> <p>Complexity analysis for a single function or method.</p> <p>Tracks detailed complexity metrics for individual functions, including their location, parameters, and various complexity scores.</p> ATTRIBUTE DESCRIPTION <code>name</code> <p>Function name</p> <p> TYPE: <code>str</code> </p> <code>full_name</code> <p>Fully qualified name (with class if method)</p> <p> TYPE: <code>str</code> </p> <code>file_path</code> <p>Path to containing file</p> <p> TYPE: <code>str</code> </p> <code>line_start</code> <p>Starting line number</p> <p> TYPE: <code>int</code> </p> <code>line_end</code> <p>Ending line number</p> <p> TYPE: <code>int</code> </p> <code>metrics</code> <p>Detailed complexity metrics</p> <p> TYPE: <code>ComplexityMetrics</code> </p> <code>calls</code> <p>Functions called by this function</p> <p> TYPE: <code>Set[str]</code> </p> <code>called_by</code> <p>Functions that call this function</p> <p> TYPE: <code>Set[str]</code> </p> <code>is_recursive</code> <p>Whether function is recursive</p> <p> TYPE: <code>bool</code> </p> <code>is_generator</code> <p>Whether function is a generator</p> <p> TYPE: <code>bool</code> </p> <code>is_async</code> <p>Whether function is async</p> <p> TYPE: <code>bool</code> </p> <code>has_decorator</code> <p>Whether function has decorators</p> <p> TYPE: <code>bool</code> </p> <code>docstring</code> <p>Function docstring if present</p> <p> TYPE: <code>Optional[str]</code> </p>"},{"location":"api/tenets/core/examiner/complexity/#tenets.core.examiner.complexity.FunctionComplexity-attributes","title":"Attributes","text":""},{"location":"api/tenets/core/examiner/complexity/#tenets.core.examiner.complexity.FunctionComplexity.lines","title":"lines  <code>property</code>","text":"Python<pre><code>lines: int\n</code></pre> <p>Get number of lines in function.</p> RETURNS DESCRIPTION <code>int</code> <p>Line count</p> <p> TYPE: <code>int</code> </p>"},{"location":"api/tenets/core/examiner/complexity/#tenets.core.examiner.complexity.FunctionComplexity.has_documentation","title":"has_documentation  <code>property</code>","text":"Python<pre><code>has_documentation: bool\n</code></pre> <p>Check if function has documentation.</p> RETURNS DESCRIPTION <code>bool</code> <p>True if docstring exists</p> <p> TYPE: <code>bool</code> </p>"},{"location":"api/tenets/core/examiner/complexity/#tenets.core.examiner.complexity.ClassComplexity","title":"ClassComplexity  <code>dataclass</code>","text":"Python<pre><code>ClassComplexity(name: str, file_path: str, line_start: int, line_end: int, metrics: ComplexityMetrics = ComplexityMetrics(), methods: List[FunctionComplexity] = list(), nested_classes: List[ClassComplexity] = list(), inheritance_depth: int = 0, parent_classes: List[str] = list(), abstract_methods: int = 0, static_methods: int = 0, properties: int = 0, instance_attributes: int = 0)\n</code></pre> <p>Complexity analysis for a class.</p> <p>Aggregates complexity metrics for an entire class including all its methods and nested classes.</p> ATTRIBUTE DESCRIPTION <code>name</code> <p>Class name</p> <p> TYPE: <code>str</code> </p> <code>file_path</code> <p>Path to containing file</p> <p> TYPE: <code>str</code> </p> <code>line_start</code> <p>Starting line number</p> <p> TYPE: <code>int</code> </p> <code>line_end</code> <p>Ending line number</p> <p> TYPE: <code>int</code> </p> <code>metrics</code> <p>Aggregated complexity metrics</p> <p> TYPE: <code>ComplexityMetrics</code> </p> <code>methods</code> <p>List of method complexity analyses</p> <p> TYPE: <code>List[FunctionComplexity]</code> </p> <code>nested_classes</code> <p>List of nested class complexities</p> <p> TYPE: <code>List[ClassComplexity]</code> </p> <code>inheritance_depth</code> <p>Depth in inheritance hierarchy</p> <p> TYPE: <code>int</code> </p> <code>parent_classes</code> <p>List of parent class names</p> <p> TYPE: <code>List[str]</code> </p> <code>abstract_methods</code> <p>Count of abstract methods</p> <p> TYPE: <code>int</code> </p> <code>static_methods</code> <p>Count of static methods</p> <p> TYPE: <code>int</code> </p> <code>properties</code> <p>Count of properties</p> <p> TYPE: <code>int</code> </p> <code>instance_attributes</code> <p>Count of instance attributes</p> <p> TYPE: <code>int</code> </p>"},{"location":"api/tenets/core/examiner/complexity/#tenets.core.examiner.complexity.ClassComplexity-attributes","title":"Attributes","text":""},{"location":"api/tenets/core/examiner/complexity/#tenets.core.examiner.complexity.ClassComplexity.total_methods","title":"total_methods  <code>property</code>","text":"Python<pre><code>total_methods: int\n</code></pre> <p>Get total number of methods.</p> RETURNS DESCRIPTION <code>int</code> <p>Method count</p> <p> TYPE: <code>int</code> </p>"},{"location":"api/tenets/core/examiner/complexity/#tenets.core.examiner.complexity.ClassComplexity.avg_method_complexity","title":"avg_method_complexity  <code>property</code>","text":"Python<pre><code>avg_method_complexity: float\n</code></pre> <p>Calculate average method complexity.</p> RETURNS DESCRIPTION <code>float</code> <p>Average cyclomatic complexity of methods</p> <p> TYPE: <code>float</code> </p>"},{"location":"api/tenets/core/examiner/complexity/#tenets.core.examiner.complexity.ClassComplexity.weighted_methods_per_class","title":"weighted_methods_per_class  <code>property</code>","text":"Python<pre><code>weighted_methods_per_class: int\n</code></pre> <p>Calculate WMC (Weighted Methods per Class) metric.</p> <p>Sum of complexities of all methods in the class.</p> RETURNS DESCRIPTION <code>int</code> <p>WMC metric value</p> <p> TYPE: <code>int</code> </p>"},{"location":"api/tenets/core/examiner/complexity/#tenets.core.examiner.complexity.FileComplexity","title":"FileComplexity  <code>dataclass</code>","text":"Python<pre><code>FileComplexity(path: str, name: str, language: str, metrics: ComplexityMetrics = ComplexityMetrics(), functions: List[FunctionComplexity] = list(), classes: List[ClassComplexity] = list(), total_complexity: int = 0, max_complexity: int = 0, complexity_hotspots: List[Dict[str, Any]] = list(), import_complexity: int = 0, coupling: float = 0.0, cohesion: float = 0.0)\n</code></pre> <p>Complexity analysis for an entire file.</p> <p>Aggregates all complexity metrics for a source file including functions, classes, and overall file metrics.</p> ATTRIBUTE DESCRIPTION <code>path</code> <p>File path</p> <p> TYPE: <code>str</code> </p> <code>name</code> <p>File name</p> <p> TYPE: <code>str</code> </p> <code>language</code> <p>Programming language</p> <p> TYPE: <code>str</code> </p> <code>metrics</code> <p>File-level complexity metrics</p> <p> TYPE: <code>ComplexityMetrics</code> </p> <code>functions</code> <p>List of function complexities</p> <p> TYPE: <code>List[FunctionComplexity]</code> </p> <code>classes</code> <p>List of class complexities</p> <p> TYPE: <code>List[ClassComplexity]</code> </p> <code>total_complexity</code> <p>Sum of all complexity in file</p> <p> TYPE: <code>int</code> </p> <code>max_complexity</code> <p>Maximum complexity found in file</p> <p> TYPE: <code>int</code> </p> <code>complexity_hotspots</code> <p>Areas of high complexity</p> <p> TYPE: <code>List[Dict[str, Any]]</code> </p> <code>import_complexity</code> <p>Complexity from imports/dependencies</p> <p> TYPE: <code>int</code> </p> <code>coupling</code> <p>Coupling metric</p> <p> TYPE: <code>float</code> </p> <code>cohesion</code> <p>Cohesion metric</p> <p> TYPE: <code>float</code> </p>"},{"location":"api/tenets/core/examiner/complexity/#tenets.core.examiner.complexity.FileComplexity-attributes","title":"Attributes","text":""},{"location":"api/tenets/core/examiner/complexity/#tenets.core.examiner.complexity.FileComplexity.avg_complexity","title":"avg_complexity  <code>property</code>","text":"Python<pre><code>avg_complexity: float\n</code></pre> <p>Calculate average complexity across all functions.</p> RETURNS DESCRIPTION <code>float</code> <p>Average complexity</p> <p> TYPE: <code>float</code> </p>"},{"location":"api/tenets/core/examiner/complexity/#tenets.core.examiner.complexity.FileComplexity.needs_refactoring","title":"needs_refactoring  <code>property</code>","text":"Python<pre><code>needs_refactoring: bool\n</code></pre> <p>Determine if file needs refactoring based on complexity.</p> RETURNS DESCRIPTION <code>bool</code> <p>True if refactoring is recommended</p> <p> TYPE: <code>bool</code> </p>"},{"location":"api/tenets/core/examiner/complexity/#tenets.core.examiner.complexity.ComplexityReport","title":"ComplexityReport  <code>dataclass</code>","text":"Python<pre><code>ComplexityReport(total_files: int = 0, total_functions: int = 0, total_classes: int = 0, avg_complexity: float = 0.0, max_complexity: int = 0, median_complexity: float = 0.0, std_dev_complexity: float = 0.0, high_complexity_count: int = 0, very_high_complexity_count: int = 0, files: List[FileComplexity] = list(), top_complex_functions: List[FunctionComplexity] = list(), top_complex_classes: List[ClassComplexity] = list(), top_complex_files: List[FileComplexity] = list(), complexity_distribution: Dict[str, int] = dict(), refactoring_candidates: List[Dict[str, Any]] = list(), technical_debt_hours: float = 0.0, trend_direction: str = 'stable', recommendations: List[str] = list(), _override_complexity_score: Optional[float] = None)\n</code></pre> <p>Comprehensive complexity analysis report.</p> <p>Aggregates complexity analysis across an entire codebase, providing statistics, trends, and actionable insights.</p> ATTRIBUTE DESCRIPTION <code>total_files</code> <p>Total files analyzed</p> <p> TYPE: <code>int</code> </p> <code>total_functions</code> <p>Total functions analyzed</p> <p> TYPE: <code>int</code> </p> <code>total_classes</code> <p>Total classes analyzed</p> <p> TYPE: <code>int</code> </p> <code>avg_complexity</code> <p>Average cyclomatic complexity</p> <p> TYPE: <code>float</code> </p> <code>max_complexity</code> <p>Maximum cyclomatic complexity found</p> <p> TYPE: <code>int</code> </p> <code>median_complexity</code> <p>Median cyclomatic complexity</p> <p> TYPE: <code>float</code> </p> <code>std_dev_complexity</code> <p>Standard deviation of complexity</p> <p> TYPE: <code>float</code> </p> <code>high_complexity_count</code> <p>Count of high complexity items</p> <p> TYPE: <code>int</code> </p> <code>very_high_complexity_count</code> <p>Count of very high complexity items</p> <p> TYPE: <code>int</code> </p> <code>files</code> <p>List of file complexity analyses</p> <p> TYPE: <code>List[FileComplexity]</code> </p> <code>top_complex_functions</code> <p>Most complex functions</p> <p> TYPE: <code>List[FunctionComplexity]</code> </p> <code>top_complex_classes</code> <p>Most complex classes</p> <p> TYPE: <code>List[ClassComplexity]</code> </p> <code>top_complex_files</code> <p>Most complex files</p> <p> TYPE: <code>List[FileComplexity]</code> </p> <code>complexity_distribution</code> <p>Distribution of complexity values</p> <p> TYPE: <code>Dict[str, int]</code> </p> <code>refactoring_candidates</code> <p>Items recommended for refactoring</p> <p> TYPE: <code>List[Dict[str, Any]]</code> </p> <code>technical_debt_hours</code> <p>Estimated hours to address complexity</p> <p> TYPE: <code>float</code> </p> <code>trend_direction</code> <p>Whether complexity is increasing/decreasing</p> <p> TYPE: <code>str</code> </p> <code>recommendations</code> <p>List of actionable recommendations</p> <p> TYPE: <code>List[str]</code> </p>"},{"location":"api/tenets/core/examiner/complexity/#tenets.core.examiner.complexity.ComplexityReport-attributes","title":"Attributes","text":""},{"location":"api/tenets/core/examiner/complexity/#tenets.core.examiner.complexity.ComplexityReport.complexity_score","title":"complexity_score  <code>property</code>","text":"Python<pre><code>complexity_score: float\n</code></pre> <p>Calculate overall complexity score (0-100).</p> <p>Lower scores indicate better (less complex) code.</p> RETURNS DESCRIPTION <code>float</code> <p>Complexity score</p> <p> TYPE: <code>float</code> </p>"},{"location":"api/tenets/core/examiner/complexity/#tenets.core.examiner.complexity.ComplexityReport-functions","title":"Functions","text":""},{"location":"api/tenets/core/examiner/complexity/#tenets.core.examiner.complexity.ComplexityReport.to_dict","title":"to_dict","text":"Python<pre><code>to_dict() -&gt; Dict[str, Any]\n</code></pre> <p>Convert report to dictionary.</p> RETURNS DESCRIPTION <code>Dict[str, Any]</code> <p>Dict[str, Any]: Dictionary representation</p>"},{"location":"api/tenets/core/examiner/complexity/#tenets.core.examiner.complexity.ComplexityAnalyzer","title":"ComplexityAnalyzer","text":"Python<pre><code>ComplexityAnalyzer(config: TenetsConfig)\n</code></pre> <p>Analyzer for code complexity metrics.</p> <p>Provides comprehensive complexity analysis including cyclomatic complexity, cognitive complexity, and various other metrics to assess code maintainability and identify refactoring opportunities.</p> ATTRIBUTE DESCRIPTION <code>config</code> <p>Configuration object</p> <p> </p> <code>logger</code> <p>Logger instance</p> <p> </p> <code>complexity_cache</code> <p>Cache of computed complexities</p> <p> TYPE: <code>Dict[str, Any]</code> </p> <p>Initialize complexity analyzer.</p> PARAMETER DESCRIPTION <code>config</code> <p>TenetsConfig instance</p> <p> TYPE: <code>TenetsConfig</code> </p>"},{"location":"api/tenets/core/examiner/complexity/#tenets.core.examiner.complexity.ComplexityAnalyzer-functions","title":"Functions","text":""},{"location":"api/tenets/core/examiner/complexity/#tenets.core.examiner.complexity.ComplexityAnalyzer.analyze","title":"analyze","text":"Python<pre><code>analyze(files: List[Any], threshold: float = 10.0, deep: bool = False) -&gt; ComplexityReport\n</code></pre> <p>Analyze complexity for a list of files.</p> <p>Performs comprehensive complexity analysis across all provided files, calculating various metrics and identifying problem areas.</p> PARAMETER DESCRIPTION <code>files</code> <p>List of analyzed file objects</p> <p> TYPE: <code>List[Any]</code> </p> <code>threshold</code> <p>Complexity threshold for flagging</p> <p> TYPE: <code>float</code> DEFAULT: <code>10.0</code> </p> <code>deep</code> <p>Whether to perform deep analysis</p> <p> TYPE: <code>bool</code> DEFAULT: <code>False</code> </p> RETURNS DESCRIPTION <code>ComplexityReport</code> <p>Comprehensive complexity analysis</p> <p> TYPE: <code>ComplexityReport</code> </p> Example <p>analyzer = ComplexityAnalyzer(config) report = analyzer.analyze(files, threshold=10) print(f\"Average complexity: {report.avg_complexity}\")</p>"},{"location":"api/tenets/core/examiner/complexity/#tenets.core.examiner.complexity.ComplexityAnalyzer.analyze_file","title":"analyze_file","text":"Python<pre><code>analyze_file(file_analysis: Any) -&gt; Dict[str, Any]\n</code></pre> <p>Analyze complexity for a single file.</p> PARAMETER DESCRIPTION <code>file_analysis</code> <p>Analyzed file object</p> <p> TYPE: <code>Any</code> </p> RETURNS DESCRIPTION <code>Dict[str, Any]</code> <p>Dict[str, Any]: File complexity details</p>"},{"location":"api/tenets/core/examiner/complexity/#tenets.core.examiner.complexity-functions","title":"Functions","text":""},{"location":"api/tenets/core/examiner/complexity/#tenets.core.examiner.complexity.analyze_complexity","title":"analyze_complexity","text":"Python<pre><code>analyze_complexity(files: List[Any], threshold: int = 10, config: Optional[TenetsConfig] = None) -&gt; ComplexityReport\n</code></pre> <p>Analyze complexity for a list of files.</p> <p>Thin wrapper that constructs a ComplexityAnalyzer and returns its report.</p> PARAMETER DESCRIPTION <code>files</code> <p>List of analyzed file-like objects</p> <p> TYPE: <code>List[Any]</code> </p> <code>threshold</code> <p>Threshold for high/very high classification</p> <p> TYPE: <code>int</code> DEFAULT: <code>10</code> </p> <code>config</code> <p>Optional TenetsConfig instance</p> <p> TYPE: <code>Optional[TenetsConfig]</code> DEFAULT: <code>None</code> </p> RETURNS DESCRIPTION <code>ComplexityReport</code> <p>ComplexityReport</p>"},{"location":"api/tenets/core/examiner/examiner/","title":"Examiner","text":""},{"location":"api/tenets/core/examiner/examiner/#tenets.core.examiner.examiner","title":"tenets.core.examiner.examiner","text":"<p>Main examiner module for comprehensive code analysis.</p> <p>This module provides the core examination functionality, orchestrating various analysis components to provide deep insights into codebases. It coordinates between metrics calculation, complexity analysis, ownership tracking, and hotspot detection to deliver comprehensive examination results.</p> <p>The Examiner class serves as the main entry point for all examination operations, handling file discovery, analysis orchestration, and result aggregation.</p>"},{"location":"api/tenets/core/examiner/examiner/#tenets.core.examiner.examiner-classes","title":"Classes","text":""},{"location":"api/tenets/core/examiner/examiner/#tenets.core.examiner.examiner.ExaminationResult","title":"ExaminationResult  <code>dataclass</code>","text":"Python<pre><code>ExaminationResult(root_path: Path, total_files: int = 0, total_lines: int = 0, languages: List[str] = list(), files: List[Any] = list(), metrics: Optional[MetricsReport] = None, complexity: Optional[ComplexityReport] = None, ownership: Optional[OwnershipReport] = None, hotspots: Optional[HotspotReport] = None, git_analysis: Optional[Any] = None, summary: Dict[str, Any] = dict(), timestamp: datetime = datetime.now(), duration: float = 0.0, config: Optional[TenetsConfig] = None, errors: List[str] = list(), excluded_files: List[str] = list(), excluded_count: int = 0, ignored_patterns: List[str] = list())\n</code></pre> <p>Comprehensive examination results for a codebase.</p> <p>This dataclass aggregates all examination findings including metrics, complexity analysis, ownership patterns, and detected hotspots. It provides a complete picture of codebase health and structure.</p> ATTRIBUTE DESCRIPTION <code>root_path</code> <p>Root directory that was examined</p> <p> TYPE: <code>Path</code> </p> <code>total_files</code> <p>Total number of files analyzed</p> <p> TYPE: <code>int</code> </p> <code>total_lines</code> <p>Total lines of code across all files</p> <p> TYPE: <code>int</code> </p> <code>languages</code> <p>List of programming languages detected</p> <p> TYPE: <code>List[str]</code> </p> <code>files</code> <p>List of analyzed file objects</p> <p> TYPE: <code>List[Any]</code> </p> <code>metrics</code> <p>Detailed metrics report</p> <p> TYPE: <code>Optional[MetricsReport]</code> </p> <code>complexity</code> <p>Complexity analysis report</p> <p> TYPE: <code>Optional[ComplexityReport]</code> </p> <code>ownership</code> <p>Code ownership report</p> <p> TYPE: <code>Optional[OwnershipReport]</code> </p> <code>hotspots</code> <p>Detected hotspot report</p> <p> TYPE: <code>Optional[HotspotReport]</code> </p> <code>git_analysis</code> <p>Git repository analysis if available</p> <p> TYPE: <code>Optional[Any]</code> </p> <code>summary</code> <p>High-level summary statistics</p> <p> TYPE: <code>Dict[str, Any]</code> </p> <code>timestamp</code> <p>When examination was performed</p> <p> TYPE: <code>datetime</code> </p> <code>duration</code> <p>How long examination took in seconds</p> <p> TYPE: <code>float</code> </p> <code>config</code> <p>Configuration used for examination</p> <p> TYPE: <code>Optional[TenetsConfig]</code> </p> <code>errors</code> <p>Any errors encountered during examination</p> <p> TYPE: <code>List[str]</code> </p>"},{"location":"api/tenets/core/examiner/examiner/#tenets.core.examiner.examiner.ExaminationResult-attributes","title":"Attributes","text":""},{"location":"api/tenets/core/examiner/examiner/#tenets.core.examiner.examiner.ExaminationResult.has_issues","title":"has_issues  <code>property</code>","text":"Python<pre><code>has_issues: bool\n</code></pre> <p>Check if examination found any issues.</p> RETURNS DESCRIPTION <code>bool</code> <p>True if any issues were detected</p> <p> TYPE: <code>bool</code> </p>"},{"location":"api/tenets/core/examiner/examiner/#tenets.core.examiner.examiner.ExaminationResult.health_score","title":"health_score  <code>property</code>","text":"Python<pre><code>health_score: float\n</code></pre> <p>Calculate overall codebase health score.</p> <p>Computes a health score from 0-100 based on various metrics including complexity, test coverage, documentation, and hotspots.</p> RETURNS DESCRIPTION <code>float</code> <p>Health score between 0 and 100</p> <p> TYPE: <code>float</code> </p>"},{"location":"api/tenets/core/examiner/examiner/#tenets.core.examiner.examiner.ExaminationResult-functions","title":"Functions","text":""},{"location":"api/tenets/core/examiner/examiner/#tenets.core.examiner.examiner.ExaminationResult.to_dict","title":"to_dict","text":"Python<pre><code>to_dict() -&gt; Dict[str, Any]\n</code></pre> <p>Convert examination results to dictionary.</p> <p>Serializes all examination data into a dictionary format suitable for JSON export or further processing. Handles nested objects and datetime serialization.</p> RETURNS DESCRIPTION <code>Dict[str, Any]</code> <p>Dict[str, Any]: Dictionary representation of examination results</p>"},{"location":"api/tenets/core/examiner/examiner/#tenets.core.examiner.examiner.ExaminationResult.to_json","title":"to_json","text":"Python<pre><code>to_json(indent: int = 2) -&gt; str\n</code></pre> <p>Convert examination results to JSON string.</p> PARAMETER DESCRIPTION <code>indent</code> <p>Number of spaces for JSON indentation</p> <p> TYPE: <code>int</code> DEFAULT: <code>2</code> </p> RETURNS DESCRIPTION <code>str</code> <p>JSON representation of examination results</p> <p> TYPE: <code>str</code> </p>"},{"location":"api/tenets/core/examiner/examiner/#tenets.core.examiner.examiner.Examiner","title":"Examiner","text":"Python<pre><code>Examiner(config: TenetsConfig)\n</code></pre> <p>Main orchestrator for code examination operations.</p> <p>The Examiner class coordinates all examination activities, managing the analysis pipeline from file discovery through final reporting. It integrates various analyzers and trackers to provide comprehensive codebase insights.</p> <p>This class serves as the primary API for examination functionality, handling configuration, error recovery, and result aggregation.</p> ATTRIBUTE DESCRIPTION <code>config</code> <p>Configuration object</p> <p> </p> <code>logger</code> <p>Logger instance</p> <p> </p> <code>analyzer</code> <p>Code analyzer instance</p> <p> TYPE: <code>CodeAnalyzer</code> </p> <code>scanner</code> <p>File scanner instance</p> <p> </p> <code>metrics_calculator</code> <p>Metrics calculation instance</p> <p> </p> <code>complexity_analyzer</code> <p>Complexity analysis instance</p> <p> </p> <code>ownership_tracker</code> <p>Ownership tracking instance</p> <p> </p> <code>hotspot_detector</code> <p>Hotspot detection instance</p> <p> </p> <p>Initialize the Examiner with configuration.</p> <p>Sets up all required components for examination including analyzers, scanners, and specialized examination modules.</p> PARAMETER DESCRIPTION <code>config</code> <p>TenetsConfig instance with examination settings</p> <p> TYPE: <code>TenetsConfig</code> </p>"},{"location":"api/tenets/core/examiner/examiner/#tenets.core.examiner.examiner.Examiner-functions","title":"Functions","text":""},{"location":"api/tenets/core/examiner/examiner/#tenets.core.examiner.examiner.Examiner.examine_project","title":"examine_project","text":"Python<pre><code>examine_project(path: Path, deep: bool = False, include_git: bool = True, include_metrics: bool = True, include_complexity: bool = True, include_ownership: bool = True, include_hotspots: bool = True, include_patterns: Optional[List[str]] = None, exclude_patterns: Optional[List[str]] = None, max_files: Optional[int] = None) -&gt; ExaminationResult\n</code></pre> <p>Perform comprehensive project examination.</p> <p>Conducts a full examination of the specified project, running all requested analysis types and aggregating results into a comprehensive report.</p> PARAMETER DESCRIPTION <code>path</code> <p>Path to project directory</p> <p> TYPE: <code>Path</code> </p> <code>deep</code> <p>Whether to perform deep AST-based analysis</p> <p> TYPE: <code>bool</code> DEFAULT: <code>False</code> </p> <code>include_git</code> <p>Whether to include git repository analysis</p> <p> TYPE: <code>bool</code> DEFAULT: <code>True</code> </p> <code>include_metrics</code> <p>Whether to calculate code metrics</p> <p> TYPE: <code>bool</code> DEFAULT: <code>True</code> </p> <code>include_complexity</code> <p>Whether to analyze code complexity</p> <p> TYPE: <code>bool</code> DEFAULT: <code>True</code> </p> <code>include_ownership</code> <p>Whether to track code ownership</p> <p> TYPE: <code>bool</code> DEFAULT: <code>True</code> </p> <code>include_hotspots</code> <p>Whether to detect code hotspots</p> <p> TYPE: <code>bool</code> DEFAULT: <code>True</code> </p> <code>include_patterns</code> <p>File patterns to include (e.g., ['*.py'])</p> <p> TYPE: <code>Optional[List[str]]</code> DEFAULT: <code>None</code> </p> <code>exclude_patterns</code> <p>File patterns to exclude (e.g., ['test_*'])</p> <p> TYPE: <code>Optional[List[str]]</code> DEFAULT: <code>None</code> </p> <code>max_files</code> <p>Maximum number of files to analyze</p> <p> TYPE: <code>Optional[int]</code> DEFAULT: <code>None</code> </p> RETURNS DESCRIPTION <code>ExaminationResult</code> <p>Comprehensive examination findings</p> <p> TYPE: <code>ExaminationResult</code> </p> RAISES DESCRIPTION <code>ValueError</code> <p>If path doesn't exist or isn't a directory</p> Example <p>examiner = Examiner(config) result = examiner.examine_project( ...     Path(\"./src\"), ...     deep=True, ...     include_git=True ... ) print(f\"Health score: {result.health_score}\")</p>"},{"location":"api/tenets/core/examiner/examiner/#tenets.core.examiner.examiner.Examiner.examine_file","title":"examine_file","text":"Python<pre><code>examine_file(file_path: Path, deep: bool = False) -&gt; Dict[str, Any]\n</code></pre> <p>Examine a single file in detail.</p> <p>Performs focused analysis on a single file, extracting all available metrics, complexity measures, and structural information.</p> PARAMETER DESCRIPTION <code>file_path</code> <p>Path to the file to examine</p> <p> TYPE: <code>Path</code> </p> <code>deep</code> <p>Whether to perform deep AST-based analysis</p> <p> TYPE: <code>bool</code> DEFAULT: <code>False</code> </p> RETURNS DESCRIPTION <code>Dict[str, Any]</code> <p>Dict[str, Any]: Detailed file examination results</p> RAISES DESCRIPTION <code>ValueError</code> <p>If file doesn't exist or isn't a file</p> Example <p>examiner = Examiner(config) result = examiner.examine_file(Path(\"main.py\"), deep=True) print(f\"Complexity: {result['complexity']}\")</p>"},{"location":"api/tenets/core/examiner/examiner/#tenets.core.examiner.examiner-functions","title":"Functions","text":""},{"location":"api/tenets/core/examiner/examiner/#tenets.core.examiner.examiner.examine_directory","title":"examine_directory","text":"Python<pre><code>examine_directory(path: Path, config: Optional[TenetsConfig] = None, **kwargs: Any) -&gt; ExaminationResult\n</code></pre> <p>Convenience function to examine a directory.</p> <p>Creates an Examiner instance and performs a full examination of the specified directory with provided options.</p> PARAMETER DESCRIPTION <code>path</code> <p>Directory path to examine</p> <p> TYPE: <code>Path</code> </p> <code>config</code> <p>Optional configuration (uses defaults if None)</p> <p> TYPE: <code>Optional[TenetsConfig]</code> DEFAULT: <code>None</code> </p> <code>**kwargs</code> <p>Additional arguments passed to examine_project()</p> <p> TYPE: <code>Any</code> DEFAULT: <code>{}</code> </p> RETURNS DESCRIPTION <code>ExaminationResult</code> <p>Examination findings</p> <p> TYPE: <code>ExaminationResult</code> </p> Example <p>result = examine_directory( ...     Path(\"./src\"), ...     deep=True, ...     include_git=True ... ) print(f\"Found {result.total_files} files\")</p>"},{"location":"api/tenets/core/examiner/hotspots/","title":"Hotspots","text":""},{"location":"api/tenets/core/examiner/hotspots/#tenets.core.examiner.hotspots","title":"tenets.core.examiner.hotspots","text":"<p>Hotspot detection module for code examination.</p> <p>This module identifies code hotspots - areas of the codebase that change frequently, have high complexity, or exhibit other problematic patterns. Hotspots often indicate areas that need refactoring, have bugs, or are difficult to maintain.</p> <p>The hotspot detector combines git history, complexity metrics, and other indicators to identify problematic areas that deserve attention.</p>"},{"location":"api/tenets/core/examiner/hotspots/#tenets.core.examiner.hotspots-classes","title":"Classes","text":""},{"location":"api/tenets/core/examiner/hotspots/#tenets.core.examiner.hotspots.HotspotMetrics","title":"HotspotMetrics  <code>dataclass</code>","text":"Python<pre><code>HotspotMetrics(change_frequency: float = 0.0, commit_count: int = 0, author_count: int = 0, lines_changed: int = 0, bug_fix_commits: int = 0, refactor_commits: int = 0, complexity: float = 0.0, coupling: int = 0, age_days: int = 0, recency_days: int = 0, churn_rate: float = 0.0, defect_density: float = 0.0, stability_score: float = 100.0, _hotspot_score_override: Optional[float] = None, _risk_level_override: Optional[str] = None)\n</code></pre> <p>Metrics for identifying and scoring hotspots.</p> <p>Combines various indicators to determine if a code area is a hotspot that requires attention or refactoring.</p> ATTRIBUTE DESCRIPTION <code>change_frequency</code> <p>How often the file changes</p> <p> TYPE: <code>float</code> </p> <code>commit_count</code> <p>Total number of commits</p> <p> TYPE: <code>int</code> </p> <code>author_count</code> <p>Number of unique authors</p> <p> TYPE: <code>int</code> </p> <code>lines_changed</code> <p>Total lines added/removed</p> <p> TYPE: <code>int</code> </p> <code>bug_fix_commits</code> <p>Number of bug fix commits</p> <p> TYPE: <code>int</code> </p> <code>refactor_commits</code> <p>Number of refactoring commits</p> <p> TYPE: <code>int</code> </p> <code>complexity</code> <p>Code complexity if available</p> <p> TYPE: <code>float</code> </p> <code>coupling</code> <p>How many other files change with this one</p> <p> TYPE: <code>int</code> </p> <code>age_days</code> <p>Days since file creation</p> <p> TYPE: <code>int</code> </p> <code>recency_days</code> <p>Days since last change</p> <p> TYPE: <code>int</code> </p> <code>churn_rate</code> <p>Rate of change over time</p> <p> TYPE: <code>float</code> </p> <code>defect_density</code> <p>Estimated defect density</p> <p> TYPE: <code>float</code> </p> <code>stability_score</code> <p>File stability score (0-100)</p> <p> TYPE: <code>float</code> </p>"},{"location":"api/tenets/core/examiner/hotspots/#tenets.core.examiner.hotspots.HotspotMetrics-attributes","title":"Attributes","text":""},{"location":"api/tenets/core/examiner/hotspots/#tenets.core.examiner.hotspots.HotspotMetrics.hotspot_score","title":"hotspot_score  <code>property</code> <code>writable</code>","text":"Python<pre><code>hotspot_score: float\n</code></pre> <p>Calculate overall hotspot score.</p> <p>Higher scores indicate more problematic areas.</p> RETURNS DESCRIPTION <code>float</code> <p>Hotspot score (0-100)</p> <p> TYPE: <code>float</code> </p>"},{"location":"api/tenets/core/examiner/hotspots/#tenets.core.examiner.hotspots.HotspotMetrics.risk_level","title":"risk_level  <code>property</code> <code>writable</code>","text":"Python<pre><code>risk_level: str\n</code></pre> <p>Determine risk level based on hotspot score.</p> RETURNS DESCRIPTION <code>str</code> <p>Risk level (critical, high, medium, low)</p> <p> TYPE: <code>str</code> </p>"},{"location":"api/tenets/core/examiner/hotspots/#tenets.core.examiner.hotspots.HotspotMetrics.needs_attention","title":"needs_attention  <code>property</code>","text":"Python<pre><code>needs_attention: bool\n</code></pre> <p>Check if this hotspot needs immediate attention.</p> RETURNS DESCRIPTION <code>bool</code> <p>True if attention needed</p> <p> TYPE: <code>bool</code> </p>"},{"location":"api/tenets/core/examiner/hotspots/#tenets.core.examiner.hotspots.FileHotspot","title":"FileHotspot  <code>dataclass</code>","text":"Python<pre><code>FileHotspot(path: str, name: str, metrics: HotspotMetrics = HotspotMetrics(), recent_commits: List[Dict[str, Any]] = list(), coupled_files: List[str] = list(), problem_indicators: List[str] = list(), recommended_actions: List[str] = list(), last_modified: Optional[datetime] = None, created: Optional[datetime] = None, size: int = 0, language: str = 'unknown')\n</code></pre> <p>Hotspot information for a single file.</p> <p>Tracks detailed information about why a file is considered a hotspot and what actions might be needed.</p> ATTRIBUTE DESCRIPTION <code>path</code> <p>File path</p> <p> TYPE: <code>str</code> </p> <code>name</code> <p>File name</p> <p> TYPE: <code>str</code> </p> <code>metrics</code> <p>Hotspot metrics</p> <p> TYPE: <code>HotspotMetrics</code> </p> <code>recent_commits</code> <p>Recent commit history</p> <p> TYPE: <code>List[Dict[str, Any]]</code> </p> <code>coupled_files</code> <p>Files that frequently change together</p> <p> TYPE: <code>List[str]</code> </p> <code>problem_indicators</code> <p>Specific problems detected</p> <p> TYPE: <code>List[str]</code> </p> <code>recommended_actions</code> <p>Suggested actions to address issues</p> <p> TYPE: <code>List[str]</code> </p> <code>last_modified</code> <p>Last modification date</p> <p> TYPE: <code>Optional[datetime]</code> </p> <code>created</code> <p>Creation date</p> <p> TYPE: <code>Optional[datetime]</code> </p> <code>size</code> <p>File size in lines</p> <p> TYPE: <code>int</code> </p> <code>language</code> <p>Programming language</p> <p> TYPE: <code>str</code> </p>"},{"location":"api/tenets/core/examiner/hotspots/#tenets.core.examiner.hotspots.FileHotspot-attributes","title":"Attributes","text":""},{"location":"api/tenets/core/examiner/hotspots/#tenets.core.examiner.hotspots.FileHotspot.summary","title":"summary  <code>property</code>","text":"Python<pre><code>summary: str\n</code></pre> <p>Generate summary of hotspot issues.</p> RETURNS DESCRIPTION <code>str</code> <p>Human-readable summary</p> <p> TYPE: <code>str</code> </p>"},{"location":"api/tenets/core/examiner/hotspots/#tenets.core.examiner.hotspots.ModuleHotspot","title":"ModuleHotspot  <code>dataclass</code>","text":"Python<pre><code>ModuleHotspot(path: str, name: str, file_count: int = 0, hotspot_files: List[FileHotspot] = list(), total_commits: int = 0, total_authors: int = 0, avg_complexity: float = 0.0, total_bugs: int = 0, stability_score: float = 100.0, cohesion: float = 1.0, coupling: float = 0.0, _module_health_override: Optional[str] = None)\n</code></pre> <p>Hotspot information for a module/directory.</p> <p>Aggregates hotspot information at the module level to identify problematic areas of the codebase.</p> ATTRIBUTE DESCRIPTION <code>path</code> <p>Module path</p> <p> TYPE: <code>str</code> </p> <code>name</code> <p>Module name</p> <p> TYPE: <code>str</code> </p> <code>file_count</code> <p>Number of files in module</p> <p> TYPE: <code>int</code> </p> <code>hotspot_files</code> <p>List of hotspot files in module</p> <p> TYPE: <code>List[FileHotspot]</code> </p> <code>total_commits</code> <p>Total commits to module</p> <p> TYPE: <code>int</code> </p> <code>total_authors</code> <p>Total unique authors</p> <p> TYPE: <code>int</code> </p> <code>avg_complexity</code> <p>Average complexity across files</p> <p> TYPE: <code>float</code> </p> <code>total_bugs</code> <p>Total bug fixes in module</p> <p> TYPE: <code>int</code> </p> <code>stability_score</code> <p>Module stability score</p> <p> TYPE: <code>float</code> </p> <code>cohesion</code> <p>Module cohesion score</p> <p> TYPE: <code>float</code> </p> <code>coupling</code> <p>Module coupling score</p> <p> TYPE: <code>float</code> </p>"},{"location":"api/tenets/core/examiner/hotspots/#tenets.core.examiner.hotspots.ModuleHotspot-attributes","title":"Attributes","text":""},{"location":"api/tenets/core/examiner/hotspots/#tenets.core.examiner.hotspots.ModuleHotspot.hotspot_density","title":"hotspot_density  <code>property</code>","text":"Python<pre><code>hotspot_density: float\n</code></pre> <p>Calculate hotspot density in module.</p> RETURNS DESCRIPTION <code>float</code> <p>Ratio of hotspot files to total files</p> <p> TYPE: <code>float</code> </p>"},{"location":"api/tenets/core/examiner/hotspots/#tenets.core.examiner.hotspots.ModuleHotspot.module_health","title":"module_health  <code>property</code> <code>writable</code>","text":"Python<pre><code>module_health: str\n</code></pre> <p>Assess overall module health.</p> RETURNS DESCRIPTION <code>str</code> <p>Health status (healthy, warning, unhealthy)</p> <p> TYPE: <code>str</code> </p>"},{"location":"api/tenets/core/examiner/hotspots/#tenets.core.examiner.hotspots.HotspotReport","title":"HotspotReport  <code>dataclass</code>","text":"Python<pre><code>HotspotReport(total_files_analyzed: int = 0, total_hotspots: int = 0, critical_count: int = 0, high_count: int = 0, file_hotspots: List[FileHotspot] = list(), module_hotspots: List[ModuleHotspot] = list(), coupling_clusters: List[List[str]] = list(), temporal_patterns: Dict[str, Any] = dict(), hotspot_trends: Dict[str, Any] = dict(), top_problems: List[Tuple[str, int]] = list(), estimated_effort: float = 0.0, recommendations: List[str] = list(), risk_matrix: Dict[str, List[str]] = dict(), _health_score_override: Optional[float] = None)\n</code></pre> <p>Comprehensive hotspot analysis report.</p> <p>Provides detailed insights into code hotspots, including problematic files, modules, trends, and recommendations for improvement.</p> ATTRIBUTE DESCRIPTION <code>total_files_analyzed</code> <p>Total files analyzed</p> <p> TYPE: <code>int</code> </p> <code>total_hotspots</code> <p>Total hotspots detected</p> <p> TYPE: <code>int</code> </p> <code>critical_count</code> <p>Number of critical hotspots</p> <p> TYPE: <code>int</code> </p> <code>high_count</code> <p>Number of high-risk hotspots</p> <p> TYPE: <code>int</code> </p> <code>file_hotspots</code> <p>List of file-level hotspots</p> <p> TYPE: <code>List[FileHotspot]</code> </p> <code>module_hotspots</code> <p>List of module-level hotspots</p> <p> TYPE: <code>List[ModuleHotspot]</code> </p> <code>coupling_clusters</code> <p>Groups of tightly coupled files</p> <p> TYPE: <code>List[List[str]]</code> </p> <code>temporal_patterns</code> <p>Time-based patterns detected</p> <p> TYPE: <code>Dict[str, Any]</code> </p> <code>hotspot_trends</code> <p>Trends in hotspot evolution</p> <p> TYPE: <code>Dict[str, Any]</code> </p> <code>top_problems</code> <p>Most common problem types</p> <p> TYPE: <code>List[Tuple[str, int]]</code> </p> <code>estimated_effort</code> <p>Estimated effort to address hotspots</p> <p> TYPE: <code>float</code> </p> <code>recommendations</code> <p>Actionable recommendations</p> <p> TYPE: <code>List[str]</code> </p> <code>risk_matrix</code> <p>Risk assessment matrix</p> <p> TYPE: <code>Dict[str, List[str]]</code> </p>"},{"location":"api/tenets/core/examiner/hotspots/#tenets.core.examiner.hotspots.HotspotReport-attributes","title":"Attributes","text":""},{"location":"api/tenets/core/examiner/hotspots/#tenets.core.examiner.hotspots.HotspotReport.total_count","title":"total_count  <code>property</code>","text":"Python<pre><code>total_count: int\n</code></pre> <p>Get total hotspot count.</p> RETURNS DESCRIPTION <code>int</code> <p>Total number of hotspots</p> <p> TYPE: <code>int</code> </p>"},{"location":"api/tenets/core/examiner/hotspots/#tenets.core.examiner.hotspots.HotspotReport.health_score","title":"health_score  <code>property</code> <code>writable</code>","text":"Python<pre><code>health_score: float\n</code></pre> <p>Calculate overall codebase health score.</p> <p>Lower scores indicate more hotspots and problems.</p> RETURNS DESCRIPTION <code>float</code> <p>Health score (0-100)</p> <p> TYPE: <code>float</code> </p>"},{"location":"api/tenets/core/examiner/hotspots/#tenets.core.examiner.hotspots.HotspotReport-functions","title":"Functions","text":""},{"location":"api/tenets/core/examiner/hotspots/#tenets.core.examiner.hotspots.HotspotReport.to_dict","title":"to_dict","text":"Python<pre><code>to_dict() -&gt; Dict[str, Any]\n</code></pre> <p>Convert report to dictionary.</p> RETURNS DESCRIPTION <code>Dict[str, Any]</code> <p>Dict[str, Any]: Dictionary representation</p>"},{"location":"api/tenets/core/examiner/hotspots/#tenets.core.examiner.hotspots.HotspotDetector","title":"HotspotDetector","text":"Python<pre><code>HotspotDetector(config: TenetsConfig)\n</code></pre> <p>Detector for code hotspots.</p> <p>Analyzes code repository to identify hotspots - areas that change frequently, have high complexity, or show other problematic patterns.</p> ATTRIBUTE DESCRIPTION <code>config</code> <p>Configuration object</p> <p> </p> <code>logger</code> <p>Logger instance</p> <p> </p> <code>git_analyzer</code> <p>Git analyzer instance</p> <p> TYPE: <code>Optional[GitAnalyzer]</code> </p> <p>Initialize hotspot detector.</p> PARAMETER DESCRIPTION <code>config</code> <p>TenetsConfig instance</p> <p> TYPE: <code>TenetsConfig</code> </p>"},{"location":"api/tenets/core/examiner/hotspots/#tenets.core.examiner.hotspots.HotspotDetector-functions","title":"Functions","text":""},{"location":"api/tenets/core/examiner/hotspots/#tenets.core.examiner.hotspots.HotspotDetector.detect","title":"detect","text":"Python<pre><code>detect(repo_path: Path, files: Optional[List[Any]] = None, since_days: int = 90, threshold: int = 10, include_stable: bool = False) -&gt; HotspotReport\n</code></pre> <p>Detect hotspots in a repository.</p> <p>Analyzes git history and code metrics to identify problematic areas that need attention or refactoring.</p> PARAMETER DESCRIPTION <code>repo_path</code> <p>Path to git repository</p> <p> TYPE: <code>Path</code> </p> <code>files</code> <p>Optional list of analyzed file objects</p> <p> TYPE: <code>Optional[List[Any]]</code> DEFAULT: <code>None</code> </p> <code>since_days</code> <p>Days of history to analyze</p> <p> TYPE: <code>int</code> DEFAULT: <code>90</code> </p> <code>threshold</code> <p>Minimum score to consider as hotspot</p> <p> TYPE: <code>int</code> DEFAULT: <code>10</code> </p> <code>include_stable</code> <p>Whether to include stable files in report</p> <p> TYPE: <code>bool</code> DEFAULT: <code>False</code> </p> RETURNS DESCRIPTION <code>HotspotReport</code> <p>Comprehensive hotspot analysis</p> <p> TYPE: <code>HotspotReport</code> </p> Example <p>detector = HotspotDetector(config) report = detector.detect(Path(\".\"), since_days=30) print(f\"Found {report.total_hotspots} hotspots\")</p>"},{"location":"api/tenets/core/examiner/hotspots/#tenets.core.examiner.hotspots-functions","title":"Functions","text":""},{"location":"api/tenets/core/examiner/hotspots/#tenets.core.examiner.hotspots.detect_hotspots","title":"detect_hotspots","text":"Python<pre><code>detect_hotspots(repo_path: Path, files: Optional[List[Any]] = None, since_days: int = 90, threshold: int = 10, include_stable: bool = False, config: Optional[TenetsConfig] = None) -&gt; HotspotReport\n</code></pre> <p>Detect hotspots in a repository path.</p> <p>Thin wrapper that constructs a HotspotDetector and delegates to detect().</p> PARAMETER DESCRIPTION <code>repo_path</code> <p>Path to the repository</p> <p> TYPE: <code>Path</code> </p> <code>files</code> <p>Optional analyzed files list</p> <p> TYPE: <code>Optional[List[Any]]</code> DEFAULT: <code>None</code> </p> <code>since_days</code> <p>History window</p> <p> TYPE: <code>int</code> DEFAULT: <code>90</code> </p> <code>threshold</code> <p>Minimum hotspot score</p> <p> TYPE: <code>int</code> DEFAULT: <code>10</code> </p> <code>include_stable</code> <p>Include stable files</p> <p> TYPE: <code>bool</code> DEFAULT: <code>False</code> </p> <code>config</code> <p>Optional TenetsConfig</p> <p> TYPE: <code>Optional[TenetsConfig]</code> DEFAULT: <code>None</code> </p> RETURNS DESCRIPTION <code>HotspotReport</code> <p>HotspotReport</p>"},{"location":"api/tenets/core/examiner/metrics/","title":"Metrics","text":""},{"location":"api/tenets/core/examiner/metrics/#tenets.core.examiner.metrics","title":"tenets.core.examiner.metrics","text":"<p>Metrics calculation module for code analysis.</p> <p>This module provides comprehensive metrics calculation for codebases, including size metrics, complexity aggregations, code quality indicators, and statistical analysis across files and languages.</p> <p>The MetricsCalculator class processes analyzed files to extract quantitative measurements that help assess code health, maintainability, and quality.</p>"},{"location":"api/tenets/core/examiner/metrics/#tenets.core.examiner.metrics-classes","title":"Classes","text":""},{"location":"api/tenets/core/examiner/metrics/#tenets.core.examiner.metrics.MetricsReport","title":"MetricsReport  <code>dataclass</code>","text":"Python<pre><code>MetricsReport(total_files: int = 0, total_lines: int = 0, total_blank_lines: int = 0, total_comment_lines: int = 0, total_code_lines: int = 0, total_functions: int = 0, total_classes: int = 0, total_imports: int = 0, avg_file_size: float = 0.0, avg_complexity: float = 0.0, max_complexity: float = 0.0, min_complexity: float = float('inf'), complexity_std_dev: float = 0.0, documentation_ratio: float = 0.0, test_coverage: float = 0.0, code_duplication_ratio: float = 0.0, technical_debt_score: float = 0.0, maintainability_index: float = 0.0, languages: Dict[str, Dict[str, Any]] = dict(), file_types: Dict[str, int] = dict(), size_distribution: Dict[str, int] = dict(), complexity_distribution: Dict[str, int] = dict(), largest_files: List[Dict[str, Any]] = list(), most_complex_files: List[Dict[str, Any]] = list(), most_imported_modules: List[Tuple[str, int]] = list())\n</code></pre> <p>Comprehensive metrics report for analyzed code.</p> <p>Aggregates various code metrics to provide quantitative insights into codebase characteristics, including size, complexity, documentation, and quality indicators.</p> ATTRIBUTE DESCRIPTION <code>total_files</code> <p>Total number of files analyzed</p> <p> TYPE: <code>int</code> </p> <code>total_lines</code> <p>Total lines of code across all files</p> <p> TYPE: <code>int</code> </p> <code>total_blank_lines</code> <p>Total blank lines</p> <p> TYPE: <code>int</code> </p> <code>total_comment_lines</code> <p>Total comment lines</p> <p> TYPE: <code>int</code> </p> <code>total_code_lines</code> <p>Total actual code lines (excluding blanks/comments)</p> <p> TYPE: <code>int</code> </p> <code>total_functions</code> <p>Total number of functions/methods</p> <p> TYPE: <code>int</code> </p> <code>total_classes</code> <p>Total number of classes</p> <p> TYPE: <code>int</code> </p> <code>total_imports</code> <p>Total number of import statements</p> <p> TYPE: <code>int</code> </p> <code>avg_file_size</code> <p>Average file size in lines</p> <p> TYPE: <code>float</code> </p> <code>avg_complexity</code> <p>Average cyclomatic complexity</p> <p> TYPE: <code>float</code> </p> <code>max_complexity</code> <p>Maximum cyclomatic complexity found</p> <p> TYPE: <code>float</code> </p> <code>min_complexity</code> <p>Minimum cyclomatic complexity found</p> <p> TYPE: <code>float</code> </p> <code>complexity_std_dev</code> <p>Standard deviation of complexity</p> <p> TYPE: <code>float</code> </p> <code>documentation_ratio</code> <p>Ratio of comment lines to code lines</p> <p> TYPE: <code>float</code> </p> <code>test_coverage</code> <p>Estimated test coverage (if test files found)</p> <p> TYPE: <code>float</code> </p> <code>languages</code> <p>Dictionary of language-specific metrics</p> <p> TYPE: <code>Dict[str, Dict[str, Any]]</code> </p> <code>file_types</code> <p>Distribution of file types</p> <p> TYPE: <code>Dict[str, int]</code> </p> <code>size_distribution</code> <p>File size distribution buckets</p> <p> TYPE: <code>Dict[str, int]</code> </p> <code>complexity_distribution</code> <p>Complexity distribution buckets</p> <p> TYPE: <code>Dict[str, int]</code> </p> <code>largest_files</code> <p>List of largest files by line count</p> <p> TYPE: <code>List[Dict[str, Any]]</code> </p> <code>most_complex_files</code> <p>List of files with highest complexity</p> <p> TYPE: <code>List[Dict[str, Any]]</code> </p> <code>most_imported_modules</code> <p>Most frequently imported modules</p> <p> TYPE: <code>List[Tuple[str, int]]</code> </p> <code>code_duplication_ratio</code> <p>Estimated code duplication ratio</p> <p> TYPE: <code>float</code> </p> <code>technical_debt_score</code> <p>Calculated technical debt score</p> <p> TYPE: <code>float</code> </p> <code>maintainability_index</code> <p>Overall maintainability index</p> <p> TYPE: <code>float</code> </p>"},{"location":"api/tenets/core/examiner/metrics/#tenets.core.examiner.metrics.MetricsReport-attributes","title":"Attributes","text":""},{"location":"api/tenets/core/examiner/metrics/#tenets.core.examiner.metrics.MetricsReport.code_to_comment_ratio","title":"code_to_comment_ratio  <code>property</code>","text":"Python<pre><code>code_to_comment_ratio: float\n</code></pre> <p>Calculate code to comment ratio.</p> RETURNS DESCRIPTION <code>float</code> <p>Ratio of code lines to comment lines</p> <p> TYPE: <code>float</code> </p>"},{"location":"api/tenets/core/examiner/metrics/#tenets.core.examiner.metrics.MetricsReport.avg_file_complexity","title":"avg_file_complexity  <code>property</code>","text":"Python<pre><code>avg_file_complexity: float\n</code></pre> <p>Calculate average complexity per file.</p> RETURNS DESCRIPTION <code>float</code> <p>Average complexity across all files</p> <p> TYPE: <code>float</code> </p>"},{"location":"api/tenets/core/examiner/metrics/#tenets.core.examiner.metrics.MetricsReport.quality_score","title":"quality_score  <code>property</code>","text":"Python<pre><code>quality_score: float\n</code></pre> <p>Calculate overall code quality score (0-100).</p> <p>Combines various metrics to produce a single quality indicator.</p> RETURNS DESCRIPTION <code>float</code> <p>Quality score between 0 and 100</p> <p> TYPE: <code>float</code> </p>"},{"location":"api/tenets/core/examiner/metrics/#tenets.core.examiner.metrics.MetricsReport-functions","title":"Functions","text":""},{"location":"api/tenets/core/examiner/metrics/#tenets.core.examiner.metrics.MetricsReport.to_dict","title":"to_dict","text":"Python<pre><code>to_dict() -&gt; Dict[str, Any]\n</code></pre> <p>Convert metrics report to dictionary.</p> RETURNS DESCRIPTION <code>Dict[str, Any]</code> <p>Dict[str, Any]: Dictionary representation of metrics</p>"},{"location":"api/tenets/core/examiner/metrics/#tenets.core.examiner.metrics.MetricsCalculator","title":"MetricsCalculator","text":"Python<pre><code>MetricsCalculator(config: TenetsConfig)\n</code></pre> <p>Calculator for code metrics extraction and aggregation.</p> <p>Processes analyzed files to compute comprehensive metrics including size measurements, complexity statistics, quality indicators, and distributional analysis.</p> ATTRIBUTE DESCRIPTION <code>config</code> <p>Configuration object</p> <p> </p> <code>logger</code> <p>Logger instance</p> <p> </p> <p>Initialize metrics calculator with configuration.</p> PARAMETER DESCRIPTION <code>config</code> <p>TenetsConfig instance with metrics settings</p> <p> TYPE: <code>TenetsConfig</code> </p>"},{"location":"api/tenets/core/examiner/metrics/#tenets.core.examiner.metrics.MetricsCalculator-functions","title":"Functions","text":""},{"location":"api/tenets/core/examiner/metrics/#tenets.core.examiner.metrics.MetricsCalculator.calculate","title":"calculate","text":"Python<pre><code>calculate(files: List[Any]) -&gt; MetricsReport\n</code></pre> <p>Calculate comprehensive metrics for analyzed files.</p> <p>Processes a list of analyzed file objects to extract and aggregate various code metrics, producing a complete metrics report.</p> PARAMETER DESCRIPTION <code>files</code> <p>List of analyzed file objects</p> <p> TYPE: <code>List[Any]</code> </p> RETURNS DESCRIPTION <code>MetricsReport</code> <p>Comprehensive metrics analysis</p> <p> TYPE: <code>MetricsReport</code> </p> Example <p>calculator = MetricsCalculator(config) report = calculator.calculate(analyzed_files) print(f\"Average complexity: {report.avg_complexity}\")</p>"},{"location":"api/tenets/core/examiner/metrics/#tenets.core.examiner.metrics.MetricsCalculator.calculate_file_metrics","title":"calculate_file_metrics","text":"Python<pre><code>calculate_file_metrics(file_analysis: Any) -&gt; Dict[str, Any]\n</code></pre> <p>Calculate metrics for a single file.</p> <p>Extracts detailed metrics from a single file analysis object, providing file-specific measurements and statistics.</p> PARAMETER DESCRIPTION <code>file_analysis</code> <p>Analyzed file object</p> <p> TYPE: <code>Any</code> </p> RETURNS DESCRIPTION <code>Dict[str, Any]</code> <p>Dict[str, Any]: File-specific metrics</p> Example <p>metrics = calculator.calculate_file_metrics(file_analysis) print(f\"File complexity: {metrics['complexity']}\")</p>"},{"location":"api/tenets/core/examiner/metrics/#tenets.core.examiner.metrics-functions","title":"Functions","text":""},{"location":"api/tenets/core/examiner/metrics/#tenets.core.examiner.metrics.calculate_metrics","title":"calculate_metrics","text":"Python<pre><code>calculate_metrics(files: List[Any], config: Optional[TenetsConfig] = None) -&gt; MetricsReport\n</code></pre> <p>Convenience function to calculate metrics for files.</p> <p>Creates a MetricsCalculator instance and calculates comprehensive metrics for the provided files.</p> PARAMETER DESCRIPTION <code>files</code> <p>List of analyzed file objects</p> <p> TYPE: <code>List[Any]</code> </p> <code>config</code> <p>Optional configuration (uses defaults if None)</p> <p> TYPE: <code>Optional[TenetsConfig]</code> DEFAULT: <code>None</code> </p> RETURNS DESCRIPTION <code>MetricsReport</code> <p>Comprehensive metrics analysis</p> <p> TYPE: <code>MetricsReport</code> </p> Example <p>report = calculate_metrics(analyzed_files) print(f\"Quality score: {report.quality_score}\")</p>"},{"location":"api/tenets/core/examiner/ownership/","title":"Ownership","text":""},{"location":"api/tenets/core/examiner/ownership/#tenets.core.examiner.ownership","title":"tenets.core.examiner.ownership","text":"<p>Code ownership tracking module for examination.</p> <p>This module analyzes code ownership patterns by examining git history, identifying primary contributors, tracking knowledge distribution, and detecting bus factor risks. It helps understand team dynamics and knowledge silos within a codebase.</p> <p>The ownership tracker integrates with git to provide insights into who knows what parts of the code and where knowledge gaps might exist.</p>"},{"location":"api/tenets/core/examiner/ownership/#tenets.core.examiner.ownership-classes","title":"Classes","text":""},{"location":"api/tenets/core/examiner/ownership/#tenets.core.examiner.ownership.ContributorInfo","title":"ContributorInfo  <code>dataclass</code>","text":"Python<pre><code>ContributorInfo(name: str, email: str, total_commits: int = 0, total_lines_added: int = 0, total_lines_removed: int = 0, files_touched: Set[str] = set(), files_created: Set[str] = set(), primary_languages: Dict[str, int] = dict(), expertise_areas: List[str] = list(), first_commit_date: Optional[datetime] = None, last_commit_date: Optional[datetime] = None, active_days: int = 0, commit_frequency: float = 0.0, review_participation: int = 0, collaboration_score: float = 0.0, bus_factor_risk: float = 0.0, knowledge_domains: Set[str] = set())\n</code></pre> <p>Information about a code contributor.</p> <p>Tracks detailed statistics and patterns for individual contributors including their areas of expertise, contribution patterns, and impact.</p> ATTRIBUTE DESCRIPTION <code>name</code> <p>Contributor name</p> <p> TYPE: <code>str</code> </p> <code>email</code> <p>Contributor email</p> <p> TYPE: <code>str</code> </p> <code>total_commits</code> <p>Total number of commits</p> <p> TYPE: <code>int</code> </p> <code>total_lines_added</code> <p>Total lines added</p> <p> TYPE: <code>int</code> </p> <code>total_lines_removed</code> <p>Total lines removed</p> <p> TYPE: <code>int</code> </p> <code>files_touched</code> <p>Set of files modified</p> <p> TYPE: <code>Set[str]</code> </p> <code>files_created</code> <p>Set of files created</p> <p> TYPE: <code>Set[str]</code> </p> <code>primary_languages</code> <p>Languages most frequently used</p> <p> TYPE: <code>Dict[str, int]</code> </p> <code>expertise_areas</code> <p>Areas of codebase expertise</p> <p> TYPE: <code>List[str]</code> </p> <code>first_commit_date</code> <p>Date of first contribution</p> <p> TYPE: <code>Optional[datetime]</code> </p> <code>last_commit_date</code> <p>Date of most recent contribution</p> <p> TYPE: <code>Optional[datetime]</code> </p> <code>active_days</code> <p>Number of days with commits</p> <p> TYPE: <code>int</code> </p> <code>commit_frequency</code> <p>Average commits per active day</p> <p> TYPE: <code>float</code> </p> <code>review_participation</code> <p>Number of reviews participated in</p> <p> TYPE: <code>int</code> </p> <code>collaboration_score</code> <p>Score indicating collaboration level</p> <p> TYPE: <code>float</code> </p> <code>bus_factor_risk</code> <p>Risk score for bus factor</p> <p> TYPE: <code>float</code> </p> <code>knowledge_domains</code> <p>Specific knowledge domains</p> <p> TYPE: <code>Set[str]</code> </p>"},{"location":"api/tenets/core/examiner/ownership/#tenets.core.examiner.ownership.ContributorInfo-attributes","title":"Attributes","text":""},{"location":"api/tenets/core/examiner/ownership/#tenets.core.examiner.ownership.ContributorInfo.net_lines_contributed","title":"net_lines_contributed  <code>property</code>","text":"Python<pre><code>net_lines_contributed: int\n</code></pre> <p>Calculate net lines contributed.</p> RETURNS DESCRIPTION <code>int</code> <p>Lines added minus lines removed</p> <p> TYPE: <code>int</code> </p>"},{"location":"api/tenets/core/examiner/ownership/#tenets.core.examiner.ownership.ContributorInfo.productivity_score","title":"productivity_score  <code>property</code>","text":"Python<pre><code>productivity_score: float\n</code></pre> <p>Calculate productivity score.</p> <p>Combines various metrics to assess productivity.</p> RETURNS DESCRIPTION <code>float</code> <p>Productivity score (0-100)</p> <p> TYPE: <code>float</code> </p>"},{"location":"api/tenets/core/examiner/ownership/#tenets.core.examiner.ownership.ContributorInfo.is_active","title":"is_active  <code>property</code>","text":"Python<pre><code>is_active: bool\n</code></pre> <p>Check if contributor is currently active.</p> <p>Considers a contributor active if they've committed in last 30 days.</p> RETURNS DESCRIPTION <code>bool</code> <p>True if active</p> <p> TYPE: <code>bool</code> </p>"},{"location":"api/tenets/core/examiner/ownership/#tenets.core.examiner.ownership.ContributorInfo.expertise_level","title":"expertise_level  <code>property</code>","text":"Python<pre><code>expertise_level: str\n</code></pre> <p>Determine expertise level.</p> RETURNS DESCRIPTION <code>str</code> <p>Expertise level (expert, senior, intermediate, junior)</p> <p> TYPE: <code>str</code> </p>"},{"location":"api/tenets/core/examiner/ownership/#tenets.core.examiner.ownership.FileOwnership","title":"FileOwnership  <code>dataclass</code>","text":"Python<pre><code>FileOwnership(path: str, primary_owner: Optional[str] = None, ownership_percentage: float = 0.0, contributors: List[Tuple[str, int]] = list(), total_changes: int = 0, last_modified: Optional[datetime] = None, last_modified_by: Optional[str] = None, creation_date: Optional[datetime] = None, created_by: Optional[str] = None, complexity: Optional[float] = None, is_orphaned: bool = False, knowledge_concentration: float = 0.0, change_frequency: float = 0.0)\n</code></pre> <p>Ownership information for a single file.</p> <p>Tracks who owns and maintains specific files, including primary owners, contributors, and change patterns.</p> ATTRIBUTE DESCRIPTION <code>path</code> <p>File path</p> <p> TYPE: <code>str</code> </p> <code>primary_owner</code> <p>Main contributor to the file</p> <p> TYPE: <code>Optional[str]</code> </p> <code>ownership_percentage</code> <p>Primary owner's contribution percentage</p> <p> TYPE: <code>float</code> </p> <code>contributors</code> <p>List of all contributors</p> <p> TYPE: <code>List[Tuple[str, int]]</code> </p> <code>total_changes</code> <p>Total number of changes</p> <p> TYPE: <code>int</code> </p> <code>last_modified</code> <p>Last modification date</p> <p> TYPE: <code>Optional[datetime]</code> </p> <code>last_modified_by</code> <p>Last person to modify</p> <p> TYPE: <code>Optional[str]</code> </p> <code>creation_date</code> <p>File creation date</p> <p> TYPE: <code>Optional[datetime]</code> </p> <code>created_by</code> <p>Original creator</p> <p> TYPE: <code>Optional[str]</code> </p> <code>complexity</code> <p>File complexity if available</p> <p> TYPE: <code>Optional[float]</code> </p> <code>is_orphaned</code> <p>Whether file lacks active maintainer</p> <p> TYPE: <code>bool</code> </p> <code>knowledge_concentration</code> <p>How concentrated knowledge is</p> <p> TYPE: <code>float</code> </p> <code>change_frequency</code> <p>How often file changes</p> <p> TYPE: <code>float</code> </p>"},{"location":"api/tenets/core/examiner/ownership/#tenets.core.examiner.ownership.FileOwnership-attributes","title":"Attributes","text":""},{"location":"api/tenets/core/examiner/ownership/#tenets.core.examiner.ownership.FileOwnership.contributor_count","title":"contributor_count  <code>property</code>","text":"Python<pre><code>contributor_count: int\n</code></pre> <p>Get number of unique contributors.</p> RETURNS DESCRIPTION <code>int</code> <p>Unique contributor count</p> <p> TYPE: <code>int</code> </p>"},{"location":"api/tenets/core/examiner/ownership/#tenets.core.examiner.ownership.FileOwnership.bus_factor","title":"bus_factor  <code>property</code>","text":"Python<pre><code>bus_factor: int\n</code></pre> <p>Calculate bus factor for this file.</p> <p>Number of people who need to be unavailable before knowledge is lost.</p> RETURNS DESCRIPTION <code>int</code> <p>Bus factor (1 is high risk)</p> <p> TYPE: <code>int</code> </p>"},{"location":"api/tenets/core/examiner/ownership/#tenets.core.examiner.ownership.FileOwnership.risk_level","title":"risk_level  <code>property</code>","text":"Python<pre><code>risk_level: str\n</code></pre> <p>Determine ownership risk level.</p> RETURNS DESCRIPTION <code>str</code> <p>Risk level (critical, high, medium, low)</p> <p> TYPE: <code>str</code> </p>"},{"location":"api/tenets/core/examiner/ownership/#tenets.core.examiner.ownership.TeamOwnership","title":"TeamOwnership  <code>dataclass</code>","text":"Python<pre><code>TeamOwnership(teams: Dict[str, List[str]] = dict(), team_territories: Dict[str, List[str]] = dict(), cross_team_files: List[str] = list(), collaboration_matrix: Dict[Tuple[str, str], int] = dict(), team_expertise: Dict[str, Set[str]] = dict(), team_bus_factor: Dict[str, int] = dict())\n</code></pre> <p>Team-level ownership patterns.</p> <p>Aggregates ownership information across teams or groups, identifying collaboration patterns and knowledge distribution.</p> ATTRIBUTE DESCRIPTION <code>teams</code> <p>Dictionary of team members</p> <p> TYPE: <code>Dict[str, List[str]]</code> </p> <code>team_territories</code> <p>Areas owned by each team</p> <p> TYPE: <code>Dict[str, List[str]]</code> </p> <code>cross_team_files</code> <p>Files touched by multiple teams</p> <p> TYPE: <code>List[str]</code> </p> <code>collaboration_matrix</code> <p>Team collaboration frequencies</p> <p> TYPE: <code>Dict[Tuple[str, str], int]</code> </p> <code>team_expertise</code> <p>Expertise areas by team</p> <p> TYPE: <code>Dict[str, Set[str]]</code> </p> <code>team_bus_factor</code> <p>Bus factor by team</p> <p> TYPE: <code>Dict[str, int]</code> </p>"},{"location":"api/tenets/core/examiner/ownership/#tenets.core.examiner.ownership.OwnershipReport","title":"OwnershipReport  <code>dataclass</code>","text":"Python<pre><code>OwnershipReport(total_contributors: int = 0, total_files_analyzed: int = 0, active_contributors: int = 0, contributors: List[ContributorInfo] = list(), file_ownership: Dict[str, FileOwnership] = dict(), orphaned_files: List[str] = list(), high_risk_files: List[Dict[str, Any]] = list(), knowledge_silos: List[Dict[str, Any]] = list(), bus_factor: int = 0, team_ownership: Optional[TeamOwnership] = None, ownership_distribution: Dict[str, float] = dict(), collaboration_graph: Dict[Tuple[str, str], int] = dict(), expertise_map: Dict[str, List[str]] = dict(), recommendations: List[str] = list(), risk_score: float = 0.0)\n</code></pre> <p>Comprehensive code ownership analysis report.</p> <p>Provides detailed insights into code ownership patterns, knowledge distribution, bus factor risks, and team dynamics.</p> ATTRIBUTE DESCRIPTION <code>total_contributors</code> <p>Total number of contributors</p> <p> TYPE: <code>int</code> </p> <code>active_contributors</code> <p>Currently active contributors</p> <p> TYPE: <code>int</code> </p> <code>contributors</code> <p>List of contributor information</p> <p> TYPE: <code>List[ContributorInfo]</code> </p> <code>file_ownership</code> <p>Ownership by file</p> <p> TYPE: <code>Dict[str, FileOwnership]</code> </p> <code>orphaned_files</code> <p>Files without active maintainers</p> <p> TYPE: <code>List[str]</code> </p> <code>high_risk_files</code> <p>Files with bus factor risks</p> <p> TYPE: <code>List[Dict[str, Any]]</code> </p> <code>knowledge_silos</code> <p>Areas with concentrated knowledge</p> <p> TYPE: <code>List[Dict[str, Any]]</code> </p> <code>bus_factor</code> <p>Overall project bus factor</p> <p> TYPE: <code>int</code> </p> <code>team_ownership</code> <p>Team-level ownership patterns</p> <p> TYPE: <code>Optional[TeamOwnership]</code> </p> <code>ownership_distribution</code> <p>Distribution of ownership</p> <p> TYPE: <code>Dict[str, float]</code> </p> <code>collaboration_graph</code> <p>Collaboration relationships</p> <p> TYPE: <code>Dict[Tuple[str, str], int]</code> </p> <code>expertise_map</code> <p>Map of expertise areas</p> <p> TYPE: <code>Dict[str, List[str]]</code> </p> <code>recommendations</code> <p>Actionable recommendations</p> <p> TYPE: <code>List[str]</code> </p> <code>risk_score</code> <p>Overall ownership risk score</p> <p> TYPE: <code>float</code> </p>"},{"location":"api/tenets/core/examiner/ownership/#tenets.core.examiner.ownership.OwnershipReport-attributes","title":"Attributes","text":""},{"location":"api/tenets/core/examiner/ownership/#tenets.core.examiner.ownership.OwnershipReport.health_score","title":"health_score  <code>property</code>","text":"Python<pre><code>health_score: float\n</code></pre> <p>Calculate ownership health score.</p> <p>Higher scores indicate better knowledge distribution.</p> RETURNS DESCRIPTION <code>float</code> <p>Health score (0-100)</p> <p> TYPE: <code>float</code> </p>"},{"location":"api/tenets/core/examiner/ownership/#tenets.core.examiner.ownership.OwnershipReport-functions","title":"Functions","text":""},{"location":"api/tenets/core/examiner/ownership/#tenets.core.examiner.ownership.OwnershipReport.to_dict","title":"to_dict","text":"Python<pre><code>to_dict() -&gt; Dict[str, Any]\n</code></pre> <p>Convert report to dictionary.</p> RETURNS DESCRIPTION <code>Dict[str, Any]</code> <p>Dict[str, Any]: Dictionary representation</p>"},{"location":"api/tenets/core/examiner/ownership/#tenets.core.examiner.ownership.OwnershipTracker","title":"OwnershipTracker","text":"Python<pre><code>OwnershipTracker(config: TenetsConfig)\n</code></pre> <p>Tracker for code ownership patterns.</p> <p>Analyzes git history to understand code ownership, knowledge distribution, and collaboration patterns within a codebase.</p> ATTRIBUTE DESCRIPTION <code>config</code> <p>Configuration object</p> <p> </p> <code>logger</code> <p>Logger instance</p> <p> </p> <code>git_analyzer</code> <p>Git analyzer instance</p> <p> TYPE: <code>Optional[GitAnalyzer]</code> </p> <p>Initialize ownership tracker.</p> PARAMETER DESCRIPTION <code>config</code> <p>TenetsConfig instance</p> <p> TYPE: <code>TenetsConfig</code> </p>"},{"location":"api/tenets/core/examiner/ownership/#tenets.core.examiner.ownership.OwnershipTracker-functions","title":"Functions","text":""},{"location":"api/tenets/core/examiner/ownership/#tenets.core.examiner.ownership.OwnershipTracker.track","title":"track","text":"Python<pre><code>track(repo_path: Path, since_days: int = 365, include_tests: bool = True, team_mapping: Optional[Dict[str, List[str]]] = None) -&gt; OwnershipReport\n</code></pre> <p>Track code ownership for a repository.</p> <p>Analyzes git history to determine ownership patterns, identify risks, and provide insights into knowledge distribution.</p> PARAMETER DESCRIPTION <code>repo_path</code> <p>Path to git repository</p> <p> TYPE: <code>Path</code> </p> <code>since_days</code> <p>Days of history to analyze</p> <p> TYPE: <code>int</code> DEFAULT: <code>365</code> </p> <code>include_tests</code> <p>Whether to include test files</p> <p> TYPE: <code>bool</code> DEFAULT: <code>True</code> </p> <code>team_mapping</code> <p>Optional mapping of team names to members</p> <p> TYPE: <code>Optional[Dict[str, List[str]]]</code> DEFAULT: <code>None</code> </p> RETURNS DESCRIPTION <code>OwnershipReport</code> <p>Comprehensive ownership analysis</p> <p> TYPE: <code>OwnershipReport</code> </p> Example <p>tracker = OwnershipTracker(config) report = tracker.track(Path(\".\"), since_days=90) print(f\"Bus factor: {report.bus_factor}\")</p>"},{"location":"api/tenets/core/examiner/ownership/#tenets.core.examiner.ownership.OwnershipTracker.analyze_ownership","title":"analyze_ownership","text":"Python<pre><code>analyze_ownership(repo_path: Path, **kwargs: Any) -&gt; OwnershipReport\n</code></pre> <p>Analyze ownership for a repository path.</p> <p>This is an alias for the track() method to maintain backward compatibility.</p> PARAMETER DESCRIPTION <code>repo_path</code> <p>Path to repository</p> <p> TYPE: <code>Path</code> </p> <code>**kwargs</code> <p>Additional arguments passed to track()</p> <p> TYPE: <code>Any</code> DEFAULT: <code>{}</code> </p> RETURNS DESCRIPTION <code>OwnershipReport</code> <p>Comprehensive ownership analysis</p> <p> TYPE: <code>OwnershipReport</code> </p>"},{"location":"api/tenets/core/examiner/ownership/#tenets.core.examiner.ownership-functions","title":"Functions","text":""},{"location":"api/tenets/core/examiner/ownership/#tenets.core.examiner.ownership.track_ownership","title":"track_ownership","text":"Python<pre><code>track_ownership(repo_path: Path, since_days: int = 90, include_tests: bool = True, team_mapping: Optional[Dict[str, List[str]]] = None, config: Optional[TenetsConfig] = None) -&gt; OwnershipReport\n</code></pre> <p>Track code ownership for a repository path.</p> <p>A convenient functional API that uses OwnershipTracker under the hood.</p> PARAMETER DESCRIPTION <code>repo_path</code> <p>Path to repository</p> <p> TYPE: <code>Path</code> </p> <code>since_days</code> <p>How many days of history to analyze</p> <p> TYPE: <code>int</code> DEFAULT: <code>90</code> </p> <code>include_tests</code> <p>Whether to include test files in analysis</p> <p> TYPE: <code>bool</code> DEFAULT: <code>True</code> </p> <code>team_mapping</code> <p>Optional mapping of team names to member emails</p> <p> TYPE: <code>Optional[Dict[str, List[str]]]</code> DEFAULT: <code>None</code> </p> <code>config</code> <p>Optional TenetsConfig</p> <p> TYPE: <code>Optional[TenetsConfig]</code> DEFAULT: <code>None</code> </p> RETURNS DESCRIPTION <code>OwnershipReport</code> <p>Comprehensive ownership analysis</p> <p> TYPE: <code>OwnershipReport</code> </p>"},{"location":"api/tenets/core/git/analyzer/","title":"Analyzer","text":""},{"location":"api/tenets/core/git/analyzer/#tenets.core.git.analyzer","title":"tenets.core.git.analyzer","text":"<p>Git analyzer using GitPython.</p> <p>Provides helpers to extract recent context, changed files, and authorship.</p>"},{"location":"api/tenets/core/git/analyzer/#tenets.core.git.analyzer-classes","title":"Classes","text":""},{"location":"api/tenets/core/git/analyzer/#tenets.core.git.analyzer.GitAnalyzer","title":"GitAnalyzer","text":"Python<pre><code>GitAnalyzer(root: Any)\n</code></pre>"},{"location":"api/tenets/core/git/analyzer/#tenets.core.git.analyzer.GitAnalyzer-functions","title":"Functions","text":""},{"location":"api/tenets/core/git/analyzer/#tenets.core.git.analyzer.GitAnalyzer.is_git_repo","title":"is_git_repo","text":"Python<pre><code>is_git_repo(path: Optional[Path] = None) -&gt; bool\n</code></pre> <p>Return True if the given path (or current root) is inside a git repo.</p> <p>If a path is provided, update internal root and repo accordingly.</p>"},{"location":"api/tenets/core/git/analyzer/#tenets.core.git.analyzer.GitAnalyzer.get_recent_commits","title":"get_recent_commits","text":"Python<pre><code>get_recent_commits(path: Optional[Path] = None, limit: int = 10, files: Optional[List[str]] = None) -&gt; List[Dict[str, Any]]\n</code></pre> <p>Return recent commits as dictionaries suitable for formatting.</p> <p>Each item contains: sha, author, email, message, date (ISO date string).</p>"},{"location":"api/tenets/core/git/analyzer/#tenets.core.git.analyzer.GitAnalyzer.get_contributors","title":"get_contributors","text":"Python<pre><code>get_contributors(path: Optional[Path] = None, files: Optional[List[str]] = None, limit: int = 20) -&gt; List[Dict[str, Any]]\n</code></pre> <p>Return contributors with commit counts.</p> <p>Returns a list of dicts: { name, email, commits } sorted by commits desc.</p>"},{"location":"api/tenets/core/git/analyzer/#tenets.core.git.analyzer.GitAnalyzer.get_current_branch","title":"get_current_branch","text":"Python<pre><code>get_current_branch(path: Optional[Path] = None) -&gt; str\n</code></pre> <p>Return current branch name, or 'HEAD' when detached/unknown.</p>"},{"location":"api/tenets/core/git/analyzer/#tenets.core.git.analyzer.GitAnalyzer.current_branch","title":"current_branch","text":"Python<pre><code>current_branch() -&gt; str\n</code></pre> <p>Alias for get_current_branch() for backward compatibility.</p>"},{"location":"api/tenets/core/git/analyzer/#tenets.core.git.analyzer.GitAnalyzer.get_tracked_files","title":"get_tracked_files","text":"Python<pre><code>get_tracked_files() -&gt; List[str]\n</code></pre> <p>Return list of tracked files in the repository.</p>"},{"location":"api/tenets/core/git/analyzer/#tenets.core.git.analyzer.GitAnalyzer.get_file_history","title":"get_file_history","text":"Python<pre><code>get_file_history(file_path: str) -&gt; List[Any]\n</code></pre> <p>Return commit history for a specific file.</p>"},{"location":"api/tenets/core/git/analyzer/#tenets.core.git.analyzer.GitAnalyzer.commit_count","title":"commit_count","text":"Python<pre><code>commit_count() -&gt; int\n</code></pre> <p>Return total number of commits in the repository.</p>"},{"location":"api/tenets/core/git/analyzer/#tenets.core.git.analyzer.GitAnalyzer.list_authors","title":"list_authors","text":"Python<pre><code>list_authors() -&gt; List[str]\n</code></pre> <p>Return list of unique authors in the repository.</p>"},{"location":"api/tenets/core/git/analyzer/#tenets.core.git.analyzer.GitAnalyzer.author_stats","title":"author_stats","text":"Python<pre><code>author_stats() -&gt; Dict[str, Dict[str, Any]]\n</code></pre> <p>Return statistics by author.</p>"},{"location":"api/tenets/core/git/analyzer/#tenets.core.git.analyzer.GitAnalyzer.get_changes_since","title":"get_changes_since","text":"Python<pre><code>get_changes_since(path: Optional[Path] = None, since: str = '1 week ago', files: Optional[List[str]] = None) -&gt; List[Dict[str, Any]]\n</code></pre> <p>Return a lightweight list of changes since a given time.</p> <p>Each item contains: sha, message, date.</p>"},{"location":"api/tenets/core/git/analyzer/#tenets.core.git.analyzer.GitAnalyzer.get_commits_since","title":"get_commits_since","text":"Python<pre><code>get_commits_since(since: datetime, max_count: int = 1000, author: Optional[str] = None, branch: Optional[str] = None, include_merges: bool = True) -&gt; List[Any]\n</code></pre> <p>Return raw commit objects since a given datetime.</p> PARAMETER DESCRIPTION <code>since</code> <p>Start datetime (inclusive)</p> <p> TYPE: <code>datetime</code> </p> <code>max_count</code> <p>Maximum number of commits</p> <p> TYPE: <code>int</code> DEFAULT: <code>1000</code> </p> <code>author</code> <p>Optional author filter</p> <p> TYPE: <code>Optional[str]</code> DEFAULT: <code>None</code> </p> <code>branch</code> <p>Optional branch name</p> <p> TYPE: <code>Optional[str]</code> DEFAULT: <code>None</code> </p> <code>include_merges</code> <p>Whether to include merge commits</p> <p> TYPE: <code>bool</code> DEFAULT: <code>True</code> </p> RETURNS DESCRIPTION <code>List[Any]</code> <p>List of GitPython commit objects</p>"},{"location":"api/tenets/core/git/analyzer/#tenets.core.git.analyzer.GitAnalyzer.get_commits","title":"get_commits","text":"Python<pre><code>get_commits(since: Optional[datetime] = None, until: Optional[datetime] = None, max_count: int = 1000, author: Optional[str] = None, branch: Optional[str] = None) -&gt; List[Dict[str, Any]]\n</code></pre> <p>Return commits between two dates.</p> <p>This method was missing and called by momentum.py.</p> PARAMETER DESCRIPTION <code>since</code> <p>Start datetime (inclusive)</p> <p> TYPE: <code>Optional[datetime]</code> DEFAULT: <code>None</code> </p> <code>until</code> <p>End datetime (exclusive)</p> <p> TYPE: <code>Optional[datetime]</code> DEFAULT: <code>None</code> </p> <code>max_count</code> <p>Maximum number of commits</p> <p> TYPE: <code>int</code> DEFAULT: <code>1000</code> </p> <code>author</code> <p>Optional author filter</p> <p> TYPE: <code>Optional[str]</code> DEFAULT: <code>None</code> </p> <code>branch</code> <p>Optional branch name</p> <p> TYPE: <code>Optional[str]</code> DEFAULT: <code>None</code> </p> RETURNS DESCRIPTION <code>List[Dict[str, Any]]</code> <p>List of commit dictionaries with standard fields</p>"},{"location":"api/tenets/core/git/analyzer/#tenets.core.git.analyzer.GitAnalyzer.blame","title":"blame","text":"Python<pre><code>blame(file_path: Path) -&gt; List[Tuple[str, str]]\n</code></pre> <p>Return list of (author, line) for a file using git blame.</p>"},{"location":"api/tenets/core/git/analyzer/#tenets.core.git.analyzer-functions","title":"Functions","text":""},{"location":"api/tenets/core/git/blame/","title":"Blame","text":""},{"location":"api/tenets/core/git/blame/#tenets.core.git.blame","title":"tenets.core.git.blame","text":"<p>Git blame analysis module.</p> <p>This module provides functionality for analyzing line-by-line authorship of files using git blame. It helps understand who wrote what code, when changes were made, and how code ownership is distributed within files.</p> <p>The blame analyzer provides detailed insights into code authorship patterns, helping identify knowledge owners and understanding code evolution.</p>"},{"location":"api/tenets/core/git/blame/#tenets.core.git.blame-classes","title":"Classes","text":""},{"location":"api/tenets/core/git/blame/#tenets.core.git.blame.BlameLine","title":"BlameLine  <code>dataclass</code>","text":"Python<pre><code>BlameLine(line_number: int, content: str, author: str, author_email: str, commit_sha: str, commit_date: datetime, commit_message: str, is_original: bool = False, age_days: int = 0, previous_authors: List[str] = list())\n</code></pre> <p>Information for a single line from git blame.</p> <p>Represents authorship information for a specific line of code, including who wrote it, when, and in which commit.</p> ATTRIBUTE DESCRIPTION <code>line_number</code> <p>Line number in file</p> <p> TYPE: <code>int</code> </p> <code>content</code> <p>Content of the line</p> <p> TYPE: <code>str</code> </p> <code>author</code> <p>Author name</p> <p> TYPE: <code>str</code> </p> <code>author_email</code> <p>Author email</p> <p> TYPE: <code>str</code> </p> <code>commit_sha</code> <p>Commit SHA that introduced this line</p> <p> TYPE: <code>str</code> </p> <code>commit_date</code> <p>Date when line was introduced</p> <p> TYPE: <code>datetime</code> </p> <code>commit_message</code> <p>Commit message (first line)</p> <p> TYPE: <code>str</code> </p> <code>is_original</code> <p>Whether this is from the original commit</p> <p> TYPE: <code>bool</code> </p> <code>age_days</code> <p>Age of the line in days</p> <p> TYPE: <code>int</code> </p> <code>previous_authors</code> <p>List of previous authors if line was modified</p> <p> TYPE: <code>List[str]</code> </p>"},{"location":"api/tenets/core/git/blame/#tenets.core.git.blame.BlameLine-attributes","title":"Attributes","text":""},{"location":"api/tenets/core/git/blame/#tenets.core.git.blame.BlameLine.is_recent","title":"is_recent  <code>property</code>","text":"Python<pre><code>is_recent: bool\n</code></pre> <p>Check if line was recently modified.</p> RETURNS DESCRIPTION <code>bool</code> <p>True if modified within last 30 days</p> <p> TYPE: <code>bool</code> </p>"},{"location":"api/tenets/core/git/blame/#tenets.core.git.blame.BlameLine.is_old","title":"is_old  <code>property</code>","text":"Python<pre><code>is_old: bool\n</code></pre> <p>Check if line is old.</p> RETURNS DESCRIPTION <code>bool</code> <p>True if older than 180 days</p> <p> TYPE: <code>bool</code> </p>"},{"location":"api/tenets/core/git/blame/#tenets.core.git.blame.BlameLine.is_documentation","title":"is_documentation  <code>property</code>","text":"Python<pre><code>is_documentation: bool\n</code></pre> <p>Check if line appears to be documentation.</p> RETURNS DESCRIPTION <code>bool</code> <p>True if line looks like documentation</p> <p> TYPE: <code>bool</code> </p>"},{"location":"api/tenets/core/git/blame/#tenets.core.git.blame.BlameLine.is_empty","title":"is_empty  <code>property</code>","text":"Python<pre><code>is_empty: bool\n</code></pre> <p>Check if line is empty or whitespace only.</p> RETURNS DESCRIPTION <code>bool</code> <p>True if empty or whitespace</p> <p> TYPE: <code>bool</code> </p>"},{"location":"api/tenets/core/git/blame/#tenets.core.git.blame.FileBlame","title":"FileBlame  <code>dataclass</code>","text":"Python<pre><code>FileBlame(file_path: str, total_lines: int = 0, blame_lines: List[BlameLine] = list(), authors: Set[str] = set(), author_stats: Dict[str, Dict[str, Any]] = dict(), commit_shas: Set[str] = set(), oldest_line: Optional[BlameLine] = None, newest_line: Optional[BlameLine] = None, age_distribution: Dict[str, int] = dict(), ownership_map: Dict[str, List[Tuple[int, int]]] = dict(), hot_spots: List[Tuple[int, int]] = list())\n</code></pre> <p>Blame information for an entire file.</p> <p>Aggregates line-by-line blame information to provide file-level authorship insights and ownership patterns.</p> ATTRIBUTE DESCRIPTION <code>file_path</code> <p>Path to the file</p> <p> TYPE: <code>str</code> </p> <code>total_lines</code> <p>Total number of lines</p> <p> TYPE: <code>int</code> </p> <code>blame_lines</code> <p>List of blame information per line</p> <p> TYPE: <code>List[BlameLine]</code> </p> <code>authors</code> <p>Set of unique authors</p> <p> TYPE: <code>Set[str]</code> </p> <code>author_stats</code> <p>Statistics per author</p> <p> TYPE: <code>Dict[str, Dict[str, Any]]</code> </p> <code>commit_shas</code> <p>Set of unique commits</p> <p> TYPE: <code>Set[str]</code> </p> <code>oldest_line</code> <p>Oldest line in file</p> <p> TYPE: <code>Optional[BlameLine]</code> </p> <code>newest_line</code> <p>Newest line in file</p> <p> TYPE: <code>Optional[BlameLine]</code> </p> <code>age_distribution</code> <p>Distribution of line ages</p> <p> TYPE: <code>Dict[str, int]</code> </p> <code>ownership_map</code> <p>Line ranges owned by each author</p> <p> TYPE: <code>Dict[str, List[Tuple[int, int]]]</code> </p> <code>hot_spots</code> <p>Lines that changed frequently</p> <p> TYPE: <code>List[Tuple[int, int]]</code> </p>"},{"location":"api/tenets/core/git/blame/#tenets.core.git.blame.FileBlame-attributes","title":"Attributes","text":""},{"location":"api/tenets/core/git/blame/#tenets.core.git.blame.FileBlame.primary_author","title":"primary_author  <code>property</code>","text":"Python<pre><code>primary_author: Optional[str]\n</code></pre> <p>Get the primary author of the file.</p> RETURNS DESCRIPTION <code>Optional[str]</code> <p>Optional[str]: Author with most lines or None</p>"},{"location":"api/tenets/core/git/blame/#tenets.core.git.blame.FileBlame.author_diversity","title":"author_diversity  <code>property</code>","text":"Python<pre><code>author_diversity: float\n</code></pre> <p>Calculate author diversity score.</p> <p>Higher scores indicate more distributed authorship.</p> RETURNS DESCRIPTION <code>float</code> <p>Diversity score (0-1)</p> <p> TYPE: <code>float</code> </p>"},{"location":"api/tenets/core/git/blame/#tenets.core.git.blame.FileBlame.average_age_days","title":"average_age_days  <code>property</code>","text":"Python<pre><code>average_age_days: float\n</code></pre> <p>Calculate average age of lines in days.</p> RETURNS DESCRIPTION <code>float</code> <p>Average age in days</p> <p> TYPE: <code>float</code> </p>"},{"location":"api/tenets/core/git/blame/#tenets.core.git.blame.FileBlame.freshness_score","title":"freshness_score  <code>property</code>","text":"Python<pre><code>freshness_score: float\n</code></pre> <p>Calculate code freshness score.</p> <p>Higher scores indicate more recently modified code.</p> RETURNS DESCRIPTION <code>float</code> <p>Freshness score (0-100)</p> <p> TYPE: <code>float</code> </p>"},{"location":"api/tenets/core/git/blame/#tenets.core.git.blame.BlameReport","title":"BlameReport  <code>dataclass</code>","text":"Python<pre><code>BlameReport(files_analyzed: int = 0, total_lines: int = 0, total_authors: int = 0, file_blames: Dict[str, FileBlame] = dict(), author_summary: Dict[str, Dict[str, Any]] = dict(), ownership_distribution: Dict[str, float] = dict(), collaboration_matrix: Dict[Tuple[str, str], int] = dict(), knowledge_map: Dict[str, Set[str]] = dict(), recommendations: List[str] = list(), hot_files: List[Dict[str, Any]] = list(), single_author_files: List[str] = list(), abandoned_code: Dict[str, int] = dict(), _bus_factor_override: Optional[int] = None, _collab_score_override: Optional[float] = None)\n</code></pre> <p>Comprehensive blame analysis report.</p> <p>Provides detailed authorship analysis across multiple files, identifying ownership patterns, knowledge distribution, and collaboration insights.</p> ATTRIBUTE DESCRIPTION <code>files_analyzed</code> <p>Number of files analyzed</p> <p> TYPE: <code>int</code> </p> <code>total_lines</code> <p>Total lines analyzed</p> <p> TYPE: <code>int</code> </p> <code>total_authors</code> <p>Total unique authors</p> <p> TYPE: <code>int</code> </p> <code>file_blames</code> <p>Blame data for each file</p> <p> TYPE: <code>Dict[str, FileBlame]</code> </p> <code>author_summary</code> <p>Summary statistics per author</p> <p> TYPE: <code>Dict[str, Dict[str, Any]]</code> </p> <code>ownership_distribution</code> <p>How ownership is distributed</p> <p> TYPE: <code>Dict[str, float]</code> </p> <code>collaboration_matrix</code> <p>Who modified whose code</p> <p> TYPE: <code>Dict[Tuple[str, str], int]</code> </p> <code>knowledge_map</code> <p>Knowledge areas per author</p> <p> TYPE: <code>Dict[str, Set[str]]</code> </p> <code>recommendations</code> <p>Actionable recommendations</p> <p> TYPE: <code>List[str]</code> </p> <code>hot_files</code> <p>Files with most contributors</p> <p> TYPE: <code>List[Dict[str, Any]]</code> </p> <code>single_author_files</code> <p>Files with only one author</p> <p> TYPE: <code>List[str]</code> </p> <code>abandoned_code</code> <p>Code from inactive authors</p> <p> TYPE: <code>Dict[str, int]</code> </p>"},{"location":"api/tenets/core/git/blame/#tenets.core.git.blame.BlameReport-attributes","title":"Attributes","text":""},{"location":"api/tenets/core/git/blame/#tenets.core.git.blame.BlameReport.bus_factor","title":"bus_factor  <code>property</code> <code>writable</code>","text":"Python<pre><code>bus_factor: int\n</code></pre> <p>Calculate bus factor based on blame data.</p> RETURNS DESCRIPTION <code>int</code> <p>Bus factor (number of critical authors)</p> <p> TYPE: <code>int</code> </p>"},{"location":"api/tenets/core/git/blame/#tenets.core.git.blame.BlameReport.collaboration_score","title":"collaboration_score  <code>property</code> <code>writable</code>","text":"Python<pre><code>collaboration_score: float\n</code></pre> <p>Calculate collaboration score.</p> <p>Higher scores indicate more collaborative development.</p> RETURNS DESCRIPTION <code>float</code> <p>Collaboration score (0-100)</p> <p> TYPE: <code>float</code> </p>"},{"location":"api/tenets/core/git/blame/#tenets.core.git.blame.BlameReport-functions","title":"Functions","text":""},{"location":"api/tenets/core/git/blame/#tenets.core.git.blame.BlameReport.to_dict","title":"to_dict","text":"Python<pre><code>to_dict() -&gt; Dict[str, Any]\n</code></pre> <p>Convert report to dictionary.</p> RETURNS DESCRIPTION <code>Dict[str, Any]</code> <p>Dict[str, Any]: Dictionary representation</p>"},{"location":"api/tenets/core/git/blame/#tenets.core.git.blame.BlameAnalyzer","title":"BlameAnalyzer","text":"Python<pre><code>BlameAnalyzer(config: TenetsConfig)\n</code></pre> <p>Analyzer for git blame operations.</p> <p>Provides line-by-line authorship analysis using git blame, helping understand code ownership and evolution patterns.</p> ATTRIBUTE DESCRIPTION <code>config</code> <p>Configuration object</p> <p> </p> <code>logger</code> <p>Logger instance</p> <p> </p> <code>_blame_cache</code> <p>Cache for blame results</p> <p> TYPE: <code>Dict[str, FileBlame]</code> </p> <p>Initialize blame analyzer.</p> PARAMETER DESCRIPTION <code>config</code> <p>TenetsConfig instance</p> <p> TYPE: <code>TenetsConfig</code> </p>"},{"location":"api/tenets/core/git/blame/#tenets.core.git.blame.BlameAnalyzer-functions","title":"Functions","text":""},{"location":"api/tenets/core/git/blame/#tenets.core.git.blame.BlameAnalyzer.analyze_file","title":"analyze_file","text":"Python<pre><code>analyze_file(repo_path: Path, file_path: str, ignore_whitespace: bool = True, follow_renames: bool = True) -&gt; FileBlame\n</code></pre> <p>Analyze blame for a single file.</p> <p>Performs git blame analysis on a file to understand line-by-line authorship.</p> PARAMETER DESCRIPTION <code>repo_path</code> <p>Path to git repository</p> <p> TYPE: <code>Path</code> </p> <code>file_path</code> <p>Path to file relative to repo root</p> <p> TYPE: <code>str</code> </p> <code>ignore_whitespace</code> <p>Ignore whitespace changes</p> <p> TYPE: <code>bool</code> DEFAULT: <code>True</code> </p> <code>follow_renames</code> <p>Follow file renames</p> <p> TYPE: <code>bool</code> DEFAULT: <code>True</code> </p> RETURNS DESCRIPTION <code>FileBlame</code> <p>Blame analysis for the file</p> <p> TYPE: <code>FileBlame</code> </p> Example <p>analyzer = BlameAnalyzer(config) blame = analyzer.analyze_file(Path(\".\"), \"src/main.py\") print(f\"Primary author: {blame.primary_author}\")</p>"},{"location":"api/tenets/core/git/blame/#tenets.core.git.blame.BlameAnalyzer.analyze_directory","title":"analyze_directory","text":"Python<pre><code>analyze_directory(repo_path: Path, directory: str = '.', file_pattern: str = '*', recursive: bool = True, max_files: int = 100) -&gt; BlameReport\n</code></pre> <p>Analyze blame for all files in a directory.</p> <p>Performs comprehensive blame analysis across multiple files to understand ownership patterns.</p> PARAMETER DESCRIPTION <code>repo_path</code> <p>Path to git repository</p> <p> TYPE: <code>Path</code> </p> <code>directory</code> <p>Directory to analyze</p> <p> TYPE: <code>str</code> DEFAULT: <code>'.'</code> </p> <code>file_pattern</code> <p>File pattern to match</p> <p> TYPE: <code>str</code> DEFAULT: <code>'*'</code> </p> <code>recursive</code> <p>Whether to recurse into subdirectories</p> <p> TYPE: <code>bool</code> DEFAULT: <code>True</code> </p> <code>max_files</code> <p>Maximum files to analyze</p> <p> TYPE: <code>int</code> DEFAULT: <code>100</code> </p> RETURNS DESCRIPTION <code>BlameReport</code> <p>Comprehensive blame analysis</p> <p> TYPE: <code>BlameReport</code> </p> Example <p>analyzer = BlameAnalyzer(config) report = analyzer.analyze_directory( ...     Path(\".\"), ...     directory=\"src\", ...     file_pattern=\"*.py\" ... ) print(f\"Bus factor: {report.bus_factor}\")</p>"},{"location":"api/tenets/core/git/blame/#tenets.core.git.blame.BlameAnalyzer.get_line_history","title":"get_line_history","text":"Python<pre><code>get_line_history(repo_path: Path, file_path: str, line_number: int, max_depth: int = 10) -&gt; List[Dict[str, Any]]\n</code></pre> <p>Get history of changes for a specific line.</p> <p>Traces the evolution of a specific line through git history.</p> PARAMETER DESCRIPTION <code>repo_path</code> <p>Path to git repository</p> <p> TYPE: <code>Path</code> </p> <code>file_path</code> <p>Path to file</p> <p> TYPE: <code>str</code> </p> <code>line_number</code> <p>Line number to trace</p> <p> TYPE: <code>int</code> </p> <code>max_depth</code> <p>Maximum history depth to retrieve</p> <p> TYPE: <code>int</code> DEFAULT: <code>10</code> </p> RETURNS DESCRIPTION <code>List[Dict[str, Any]]</code> <p>List[Dict[str, Any]]: History of line changes</p> Example <p>analyzer = BlameAnalyzer(config) history = analyzer.get_line_history( ...     Path(\".\"), ...     \"src/main.py\", ...     42 ... ) for change in history: ...     print(f\"{change['date']}: {change['author']}\")</p>"},{"location":"api/tenets/core/git/blame/#tenets.core.git.blame-functions","title":"Functions","text":""},{"location":"api/tenets/core/git/blame/#tenets.core.git.blame.analyze_blame","title":"analyze_blame","text":"Python<pre><code>analyze_blame(repo_path: Path, target: str = '.', config: Optional[TenetsConfig] = None, **kwargs: Any) -&gt; BlameReport\n</code></pre> <p>Convenience function to analyze blame.</p> PARAMETER DESCRIPTION <code>repo_path</code> <p>Path to repository</p> <p> TYPE: <code>Path</code> </p> <code>target</code> <p>File or directory to analyze</p> <p> TYPE: <code>str</code> DEFAULT: <code>'.'</code> </p> <code>config</code> <p>Optional configuration</p> <p> TYPE: <code>Optional[TenetsConfig]</code> DEFAULT: <code>None</code> </p> <code>**kwargs</code> <p>Additional arguments</p> <p> TYPE: <code>Any</code> DEFAULT: <code>{}</code> </p> RETURNS DESCRIPTION <code>BlameReport</code> <p>Blame analysis report</p> <p> TYPE: <code>BlameReport</code> </p> Example <p>from tenets.core.git.blame import analyze_blame report = analyze_blame(Path(\".\"), target=\"src/\") print(f\"Bus factor: {report.bus_factor}\")</p>"},{"location":"api/tenets/core/git/chronicle/","title":"Chronicle","text":""},{"location":"api/tenets/core/git/chronicle/#tenets.core.git.chronicle","title":"tenets.core.git.chronicle","text":"<p>Chronicle module for git history analysis.</p> <p>This module provides functionality for analyzing and summarizing git repository history, including commit patterns, contributor activity, and development trends. It extracts historical insights to help understand project evolution and team dynamics over time.</p> <p>The chronicle functionality provides a narrative view of repository changes, making it easy to understand what happened, when, and by whom.</p>"},{"location":"api/tenets/core/git/chronicle/#tenets.core.git.chronicle-classes","title":"Classes","text":""},{"location":"api/tenets/core/git/chronicle/#tenets.core.git.chronicle.CommitSummary","title":"CommitSummary  <code>dataclass</code>","text":"Python<pre><code>CommitSummary(sha: str, author: str, email: str, date: datetime, message: str, files_changed: int = 0, lines_added: int = 0, lines_removed: int = 0, is_merge: bool = False, is_revert: bool = False, tags: List[str] = list(), branch: Optional[str] = None, issue_refs: List[str] = list(), pr_refs: List[str] = list())\n</code></pre> <p>Summary information for a single commit.</p> <p>Provides a concise representation of a commit with key information for historical analysis and reporting.</p> ATTRIBUTE DESCRIPTION <code>sha</code> <p>Commit SHA (short form)</p> <p> TYPE: <code>str</code> </p> <code>author</code> <p>Commit author name</p> <p> TYPE: <code>str</code> </p> <code>email</code> <p>Author email</p> <p> TYPE: <code>str</code> </p> <code>date</code> <p>Commit date</p> <p> TYPE: <code>datetime</code> </p> <code>message</code> <p>Commit message (first line)</p> <p> TYPE: <code>str</code> </p> <code>files_changed</code> <p>Number of files changed</p> <p> TYPE: <code>int</code> </p> <code>lines_added</code> <p>Lines added</p> <p> TYPE: <code>int</code> </p> <code>lines_removed</code> <p>Lines removed</p> <p> TYPE: <code>int</code> </p> <code>is_merge</code> <p>Whether this is a merge commit</p> <p> TYPE: <code>bool</code> </p> <code>is_revert</code> <p>Whether this is a revert commit</p> <p> TYPE: <code>bool</code> </p> <code>tags</code> <p>Associated tags</p> <p> TYPE: <code>List[str]</code> </p> <code>branch</code> <p>Branch name if available</p> <p> TYPE: <code>Optional[str]</code> </p> <code>issue_refs</code> <p>Referenced issue numbers</p> <p> TYPE: <code>List[str]</code> </p> <code>pr_refs</code> <p>Referenced PR numbers</p> <p> TYPE: <code>List[str]</code> </p>"},{"location":"api/tenets/core/git/chronicle/#tenets.core.git.chronicle.CommitSummary-attributes","title":"Attributes","text":""},{"location":"api/tenets/core/git/chronicle/#tenets.core.git.chronicle.CommitSummary.net_lines","title":"net_lines  <code>property</code>","text":"Python<pre><code>net_lines: int\n</code></pre> <p>Calculate net lines changed.</p> RETURNS DESCRIPTION <code>int</code> <p>Lines added minus lines removed</p> <p> TYPE: <code>int</code> </p>"},{"location":"api/tenets/core/git/chronicle/#tenets.core.git.chronicle.CommitSummary.commit_type","title":"commit_type  <code>property</code>","text":"Python<pre><code>commit_type: str\n</code></pre> <p>Determine commit type from message.</p> RETURNS DESCRIPTION <code>str</code> <p>Commit type (feat, fix, docs, etc.)</p> <p> TYPE: <code>str</code> </p>"},{"location":"api/tenets/core/git/chronicle/#tenets.core.git.chronicle.CommitSummary-functions","title":"Functions","text":""},{"location":"api/tenets/core/git/chronicle/#tenets.core.git.chronicle.CommitSummary.to_dict","title":"to_dict","text":"Python<pre><code>to_dict() -&gt; Dict[str, Any]\n</code></pre> <p>Convert to dictionary representation.</p> RETURNS DESCRIPTION <code>Dict[str, Any]</code> <p>Dict[str, Any]: Dictionary representation</p>"},{"location":"api/tenets/core/git/chronicle/#tenets.core.git.chronicle.DayActivity","title":"DayActivity  <code>dataclass</code>","text":"Python<pre><code>DayActivity(date: datetime, commits: List[CommitSummary] = list(), total_commits: int = 0, unique_authors: Set[str] = set(), lines_added: int = 0, lines_removed: int = 0, files_touched: Set[str] = set(), commit_types: Dict[str, int] = dict(), peak_hour: Optional[int] = None, first_commit_time: Optional[datetime] = None, last_commit_time: Optional[datetime] = None)\n</code></pre> <p>Activity summary for a single day.</p> <p>Aggregates all repository activity for a specific day to provide daily development rhythm insights.</p> ATTRIBUTE DESCRIPTION <code>date</code> <p>Date of activity</p> <p> TYPE: <code>datetime</code> </p> <code>commits</code> <p>List of commits on this day</p> <p> TYPE: <code>List[CommitSummary]</code> </p> <code>total_commits</code> <p>Total commit count</p> <p> TYPE: <code>int</code> </p> <code>unique_authors</code> <p>Set of unique authors</p> <p> TYPE: <code>Set[str]</code> </p> <code>lines_added</code> <p>Total lines added</p> <p> TYPE: <code>int</code> </p> <code>lines_removed</code> <p>Total lines removed</p> <p> TYPE: <code>int</code> </p> <code>files_touched</code> <p>Set of files modified</p> <p> TYPE: <code>Set[str]</code> </p> <code>commit_types</code> <p>Distribution of commit types</p> <p> TYPE: <code>Dict[str, int]</code> </p> <code>peak_hour</code> <p>Hour with most commits</p> <p> TYPE: <code>Optional[int]</code> </p> <code>first_commit_time</code> <p>Time of first commit</p> <p> TYPE: <code>Optional[datetime]</code> </p> <code>last_commit_time</code> <p>Time of last commit</p> <p> TYPE: <code>Optional[datetime]</code> </p>"},{"location":"api/tenets/core/git/chronicle/#tenets.core.git.chronicle.DayActivity-attributes","title":"Attributes","text":""},{"location":"api/tenets/core/git/chronicle/#tenets.core.git.chronicle.DayActivity.net_lines","title":"net_lines  <code>property</code>","text":"Python<pre><code>net_lines: int\n</code></pre> <p>Calculate net lines changed.</p> RETURNS DESCRIPTION <code>int</code> <p>Net lines changed for the day</p> <p> TYPE: <code>int</code> </p>"},{"location":"api/tenets/core/git/chronicle/#tenets.core.git.chronicle.DayActivity.productivity_score","title":"productivity_score  <code>property</code>","text":"Python<pre><code>productivity_score: float\n</code></pre> <p>Calculate daily productivity score.</p> RETURNS DESCRIPTION <code>float</code> <p>Productivity score (0-100)</p> <p> TYPE: <code>float</code> </p>"},{"location":"api/tenets/core/git/chronicle/#tenets.core.git.chronicle.ChronicleReport","title":"ChronicleReport  <code>dataclass</code>","text":"Python<pre><code>ChronicleReport(period_start: datetime, period_end: datetime, total_commits: int = 0, total_contributors: int = 0, commits: List[CommitSummary] = list(), daily_activity: List[DayActivity] = list(), contributor_stats: Dict[str, Dict[str, Any]] = dict(), commit_type_distribution: Dict[str, int] = dict(), file_change_frequency: List[Tuple[str, int]] = list(), hot_periods: List[Dict[str, Any]] = list(), quiet_periods: List[Dict[str, Any]] = list(), significant_events: List[Dict[str, Any]] = list(), trends: List[str] = list(), summary: str = '')\n</code></pre> <p>Comprehensive chronicle report of repository history.</p> <p>Provides a complete narrative view of repository evolution including commits, contributors, trends, and significant events.</p> ATTRIBUTE DESCRIPTION <code>period_start</code> <p>Start of chronicle period</p> <p> TYPE: <code>datetime</code> </p> <code>period_end</code> <p>End of chronicle period</p> <p> TYPE: <code>datetime</code> </p> <code>total_commits</code> <p>Total commits in period</p> <p> TYPE: <code>int</code> </p> <code>total_contributors</code> <p>Total unique contributors</p> <p> TYPE: <code>int</code> </p> <code>commits</code> <p>List of commit summaries</p> <p> TYPE: <code>List[CommitSummary]</code> </p> <code>daily_activity</code> <p>Daily activity breakdown</p> <p> TYPE: <code>List[DayActivity]</code> </p> <code>contributor_stats</code> <p>Statistics by contributor</p> <p> TYPE: <code>Dict[str, Dict[str, Any]]</code> </p> <code>commit_type_distribution</code> <p>Distribution of commit types</p> <p> TYPE: <code>Dict[str, int]</code> </p> <code>file_change_frequency</code> <p>Most frequently changed files</p> <p> TYPE: <code>List[Tuple[str, int]]</code> </p> <code>hot_periods</code> <p>Periods of high activity</p> <p> TYPE: <code>List[Dict[str, Any]]</code> </p> <code>quiet_periods</code> <p>Periods of low activity</p> <p> TYPE: <code>List[Dict[str, Any]]</code> </p> <code>significant_events</code> <p>Notable events (releases, major changes)</p> <p> TYPE: <code>List[Dict[str, Any]]</code> </p> <code>trends</code> <p>Identified trends in development</p> <p> TYPE: <code>List[str]</code> </p> <code>summary</code> <p>Executive summary of the period</p> <p> TYPE: <code>str</code> </p>"},{"location":"api/tenets/core/git/chronicle/#tenets.core.git.chronicle.ChronicleReport-attributes","title":"Attributes","text":""},{"location":"api/tenets/core/git/chronicle/#tenets.core.git.chronicle.ChronicleReport.most_active_day","title":"most_active_day  <code>property</code>","text":"Python<pre><code>most_active_day: Optional[DayActivity]\n</code></pre> <p>Get the most active day.</p> RETURNS DESCRIPTION <code>Optional[DayActivity]</code> <p>Optional[DayActivity]: Most active day or None</p>"},{"location":"api/tenets/core/git/chronicle/#tenets.core.git.chronicle.ChronicleReport.activity_level","title":"activity_level  <code>property</code>","text":"Python<pre><code>activity_level: str\n</code></pre> <p>Determine overall activity level.</p> RETURNS DESCRIPTION <code>str</code> <p>Activity level (high, moderate, low)</p> <p> TYPE: <code>str</code> </p>"},{"location":"api/tenets/core/git/chronicle/#tenets.core.git.chronicle.ChronicleReport-functions","title":"Functions","text":""},{"location":"api/tenets/core/git/chronicle/#tenets.core.git.chronicle.ChronicleReport.to_dict","title":"to_dict","text":"Python<pre><code>to_dict() -&gt; Dict[str, Any]\n</code></pre> <p>Convert to dictionary representation.</p> RETURNS DESCRIPTION <code>Dict[str, Any]</code> <p>Dict[str, Any]: Dictionary representation</p>"},{"location":"api/tenets/core/git/chronicle/#tenets.core.git.chronicle.Chronicle","title":"Chronicle","text":"Python<pre><code>Chronicle(config: TenetsConfig)\n</code></pre> <p>Main chronicle analyzer for git repositories.</p> <p>Analyzes git history to create a narrative view of repository evolution, identifying patterns, trends, and significant events.</p> ATTRIBUTE DESCRIPTION <code>config</code> <p>Configuration object</p> <p> </p> <code>logger</code> <p>Logger instance</p> <p> </p> <code>git_analyzer</code> <p>Git analyzer instance</p> <p> TYPE: <code>Optional[GitAnalyzer]</code> </p> <p>Initialize chronicle analyzer.</p> PARAMETER DESCRIPTION <code>config</code> <p>TenetsConfig instance</p> <p> TYPE: <code>TenetsConfig</code> </p>"},{"location":"api/tenets/core/git/chronicle/#tenets.core.git.chronicle.Chronicle-functions","title":"Functions","text":""},{"location":"api/tenets/core/git/chronicle/#tenets.core.git.chronicle.Chronicle.analyze","title":"analyze","text":"Python<pre><code>analyze(repo_path: Path, since: Optional[str] = None, until: Optional[str] = None, author: Optional[str] = None, branch: Optional[str] = None, include_merges: bool = True, include_stats: bool = True, max_commits: int = 1000) -&gt; ChronicleReport\n</code></pre> <p>Analyze repository history and create chronicle report.</p> <p>Creates a comprehensive narrative of repository evolution including commits, contributors, trends, and significant events.</p> PARAMETER DESCRIPTION <code>repo_path</code> <p>Path to git repository</p> <p> TYPE: <code>Path</code> </p> <code>since</code> <p>Start date or relative time (e.g., \"2 weeks ago\")</p> <p> TYPE: <code>Optional[str]</code> DEFAULT: <code>None</code> </p> <code>until</code> <p>End date or relative time</p> <p> TYPE: <code>Optional[str]</code> DEFAULT: <code>None</code> </p> <code>author</code> <p>Filter by specific author</p> <p> TYPE: <code>Optional[str]</code> DEFAULT: <code>None</code> </p> <code>branch</code> <p>Specific branch to analyze</p> <p> TYPE: <code>Optional[str]</code> DEFAULT: <code>None</code> </p> <code>include_merges</code> <p>Whether to include merge commits</p> <p> TYPE: <code>bool</code> DEFAULT: <code>True</code> </p> <code>include_stats</code> <p>Whether to include detailed statistics</p> <p> TYPE: <code>bool</code> DEFAULT: <code>True</code> </p> <code>max_commits</code> <p>Maximum commits to analyze</p> <p> TYPE: <code>int</code> DEFAULT: <code>1000</code> </p> RETURNS DESCRIPTION <code>ChronicleReport</code> <p>Comprehensive chronicle analysis</p> <p> TYPE: <code>ChronicleReport</code> </p> Example <p>chronicle = Chronicle(config) report = chronicle.analyze( ...     Path(\".\"), ...     since=\"1 month ago\", ...     include_stats=True ... ) print(report.summary)</p>"},{"location":"api/tenets/core/git/chronicle/#tenets.core.git.chronicle.ChronicleBuilder","title":"ChronicleBuilder","text":"Python<pre><code>ChronicleBuilder(config: Optional[TenetsConfig] = None)\n</code></pre> <p>High-level builder that assembles a simple chronicle dict for CLI.</p> <p>This composes the existing Chronicle and GitAnalyzer without duplicating analysis logic. It converts inputs to what Chronicle expects and returns a compact, CLI-friendly dictionary.</p> <p>The CLI tests patch this class, but we provide a functional default for real usage.</p>"},{"location":"api/tenets/core/git/chronicle/#tenets.core.git.chronicle.ChronicleBuilder-functions","title":"Functions","text":""},{"location":"api/tenets/core/git/chronicle/#tenets.core.git.chronicle.ChronicleBuilder.build_chronicle","title":"build_chronicle","text":"Python<pre><code>build_chronicle(repo_path: Path, *, since: Optional[object] = None, until: Optional[object] = None, branch: Optional[str] = None, authors: Optional[List[str]] = None, include_merges: bool = True, limit: Optional[int] = None) -&gt; Dict[str, Any]\n</code></pre> <p>Build a chronicle summary for the given repository.</p> PARAMETER DESCRIPTION <code>repo_path</code> <p>Path to a git repository</p> <p> TYPE: <code>Path</code> </p> <code>since</code> <p>Start time (datetime or relative/ISO string)</p> <p> TYPE: <code>Optional[object]</code> DEFAULT: <code>None</code> </p> <code>until</code> <p>End time (datetime or relative/ISO string)</p> <p> TYPE: <code>Optional[object]</code> DEFAULT: <code>None</code> </p> <code>branch</code> <p>Branch name to analyze</p> <p> TYPE: <code>Optional[str]</code> DEFAULT: <code>None</code> </p> <code>authors</code> <p>Optional author filters (currently advisory)</p> <p> TYPE: <code>Optional[List[str]]</code> DEFAULT: <code>None</code> </p> <code>include_merges</code> <p>Include merge commits</p> <p> TYPE: <code>bool</code> DEFAULT: <code>True</code> </p> <code>limit</code> <p>Max commits to analyze (advisory to Chronicle)</p> <p> TYPE: <code>Optional[int]</code> DEFAULT: <code>None</code> </p> RETURNS DESCRIPTION <code>Dict[str, Any]</code> <p>A dictionary with keys expected by the CLI views.</p>"},{"location":"api/tenets/core/git/chronicle/#tenets.core.git.chronicle-functions","title":"Functions","text":""},{"location":"api/tenets/core/git/chronicle/#tenets.core.git.chronicle.create_chronicle","title":"create_chronicle","text":"Python<pre><code>create_chronicle(repo_path: Path, since: Optional[str] = None, config: Optional[TenetsConfig] = None, **kwargs: Any) -&gt; ChronicleReport\n</code></pre> <p>Convenience function to create a repository chronicle.</p> PARAMETER DESCRIPTION <code>repo_path</code> <p>Path to repository</p> <p> TYPE: <code>Path</code> </p> <code>since</code> <p>Start time for chronicle</p> <p> TYPE: <code>Optional[str]</code> DEFAULT: <code>None</code> </p> <code>config</code> <p>Optional configuration</p> <p> TYPE: <code>Optional[TenetsConfig]</code> DEFAULT: <code>None</code> </p> <code>**kwargs</code> <p>Additional arguments for chronicle</p> <p> TYPE: <code>Any</code> DEFAULT: <code>{}</code> </p> RETURNS DESCRIPTION <code>ChronicleReport</code> <p>Chronicle analysis</p> <p> TYPE: <code>ChronicleReport</code> </p> Example <p>from tenets.core.git.chronicle import create_chronicle report = create_chronicle(Path(\".\"), since=\"1 month ago\") print(report.summary)</p>"},{"location":"api/tenets/core/git/stats/","title":"Stats","text":""},{"location":"api/tenets/core/git/stats/#tenets.core.git.stats","title":"tenets.core.git.stats","text":"<p>Git statistics module.</p> <p>This module provides comprehensive statistical analysis of git repositories, including commit patterns, contributor metrics, file statistics, and repository growth analysis. It helps understand repository health, development patterns, and team dynamics through data-driven insights.</p> <p>The statistics module aggregates various git metrics to provide actionable insights for project management and technical decision-making.</p>"},{"location":"api/tenets/core/git/stats/#tenets.core.git.stats-classes","title":"Classes","text":""},{"location":"api/tenets/core/git/stats/#tenets.core.git.stats.CommitStats","title":"CommitStats  <code>dataclass</code>","text":"Python<pre><code>CommitStats(total_commits: int = 0, commits_per_day: float = 0.0, commits_per_week: float = 0.0, commits_per_month: float = 0.0, commit_size_avg: float = 0.0, commit_size_median: float = 0.0, commit_size_std: float = 0.0, largest_commit: Dict[str, Any] = dict(), smallest_commit: Dict[str, Any] = dict(), merge_commits: int = 0, revert_commits: int = 0, fix_commits: int = 0, feature_commits: int = 0, hourly_distribution: List[int] = (lambda: [0] * 24)(), daily_distribution: List[int] = (lambda: [0] * 7)(), monthly_distribution: List[int] = (lambda: [0] * 12)())\n</code></pre> <p>Statistics for commits.</p> <p>Provides detailed statistical analysis of commit patterns including frequency, size, timing, and distribution metrics.</p> ATTRIBUTE DESCRIPTION <code>total_commits</code> <p>Total number of commits</p> <p> TYPE: <code>int</code> </p> <code>commits_per_day</code> <p>Average commits per day</p> <p> TYPE: <code>float</code> </p> <code>commits_per_week</code> <p>Average commits per week</p> <p> TYPE: <code>float</code> </p> <code>commits_per_month</code> <p>Average commits per month</p> <p> TYPE: <code>float</code> </p> <code>commit_size_avg</code> <p>Average commit size (lines changed)</p> <p> TYPE: <code>float</code> </p> <code>commit_size_median</code> <p>Median commit size</p> <p> TYPE: <code>float</code> </p> <code>commit_size_std</code> <p>Standard deviation of commit size</p> <p> TYPE: <code>float</code> </p> <code>largest_commit</code> <p>Largest single commit</p> <p> TYPE: <code>Dict[str, Any]</code> </p> <code>smallest_commit</code> <p>Smallest single commit</p> <p> TYPE: <code>Dict[str, Any]</code> </p> <code>merge_commits</code> <p>Number of merge commits</p> <p> TYPE: <code>int</code> </p> <code>revert_commits</code> <p>Number of revert commits</p> <p> TYPE: <code>int</code> </p> <code>fix_commits</code> <p>Number of fix commits</p> <p> TYPE: <code>int</code> </p> <code>feature_commits</code> <p>Number of feature commits</p> <p> TYPE: <code>int</code> </p> <code>hourly_distribution</code> <p>Commits by hour of day</p> <p> TYPE: <code>List[int]</code> </p> <code>daily_distribution</code> <p>Commits by day of week</p> <p> TYPE: <code>List[int]</code> </p> <code>monthly_distribution</code> <p>Commits by month</p> <p> TYPE: <code>List[int]</code> </p>"},{"location":"api/tenets/core/git/stats/#tenets.core.git.stats.CommitStats-attributes","title":"Attributes","text":""},{"location":"api/tenets/core/git/stats/#tenets.core.git.stats.CommitStats.merge_ratio","title":"merge_ratio  <code>property</code>","text":"Python<pre><code>merge_ratio: float\n</code></pre> <p>Calculate merge commit ratio.</p> RETURNS DESCRIPTION <code>float</code> <p>Ratio of merge commits to total</p> <p> TYPE: <code>float</code> </p>"},{"location":"api/tenets/core/git/stats/#tenets.core.git.stats.CommitStats.fix_ratio","title":"fix_ratio  <code>property</code>","text":"Python<pre><code>fix_ratio: float\n</code></pre> <p>Calculate fix commit ratio.</p> RETURNS DESCRIPTION <code>float</code> <p>Ratio of fix commits to total</p> <p> TYPE: <code>float</code> </p>"},{"location":"api/tenets/core/git/stats/#tenets.core.git.stats.CommitStats.peak_hour","title":"peak_hour  <code>property</code>","text":"Python<pre><code>peak_hour: int\n</code></pre> <p>Find peak commit hour.</p> RETURNS DESCRIPTION <code>int</code> <p>Hour with most commits (0-23)</p> <p> TYPE: <code>int</code> </p>"},{"location":"api/tenets/core/git/stats/#tenets.core.git.stats.CommitStats.peak_day","title":"peak_day  <code>property</code>","text":"Python<pre><code>peak_day: str\n</code></pre> <p>Find peak commit day.</p> RETURNS DESCRIPTION <code>str</code> <p>Day with most commits</p> <p> TYPE: <code>str</code> </p>"},{"location":"api/tenets/core/git/stats/#tenets.core.git.stats.ContributorStats","title":"ContributorStats  <code>dataclass</code>","text":"Python<pre><code>ContributorStats(total_contributors: int = 0, active_contributors: int = 0, new_contributors: int = 0, contributor_commits: Dict[str, int] = dict(), contributor_lines: Dict[str, int] = dict(), contributor_files: Dict[str, Set[str]] = dict(), top_contributors: List[Tuple[str, int]] = list(), contribution_inequality: float = 0.0, collaboration_graph: Dict[Tuple[str, str], int] = dict(), timezone_distribution: Dict[str, int] = dict(), retention_rate: float = 0.0, churn_rate: float = 0.0)\n</code></pre> <p>Statistics for contributors.</p> <p>Provides analysis of contributor patterns, productivity metrics, and team dynamics based on git history.</p> ATTRIBUTE DESCRIPTION <code>total_contributors</code> <p>Total unique contributors</p> <p> TYPE: <code>int</code> </p> <code>active_contributors</code> <p>Contributors active in last 30 days</p> <p> TYPE: <code>int</code> </p> <code>new_contributors</code> <p>New contributors in period</p> <p> TYPE: <code>int</code> </p> <code>contributor_commits</code> <p>Commits per contributor</p> <p> TYPE: <code>Dict[str, int]</code> </p> <code>contributor_lines</code> <p>Lines changed per contributor</p> <p> TYPE: <code>Dict[str, int]</code> </p> <code>contributor_files</code> <p>Files touched per contributor</p> <p> TYPE: <code>Dict[str, Set[str]]</code> </p> <code>top_contributors</code> <p>Most active contributors</p> <p> TYPE: <code>List[Tuple[str, int]]</code> </p> <code>contribution_inequality</code> <p>Gini coefficient of contributions</p> <p> TYPE: <code>float</code> </p> <code>collaboration_graph</code> <p>Who works with whom</p> <p> TYPE: <code>Dict[Tuple[str, str], int]</code> </p> <code>timezone_distribution</code> <p>Contributors by timezone</p> <p> TYPE: <code>Dict[str, int]</code> </p> <code>retention_rate</code> <p>Contributor retention rate</p> <p> TYPE: <code>float</code> </p> <code>churn_rate</code> <p>Contributor churn rate</p> <p> TYPE: <code>float</code> </p>"},{"location":"api/tenets/core/git/stats/#tenets.core.git.stats.ContributorStats-attributes","title":"Attributes","text":""},{"location":"api/tenets/core/git/stats/#tenets.core.git.stats.ContributorStats.avg_commits_per_contributor","title":"avg_commits_per_contributor  <code>property</code>","text":"Python<pre><code>avg_commits_per_contributor: float\n</code></pre> <p>Calculate average commits per contributor.</p> RETURNS DESCRIPTION <code>float</code> <p>Average commits</p> <p> TYPE: <code>float</code> </p>"},{"location":"api/tenets/core/git/stats/#tenets.core.git.stats.ContributorStats.bus_factor","title":"bus_factor  <code>property</code>","text":"Python<pre><code>bus_factor: int\n</code></pre> <p>Calculate bus factor.</p> RETURNS DESCRIPTION <code>int</code> <p>Number of key contributors</p> <p> TYPE: <code>int</code> </p>"},{"location":"api/tenets/core/git/stats/#tenets.core.git.stats.ContributorStats.collaboration_score","title":"collaboration_score  <code>property</code>","text":"Python<pre><code>collaboration_score: float\n</code></pre> <p>Calculate collaboration score.</p> RETURNS DESCRIPTION <code>float</code> <p>Collaboration score (0-100)</p> <p> TYPE: <code>float</code> </p>"},{"location":"api/tenets/core/git/stats/#tenets.core.git.stats.FileStats","title":"FileStats  <code>dataclass</code>","text":"Python<pre><code>FileStats(total_files: int = 0, active_files: int = 0, new_files: int = 0, deleted_files: int = 0, file_changes: Dict[str, int] = dict(), file_sizes: Dict[str, int] = dict(), largest_files: List[Tuple[str, int]] = list(), most_changed: List[Tuple[str, int]] = list(), file_age: Dict[str, int] = dict(), file_churn: Dict[str, float] = dict(), hot_files: List[str] = list(), stable_files: List[str] = list(), file_types: Dict[str, int] = dict())\n</code></pre> <p>Statistics for files.</p> <p>Provides analysis of file-level metrics including change frequency, size distribution, and file lifecycle patterns.</p> ATTRIBUTE DESCRIPTION <code>total_files</code> <p>Total files in repository</p> <p> TYPE: <code>int</code> </p> <code>active_files</code> <p>Files changed in period</p> <p> TYPE: <code>int</code> </p> <code>new_files</code> <p>Files added in period</p> <p> TYPE: <code>int</code> </p> <code>deleted_files</code> <p>Files deleted in period</p> <p> TYPE: <code>int</code> </p> <code>file_changes</code> <p>Number of changes per file</p> <p> TYPE: <code>Dict[str, int]</code> </p> <code>file_sizes</code> <p>Size distribution of files</p> <p> TYPE: <code>Dict[str, int]</code> </p> <code>largest_files</code> <p>Largest files by line count</p> <p> TYPE: <code>List[Tuple[str, int]]</code> </p> <code>most_changed</code> <p>Most frequently changed files</p> <p> TYPE: <code>List[Tuple[str, int]]</code> </p> <code>file_age</code> <p>Age distribution of files</p> <p> TYPE: <code>Dict[str, int]</code> </p> <code>file_churn</code> <p>Churn rate per file</p> <p> TYPE: <code>Dict[str, float]</code> </p> <code>hot_files</code> <p>Files with high activity</p> <p> TYPE: <code>List[str]</code> </p> <code>stable_files</code> <p>Files with low activity</p> <p> TYPE: <code>List[str]</code> </p> <code>file_types</code> <p>Distribution by file type</p> <p> TYPE: <code>Dict[str, int]</code> </p>"},{"location":"api/tenets/core/git/stats/#tenets.core.git.stats.FileStats-attributes","title":"Attributes","text":""},{"location":"api/tenets/core/git/stats/#tenets.core.git.stats.FileStats.avg_file_size","title":"avg_file_size  <code>property</code>","text":"Python<pre><code>avg_file_size: float\n</code></pre> <p>Calculate average file size.</p> RETURNS DESCRIPTION <code>float</code> <p>Average size in lines</p> <p> TYPE: <code>float</code> </p>"},{"location":"api/tenets/core/git/stats/#tenets.core.git.stats.FileStats.file_stability","title":"file_stability  <code>property</code>","text":"Python<pre><code>file_stability: float\n</code></pre> <p>Calculate overall file stability.</p> RETURNS DESCRIPTION <code>float</code> <p>Stability score (0-100)</p> <p> TYPE: <code>float</code> </p>"},{"location":"api/tenets/core/git/stats/#tenets.core.git.stats.FileStats.churn_rate","title":"churn_rate  <code>property</code>","text":"Python<pre><code>churn_rate: float\n</code></pre> <p>Calculate overall churn rate.</p> RETURNS DESCRIPTION <code>float</code> <p>Average churn rate</p> <p> TYPE: <code>float</code> </p>"},{"location":"api/tenets/core/git/stats/#tenets.core.git.stats.RepositoryStats","title":"RepositoryStats  <code>dataclass</code>","text":"Python<pre><code>RepositoryStats(repo_age_days: int = 0, total_commits: int = 0, total_contributors: int = 0, total_files: int = 0, total_lines: int = 0, languages: Dict[str, int] = dict(), commit_stats: CommitStats = CommitStats(), contributor_stats: ContributorStats = ContributorStats(), file_stats: FileStats = FileStats(), growth_rate: float = 0.0, activity_trend: str = 'stable', health_score: float = 0.0, risk_factors: List[str] = list(), strengths: List[str] = list())\n</code></pre> <p>Overall repository statistics.</p> <p>Aggregates various statistical analyses to provide comprehensive insights into repository health and development patterns.</p> ATTRIBUTE DESCRIPTION <code>repo_age_days</code> <p>Age of repository in days</p> <p> TYPE: <code>int</code> </p> <code>total_commits</code> <p>Total commits</p> <p> TYPE: <code>int</code> </p> <code>total_contributors</code> <p>Total contributors</p> <p> TYPE: <code>int</code> </p> <code>total_files</code> <p>Total files</p> <p> TYPE: <code>int</code> </p> <code>total_lines</code> <p>Total lines of code</p> <p> TYPE: <code>int</code> </p> <code>languages</code> <p>Programming languages used</p> <p> TYPE: <code>Dict[str, int]</code> </p> <code>commit_stats</code> <p>Commit statistics</p> <p> TYPE: <code>CommitStats</code> </p> <code>contributor_stats</code> <p>Contributor statistics</p> <p> TYPE: <code>ContributorStats</code> </p> <code>file_stats</code> <p>File statistics</p> <p> TYPE: <code>FileStats</code> </p> <code>growth_rate</code> <p>Repository growth rate</p> <p> TYPE: <code>float</code> </p> <code>activity_trend</code> <p>Recent activity trend</p> <p> TYPE: <code>str</code> </p> <code>health_score</code> <p>Overall health score</p> <p> TYPE: <code>float</code> </p> <code>risk_factors</code> <p>Identified risk factors</p> <p> TYPE: <code>List[str]</code> </p> <code>strengths</code> <p>Identified strengths</p> <p> TYPE: <code>List[str]</code> </p>"},{"location":"api/tenets/core/git/stats/#tenets.core.git.stats.RepositoryStats-functions","title":"Functions","text":""},{"location":"api/tenets/core/git/stats/#tenets.core.git.stats.RepositoryStats.to_dict","title":"to_dict","text":"Python<pre><code>to_dict() -&gt; Dict[str, Any]\n</code></pre> <p>Convert to dictionary representation.</p> RETURNS DESCRIPTION <code>Dict[str, Any]</code> <p>Dict[str, Any]: Dictionary representation</p>"},{"location":"api/tenets/core/git/stats/#tenets.core.git.stats.GitStatsAnalyzer","title":"GitStatsAnalyzer","text":"Python<pre><code>GitStatsAnalyzer(config: TenetsConfig)\n</code></pre> <p>Analyzer for git repository statistics.</p> <p>Provides comprehensive statistical analysis of git repositories to understand development patterns, team dynamics, and code health.</p> ATTRIBUTE DESCRIPTION <code>config</code> <p>Configuration object</p> <p> </p> <code>logger</code> <p>Logger instance</p> <p> </p> <code>git_analyzer</code> <p>Git analyzer instance</p> <p> TYPE: <code>Optional[GitAnalyzer]</code> </p> <p>Initialize statistics analyzer.</p> PARAMETER DESCRIPTION <code>config</code> <p>TenetsConfig instance</p> <p> TYPE: <code>TenetsConfig</code> </p>"},{"location":"api/tenets/core/git/stats/#tenets.core.git.stats.GitStatsAnalyzer-functions","title":"Functions","text":""},{"location":"api/tenets/core/git/stats/#tenets.core.git.stats.GitStatsAnalyzer.analyze","title":"analyze","text":"Python<pre><code>analyze(repo_path: Path, since: Optional[str] = None, until: Optional[str] = None, branch: Optional[str] = None, include_files: bool = True, include_languages: bool = True, max_commits: int = 10000) -&gt; RepositoryStats\n</code></pre> <p>Analyze repository statistics.</p> <p>Performs comprehensive statistical analysis of a git repository to provide insights into development patterns and health.</p> PARAMETER DESCRIPTION <code>repo_path</code> <p>Path to git repository</p> <p> TYPE: <code>Path</code> </p> <code>since</code> <p>Start date or relative time</p> <p> TYPE: <code>Optional[str]</code> DEFAULT: <code>None</code> </p> <code>until</code> <p>End date or relative time</p> <p> TYPE: <code>Optional[str]</code> DEFAULT: <code>None</code> </p> <code>branch</code> <p>Specific branch to analyze</p> <p> TYPE: <code>Optional[str]</code> DEFAULT: <code>None</code> </p> <code>include_files</code> <p>Whether to include file statistics</p> <p> TYPE: <code>bool</code> DEFAULT: <code>True</code> </p> <code>include_languages</code> <p>Whether to analyze languages</p> <p> TYPE: <code>bool</code> DEFAULT: <code>True</code> </p> <code>max_commits</code> <p>Maximum commits to analyze</p> <p> TYPE: <code>int</code> DEFAULT: <code>10000</code> </p> RETURNS DESCRIPTION <code>RepositoryStats</code> <p>Comprehensive statistics</p> <p> TYPE: <code>RepositoryStats</code> </p> Example <p>analyzer = GitStatsAnalyzer(config) stats = analyzer.analyze(Path(\".\")) print(f\"Health score: {stats.health_score}\")</p>"},{"location":"api/tenets/core/git/stats/#tenets.core.git.stats-functions","title":"Functions","text":""},{"location":"api/tenets/core/git/stats/#tenets.core.git.stats.analyze_git_stats","title":"analyze_git_stats","text":"Python<pre><code>analyze_git_stats(repo_path: Path, config: Optional[TenetsConfig] = None, **kwargs: Any) -&gt; RepositoryStats\n</code></pre> <p>Convenience function to analyze git statistics.</p> PARAMETER DESCRIPTION <code>repo_path</code> <p>Path to repository</p> <p> TYPE: <code>Path</code> </p> <code>config</code> <p>Optional configuration</p> <p> TYPE: <code>Optional[TenetsConfig]</code> DEFAULT: <code>None</code> </p> <code>**kwargs</code> <p>Additional arguments</p> <p> TYPE: <code>Any</code> DEFAULT: <code>{}</code> </p> RETURNS DESCRIPTION <code>RepositoryStats</code> <p>Repository statistics</p> <p> TYPE: <code>RepositoryStats</code> </p> Example <p>from tenets.core.git.stats import analyze_git_stats stats = analyze_git_stats(Path(\".\")) print(f\"Health score: {stats.health_score}\")</p>"},{"location":"api/tenets/core/instiller/injector/","title":"Injector","text":""},{"location":"api/tenets/core/instiller/injector/#tenets.core.instiller.injector","title":"tenets.core.instiller.injector","text":"<p>Tenet injection system.</p> <p>This module handles the strategic injection of tenets into generated context to maintain consistency across AI interactions.</p>"},{"location":"api/tenets/core/instiller/injector/#tenets.core.instiller.injector-classes","title":"Classes","text":""},{"location":"api/tenets/core/instiller/injector/#tenets.core.instiller.injector.InjectionPosition","title":"InjectionPosition","text":"<p>               Bases: <code>Enum</code></p> <p>Where to inject tenets in the context.</p>"},{"location":"api/tenets/core/instiller/injector/#tenets.core.instiller.injector.InjectionPoint","title":"InjectionPoint  <code>dataclass</code>","text":"Python<pre><code>InjectionPoint(position: int, score: float, reason: str, after_section: Optional[str] = None)\n</code></pre> <p>A specific point where a tenet can be injected.</p>"},{"location":"api/tenets/core/instiller/injector/#tenets.core.instiller.injector.TenetInjector","title":"TenetInjector","text":"Python<pre><code>TenetInjector(config: Optional[Dict[str, Any]] = None)\n</code></pre> <p>Handles strategic injection of tenets into context.</p> <p>Initialize the injector.</p> PARAMETER DESCRIPTION <code>config</code> <p>Injection configuration</p> <p> TYPE: <code>Optional[Dict[str, Any]]</code> DEFAULT: <code>None</code> </p>"},{"location":"api/tenets/core/instiller/injector/#tenets.core.instiller.injector.TenetInjector-functions","title":"Functions","text":""},{"location":"api/tenets/core/instiller/injector/#tenets.core.instiller.injector.TenetInjector.inject_tenets","title":"inject_tenets","text":"Python<pre><code>inject_tenets(content: str, tenets: List[Tenet], format: str = 'markdown', context_metadata: Optional[Dict[str, Any]] = None) -&gt; Tuple[str, Dict[str, Any]]\n</code></pre> <p>Inject tenets into content.</p> PARAMETER DESCRIPTION <code>content</code> <p>The content to inject into</p> <p> TYPE: <code>str</code> </p> <code>tenets</code> <p>List of tenets to inject</p> <p> TYPE: <code>List[Tenet]</code> </p> <code>format</code> <p>Content format (markdown, xml, json)</p> <p> TYPE: <code>str</code> DEFAULT: <code>'markdown'</code> </p> <code>context_metadata</code> <p>Metadata about the context</p> <p> TYPE: <code>Optional[Dict[str, Any]]</code> DEFAULT: <code>None</code> </p> RETURNS DESCRIPTION <code>Tuple[str, Dict[str, Any]]</code> <p>Tuple of (modified content, injection metadata)</p>"},{"location":"api/tenets/core/instiller/injector/#tenets.core.instiller.injector.TenetInjector.calculate_optimal_injection_count","title":"calculate_optimal_injection_count","text":"Python<pre><code>calculate_optimal_injection_count(content_length: int, available_tenets: int, max_token_increase: int = 1000) -&gt; int\n</code></pre> <p>Calculate optimal number of tenets to inject.</p> PARAMETER DESCRIPTION <code>content_length</code> <p>Current content length</p> <p> TYPE: <code>int</code> </p> <code>available_tenets</code> <p>Number of available tenets</p> <p> TYPE: <code>int</code> </p> <code>max_token_increase</code> <p>Maximum allowed token increase</p> <p> TYPE: <code>int</code> DEFAULT: <code>1000</code> </p> RETURNS DESCRIPTION <code>int</code> <p>Optimal number of tenets to inject</p>"},{"location":"api/tenets/core/instiller/injector/#tenets.core.instiller.injector.TenetInjector.inject_into_context_result","title":"inject_into_context_result","text":"Python<pre><code>inject_into_context_result(context_result: ContextResult, tenets: List[Tenet]) -&gt; ContextResult\n</code></pre> <p>Inject tenets into a ContextResult object.</p> PARAMETER DESCRIPTION <code>context_result</code> <p>The context result to modify</p> <p> TYPE: <code>ContextResult</code> </p> <code>tenets</code> <p>Tenets to inject</p> <p> TYPE: <code>List[Tenet]</code> </p> RETURNS DESCRIPTION <code>ContextResult</code> <p>Modified context result</p>"},{"location":"api/tenets/core/instiller/injector/#tenets.core.instiller.injector-functions","title":"Functions","text":""},{"location":"api/tenets/core/instiller/instiller/","title":"Instiller","text":""},{"location":"api/tenets/core/instiller/instiller/#tenets.core.instiller.instiller","title":"tenets.core.instiller.instiller","text":"<p>Instiller module - Orchestrates intelligent tenet injection into context.</p> <p>This module provides the main Instiller class that manages the injection of guiding principles (tenets) into generated context. It supports various injection strategies including: - Always inject - Periodic injection (every Nth time) - Adaptive injection based on context complexity - Session-aware smart injection</p> <p>The instiller tracks injection history, analyzes context complexity using NLP components, and adapts injection frequency based on session patterns.</p>"},{"location":"api/tenets/core/instiller/instiller/#tenets.core.instiller.instiller-classes","title":"Classes","text":""},{"location":"api/tenets/core/instiller/instiller/#tenets.core.instiller.instiller.InjectionHistory","title":"InjectionHistory  <code>dataclass</code>","text":"Python<pre><code>InjectionHistory(session_id: str, total_distills: int = 0, total_injections: int = 0, last_injection: Optional[datetime] = None, last_injection_index: int = 0, complexity_scores: List[float] = list(), injected_tenets: Set[str] = set(), reinforcement_count: int = 0, system_instruction_injected: bool = False, created_at: datetime = datetime.now(), updated_at: datetime = datetime.now())\n</code></pre> <p>Track injection history for a session.</p> ATTRIBUTE DESCRIPTION <code>session_id</code> <p>Session identifier</p> <p> TYPE: <code>str</code> </p> <code>total_distills</code> <p>Total number of distill operations</p> <p> TYPE: <code>int</code> </p> <code>total_injections</code> <p>Total number of tenet injections</p> <p> TYPE: <code>int</code> </p> <code>last_injection</code> <p>Timestamp of last injection</p> <p> TYPE: <code>Optional[datetime]</code> </p> <code>last_injection_index</code> <p>Index of last injection (for periodic)</p> <p> TYPE: <code>int</code> </p> <code>complexity_scores</code> <p>List of context complexity scores</p> <p> TYPE: <code>List[float]</code> </p> <code>injected_tenets</code> <p>Set of tenet IDs that have been injected</p> <p> TYPE: <code>Set[str]</code> </p> <code>reinforcement_count</code> <p>Count of reinforcement injections</p> <p> TYPE: <code>int</code> </p> <code>created_at</code> <p>When this history was created</p> <p> TYPE: <code>datetime</code> </p> <code>updated_at</code> <p>Last update timestamp</p> <p> TYPE: <code>datetime</code> </p>"},{"location":"api/tenets/core/instiller/instiller/#tenets.core.instiller.instiller.InjectionHistory-functions","title":"Functions","text":""},{"location":"api/tenets/core/instiller/instiller/#tenets.core.instiller.instiller.InjectionHistory.should_inject","title":"should_inject","text":"Python<pre><code>should_inject(frequency: str, interval: int, complexity: float, complexity_threshold: float, min_session_length: int) -&gt; Tuple[bool, str]\n</code></pre> <p>Determine if tenets should be injected.</p> PARAMETER DESCRIPTION <code>frequency</code> <p>Injection frequency mode</p> <p> TYPE: <code>str</code> </p> <code>interval</code> <p>Injection interval for periodic mode</p> <p> TYPE: <code>int</code> </p> <code>complexity</code> <p>Current context complexity score</p> <p> TYPE: <code>float</code> </p> <code>complexity_threshold</code> <p>Threshold for complexity-based injection</p> <p> TYPE: <code>float</code> </p> <code>min_session_length</code> <p>Minimum session length before injection</p> <p> TYPE: <code>int</code> </p> RETURNS DESCRIPTION <code>Tuple[bool, str]</code> <p>Tuple of (should_inject, reason)</p>"},{"location":"api/tenets/core/instiller/instiller/#tenets.core.instiller.instiller.InjectionHistory.record_injection","title":"record_injection","text":"Python<pre><code>record_injection(tenets: List[Tenet], complexity: float) -&gt; None\n</code></pre> <p>Record that an injection occurred.</p> PARAMETER DESCRIPTION <code>tenets</code> <p>List of tenets that were injected</p> <p> TYPE: <code>List[Tenet]</code> </p> <code>complexity</code> <p>Complexity score of the context</p> <p> TYPE: <code>float</code> </p>"},{"location":"api/tenets/core/instiller/instiller/#tenets.core.instiller.instiller.InjectionHistory.get_stats","title":"get_stats","text":"Python<pre><code>get_stats() -&gt; Dict[str, Any]\n</code></pre> <p>Get injection statistics for this session.</p> RETURNS DESCRIPTION <code>Dict[str, Any]</code> <p>Dictionary of statistics</p>"},{"location":"api/tenets/core/instiller/instiller/#tenets.core.instiller.instiller.InstillationResult","title":"InstillationResult  <code>dataclass</code>","text":"Python<pre><code>InstillationResult(tenets_instilled: List[Tenet], injection_positions: List[Dict[str, Any]], token_increase: int, strategy_used: str, session: Optional[str] = None, timestamp: datetime = datetime.now(), success: bool = True, error_message: Optional[str] = None, metrics: Optional[Dict[str, Any]] = None, complexity_score: float = 0.0, skip_reason: Optional[str] = None)\n</code></pre> <p>Result of a tenet instillation operation.</p> ATTRIBUTE DESCRIPTION <code>tenets_instilled</code> <p>List of tenets that were instilled</p> <p> TYPE: <code>List[Tenet]</code> </p> <code>injection_positions</code> <p>Where tenets were injected</p> <p> TYPE: <code>List[Dict[str, Any]]</code> </p> <code>token_increase</code> <p>Number of tokens added</p> <p> TYPE: <code>int</code> </p> <code>strategy_used</code> <p>Injection strategy that was used</p> <p> TYPE: <code>str</code> </p> <code>session</code> <p>Session identifier if any</p> <p> TYPE: <code>Optional[str]</code> </p> <code>timestamp</code> <p>When instillation occurred</p> <p> TYPE: <code>datetime</code> </p> <code>success</code> <p>Whether instillation succeeded</p> <p> TYPE: <code>bool</code> </p> <code>error_message</code> <p>Error message if failed</p> <p> TYPE: <code>Optional[str]</code> </p> <code>metrics</code> <p>Additional metrics from the operation</p> <p> TYPE: <code>Optional[Dict[str, Any]]</code> </p> <code>complexity_score</code> <p>Complexity score of the context</p> <p> TYPE: <code>float</code> </p> <code>skip_reason</code> <p>Reason if injection was skipped</p> <p> TYPE: <code>Optional[str]</code> </p>"},{"location":"api/tenets/core/instiller/instiller/#tenets.core.instiller.instiller.InstillationResult-functions","title":"Functions","text":""},{"location":"api/tenets/core/instiller/instiller/#tenets.core.instiller.instiller.InstillationResult.to_dict","title":"to_dict","text":"Python<pre><code>to_dict() -&gt; Dict[str, Any]\n</code></pre> <p>Convert to dictionary for serialization.</p>"},{"location":"api/tenets/core/instiller/instiller/#tenets.core.instiller.instiller.ComplexityAnalyzer","title":"ComplexityAnalyzer","text":"Python<pre><code>ComplexityAnalyzer(config: TenetsConfig)\n</code></pre> <p>Analyze context complexity to guide injection decisions.</p> <p>Uses NLP components to analyze: - Token count and density - Code vs documentation ratio - Keyword diversity - Structural complexity - Topic coherence</p> <p>Initialize complexity analyzer.</p> PARAMETER DESCRIPTION <code>config</code> <p>Configuration object</p> <p> TYPE: <code>TenetsConfig</code> </p>"},{"location":"api/tenets/core/instiller/instiller/#tenets.core.instiller.instiller.ComplexityAnalyzer-functions","title":"Functions","text":""},{"location":"api/tenets/core/instiller/instiller/#tenets.core.instiller.instiller.ComplexityAnalyzer.analyze","title":"analyze","text":"Python<pre><code>analyze(context: Union[str, ContextResult]) -&gt; float\n</code></pre> <p>Analyze context complexity.</p> PARAMETER DESCRIPTION <code>context</code> <p>Context to analyze (string or ContextResult)</p> <p> TYPE: <code>Union[str, ContextResult]</code> </p> RETURNS DESCRIPTION <code>float</code> <p>Complexity score between 0 and 1</p>"},{"location":"api/tenets/core/instiller/instiller/#tenets.core.instiller.instiller.MetricsTracker","title":"MetricsTracker","text":"Python<pre><code>MetricsTracker()\n</code></pre> <p>Track metrics for tenet instillation.</p> <p>Tracks: - Instillation counts and frequencies - Token usage and increases - Strategy effectiveness - Session-specific metrics - Tenet performance</p> <p>Initialize metrics tracker.</p>"},{"location":"api/tenets/core/instiller/instiller/#tenets.core.instiller.instiller.MetricsTracker-functions","title":"Functions","text":""},{"location":"api/tenets/core/instiller/instiller/#tenets.core.instiller.instiller.MetricsTracker.record_instillation","title":"record_instillation","text":"Python<pre><code>record_instillation(tenet_count: int, token_increase: int, strategy: str, session: Optional[str] = None, complexity: float = 0.0, skip_reason: Optional[str] = None) -&gt; None\n</code></pre> <p>Record an instillation event.</p> PARAMETER DESCRIPTION <code>tenet_count</code> <p>Number of tenets instilled</p> <p> TYPE: <code>int</code> </p> <code>token_increase</code> <p>Tokens added</p> <p> TYPE: <code>int</code> </p> <code>strategy</code> <p>Strategy used</p> <p> TYPE: <code>str</code> </p> <code>session</code> <p>Session identifier</p> <p> TYPE: <code>Optional[str]</code> DEFAULT: <code>None</code> </p> <code>complexity</code> <p>Context complexity score</p> <p> TYPE: <code>float</code> DEFAULT: <code>0.0</code> </p> <code>skip_reason</code> <p>Reason if skipped</p> <p> TYPE: <code>Optional[str]</code> DEFAULT: <code>None</code> </p>"},{"location":"api/tenets/core/instiller/instiller/#tenets.core.instiller.instiller.MetricsTracker.record_tenet_usage","title":"record_tenet_usage","text":"Python<pre><code>record_tenet_usage(tenet_id: str) -&gt; None\n</code></pre> <p>Record that a tenet was used.</p> PARAMETER DESCRIPTION <code>tenet_id</code> <p>Tenet identifier</p> <p> TYPE: <code>str</code> </p>"},{"location":"api/tenets/core/instiller/instiller/#tenets.core.instiller.instiller.MetricsTracker.get_metrics","title":"get_metrics","text":"Python<pre><code>get_metrics(session: Optional[str] = None) -&gt; Dict[str, Any]\n</code></pre> <p>Get aggregated metrics.</p> PARAMETER DESCRIPTION <code>session</code> <p>Optional session filter</p> <p> TYPE: <code>Optional[str]</code> DEFAULT: <code>None</code> </p> RETURNS DESCRIPTION <code>Dict[str, Any]</code> <p>Dictionary of metrics</p>"},{"location":"api/tenets/core/instiller/instiller/#tenets.core.instiller.instiller.MetricsTracker.get_all_metrics","title":"get_all_metrics","text":"Python<pre><code>get_all_metrics() -&gt; Dict[str, Any]\n</code></pre> <p>Get all tracked metrics for export.</p>"},{"location":"api/tenets/core/instiller/instiller/#tenets.core.instiller.instiller.Instiller","title":"Instiller","text":"Python<pre><code>Instiller(config: TenetsConfig)\n</code></pre> <p>Main orchestrator for tenet instillation with smart injection.</p> <p>The Instiller manages the entire process of injecting tenets into context, including: - Tracking injection history per session - Analyzing context complexity - Determining optimal injection frequency - Selecting appropriate tenets - Applying injection strategies - Recording metrics and effectiveness</p> <p>It supports multiple injection modes: - Always: Inject into every context - Periodic: Inject every Nth distillation - Adaptive: Smart injection based on complexity and session - Manual: Only inject when explicitly requested</p> <p>Initialize the Instiller.</p> PARAMETER DESCRIPTION <code>config</code> <p>Configuration object</p> <p> TYPE: <code>TenetsConfig</code> </p>"},{"location":"api/tenets/core/instiller/instiller/#tenets.core.instiller.instiller.Instiller-functions","title":"Functions","text":""},{"location":"api/tenets/core/instiller/instiller/#tenets.core.instiller.instiller.Instiller.inject_system_instruction","title":"inject_system_instruction","text":"Python<pre><code>inject_system_instruction(content: str, format: str = 'markdown', session: Optional[str] = None) -&gt; Tuple[str, Dict[str, Any]]\n</code></pre> <p>Inject system instruction (system prompt) according to config.</p> <p>Behavior: - If system instruction is disabled or empty, return unchanged. - If session provided and once-per-session is enabled, inject only on first distill. - If no session, inject on every distill. - Placement controlled by system_instruction_position. - Formatting controlled by system_instruction_format.</p> <p>Returns modified content and metadata about injection.</p>"},{"location":"api/tenets/core/instiller/instiller/#tenets.core.instiller.instiller.Instiller.instill","title":"instill","text":"Python<pre><code>instill(context: Union[str, ContextResult], session: Optional[str] = None, force: bool = False, strategy: Optional[str] = None, max_tenets: Optional[int] = None, check_frequency: bool = True, inject_system_instruction: Optional[bool] = None) -&gt; Union[str, ContextResult]\n</code></pre> <p>Instill tenets into context with smart injection.</p> PARAMETER DESCRIPTION <code>context</code> <p>Context to inject tenets into</p> <p> TYPE: <code>Union[str, ContextResult]</code> </p> <code>session</code> <p>Session identifier for tracking</p> <p> TYPE: <code>Optional[str]</code> DEFAULT: <code>None</code> </p> <code>force</code> <p>Force injection regardless of frequency settings</p> <p> TYPE: <code>bool</code> DEFAULT: <code>False</code> </p> <code>strategy</code> <p>Override injection strategy</p> <p> TYPE: <code>Optional[str]</code> DEFAULT: <code>None</code> </p> <code>max_tenets</code> <p>Override maximum tenets</p> <p> TYPE: <code>Optional[int]</code> DEFAULT: <code>None</code> </p> <code>check_frequency</code> <p>Whether to check injection frequency</p> <p> TYPE: <code>bool</code> DEFAULT: <code>True</code> </p> RETURNS DESCRIPTION <code>Union[str, ContextResult]</code> <p>Modified context with tenets injected (if applicable)</p>"},{"location":"api/tenets/core/instiller/instiller/#tenets.core.instiller.instiller.Instiller.get_session_stats","title":"get_session_stats","text":"Python<pre><code>get_session_stats(session: str) -&gt; Dict[str, Any]\n</code></pre> <p>Get statistics for a specific session.</p> PARAMETER DESCRIPTION <code>session</code> <p>Session identifier</p> <p> TYPE: <code>str</code> </p> RETURNS DESCRIPTION <code>Dict[str, Any]</code> <p>Dictionary of session statistics</p>"},{"location":"api/tenets/core/instiller/instiller/#tenets.core.instiller.instiller.Instiller.get_all_session_stats","title":"get_all_session_stats","text":"Python<pre><code>get_all_session_stats() -&gt; Dict[str, Dict[str, Any]]\n</code></pre> <p>Get statistics for all sessions.</p> RETURNS DESCRIPTION <code>Dict[str, Dict[str, Any]]</code> <p>Dictionary mapping session IDs to stats</p>"},{"location":"api/tenets/core/instiller/instiller/#tenets.core.instiller.instiller.Instiller.analyze_effectiveness","title":"analyze_effectiveness","text":"Python<pre><code>analyze_effectiveness(session: Optional[str] = None) -&gt; Dict[str, Any]\n</code></pre> <p>Analyze the effectiveness of tenet instillation.</p> PARAMETER DESCRIPTION <code>session</code> <p>Optional session to analyze</p> <p> TYPE: <code>Optional[str]</code> DEFAULT: <code>None</code> </p> RETURNS DESCRIPTION <code>Dict[str, Any]</code> <p>Dictionary with analysis results and recommendations</p>"},{"location":"api/tenets/core/instiller/instiller/#tenets.core.instiller.instiller.Instiller.export_instillation_history","title":"export_instillation_history","text":"Python<pre><code>export_instillation_history(output_path: Path, format: str = 'json', session: Optional[str] = None) -&gt; None\n</code></pre> <p>Export instillation history to file.</p> PARAMETER DESCRIPTION <code>output_path</code> <p>Path to output file</p> <p> TYPE: <code>Path</code> </p> <code>format</code> <p>Export format (json or csv)</p> <p> TYPE: <code>str</code> DEFAULT: <code>'json'</code> </p> <code>session</code> <p>Optional session filter</p> <p> TYPE: <code>Optional[str]</code> DEFAULT: <code>None</code> </p> RAISES DESCRIPTION <code>ValueError</code> <p>If format is not supported</p>"},{"location":"api/tenets/core/instiller/instiller/#tenets.core.instiller.instiller.Instiller.reset_session_history","title":"reset_session_history","text":"Python<pre><code>reset_session_history(session: str) -&gt; bool\n</code></pre> <p>Reset injection history for a session.</p> PARAMETER DESCRIPTION <code>session</code> <p>Session identifier</p> <p> TYPE: <code>str</code> </p> RETURNS DESCRIPTION <code>bool</code> <p>True if reset, False if session not found</p>"},{"location":"api/tenets/core/instiller/instiller/#tenets.core.instiller.instiller.Instiller.clear_cache","title":"clear_cache","text":"Python<pre><code>clear_cache() -&gt; None\n</code></pre> <p>Clear the results cache.</p>"},{"location":"api/tenets/core/instiller/instiller/#tenets.core.instiller.instiller-functions","title":"Functions","text":""},{"location":"api/tenets/core/instiller/instiller/#tenets.core.instiller.instiller.estimate_tokens","title":"estimate_tokens","text":"Python<pre><code>estimate_tokens(text: str) -&gt; int\n</code></pre> <p>Lightweight wrapper so tests can patch token estimation.</p> <p>Defaults to the shared count_tokens utility.</p>"},{"location":"api/tenets/core/instiller/manager/","title":"Manager","text":""},{"location":"api/tenets/core/instiller/manager/#tenets.core.instiller.manager","title":"tenets.core.instiller.manager","text":"<p>Tenet management system.</p> <p>This module manages the lifecycle of tenets (guiding principles) and handles their storage, retrieval, and application to contexts.</p>"},{"location":"api/tenets/core/instiller/manager/#tenets.core.instiller.manager-classes","title":"Classes","text":""},{"location":"api/tenets/core/instiller/manager/#tenets.core.instiller.manager.TenetManager","title":"TenetManager","text":"Python<pre><code>TenetManager(config: TenetsConfig)\n</code></pre> <p>Manages tenets throughout their lifecycle.</p> <p>Initialize the tenet manager.</p> PARAMETER DESCRIPTION <code>config</code> <p>Tenets configuration</p> <p> TYPE: <code>TenetsConfig</code> </p>"},{"location":"api/tenets/core/instiller/manager/#tenets.core.instiller.manager.TenetManager-functions","title":"Functions","text":""},{"location":"api/tenets/core/instiller/manager/#tenets.core.instiller.manager.TenetManager.add_tenet","title":"add_tenet","text":"Python<pre><code>add_tenet(content: Union[str, Tenet], priority: Union[str, Priority] = 'medium', category: Optional[Union[str, TenetCategory]] = None, session: Optional[str] = None, author: Optional[str] = None) -&gt; Tenet\n</code></pre> <p>Add a new tenet.</p> PARAMETER DESCRIPTION <code>content</code> <p>The guiding principle text or a Tenet object</p> <p> TYPE: <code>Union[str, Tenet]</code> </p> <code>priority</code> <p>Priority level (low, medium, high, critical)</p> <p> TYPE: <code>Union[str, Priority]</code> DEFAULT: <code>'medium'</code> </p> <code>category</code> <p>Category for organization</p> <p> TYPE: <code>Optional[Union[str, TenetCategory]]</code> DEFAULT: <code>None</code> </p> <code>session</code> <p>Bind to specific session</p> <p> TYPE: <code>Optional[str]</code> DEFAULT: <code>None</code> </p> <code>author</code> <p>Who created the tenet</p> <p> TYPE: <code>Optional[str]</code> DEFAULT: <code>None</code> </p> RETURNS DESCRIPTION <code>Tenet</code> <p>The created Tenet</p>"},{"location":"api/tenets/core/instiller/manager/#tenets.core.instiller.manager.TenetManager.get_tenet","title":"get_tenet","text":"Python<pre><code>get_tenet(tenet_id: str) -&gt; Optional[Tenet]\n</code></pre> <p>Get a specific tenet by ID.</p> PARAMETER DESCRIPTION <code>tenet_id</code> <p>Tenet ID (can be partial)</p> <p> TYPE: <code>str</code> </p> RETURNS DESCRIPTION <code>Optional[Tenet]</code> <p>The Tenet or None if not found</p>"},{"location":"api/tenets/core/instiller/manager/#tenets.core.instiller.manager.TenetManager.list_tenets","title":"list_tenets","text":"Python<pre><code>list_tenets(pending_only: bool = False, instilled_only: bool = False, session: Optional[str] = None, category: Optional[Union[str, TenetCategory]] = None) -&gt; List[Dict[str, Any]]\n</code></pre> <p>List tenets with filtering.</p> PARAMETER DESCRIPTION <code>pending_only</code> <p>Only show pending tenets</p> <p> TYPE: <code>bool</code> DEFAULT: <code>False</code> </p> <code>instilled_only</code> <p>Only show instilled tenets</p> <p> TYPE: <code>bool</code> DEFAULT: <code>False</code> </p> <code>session</code> <p>Filter by session binding</p> <p> TYPE: <code>Optional[str]</code> DEFAULT: <code>None</code> </p> <code>category</code> <p>Filter by category</p> <p> TYPE: <code>Optional[Union[str, TenetCategory]]</code> DEFAULT: <code>None</code> </p> RETURNS DESCRIPTION <code>List[Dict[str, Any]]</code> <p>List of tenet dictionaries</p>"},{"location":"api/tenets/core/instiller/manager/#tenets.core.instiller.manager.TenetManager.get_pending_tenets","title":"get_pending_tenets","text":"Python<pre><code>get_pending_tenets(session: Optional[str] = None) -&gt; List[Tenet]\n</code></pre> <p>Get all pending tenets.</p> PARAMETER DESCRIPTION <code>session</code> <p>Filter by session</p> <p> TYPE: <code>Optional[str]</code> DEFAULT: <code>None</code> </p> RETURNS DESCRIPTION <code>List[Tenet]</code> <p>List of pending Tenet objects</p>"},{"location":"api/tenets/core/instiller/manager/#tenets.core.instiller.manager.TenetManager.remove_tenet","title":"remove_tenet","text":"Python<pre><code>remove_tenet(tenet_id: str) -&gt; bool\n</code></pre> <p>Remove a tenet.</p> PARAMETER DESCRIPTION <code>tenet_id</code> <p>Tenet ID (can be partial)</p> <p> TYPE: <code>str</code> </p> RETURNS DESCRIPTION <code>bool</code> <p>True if removed, False if not found</p>"},{"location":"api/tenets/core/instiller/manager/#tenets.core.instiller.manager.TenetManager.instill_tenets","title":"instill_tenets","text":"Python<pre><code>instill_tenets(session: Optional[str] = None, force: bool = False) -&gt; Dict[str, Any]\n</code></pre> <p>Instill pending tenets.</p> PARAMETER DESCRIPTION <code>session</code> <p>Target session</p> <p> TYPE: <code>Optional[str]</code> DEFAULT: <code>None</code> </p> <code>force</code> <p>Re-instill even if already instilled</p> <p> TYPE: <code>bool</code> DEFAULT: <code>False</code> </p> RETURNS DESCRIPTION <code>Dict[str, Any]</code> <p>Dictionary with results</p>"},{"location":"api/tenets/core/instiller/manager/#tenets.core.instiller.manager.TenetManager.get_tenets_for_injection","title":"get_tenets_for_injection","text":"Python<pre><code>get_tenets_for_injection(context_length: int, session: Optional[str] = None, max_tenets: int = 5) -&gt; List[Tenet]\n</code></pre> <p>Get tenets ready for injection into context.</p> PARAMETER DESCRIPTION <code>context_length</code> <p>Current context length in tokens</p> <p> TYPE: <code>int</code> </p> <code>session</code> <p>Current session</p> <p> TYPE: <code>Optional[str]</code> DEFAULT: <code>None</code> </p> <code>max_tenets</code> <p>Maximum number of tenets to return</p> <p> TYPE: <code>int</code> DEFAULT: <code>5</code> </p> RETURNS DESCRIPTION <code>List[Tenet]</code> <p>List of tenets to inject</p>"},{"location":"api/tenets/core/instiller/manager/#tenets.core.instiller.manager.TenetManager.export_tenets","title":"export_tenets","text":"Python<pre><code>export_tenets(format: str = 'yaml', session: Optional[str] = None, include_archived: bool = False) -&gt; str\n</code></pre> <p>Export tenets to YAML or JSON.</p> PARAMETER DESCRIPTION <code>format</code> <p>Export format (yaml or json)</p> <p> TYPE: <code>str</code> DEFAULT: <code>'yaml'</code> </p> <code>session</code> <p>Filter by session</p> <p> TYPE: <code>Optional[str]</code> DEFAULT: <code>None</code> </p> <code>include_archived</code> <p>Include archived tenets</p> <p> TYPE: <code>bool</code> DEFAULT: <code>False</code> </p> RETURNS DESCRIPTION <code>str</code> <p>Serialized tenets</p>"},{"location":"api/tenets/core/instiller/manager/#tenets.core.instiller.manager.TenetManager.import_tenets","title":"import_tenets","text":"Python<pre><code>import_tenets(file_path: Union[str, Path], session: Optional[str] = None, override_priority: Optional[Priority] = None) -&gt; int\n</code></pre> <p>Import tenets from file.</p> PARAMETER DESCRIPTION <code>file_path</code> <p>Path to import file</p> <p> TYPE: <code>Union[str, Path]</code> </p> <code>session</code> <p>Bind imported tenets to session</p> <p> TYPE: <code>Optional[str]</code> DEFAULT: <code>None</code> </p> <code>override_priority</code> <p>Override priority for all imported tenets</p> <p> TYPE: <code>Optional[Priority]</code> DEFAULT: <code>None</code> </p> RETURNS DESCRIPTION <code>int</code> <p>Number of tenets imported</p>"},{"location":"api/tenets/core/instiller/manager/#tenets.core.instiller.manager.TenetManager.create_collection","title":"create_collection","text":"Python<pre><code>create_collection(name: str, description: str = '', tenet_ids: Optional[List[str]] = None) -&gt; TenetCollection\n</code></pre> <p>Create a collection of related tenets.</p> PARAMETER DESCRIPTION <code>name</code> <p>Collection name</p> <p> TYPE: <code>str</code> </p> <code>description</code> <p>Collection description</p> <p> TYPE: <code>str</code> DEFAULT: <code>''</code> </p> <code>tenet_ids</code> <p>IDs of tenets to include</p> <p> TYPE: <code>Optional[List[str]]</code> DEFAULT: <code>None</code> </p> RETURNS DESCRIPTION <code>TenetCollection</code> <p>The created TenetCollection</p>"},{"location":"api/tenets/core/instiller/manager/#tenets.core.instiller.manager.TenetManager.analyze_tenet_effectiveness","title":"analyze_tenet_effectiveness","text":"Python<pre><code>analyze_tenet_effectiveness() -&gt; Dict[str, Any]\n</code></pre> <p>Analyze effectiveness of tenets.</p> RETURNS DESCRIPTION <code>Dict[str, Any]</code> <p>Analysis of tenet usage and effectiveness</p>"},{"location":"api/tenets/core/instiller/manager/#tenets.core.instiller.manager-functions","title":"Functions","text":""},{"location":"api/tenets/core/momentum/metrics/","title":"Metrics","text":""},{"location":"api/tenets/core/momentum/metrics/#tenets.core.momentum.metrics","title":"tenets.core.momentum.metrics","text":"<p>Metrics calculation module for momentum tracking.</p> <p>This module provides various metrics classes and calculation functions for development momentum analysis. It includes sprint metrics, team metrics, productivity metrics, and velocity trend analysis.</p> <p>The metrics in this module help quantify development pace, team efficiency, and project health through data-driven measurements.</p>"},{"location":"api/tenets/core/momentum/metrics/#tenets.core.momentum.metrics-classes","title":"Classes","text":""},{"location":"api/tenets/core/momentum/metrics/#tenets.core.momentum.metrics.VelocityTrend","title":"VelocityTrend  <code>dataclass</code>","text":"Python<pre><code>VelocityTrend(trend_direction: str = 'stable', avg_velocity: float = 0.0, max_velocity: float = 0.0, min_velocity: float = 0.0, std_deviation: float = 0.0, stability_score: float = 0.0, acceleration: float = 0.0, data_points: List[Dict[str, Any]] = list(), forecast: Optional[float] = None, confidence_level: float = 0.0, seasonal_pattern: Optional[str] = None, anomalies: List[Dict[str, Any]] = list())\n</code></pre> <p>Velocity trend analysis over time.</p> <p>Tracks how development velocity changes over time, identifying patterns, trends, and stability in the development process.</p> ATTRIBUTE DESCRIPTION <code>trend_direction</code> <p>Direction of trend (increasing, decreasing, stable)</p> <p> TYPE: <code>str</code> </p> <code>avg_velocity</code> <p>Average velocity over period</p> <p> TYPE: <code>float</code> </p> <code>max_velocity</code> <p>Maximum velocity observed</p> <p> TYPE: <code>float</code> </p> <code>min_velocity</code> <p>Minimum velocity observed</p> <p> TYPE: <code>float</code> </p> <code>std_deviation</code> <p>Standard deviation of velocity</p> <p> TYPE: <code>float</code> </p> <code>stability_score</code> <p>Stability score (0-100, higher is more stable)</p> <p> TYPE: <code>float</code> </p> <code>acceleration</code> <p>Rate of change in velocity</p> <p> TYPE: <code>float</code> </p> <code>data_points</code> <p>List of velocity data points for visualization</p> <p> TYPE: <code>List[Dict[str, Any]]</code> </p> <code>forecast</code> <p>Predicted future velocity</p> <p> TYPE: <code>Optional[float]</code> </p> <code>confidence_level</code> <p>Confidence in forecast (0-1)</p> <p> TYPE: <code>float</code> </p> <code>seasonal_pattern</code> <p>Detected seasonal patterns</p> <p> TYPE: <code>Optional[str]</code> </p> <code>anomalies</code> <p>Detected anomalies in velocity</p> <p> TYPE: <code>List[Dict[str, Any]]</code> </p>"},{"location":"api/tenets/core/momentum/metrics/#tenets.core.momentum.metrics.VelocityTrend-attributes","title":"Attributes","text":""},{"location":"api/tenets/core/momentum/metrics/#tenets.core.momentum.metrics.VelocityTrend.is_stable","title":"is_stable  <code>property</code>","text":"Python<pre><code>is_stable: bool\n</code></pre> <p>Check if velocity is stable.</p> RETURNS DESCRIPTION <code>bool</code> <p>True if velocity is stable</p> <p> TYPE: <code>bool</code> </p>"},{"location":"api/tenets/core/momentum/metrics/#tenets.core.momentum.metrics.VelocityTrend.is_improving","title":"is_improving  <code>property</code>","text":"Python<pre><code>is_improving: bool\n</code></pre> <p>Check if velocity is improving.</p> RETURNS DESCRIPTION <code>bool</code> <p>True if velocity is increasing</p> <p> TYPE: <code>bool</code> </p>"},{"location":"api/tenets/core/momentum/metrics/#tenets.core.momentum.metrics.VelocityTrend.volatility","title":"volatility  <code>property</code>","text":"Python<pre><code>volatility: float\n</code></pre> <p>Calculate velocity volatility.</p> <p>Coefficient of variation as a measure of volatility.</p> RETURNS DESCRIPTION <code>float</code> <p>Volatility score (0-1)</p> <p> TYPE: <code>float</code> </p>"},{"location":"api/tenets/core/momentum/metrics/#tenets.core.momentum.metrics.VelocityTrend-functions","title":"Functions","text":""},{"location":"api/tenets/core/momentum/metrics/#tenets.core.momentum.metrics.VelocityTrend.to_dict","title":"to_dict","text":"Python<pre><code>to_dict() -&gt; Dict[str, Any]\n</code></pre> <p>Convert to dictionary representation.</p> RETURNS DESCRIPTION <code>Dict[str, Any]</code> <p>Dict[str, Any]: Dictionary representation</p>"},{"location":"api/tenets/core/momentum/metrics/#tenets.core.momentum.metrics.SprintMetrics","title":"SprintMetrics  <code>dataclass</code>","text":"Python<pre><code>SprintMetrics(total_sprints: int = 0, avg_velocity: float = 0.0, max_velocity: float = 0.0, min_velocity: float = 0.0, velocity_trend: str = 'stable', sprint_data: List[Dict[str, Any]] = list(), completion_rate: float = 0.0, predictability: float = 0.0, burndown_efficiency: float = 0.0, scope_change_rate: float = 0.0, carry_over_rate: float = 0.0, sprint_health: str = 'unknown')\n</code></pre> <p>Sprint-based velocity and performance metrics.</p> <p>Provides sprint-level analysis for teams using agile methodologies, tracking velocity, completion rates, and sprint health.</p> ATTRIBUTE DESCRIPTION <code>total_sprints</code> <p>Total number of sprints analyzed</p> <p> TYPE: <code>int</code> </p> <code>avg_velocity</code> <p>Average sprint velocity</p> <p> TYPE: <code>float</code> </p> <code>max_velocity</code> <p>Maximum sprint velocity</p> <p> TYPE: <code>float</code> </p> <code>min_velocity</code> <p>Minimum sprint velocity</p> <p> TYPE: <code>float</code> </p> <code>velocity_trend</code> <p>Trend in sprint velocity</p> <p> TYPE: <code>str</code> </p> <code>sprint_data</code> <p>Detailed data for each sprint</p> <p> TYPE: <code>List[Dict[str, Any]]</code> </p> <code>completion_rate</code> <p>Average sprint completion rate</p> <p> TYPE: <code>float</code> </p> <code>predictability</code> <p>Sprint predictability score</p> <p> TYPE: <code>float</code> </p> <code>burndown_efficiency</code> <p>Burndown chart efficiency</p> <p> TYPE: <code>float</code> </p> <code>scope_change_rate</code> <p>Rate of scope changes mid-sprint</p> <p> TYPE: <code>float</code> </p> <code>carry_over_rate</code> <p>Rate of work carried to next sprint</p> <p> TYPE: <code>float</code> </p> <code>sprint_health</code> <p>Overall sprint health assessment</p> <p> TYPE: <code>str</code> </p>"},{"location":"api/tenets/core/momentum/metrics/#tenets.core.momentum.metrics.SprintMetrics-attributes","title":"Attributes","text":""},{"location":"api/tenets/core/momentum/metrics/#tenets.core.momentum.metrics.SprintMetrics.velocity_consistency","title":"velocity_consistency  <code>property</code>","text":"Python<pre><code>velocity_consistency: float\n</code></pre> <p>Calculate velocity consistency across sprints.</p> RETURNS DESCRIPTION <code>float</code> <p>Consistency score (0-100)</p> <p> TYPE: <code>float</code> </p>"},{"location":"api/tenets/core/momentum/metrics/#tenets.core.momentum.metrics.SprintMetrics.is_healthy","title":"is_healthy  <code>property</code>","text":"Python<pre><code>is_healthy: bool\n</code></pre> <p>Check if sprint metrics indicate healthy process.</p> RETURNS DESCRIPTION <code>bool</code> <p>True if sprints are healthy</p> <p> TYPE: <code>bool</code> </p>"},{"location":"api/tenets/core/momentum/metrics/#tenets.core.momentum.metrics.SprintMetrics-functions","title":"Functions","text":""},{"location":"api/tenets/core/momentum/metrics/#tenets.core.momentum.metrics.SprintMetrics.to_dict","title":"to_dict","text":"Python<pre><code>to_dict() -&gt; Dict[str, Any]\n</code></pre> <p>Convert to dictionary representation.</p> RETURNS DESCRIPTION <code>Dict[str, Any]</code> <p>Dict[str, Any]: Dictionary representation</p>"},{"location":"api/tenets/core/momentum/metrics/#tenets.core.momentum.metrics.TeamMetrics","title":"TeamMetrics  <code>dataclass</code>","text":"Python<pre><code>TeamMetrics(total_members: int = 0, active_members: int = 0, team_velocity: float = 0.0, collaboration_score: float = 0.0, efficiency_score: float = 0.0, bus_factor: int = 0, skill_diversity: float = 0.0, communication_score: float = 0.0, team_health: str = 'unknown', teams: Dict[str, Dict[str, Any]] = dict(), knowledge_silos: List[str] = list(), collaboration_matrix: Dict[Tuple[str, str], int] = dict())\n</code></pre> <p>Team-level productivity and collaboration metrics.</p> <p>Measures team dynamics, collaboration patterns, and overall team effectiveness in delivering value.</p> ATTRIBUTE DESCRIPTION <code>total_members</code> <p>Total team members</p> <p> TYPE: <code>int</code> </p> <code>active_members</code> <p>Currently active members</p> <p> TYPE: <code>int</code> </p> <code>team_velocity</code> <p>Overall team velocity</p> <p> TYPE: <code>float</code> </p> <code>collaboration_score</code> <p>Team collaboration score</p> <p> TYPE: <code>float</code> </p> <code>efficiency_score</code> <p>Team efficiency score</p> <p> TYPE: <code>float</code> </p> <code>bus_factor</code> <p>Team bus factor (knowledge distribution)</p> <p> TYPE: <code>int</code> </p> <code>skill_diversity</code> <p>Skill diversity index</p> <p> TYPE: <code>float</code> </p> <code>communication_score</code> <p>Team communication effectiveness</p> <p> TYPE: <code>float</code> </p> <code>team_health</code> <p>Overall team health assessment</p> <p> TYPE: <code>str</code> </p> <code>teams</code> <p>Sub-team metrics if applicable</p> <p> TYPE: <code>Dict[str, Dict[str, Any]]</code> </p> <code>knowledge_silos</code> <p>Identified knowledge silos</p> <p> TYPE: <code>List[str]</code> </p> <code>collaboration_matrix</code> <p>Who collaborates with whom</p> <p> TYPE: <code>Dict[Tuple[str, str], int]</code> </p>"},{"location":"api/tenets/core/momentum/metrics/#tenets.core.momentum.metrics.TeamMetrics-attributes","title":"Attributes","text":""},{"location":"api/tenets/core/momentum/metrics/#tenets.core.momentum.metrics.TeamMetrics.participation_rate","title":"participation_rate  <code>property</code>","text":"Python<pre><code>participation_rate: float\n</code></pre> <p>Calculate team participation rate.</p> RETURNS DESCRIPTION <code>float</code> <p>Participation rate (0-100)</p> <p> TYPE: <code>float</code> </p>"},{"location":"api/tenets/core/momentum/metrics/#tenets.core.momentum.metrics.TeamMetrics.velocity_per_member","title":"velocity_per_member  <code>property</code>","text":"Python<pre><code>velocity_per_member: float\n</code></pre> <p>Calculate average velocity per team member.</p> RETURNS DESCRIPTION <code>float</code> <p>Velocity per member</p> <p> TYPE: <code>float</code> </p>"},{"location":"api/tenets/core/momentum/metrics/#tenets.core.momentum.metrics.TeamMetrics.needs_attention","title":"needs_attention  <code>property</code>","text":"Python<pre><code>needs_attention: bool\n</code></pre> <p>Check if team metrics indicate issues.</p> RETURNS DESCRIPTION <code>bool</code> <p>True if team needs attention</p> <p> TYPE: <code>bool</code> </p>"},{"location":"api/tenets/core/momentum/metrics/#tenets.core.momentum.metrics.TeamMetrics-functions","title":"Functions","text":""},{"location":"api/tenets/core/momentum/metrics/#tenets.core.momentum.metrics.TeamMetrics.to_dict","title":"to_dict","text":"Python<pre><code>to_dict() -&gt; Dict[str, Any]\n</code></pre> <p>Convert to dictionary representation.</p> RETURNS DESCRIPTION <code>Dict[str, Any]</code> <p>Dict[str, Any]: Dictionary representation</p>"},{"location":"api/tenets/core/momentum/metrics/#tenets.core.momentum.metrics.ProductivityMetrics","title":"ProductivityMetrics  <code>dataclass</code>","text":"Python<pre><code>ProductivityMetrics(overall_productivity: float = 0.0, avg_daily_commits: float = 0.0, avg_daily_lines: float = 0.0, code_churn: float = 0.0, rework_rate: float = 0.0, review_turnaround: float = 0.0, peak_productivity_date: Optional[datetime] = None, peak_productivity_score: float = 0.0, productivity_trend: str = 'stable', top_performers: List[Dict[str, Any]] = list(), bottlenecks: List[str] = list(), focus_areas: List[Tuple[str, int]] = list(), time_distribution: Dict[str, float] = dict())\n</code></pre> <p>Individual and team productivity measurements.</p> <p>Tracks various productivity indicators to understand work efficiency, output quality, and areas for improvement.</p> ATTRIBUTE DESCRIPTION <code>overall_productivity</code> <p>Overall productivity score</p> <p> TYPE: <code>float</code> </p> <code>avg_daily_commits</code> <p>Average commits per day</p> <p> TYPE: <code>float</code> </p> <code>avg_daily_lines</code> <p>Average lines changed per day</p> <p> TYPE: <code>float</code> </p> <code>code_churn</code> <p>Code churn rate</p> <p> TYPE: <code>float</code> </p> <code>rework_rate</code> <p>Rate of rework/refactoring</p> <p> TYPE: <code>float</code> </p> <code>review_turnaround</code> <p>Average review turnaround time</p> <p> TYPE: <code>float</code> </p> <code>peak_productivity_date</code> <p>Date of peak productivity</p> <p> TYPE: <code>Optional[datetime]</code> </p> <code>peak_productivity_score</code> <p>Peak productivity score</p> <p> TYPE: <code>float</code> </p> <code>productivity_trend</code> <p>Productivity trend direction</p> <p> TYPE: <code>str</code> </p> <code>top_performers</code> <p>List of top performing contributors</p> <p> TYPE: <code>List[Dict[str, Any]]</code> </p> <code>bottlenecks</code> <p>Identified productivity bottlenecks</p> <p> TYPE: <code>List[str]</code> </p> <code>focus_areas</code> <p>Main areas of focus</p> <p> TYPE: <code>List[Tuple[str, int]]</code> </p> <code>time_distribution</code> <p>How time is distributed across activities</p> <p> TYPE: <code>Dict[str, float]</code> </p>"},{"location":"api/tenets/core/momentum/metrics/#tenets.core.momentum.metrics.ProductivityMetrics-attributes","title":"Attributes","text":""},{"location":"api/tenets/core/momentum/metrics/#tenets.core.momentum.metrics.ProductivityMetrics.efficiency_rating","title":"efficiency_rating  <code>property</code>","text":"Python<pre><code>efficiency_rating: str\n</code></pre> <p>Get efficiency rating based on productivity.</p> RETURNS DESCRIPTION <code>str</code> <p>Efficiency rating (excellent, good, fair, poor)</p> <p> TYPE: <code>str</code> </p>"},{"location":"api/tenets/core/momentum/metrics/#tenets.core.momentum.metrics.ProductivityMetrics.has_bottlenecks","title":"has_bottlenecks  <code>property</code>","text":"Python<pre><code>has_bottlenecks: bool\n</code></pre> <p>Check if bottlenecks are identified.</p> RETURNS DESCRIPTION <code>bool</code> <p>True if bottlenecks exist</p> <p> TYPE: <code>bool</code> </p>"},{"location":"api/tenets/core/momentum/metrics/#tenets.core.momentum.metrics.ProductivityMetrics-functions","title":"Functions","text":""},{"location":"api/tenets/core/momentum/metrics/#tenets.core.momentum.metrics.ProductivityMetrics.to_dict","title":"to_dict","text":"Python<pre><code>to_dict() -&gt; Dict[str, Any]\n</code></pre> <p>Convert to dictionary representation.</p> RETURNS DESCRIPTION <code>Dict[str, Any]</code> <p>Dict[str, Any]: Dictionary representation</p>"},{"location":"api/tenets/core/momentum/metrics/#tenets.core.momentum.metrics.MomentumMetrics","title":"MomentumMetrics  <code>dataclass</code>","text":"Python<pre><code>MomentumMetrics(momentum_score: float = 0.0, velocity_score: float = 0.0, quality_score: float = 0.0, collaboration_score: float = 0.0, productivity_score: float = 0.0, momentum_trend: str = 'stable', acceleration: float = 0.0, sustainability: float = 0.0, risk_factors: List[str] = list(), opportunities: List[str] = list(), health_indicators: Dict[str, bool] = dict())\n</code></pre> <p>Overall momentum metrics for development.</p> <p>Aggregates various metrics to provide a comprehensive view of development momentum and project health.</p> ATTRIBUTE DESCRIPTION <code>momentum_score</code> <p>Overall momentum score (0-100)</p> <p> TYPE: <code>float</code> </p> <code>velocity_score</code> <p>Velocity component score</p> <p> TYPE: <code>float</code> </p> <code>quality_score</code> <p>Quality component score</p> <p> TYPE: <code>float</code> </p> <code>collaboration_score</code> <p>Collaboration component score</p> <p> TYPE: <code>float</code> </p> <code>productivity_score</code> <p>Productivity component score</p> <p> TYPE: <code>float</code> </p> <code>momentum_trend</code> <p>Momentum trend direction</p> <p> TYPE: <code>str</code> </p> <code>acceleration</code> <p>Rate of momentum change</p> <p> TYPE: <code>float</code> </p> <code>sustainability</code> <p>Momentum sustainability score</p> <p> TYPE: <code>float</code> </p> <code>risk_factors</code> <p>Identified risk factors</p> <p> TYPE: <code>List[str]</code> </p> <code>opportunities</code> <p>Identified opportunities</p> <p> TYPE: <code>List[str]</code> </p> <code>health_indicators</code> <p>Key health indicators</p> <p> TYPE: <code>Dict[str, bool]</code> </p>"},{"location":"api/tenets/core/momentum/metrics/#tenets.core.momentum.metrics.MomentumMetrics-attributes","title":"Attributes","text":""},{"location":"api/tenets/core/momentum/metrics/#tenets.core.momentum.metrics.MomentumMetrics.is_healthy","title":"is_healthy  <code>property</code>","text":"Python<pre><code>is_healthy: bool\n</code></pre> <p>Check if momentum is healthy.</p> RETURNS DESCRIPTION <code>bool</code> <p>True if momentum is healthy</p> <p> TYPE: <code>bool</code> </p>"},{"location":"api/tenets/core/momentum/metrics/#tenets.core.momentum.metrics.MomentumMetrics.momentum_category","title":"momentum_category  <code>property</code>","text":"Python<pre><code>momentum_category: str\n</code></pre> <p>Categorize momentum level.</p> RETURNS DESCRIPTION <code>str</code> <p>Momentum category (excellent, good, fair, poor)</p> <p> TYPE: <code>str</code> </p>"},{"location":"api/tenets/core/momentum/metrics/#tenets.core.momentum.metrics.MomentumMetrics-functions","title":"Functions","text":""},{"location":"api/tenets/core/momentum/metrics/#tenets.core.momentum.metrics.MomentumMetrics.to_dict","title":"to_dict","text":"Python<pre><code>to_dict() -&gt; Dict[str, Any]\n</code></pre> <p>Convert to dictionary representation.</p> RETURNS DESCRIPTION <code>Dict[str, Any]</code> <p>Dict[str, Any]: Dictionary representation</p>"},{"location":"api/tenets/core/momentum/metrics/#tenets.core.momentum.metrics-functions","title":"Functions","text":""},{"location":"api/tenets/core/momentum/metrics/#tenets.core.momentum.metrics.calculate_momentum_metrics","title":"calculate_momentum_metrics","text":"Python<pre><code>calculate_momentum_metrics(daily_velocities: List[Any], individual_velocities: List[Any]) -&gt; MomentumMetrics\n</code></pre> <p>Calculate overall momentum metrics from velocity data.</p> <p>Aggregates various velocity and productivity data to compute comprehensive momentum metrics.</p> PARAMETER DESCRIPTION <code>daily_velocities</code> <p>List of daily velocity data</p> <p> TYPE: <code>List[Any]</code> </p> <code>individual_velocities</code> <p>List of individual contributor velocities</p> <p> TYPE: <code>List[Any]</code> </p> RETURNS DESCRIPTION <code>MomentumMetrics</code> <p>Calculated momentum metrics</p> <p> TYPE: <code>MomentumMetrics</code> </p> Example <p>metrics = calculate_momentum_metrics( ...     daily_data, ...     contributor_data ... ) print(f\"Momentum score: {metrics.momentum_score}\")</p>"},{"location":"api/tenets/core/momentum/metrics/#tenets.core.momentum.metrics.calculate_sprint_velocity","title":"calculate_sprint_velocity","text":"Python<pre><code>calculate_sprint_velocity(commits: List[Any], sprint_duration: int = 14) -&gt; float\n</code></pre> <p>Calculate velocity for a sprint period.</p> <p>Calculates story points or velocity equivalent based on commit activity and code changes.</p> PARAMETER DESCRIPTION <code>commits</code> <p>List of commits in sprint</p> <p> TYPE: <code>List[Any]</code> </p> <code>sprint_duration</code> <p>Sprint length in days</p> <p> TYPE: <code>int</code> DEFAULT: <code>14</code> </p> RETURNS DESCRIPTION <code>float</code> <p>Calculated sprint velocity</p> <p> TYPE: <code>float</code> </p> Example <p>velocity = calculate_sprint_velocity( ...     sprint_commits, ...     sprint_duration=14 ... ) print(f\"Sprint velocity: {velocity}\")</p>"},{"location":"api/tenets/core/momentum/metrics/#tenets.core.momentum.metrics.calculate_team_efficiency","title":"calculate_team_efficiency","text":"Python<pre><code>calculate_team_efficiency(team_metrics: TeamMetrics) -&gt; float\n</code></pre> <p>Calculate team efficiency score.</p> <p>Combines various team metrics to compute an overall efficiency score.</p> PARAMETER DESCRIPTION <code>team_metrics</code> <p>Team metrics data</p> <p> TYPE: <code>TeamMetrics</code> </p> RETURNS DESCRIPTION <code>float</code> <p>Team efficiency score (0-100)</p> <p> TYPE: <code>float</code> </p> Example <p>efficiency = calculate_team_efficiency(team_metrics) print(f\"Team efficiency: {efficiency}%\")</p>"},{"location":"api/tenets/core/momentum/metrics/#tenets.core.momentum.metrics.predict_velocity","title":"predict_velocity","text":"Python<pre><code>predict_velocity(historical_velocities: List[float], periods_ahead: int = 1, confidence_level: float = 0.8) -&gt; Tuple[float, float]\n</code></pre> <p>Predict future velocity based on historical data.</p> <p>Uses simple linear regression to predict future velocity with confidence intervals.</p> PARAMETER DESCRIPTION <code>historical_velocities</code> <p>List of historical velocity values</p> <p> TYPE: <code>List[float]</code> </p> <code>periods_ahead</code> <p>Number of periods to predict ahead</p> <p> TYPE: <code>int</code> DEFAULT: <code>1</code> </p> <code>confidence_level</code> <p>Confidence level for prediction</p> <p> TYPE: <code>float</code> DEFAULT: <code>0.8</code> </p> RETURNS DESCRIPTION <code>Tuple[float, float]</code> <p>Tuple[float, float]: (predicted_velocity, confidence)</p> Example <p>prediction, confidence = predict_velocity( ...     [10, 12, 11, 13, 14], ...     periods_ahead=2 ... ) print(f\"Predicted: {prediction} (confidence: {confidence})\")</p>"},{"location":"api/tenets/core/momentum/metrics/#tenets.core.momentum.metrics.calculate_burndown_rate","title":"calculate_burndown_rate","text":"Python<pre><code>calculate_burndown_rate(completed_work: List[float], total_work: float, time_elapsed: int, total_time: int) -&gt; Dict[str, Any]\n</code></pre> <p>Calculate burndown rate and projections.</p> <p>Analyzes work completion rate for burndown charts and sprint completion predictions.</p> PARAMETER DESCRIPTION <code>completed_work</code> <p>List of completed work per time unit</p> <p> TYPE: <code>List[float]</code> </p> <code>total_work</code> <p>Total work to complete</p> <p> TYPE: <code>float</code> </p> <code>time_elapsed</code> <p>Time units elapsed</p> <p> TYPE: <code>int</code> </p> <code>total_time</code> <p>Total time units available</p> <p> TYPE: <code>int</code> </p> RETURNS DESCRIPTION <code>Dict[str, Any]</code> <p>Dict[str, Any]: Burndown metrics and projections</p> Example <p>burndown = calculate_burndown_rate( ...     [10, 8, 12, 9], ...     100, ...     4, ...     14 ... ) print(f\"On track: {burndown['on_track']}\")</p>"},{"location":"api/tenets/core/momentum/tracker/","title":"Tracker","text":""},{"location":"api/tenets/core/momentum/tracker/#tenets.core.momentum.tracker","title":"tenets.core.momentum.tracker","text":"<p>Velocity tracker module for development momentum analysis.</p> <p>This module provides the main tracking functionality for development velocity and momentum. It analyzes git history to understand development patterns, team productivity, and project velocity trends over time.</p> <p>The VelocityTracker class orchestrates the analysis of commits, code changes, and contributor activity to provide actionable insights into team momentum.</p>"},{"location":"api/tenets/core/momentum/tracker/#tenets.core.momentum.tracker-classes","title":"Classes","text":""},{"location":"api/tenets/core/momentum/tracker/#tenets.core.momentum.tracker.DailyVelocity","title":"DailyVelocity  <code>dataclass</code>","text":"Python<pre><code>DailyVelocity(date: datetime, commits: int = 0, lines_added: int = 0, lines_removed: int = 0, files_changed: int = 0, contributors: Set[str] = set(), pull_requests: int = 0, issues_closed: int = 0, velocity_points: float = 0.0, productivity_score: float = 0.0)\n</code></pre> <p>Velocity metrics for a single day.</p> <p>Tracks development activity and productivity for a specific day, used for building velocity trends and burndown charts.</p> ATTRIBUTE DESCRIPTION <code>date</code> <p>Date of activity</p> <p> TYPE: <code>datetime</code> </p> <code>commits</code> <p>Number of commits</p> <p> TYPE: <code>int</code> </p> <code>lines_added</code> <p>Lines of code added</p> <p> TYPE: <code>int</code> </p> <code>lines_removed</code> <p>Lines of code removed</p> <p> TYPE: <code>int</code> </p> <code>files_changed</code> <p>Number of files modified</p> <p> TYPE: <code>int</code> </p> <code>contributors</code> <p>Set of active contributors</p> <p> TYPE: <code>Set[str]</code> </p> <code>pull_requests</code> <p>Number of PRs merged</p> <p> TYPE: <code>int</code> </p> <code>issues_closed</code> <p>Number of issues closed</p> <p> TYPE: <code>int</code> </p> <code>velocity_points</code> <p>Calculated velocity points</p> <p> TYPE: <code>float</code> </p> <code>productivity_score</code> <p>Daily productivity score</p> <p> TYPE: <code>float</code> </p>"},{"location":"api/tenets/core/momentum/tracker/#tenets.core.momentum.tracker.DailyVelocity-attributes","title":"Attributes","text":""},{"location":"api/tenets/core/momentum/tracker/#tenets.core.momentum.tracker.DailyVelocity.net_lines","title":"net_lines  <code>property</code>","text":"Python<pre><code>net_lines: int\n</code></pre> <p>Calculate net lines changed.</p> RETURNS DESCRIPTION <code>int</code> <p>Lines added minus lines removed</p> <p> TYPE: <code>int</code> </p>"},{"location":"api/tenets/core/momentum/tracker/#tenets.core.momentum.tracker.DailyVelocity.contributor_count","title":"contributor_count  <code>property</code>","text":"Python<pre><code>contributor_count: int\n</code></pre> <p>Get number of unique contributors.</p> RETURNS DESCRIPTION <code>int</code> <p>Unique contributor count</p> <p> TYPE: <code>int</code> </p>"},{"location":"api/tenets/core/momentum/tracker/#tenets.core.momentum.tracker.DailyVelocity.is_active","title":"is_active  <code>property</code>","text":"Python<pre><code>is_active: bool\n</code></pre> <p>Check if this was an active day.</p> RETURNS DESCRIPTION <code>bool</code> <p>True if any activity occurred</p> <p> TYPE: <code>bool</code> </p>"},{"location":"api/tenets/core/momentum/tracker/#tenets.core.momentum.tracker.WeeklyVelocity","title":"WeeklyVelocity  <code>dataclass</code>","text":"Python<pre><code>WeeklyVelocity(week_start: datetime, week_end: datetime, week_number: int, daily_velocities: List[DailyVelocity] = list(), total_commits: int = 0, total_lines_changed: int = 0, unique_contributors: Set[str] = set(), avg_daily_velocity: float = 0.0, velocity_variance: float = 0.0, sprint_completion: Optional[float] = None)\n</code></pre> <p>Velocity metrics aggregated by week.</p> <p>Provides week-level velocity metrics for sprint tracking and longer-term trend analysis.</p> ATTRIBUTE DESCRIPTION <code>week_start</code> <p>Start date of the week</p> <p> TYPE: <code>datetime</code> </p> <code>week_end</code> <p>End date of the week</p> <p> TYPE: <code>datetime</code> </p> <code>week_number</code> <p>Week number in year</p> <p> TYPE: <code>int</code> </p> <code>daily_velocities</code> <p>List of daily velocities</p> <p> TYPE: <code>List[DailyVelocity]</code> </p> <code>total_commits</code> <p>Total commits in week</p> <p> TYPE: <code>int</code> </p> <code>total_lines_changed</code> <p>Total lines changed</p> <p> TYPE: <code>int</code> </p> <code>unique_contributors</code> <p>Unique contributors in week</p> <p> TYPE: <code>Set[str]</code> </p> <code>avg_daily_velocity</code> <p>Average daily velocity</p> <p> TYPE: <code>float</code> </p> <code>velocity_variance</code> <p>Variance in daily velocity</p> <p> TYPE: <code>float</code> </p> <code>sprint_completion</code> <p>Sprint completion percentage if applicable</p> <p> TYPE: <code>Optional[float]</code> </p>"},{"location":"api/tenets/core/momentum/tracker/#tenets.core.momentum.tracker.WeeklyVelocity-attributes","title":"Attributes","text":""},{"location":"api/tenets/core/momentum/tracker/#tenets.core.momentum.tracker.WeeklyVelocity.active_days","title":"active_days  <code>property</code>","text":"Python<pre><code>active_days: int\n</code></pre> <p>Count active days in the week.</p> RETURNS DESCRIPTION <code>int</code> <p>Number of days with activity</p> <p> TYPE: <code>int</code> </p>"},{"location":"api/tenets/core/momentum/tracker/#tenets.core.momentum.tracker.WeeklyVelocity.productivity_score","title":"productivity_score  <code>property</code>","text":"Python<pre><code>productivity_score: float\n</code></pre> <p>Calculate weekly productivity score.</p> RETURNS DESCRIPTION <code>float</code> <p>Productivity score (0-100)</p> <p> TYPE: <code>float</code> </p>"},{"location":"api/tenets/core/momentum/tracker/#tenets.core.momentum.tracker.ContributorVelocity","title":"ContributorVelocity  <code>dataclass</code>","text":"Python<pre><code>ContributorVelocity(name: str, email: str, commits: int = 0, lines_added: int = 0, lines_removed: int = 0, files_touched: Set[str] = set(), active_days: Set[str] = set(), first_commit: Optional[datetime] = None, last_commit: Optional[datetime] = None, velocity_trend: str = 'stable', productivity_score: float = 0.0, consistency_score: float = 0.0, impact_score: float = 0.0, collaboration_score: float = 0.0, specialization_areas: List[str] = list())\n</code></pre> <p>Velocity metrics for an individual contributor.</p> <p>Tracks individual developer productivity and contribution patterns to understand team dynamics and individual performance.</p> ATTRIBUTE DESCRIPTION <code>name</code> <p>Contributor name</p> <p> TYPE: <code>str</code> </p> <code>email</code> <p>Contributor email</p> <p> TYPE: <code>str</code> </p> <code>commits</code> <p>Total commits</p> <p> TYPE: <code>int</code> </p> <code>lines_added</code> <p>Total lines added</p> <p> TYPE: <code>int</code> </p> <code>lines_removed</code> <p>Total lines removed</p> <p> TYPE: <code>int</code> </p> <code>files_touched</code> <p>Set of files modified</p> <p> TYPE: <code>Set[str]</code> </p> <code>active_days</code> <p>Days with commits</p> <p> TYPE: <code>Set[str]</code> </p> <code>first_commit</code> <p>First commit date in period</p> <p> TYPE: <code>Optional[datetime]</code> </p> <code>last_commit</code> <p>Last commit date in period</p> <p> TYPE: <code>Optional[datetime]</code> </p> <code>velocity_trend</code> <p>Individual velocity trend</p> <p> TYPE: <code>str</code> </p> <code>productivity_score</code> <p>Individual productivity score</p> <p> TYPE: <code>float</code> </p> <code>consistency_score</code> <p>Consistency of contributions</p> <p> TYPE: <code>float</code> </p> <code>impact_score</code> <p>Impact/influence score</p> <p> TYPE: <code>float</code> </p> <code>collaboration_score</code> <p>Collaboration with others</p> <p> TYPE: <code>float</code> </p> <code>specialization_areas</code> <p>Areas of expertise</p> <p> TYPE: <code>List[str]</code> </p>"},{"location":"api/tenets/core/momentum/tracker/#tenets.core.momentum.tracker.ContributorVelocity-attributes","title":"Attributes","text":""},{"location":"api/tenets/core/momentum/tracker/#tenets.core.momentum.tracker.ContributorVelocity.net_lines","title":"net_lines  <code>property</code>","text":"Python<pre><code>net_lines: int\n</code></pre> <p>Calculate net lines contributed.</p> RETURNS DESCRIPTION <code>int</code> <p>Lines added minus lines removed</p> <p> TYPE: <code>int</code> </p>"},{"location":"api/tenets/core/momentum/tracker/#tenets.core.momentum.tracker.ContributorVelocity.avg_commit_size","title":"avg_commit_size  <code>property</code>","text":"Python<pre><code>avg_commit_size: float\n</code></pre> <p>Calculate average commit size.</p> RETURNS DESCRIPTION <code>float</code> <p>Average lines changed per commit</p> <p> TYPE: <code>float</code> </p>"},{"location":"api/tenets/core/momentum/tracker/#tenets.core.momentum.tracker.ContributorVelocity.daily_commit_rate","title":"daily_commit_rate  <code>property</code>","text":"Python<pre><code>daily_commit_rate: float\n</code></pre> <p>Calculate average commits per active day.</p> RETURNS DESCRIPTION <code>float</code> <p>Commits per active day</p> <p> TYPE: <code>float</code> </p>"},{"location":"api/tenets/core/momentum/tracker/#tenets.core.momentum.tracker.MomentumReport","title":"MomentumReport  <code>dataclass</code>","text":"Python<pre><code>MomentumReport(period_start: datetime, period_end: datetime, total_commits: int = 0, total_contributors: int = 0, active_contributors: int = 0, momentum_metrics: Optional[MomentumMetrics] = None, velocity_trend: Optional[VelocityTrend] = None, sprint_metrics: Optional[SprintMetrics] = None, team_metrics: Optional[TeamMetrics] = None, individual_velocities: List[ContributorVelocity] = list(), daily_breakdown: List[DailyVelocity] = list(), weekly_breakdown: List[WeeklyVelocity] = list(), productivity_metrics: Optional[ProductivityMetrics] = None, recommendations: List[str] = list(), health_score: float = 0.0)\n</code></pre> <p>Comprehensive momentum and velocity analysis report.</p> <p>Aggregates all velocity metrics and trends to provide a complete picture of development momentum and team productivity.</p> ATTRIBUTE DESCRIPTION <code>period_start</code> <p>Start date of analysis period</p> <p> TYPE: <code>datetime</code> </p> <code>period_end</code> <p>End date of analysis period</p> <p> TYPE: <code>datetime</code> </p> <code>total_commits</code> <p>Total commits in period</p> <p> TYPE: <code>int</code> </p> <code>total_contributors</code> <p>Total unique contributors</p> <p> TYPE: <code>int</code> </p> <code>active_contributors</code> <p>Currently active contributors</p> <p> TYPE: <code>int</code> </p> <code>momentum_metrics</code> <p>Overall momentum metrics</p> <p> TYPE: <code>Optional[MomentumMetrics]</code> </p> <code>velocity_trend</code> <p>Velocity trend analysis</p> <p> TYPE: <code>Optional[VelocityTrend]</code> </p> <code>sprint_metrics</code> <p>Sprint-based metrics</p> <p> TYPE: <code>Optional[SprintMetrics]</code> </p> <code>team_metrics</code> <p>Team-level metrics</p> <p> TYPE: <code>Optional[TeamMetrics]</code> </p> <code>individual_velocities</code> <p>Individual contributor velocities</p> <p> TYPE: <code>List[ContributorVelocity]</code> </p> <code>daily_breakdown</code> <p>Daily velocity breakdown</p> <p> TYPE: <code>List[DailyVelocity]</code> </p> <code>weekly_breakdown</code> <p>Weekly velocity breakdown</p> <p> TYPE: <code>List[WeeklyVelocity]</code> </p> <code>productivity_metrics</code> <p>Productivity analysis</p> <p> TYPE: <code>Optional[ProductivityMetrics]</code> </p> <code>recommendations</code> <p>Actionable recommendations</p> <p> TYPE: <code>List[str]</code> </p> <code>health_score</code> <p>Overall momentum health score</p> <p> TYPE: <code>float</code> </p>"},{"location":"api/tenets/core/momentum/tracker/#tenets.core.momentum.tracker.MomentumReport-attributes","title":"Attributes","text":""},{"location":"api/tenets/core/momentum/tracker/#tenets.core.momentum.tracker.MomentumReport.avg_daily_velocity","title":"avg_daily_velocity  <code>property</code>","text":"Python<pre><code>avg_daily_velocity: float\n</code></pre> <p>Calculate average daily velocity.</p> RETURNS DESCRIPTION <code>float</code> <p>Average velocity per day</p> <p> TYPE: <code>float</code> </p>"},{"location":"api/tenets/core/momentum/tracker/#tenets.core.momentum.tracker.MomentumReport.velocity_stability","title":"velocity_stability  <code>property</code>","text":"Python<pre><code>velocity_stability: float\n</code></pre> <p>Calculate velocity stability score.</p> <p>Lower variance indicates more stable/predictable velocity.</p> RETURNS DESCRIPTION <code>float</code> <p>Stability score (0-100)</p> <p> TYPE: <code>float</code> </p>"},{"location":"api/tenets/core/momentum/tracker/#tenets.core.momentum.tracker.MomentumReport-functions","title":"Functions","text":""},{"location":"api/tenets/core/momentum/tracker/#tenets.core.momentum.tracker.MomentumReport.to_dict","title":"to_dict","text":"Python<pre><code>to_dict() -&gt; Dict[str, Any]\n</code></pre> <p>Convert report to dictionary.</p> RETURNS DESCRIPTION <code>Dict[str, Any]</code> <p>Dict[str, Any]: Dictionary representation</p>"},{"location":"api/tenets/core/momentum/tracker/#tenets.core.momentum.tracker.VelocityTracker","title":"VelocityTracker","text":"Python<pre><code>VelocityTracker(config: TenetsConfig)\n</code></pre> <p>Main tracker for development velocity and momentum.</p> <p>Orchestrates the analysis of git history to track development velocity, team productivity, and momentum trends over time.</p> ATTRIBUTE DESCRIPTION <code>config</code> <p>Configuration object</p> <p> </p> <code>logger</code> <p>Logger instance</p> <p> </p> <code>git_analyzer</code> <p>Git analyzer instance</p> <p> TYPE: <code>Optional[GitAnalyzer]</code> </p> <p>Initialize velocity tracker.</p> PARAMETER DESCRIPTION <code>config</code> <p>TenetsConfig instance</p> <p> TYPE: <code>TenetsConfig</code> </p>"},{"location":"api/tenets/core/momentum/tracker/#tenets.core.momentum.tracker.VelocityTracker-functions","title":"Functions","text":""},{"location":"api/tenets/core/momentum/tracker/#tenets.core.momentum.tracker.VelocityTracker.track_momentum","title":"track_momentum","text":"Python<pre><code>track_momentum(repo_path: Path, period: str = 'last-month', team: bool = False, author: Optional[str] = None, team_mapping: Optional[Dict[str, List[str]]] = None, sprint_duration: int = 14, daily_breakdown: bool = False, interval: str = 'weekly', exclude_bots: bool = True, **kwargs) -&gt; MomentumReport\n</code></pre> <p>Track development momentum for a repository.</p> <p>Analyzes git history to calculate velocity metrics, identify trends, and provide insights into development momentum.</p> PARAMETER DESCRIPTION <code>repo_path</code> <p>Path to git repository</p> <p> TYPE: <code>Path</code> </p> <code>period</code> <p>Time period to analyze (e.g., \"last-month\", \"30 days\")</p> <p> TYPE: <code>str</code> DEFAULT: <code>'last-month'</code> </p> <code>team</code> <p>Whether to include team-wide metrics</p> <p> TYPE: <code>bool</code> DEFAULT: <code>False</code> </p> <code>author</code> <p>Specific author to analyze</p> <p> TYPE: <code>Optional[str]</code> DEFAULT: <code>None</code> </p> <code>team_mapping</code> <p>Optional mapping of team names to members</p> <p> TYPE: <code>Optional[Dict[str, List[str]]]</code> DEFAULT: <code>None</code> </p> <code>sprint_duration</code> <p>Sprint length in days for sprint metrics</p> <p> TYPE: <code>int</code> DEFAULT: <code>14</code> </p> <code>daily_breakdown</code> <p>Whether to include daily velocity data</p> <p> TYPE: <code>bool</code> DEFAULT: <code>False</code> </p> <code>interval</code> <p>Aggregation interval (daily, weekly, monthly)</p> <p> TYPE: <code>str</code> DEFAULT: <code>'weekly'</code> </p> <code>exclude_bots</code> <p>Whether to exclude bot commits from analysis</p> <p> TYPE: <code>bool</code> DEFAULT: <code>True</code> </p> RETURNS DESCRIPTION <code>MomentumReport</code> <p>Comprehensive momentum analysis</p> <p> TYPE: <code>MomentumReport</code> </p> Example <p>tracker = VelocityTracker(config) report = tracker.track_momentum( ...     Path(\".\"), ...     period=\"last-quarter\", ...     team=True ... ) print(f\"Team velocity: {report.avg_daily_velocity}\")</p>"},{"location":"api/tenets/core/momentum/tracker/#tenets.core.momentum.tracker-functions","title":"Functions","text":""},{"location":"api/tenets/core/momentum/tracker/#tenets.core.momentum.tracker.is_bot_commit","title":"is_bot_commit","text":"Python<pre><code>is_bot_commit(author_name: str, author_email: str) -&gt; bool\n</code></pre> <p>Check if a commit is from a bot or automated system.</p> PARAMETER DESCRIPTION <code>author_name</code> <p>Commit author name</p> <p> TYPE: <code>str</code> </p> <code>author_email</code> <p>Commit author email</p> <p> TYPE: <code>str</code> </p> RETURNS DESCRIPTION <code>bool</code> <p>True if commit appears to be from a bot</p> <p> TYPE: <code>bool</code> </p>"},{"location":"api/tenets/core/momentum/tracker/#tenets.core.momentum.tracker.track_momentum","title":"track_momentum","text":"Python<pre><code>track_momentum(repo_path: Path, period: str = 'last-month', config: Optional[TenetsConfig] = None, **kwargs) -&gt; MomentumReport\n</code></pre> <p>Convenience function to track momentum.</p> PARAMETER DESCRIPTION <code>repo_path</code> <p>Path to repository</p> <p> TYPE: <code>Path</code> </p> <code>period</code> <p>Time period to analyze</p> <p> TYPE: <code>str</code> DEFAULT: <code>'last-month'</code> </p> <code>config</code> <p>Optional configuration</p> <p> TYPE: <code>Optional[TenetsConfig]</code> DEFAULT: <code>None</code> </p> <code>**kwargs</code> <p>Additional arguments for tracker</p> <p> DEFAULT: <code>{}</code> </p> RETURNS DESCRIPTION <code>MomentumReport</code> <p>Momentum analysis</p> <p> TYPE: <code>MomentumReport</code> </p>"},{"location":"api/tenets/core/momentum/tracker/#tenets.core.momentum.tracker.track_team_velocity","title":"track_team_velocity","text":"Python<pre><code>track_team_velocity(repo_path: Path, period: str = 'last-month', team_mapping: Optional[Dict[str, List[str]]] = None, config: Optional[TenetsConfig] = None) -&gt; TeamMetrics\n</code></pre> <p>Track team velocity metrics.</p> PARAMETER DESCRIPTION <code>repo_path</code> <p>Path to repository</p> <p> TYPE: <code>Path</code> </p> <code>period</code> <p>Time period to analyze</p> <p> TYPE: <code>str</code> DEFAULT: <code>'last-month'</code> </p> <code>team_mapping</code> <p>Team structure mapping</p> <p> TYPE: <code>Optional[Dict[str, List[str]]]</code> DEFAULT: <code>None</code> </p> <code>config</code> <p>Optional configuration</p> <p> TYPE: <code>Optional[TenetsConfig]</code> DEFAULT: <code>None</code> </p> RETURNS DESCRIPTION <code>TeamMetrics</code> <p>Team velocity metrics</p> <p> TYPE: <code>TeamMetrics</code> </p>"},{"location":"api/tenets/core/momentum/tracker/#tenets.core.momentum.tracker.track_individual_velocity","title":"track_individual_velocity","text":"Python<pre><code>track_individual_velocity(repo_path: Path, author: str, period: str = 'last-month', config: Optional[TenetsConfig] = None) -&gt; Optional[ContributorVelocity]\n</code></pre> <p>Track individual contributor velocity.</p> PARAMETER DESCRIPTION <code>repo_path</code> <p>Path to repository</p> <p> TYPE: <code>Path</code> </p> <code>author</code> <p>Author name or email</p> <p> TYPE: <code>str</code> </p> <code>period</code> <p>Time period to analyze</p> <p> TYPE: <code>str</code> DEFAULT: <code>'last-month'</code> </p> <code>config</code> <p>Optional configuration</p> <p> TYPE: <code>Optional[TenetsConfig]</code> DEFAULT: <code>None</code> </p> RETURNS DESCRIPTION <code>Optional[ContributorVelocity]</code> <p>Optional[ContributorVelocity]: Individual velocity metrics</p>"},{"location":"api/tenets/core/nlp/bm25/","title":"Bm25","text":""},{"location":"api/tenets/core/nlp/bm25/#tenets.core.nlp.bm25","title":"tenets.core.nlp.bm25","text":"<p>BM25 ranking algorithm implementation.</p> <p>BM25 (Best Matching 25) is a probabilistic ranking function that improves upon TF-IDF for information retrieval. This module provides a robust, well-documented implementation optimized for code search.</p> Key Features <ul> <li>Term frequency saturation to prevent over-weighting repeated terms</li> <li>Sophisticated document length normalization</li> <li>Configurable parameters for different document types</li> <li>Efficient sparse representation for large corpora</li> <li>Cache-friendly design for repeated queries</li> </ul> Mathematical Foundation <p>BM25 score for document D given query Q:</p> <p>Score(D,Q) = \u03a3 IDF(qi) \u00d7 [f(qi,D) \u00d7 (k1 + 1)] / [f(qi,D) + k1 \u00d7 (1 - b + b \u00d7 |D|/avgdl)]</p> <p>Where:     qi = each query term     f(qi,D) = frequency of term qi in document D     |D| = length of document D in tokens     avgdl = average document length in the corpus     k1 = term frequency saturation parameter (default: 1.2)     b = length normalization parameter (default: 0.75)</p> <p>IDF Component:     IDF(qi) = log[(N - df(qi) + 0.5) / (df(qi) + 0.5) + 1]</p> Text Only<pre><code>Where:\n    N = total number of documents\n    df(qi) = number of documents containing term qi\n</code></pre> Usage <p>from tenets.core.nlp.bm25 import BM25Calculator</p> References <ul> <li>Robertson &amp; Walker (1994): \"Some simple effective approximations to the   2-Poisson model for probabilistic weighted retrieval\"</li> <li>Trotman et al. (2014): \"Improvements to BM25 and language models examined\"</li> </ul>"},{"location":"api/tenets/core/nlp/bm25/#tenets.core.nlp.bm25--initialize-calculator","title":"Initialize calculator","text":"<p>bm25 = BM25Calculator(k1=1.2, b=0.75)</p>"},{"location":"api/tenets/core/nlp/bm25/#tenets.core.nlp.bm25--build-corpus","title":"Build corpus","text":"<p>documents = [ ...     (\"doc1\", \"Python web framework Django\"), ...     (\"doc2\", \"Flask is a lightweight Python framework\"), ...     (\"doc3\", \"JavaScript React framework for UI\") ... ] bm25.build_corpus(documents)</p>"},{"location":"api/tenets/core/nlp/bm25/#tenets.core.nlp.bm25--score-documents-for-a-query","title":"Score documents for a query","text":"<p>scores = bm25.get_scores(\"Python framework\") for doc_id, score in scores: ...     print(f\"{doc_id}: {score:.3f}\")</p>"},{"location":"api/tenets/core/nlp/bm25/#tenets.core.nlp.bm25-classes","title":"Classes","text":""},{"location":"api/tenets/core/nlp/bm25/#tenets.core.nlp.bm25.BM25Calculator","title":"BM25Calculator","text":"Python<pre><code>BM25Calculator(k1: float = 1.2, b: float = 0.75, epsilon: float = 0.25, use_stopwords: bool = False, stopword_set: str = 'code')\n</code></pre> <p>BM25 ranking algorithm with advanced features for code search.</p> This implementation provides <ul> <li>Configurable term saturation (k1) and length normalization (b)</li> <li>Efficient tokenization with optional stopword filtering</li> <li>IDF caching for performance</li> <li>Support for incremental corpus updates</li> <li>Query expansion capabilities</li> <li>Detailed scoring explanations for debugging</li> </ul> ATTRIBUTE DESCRIPTION <code>k1</code> <p>Controls term frequency saturation. Higher values mean        less saturation (more weight to term frequency).        Typical range: 0.5-2.0, default: 1.2</p> <p> TYPE: <code>float</code> </p> <code>b</code> <p>Controls document length normalization.       0 = no normalization, 1 = full normalization.       Typical range: 0.5-0.8, default: 0.75</p> <p> TYPE: <code>float</code> </p> <code>epsilon</code> <p>Small constant to prevent division by zero</p> <p> TYPE: <code>float</code> </p> <p>Initialize BM25 calculator with configurable parameters.</p> PARAMETER DESCRIPTION <code>k1</code> <p>Term frequency saturation parameter. Lower values (0.5-1.0) work well for short queries, higher values (1.5-2.0) for longer queries. Default: 1.2 (good general purpose value)</p> <p> TYPE: <code>float</code> DEFAULT: <code>1.2</code> </p> <code>b</code> <p>Length normalization parameter. Set to 0 to disable length normalization, 1 for full normalization. Default: 0.75 (moderate normalization, good for mixed-length documents)</p> <p> TYPE: <code>float</code> DEFAULT: <code>0.75</code> </p> <code>epsilon</code> <p>Small constant for numerical stability</p> <p> TYPE: <code>float</code> DEFAULT: <code>0.25</code> </p> <code>use_stopwords</code> <p>Whether to filter common words</p> <p> TYPE: <code>bool</code> DEFAULT: <code>False</code> </p> <code>stopword_set</code> <p>Which stopword set to use ('code' for programming,          'english' for natural language)</p> <p> TYPE: <code>str</code> DEFAULT: <code>'code'</code> </p>"},{"location":"api/tenets/core/nlp/bm25/#tenets.core.nlp.bm25.BM25Calculator-functions","title":"Functions","text":""},{"location":"api/tenets/core/nlp/bm25/#tenets.core.nlp.bm25.BM25Calculator.tokenize","title":"tokenize","text":"Python<pre><code>tokenize(text: str) -&gt; List[str]\n</code></pre> <p>Tokenize text using code-aware tokenizer.</p> Handles various code constructs <ul> <li>CamelCase and snake_case splitting</li> <li>Preservation of important symbols</li> <li>Number and identifier extraction</li> </ul> PARAMETER DESCRIPTION <code>text</code> <p>Input text to tokenize</p> <p> TYPE: <code>str</code> </p> RETURNS DESCRIPTION <code>List[str]</code> <p>List of tokens, lowercased and filtered</p>"},{"location":"api/tenets/core/nlp/bm25/#tenets.core.nlp.bm25.BM25Calculator.add_document","title":"add_document","text":"Python<pre><code>add_document(doc_id: str, text: str) -&gt; None\n</code></pre> <p>Add a document to the BM25 corpus.</p> <p>Updates all corpus statistics including document frequency, average document length, and vocabulary.</p> PARAMETER DESCRIPTION <code>doc_id</code> <p>Unique identifier for the document</p> <p> TYPE: <code>str</code> </p> <code>text</code> <p>Document content</p> <p> TYPE: <code>str</code> </p> Note <p>Adding documents invalidates the IDF and score caches. For bulk loading, use build_corpus() instead.</p>"},{"location":"api/tenets/core/nlp/bm25/#tenets.core.nlp.bm25.BM25Calculator.build_corpus","title":"build_corpus","text":"Python<pre><code>build_corpus(documents: List[Tuple[str, str]]) -&gt; None\n</code></pre> <p>Build BM25 corpus from multiple documents efficiently.</p> <p>More efficient than repeated add_document() calls as it calculates statistics once at the end.</p> PARAMETER DESCRIPTION <code>documents</code> <p>List of (doc_id, text) tuples</p> <p> TYPE: <code>List[Tuple[str, str]]</code> </p> Example <p>documents = [ ...     (\"file1.py\", \"import os\\nclass FileHandler\"), ...     (\"file2.py\", \"from pathlib import Path\") ... ] bm25.build_corpus(documents)</p>"},{"location":"api/tenets/core/nlp/bm25/#tenets.core.nlp.bm25.BM25Calculator.compute_idf","title":"compute_idf","text":"Python<pre><code>compute_idf(term: str) -&gt; float\n</code></pre> <p>Compute IDF (Inverse Document Frequency) for a term.</p> <p>Uses the standard BM25 IDF formula with smoothing to handle edge cases and prevent negative values.</p> Formula <p>IDF(term) = log[(N - df + 0.5) / (df + 0.5) + 1]</p> PARAMETER DESCRIPTION <code>term</code> <p>Term to compute IDF for</p> <p> TYPE: <code>str</code> </p> RETURNS DESCRIPTION <code>float</code> <p>IDF value (always positive due to +1 in formula)</p>"},{"location":"api/tenets/core/nlp/bm25/#tenets.core.nlp.bm25.BM25Calculator.score_document","title":"score_document","text":"Python<pre><code>score_document(query_tokens: List[str], doc_id: str, explain: bool = False) -&gt; float\n</code></pre> <p>Calculate BM25 score for a document given query tokens.</p> <p>Implements the full BM25 scoring formula with term saturation and length normalization.</p> PARAMETER DESCRIPTION <code>query_tokens</code> <p>Tokenized query terms</p> <p> TYPE: <code>List[str]</code> </p> <code>doc_id</code> <p>Document identifier to score</p> <p> TYPE: <code>str</code> </p> <code>explain</code> <p>If True, return detailed scoring breakdown</p> <p> TYPE: <code>bool</code> DEFAULT: <code>False</code> </p> RETURNS DESCRIPTION <code>float</code> <p>BM25 score (higher is more relevant)</p> <code>float</code> <p>If explain=True, returns tuple of (score, explanation_dict)</p>"},{"location":"api/tenets/core/nlp/bm25/#tenets.core.nlp.bm25.BM25Calculator.get_scores","title":"get_scores","text":"Python<pre><code>get_scores(query: str, doc_ids: Optional[List[str]] = None) -&gt; List[Tuple[str, float]]\n</code></pre> <p>Get BM25 scores for all documents or a subset.</p> PARAMETER DESCRIPTION <code>query</code> <p>Search query string</p> <p> TYPE: <code>str</code> </p> <code>doc_ids</code> <p>Optional list of document IDs to score.     If None, scores all documents.</p> <p> TYPE: <code>Optional[List[str]]</code> DEFAULT: <code>None</code> </p> RETURNS DESCRIPTION <code>List[Tuple[str, float]]</code> <p>List of (doc_id, score) tuples sorted by score (descending)</p>"},{"location":"api/tenets/core/nlp/bm25/#tenets.core.nlp.bm25.BM25Calculator.get_top_k","title":"get_top_k","text":"Python<pre><code>get_top_k(query: str, k: int = 10, threshold: float = 0.0) -&gt; List[Tuple[str, float]]\n</code></pre> <p>Get top-k documents by BM25 score.</p> PARAMETER DESCRIPTION <code>query</code> <p>Search query</p> <p> TYPE: <code>str</code> </p> <code>k</code> <p>Number of top documents to return</p> <p> TYPE: <code>int</code> DEFAULT: <code>10</code> </p> <code>threshold</code> <p>Minimum score threshold (documents below are filtered)</p> <p> TYPE: <code>float</code> DEFAULT: <code>0.0</code> </p> RETURNS DESCRIPTION <code>List[Tuple[str, float]]</code> <p>List of top-k (doc_id, score) tuples</p>"},{"location":"api/tenets/core/nlp/bm25/#tenets.core.nlp.bm25.BM25Calculator.compute_similarity","title":"compute_similarity","text":"Python<pre><code>compute_similarity(query: str, doc_id: str) -&gt; float\n</code></pre> <p>Compute normalized similarity score between query and document.</p> <p>Returns a value between 0 and 1 for consistency with other similarity measures.</p> PARAMETER DESCRIPTION <code>query</code> <p>Query text</p> <p> TYPE: <code>str</code> </p> <code>doc_id</code> <p>Document identifier</p> <p> TYPE: <code>str</code> </p> RETURNS DESCRIPTION <code>float</code> <p>Normalized similarity score (0-1)</p>"},{"location":"api/tenets/core/nlp/bm25/#tenets.core.nlp.bm25.BM25Calculator.explain_score","title":"explain_score","text":"Python<pre><code>explain_score(query: str, doc_id: str) -&gt; Dict\n</code></pre> <p>Get detailed explanation of BM25 scoring for debugging.</p> PARAMETER DESCRIPTION <code>query</code> <p>Query text</p> <p> TYPE: <code>str</code> </p> <code>doc_id</code> <p>Document to explain scoring for</p> <p> TYPE: <code>str</code> </p> RETURNS DESCRIPTION <code>Dict</code> <p>Dictionary with detailed scoring breakdown</p>"},{"location":"api/tenets/core/nlp/bm25/#tenets.core.nlp.bm25.BM25Calculator.get_stats","title":"get_stats","text":"Python<pre><code>get_stats() -&gt; Dict\n</code></pre> <p>Get calculator statistics for monitoring.</p> RETURNS DESCRIPTION <code>Dict</code> <p>Dictionary with usage statistics</p>"},{"location":"api/tenets/core/nlp/bm25/#tenets.core.nlp.bm25.BM25Calculator.clear_cache","title":"clear_cache","text":"Python<pre><code>clear_cache() -&gt; None\n</code></pre> <p>Clear all caches to free memory.</p>"},{"location":"api/tenets/core/nlp/bm25/#tenets.core.nlp.bm25-functions","title":"Functions","text":""},{"location":"api/tenets/core/nlp/bm25/#tenets.core.nlp.bm25.create_bm25","title":"create_bm25","text":"Python<pre><code>create_bm25(documents: List[Tuple[str, str]], **kwargs) -&gt; BM25Calculator\n</code></pre> <p>Create and initialize a BM25 calculator with documents.</p> PARAMETER DESCRIPTION <code>documents</code> <p>List of (doc_id, text) tuples</p> <p> TYPE: <code>List[Tuple[str, str]]</code> </p> <code>**kwargs</code> <p>Additional arguments for BM25Calculator</p> <p> DEFAULT: <code>{}</code> </p> RETURNS DESCRIPTION <code>BM25Calculator</code> <p>Initialized BM25Calculator with corpus built</p>"},{"location":"api/tenets/core/nlp/cache/","title":"Cache","text":""},{"location":"api/tenets/core/nlp/cache/#tenets.core.nlp.cache","title":"tenets.core.nlp.cache","text":"<p>Embedding cache management.</p> <p>This module provides caching for embeddings to avoid recomputation of expensive embedding operations.</p>"},{"location":"api/tenets/core/nlp/cache/#tenets.core.nlp.cache-classes","title":"Classes","text":""},{"location":"api/tenets/core/nlp/cache/#tenets.core.nlp.cache.EmbeddingCache","title":"EmbeddingCache","text":"Python<pre><code>EmbeddingCache(cache_dir: Path, max_memory_items: int = 1000, ttl_days: int = 30)\n</code></pre> <p>Cache for embedding vectors.</p> <p>Uses a two-level cache: 1. Memory cache for hot embeddings 2. Disk cache for persistence</p> <p>Initialize embedding cache.</p> PARAMETER DESCRIPTION <code>cache_dir</code> <p>Directory for disk cache</p> <p> TYPE: <code>Path</code> </p> <code>max_memory_items</code> <p>Maximum items in memory cache</p> <p> TYPE: <code>int</code> DEFAULT: <code>1000</code> </p> <code>ttl_days</code> <p>Time to live for cached embeddings</p> <p> TYPE: <code>int</code> DEFAULT: <code>30</code> </p>"},{"location":"api/tenets/core/nlp/cache/#tenets.core.nlp.cache.EmbeddingCache-functions","title":"Functions","text":""},{"location":"api/tenets/core/nlp/cache/#tenets.core.nlp.cache.EmbeddingCache.get","title":"get","text":"Python<pre><code>get(text: str, model_name: str = 'default') -&gt; Optional[np.ndarray]\n</code></pre> <p>Get cached embedding.</p> PARAMETER DESCRIPTION <code>text</code> <p>Text that was embedded</p> <p> TYPE: <code>str</code> </p> <code>model_name</code> <p>Model used for embedding</p> <p> TYPE: <code>str</code> DEFAULT: <code>'default'</code> </p> RETURNS DESCRIPTION <code>Optional[ndarray]</code> <p>Cached embedding or None</p>"},{"location":"api/tenets/core/nlp/cache/#tenets.core.nlp.cache.EmbeddingCache.put","title":"put","text":"Python<pre><code>put(text: str, embedding: ndarray, model_name: str = 'default')\n</code></pre> <p>Cache an embedding.</p> PARAMETER DESCRIPTION <code>text</code> <p>Text that was embedded</p> <p> TYPE: <code>str</code> </p> <code>embedding</code> <p>Embedding vector</p> <p> TYPE: <code>ndarray</code> </p> <code>model_name</code> <p>Model used</p> <p> TYPE: <code>str</code> DEFAULT: <code>'default'</code> </p>"},{"location":"api/tenets/core/nlp/cache/#tenets.core.nlp.cache.EmbeddingCache.get_batch","title":"get_batch","text":"Python<pre><code>get_batch(texts: list[str], model_name: str = 'default') -&gt; Dict[str, Optional[np.ndarray]]\n</code></pre> <p>Get multiple cached embeddings.</p> PARAMETER DESCRIPTION <code>texts</code> <p>List of texts</p> <p> TYPE: <code>list[str]</code> </p> <code>model_name</code> <p>Model used</p> <p> TYPE: <code>str</code> DEFAULT: <code>'default'</code> </p> RETURNS DESCRIPTION <code>Dict[str, Optional[ndarray]]</code> <p>Dict mapping text to embedding (or None if not cached)</p>"},{"location":"api/tenets/core/nlp/cache/#tenets.core.nlp.cache.EmbeddingCache.put_batch","title":"put_batch","text":"Python<pre><code>put_batch(embeddings: Dict[str, ndarray], model_name: str = 'default')\n</code></pre> <p>Cache multiple embeddings.</p> PARAMETER DESCRIPTION <code>embeddings</code> <p>Dict mapping text to embedding</p> <p> TYPE: <code>Dict[str, ndarray]</code> </p> <code>model_name</code> <p>Model used</p> <p> TYPE: <code>str</code> DEFAULT: <code>'default'</code> </p>"},{"location":"api/tenets/core/nlp/cache/#tenets.core.nlp.cache.EmbeddingCache.clear_memory","title":"clear_memory","text":"Python<pre><code>clear_memory()\n</code></pre> <p>Clear memory cache.</p>"},{"location":"api/tenets/core/nlp/cache/#tenets.core.nlp.cache.EmbeddingCache.clear_all","title":"clear_all","text":"Python<pre><code>clear_all()\n</code></pre> <p>Clear all caches.</p>"},{"location":"api/tenets/core/nlp/cache/#tenets.core.nlp.cache.EmbeddingCache.cleanup","title":"cleanup","text":"Python<pre><code>cleanup() -&gt; int\n</code></pre> <p>Clean up old cache entries.</p> RETURNS DESCRIPTION <code>int</code> <p>Number of entries deleted</p>"},{"location":"api/tenets/core/nlp/cache/#tenets.core.nlp.cache.EmbeddingCache.stats","title":"stats","text":"Python<pre><code>stats() -&gt; Dict[str, Any]\n</code></pre> <p>Get cache statistics.</p> RETURNS DESCRIPTION <code>Dict[str, Any]</code> <p>Cache statistics</p>"},{"location":"api/tenets/core/nlp/cache/#tenets.core.nlp.cache-functions","title":"Functions","text":""},{"location":"api/tenets/core/nlp/embeddings/","title":"Embeddings","text":""},{"location":"api/tenets/core/nlp/embeddings/#tenets.core.nlp.embeddings","title":"tenets.core.nlp.embeddings","text":"<p>Embedding generation and management.</p> <p>This module provides local embedding generation using sentence transformers. No external API calls are made - everything runs locally.</p>"},{"location":"api/tenets/core/nlp/embeddings/#tenets.core.nlp.embeddings-classes","title":"Classes","text":""},{"location":"api/tenets/core/nlp/embeddings/#tenets.core.nlp.embeddings.EmbeddingModel","title":"EmbeddingModel","text":"Python<pre><code>EmbeddingModel(model_name: str = 'all-MiniLM-L6-v2')\n</code></pre> <p>Base class for embedding models.</p> <p>Initialize embedding model.</p> PARAMETER DESCRIPTION <code>model_name</code> <p>Name of the model to use</p> <p> TYPE: <code>str</code> DEFAULT: <code>'all-MiniLM-L6-v2'</code> </p>"},{"location":"api/tenets/core/nlp/embeddings/#tenets.core.nlp.embeddings.EmbeddingModel-functions","title":"Functions","text":""},{"location":"api/tenets/core/nlp/embeddings/#tenets.core.nlp.embeddings.EmbeddingModel.encode","title":"encode","text":"Python<pre><code>encode(texts: Union[str, List[str]], batch_size: int = 32, show_progress: bool = False) -&gt; np.ndarray\n</code></pre> <p>Encode texts to embeddings.</p> PARAMETER DESCRIPTION <code>texts</code> <p>Text or list of texts</p> <p> TYPE: <code>Union[str, List[str]]</code> </p> <code>batch_size</code> <p>Batch size for encoding</p> <p> TYPE: <code>int</code> DEFAULT: <code>32</code> </p> <code>show_progress</code> <p>Show progress bar</p> <p> TYPE: <code>bool</code> DEFAULT: <code>False</code> </p> RETURNS DESCRIPTION <code>ndarray</code> <p>Numpy array of embeddings</p>"},{"location":"api/tenets/core/nlp/embeddings/#tenets.core.nlp.embeddings.EmbeddingModel.get_embedding_dim","title":"get_embedding_dim","text":"Python<pre><code>get_embedding_dim() -&gt; int\n</code></pre> <p>Get embedding dimension.</p>"},{"location":"api/tenets/core/nlp/embeddings/#tenets.core.nlp.embeddings.LocalEmbeddings","title":"LocalEmbeddings","text":"Python<pre><code>LocalEmbeddings(model_name: str = 'all-MiniLM-L6-v2', device: Optional[str] = None, cache_dir: Optional[Path] = None)\n</code></pre> <p>               Bases: <code>EmbeddingModel</code></p> <p>Local embedding generation using sentence transformers.</p> <p>This runs completely locally with no external API calls. Models are downloaded and cached by sentence-transformers.</p> <p>Initialize local embeddings.</p> PARAMETER DESCRIPTION <code>model_name</code> <p>Sentence transformer model name</p> <p> TYPE: <code>str</code> DEFAULT: <code>'all-MiniLM-L6-v2'</code> </p> <code>device</code> <p>Device to use ('cpu', 'cuda', or None for auto)</p> <p> TYPE: <code>Optional[str]</code> DEFAULT: <code>None</code> </p> <code>cache_dir</code> <p>Directory to cache models</p> <p> TYPE: <code>Optional[Path]</code> DEFAULT: <code>None</code> </p>"},{"location":"api/tenets/core/nlp/embeddings/#tenets.core.nlp.embeddings.LocalEmbeddings-functions","title":"Functions","text":""},{"location":"api/tenets/core/nlp/embeddings/#tenets.core.nlp.embeddings.LocalEmbeddings.encode","title":"encode","text":"Python<pre><code>encode(texts: Union[str, List[str]], batch_size: int = 32, show_progress: bool = False, normalize: bool = True) -&gt; np.ndarray\n</code></pre> <p>Encode texts to embeddings.</p> PARAMETER DESCRIPTION <code>texts</code> <p>Text or list of texts</p> <p> TYPE: <code>Union[str, List[str]]</code> </p> <code>batch_size</code> <p>Batch size for encoding</p> <p> TYPE: <code>int</code> DEFAULT: <code>32</code> </p> <code>show_progress</code> <p>Show progress bar</p> <p> TYPE: <code>bool</code> DEFAULT: <code>False</code> </p> <code>normalize</code> <p>L2 normalize embeddings</p> <p> TYPE: <code>bool</code> DEFAULT: <code>True</code> </p> RETURNS DESCRIPTION <code>ndarray</code> <p>Numpy array of embeddings</p>"},{"location":"api/tenets/core/nlp/embeddings/#tenets.core.nlp.embeddings.LocalEmbeddings.encode_file","title":"encode_file","text":"Python<pre><code>encode_file(file_path: Path, chunk_size: int = 1000, overlap: int = 100) -&gt; np.ndarray\n</code></pre> <p>Encode a file with chunking for long files.</p> PARAMETER DESCRIPTION <code>file_path</code> <p>Path to file</p> <p> TYPE: <code>Path</code> </p> <code>chunk_size</code> <p>Characters per chunk</p> <p> TYPE: <code>int</code> DEFAULT: <code>1000</code> </p> <code>overlap</code> <p>Overlap between chunks</p> <p> TYPE: <code>int</code> DEFAULT: <code>100</code> </p> RETURNS DESCRIPTION <code>ndarray</code> <p>Mean pooled embedding for the file</p>"},{"location":"api/tenets/core/nlp/embeddings/#tenets.core.nlp.embeddings.FallbackEmbeddings","title":"FallbackEmbeddings","text":"Python<pre><code>FallbackEmbeddings(embedding_dim: int = 384)\n</code></pre> <p>               Bases: <code>EmbeddingModel</code></p> <p>Fallback embeddings using TF-IDF when ML not available.</p> <p>Initialize fallback embeddings.</p> PARAMETER DESCRIPTION <code>embedding_dim</code> <p>Dimension for embeddings</p> <p> TYPE: <code>int</code> DEFAULT: <code>384</code> </p>"},{"location":"api/tenets/core/nlp/embeddings/#tenets.core.nlp.embeddings.FallbackEmbeddings-functions","title":"Functions","text":""},{"location":"api/tenets/core/nlp/embeddings/#tenets.core.nlp.embeddings.FallbackEmbeddings.encode","title":"encode","text":"Python<pre><code>encode(texts: Union[str, List[str]], batch_size: int = 32, show_progress: bool = False) -&gt; np.ndarray\n</code></pre> <p>Generate pseudo-embeddings using TF-IDF.</p> PARAMETER DESCRIPTION <code>texts</code> <p>Text or list of texts</p> <p> TYPE: <code>Union[str, List[str]]</code> </p> <code>batch_size</code> <p>Ignored</p> <p> TYPE: <code>int</code> DEFAULT: <code>32</code> </p> <code>show_progress</code> <p>Ignored</p> <p> TYPE: <code>bool</code> DEFAULT: <code>False</code> </p> RETURNS DESCRIPTION <code>ndarray</code> <p>Numpy array of pseudo-embeddings</p>"},{"location":"api/tenets/core/nlp/embeddings/#tenets.core.nlp.embeddings-functions","title":"Functions","text":""},{"location":"api/tenets/core/nlp/embeddings/#tenets.core.nlp.embeddings.create_embedding_model","title":"create_embedding_model","text":"Python<pre><code>create_embedding_model(prefer_local: bool = True, model_name: Optional[str] = None, **kwargs) -&gt; EmbeddingModel\n</code></pre> <p>Create best available embedding model.</p> PARAMETER DESCRIPTION <code>prefer_local</code> <p>Prefer local models over API-based</p> <p> TYPE: <code>bool</code> DEFAULT: <code>True</code> </p> <code>model_name</code> <p>Specific model to use</p> <p> TYPE: <code>Optional[str]</code> DEFAULT: <code>None</code> </p> <code>**kwargs</code> <p>Additional arguments for model</p> <p> DEFAULT: <code>{}</code> </p> RETURNS DESCRIPTION <code>EmbeddingModel</code> <p>EmbeddingModel instance</p>"},{"location":"api/tenets/core/nlp/keyword_extractor/","title":"Keyword Extractor","text":""},{"location":"api/tenets/core/nlp/keyword_extractor/#tenets.core.nlp.keyword_extractor","title":"tenets.core.nlp.keyword_extractor","text":"<p>Keyword extraction using multiple methods.</p> <p>This module provides comprehensive keyword extraction using: - RAKE (Rapid Automatic Keyword Extraction) - primary method - YAKE (if available and Python &lt; 3.13) - TF-IDF with code-aware tokenization - BM25 ranking - Simple frequency-based extraction</p> <p>Consolidates all keyword extraction logic to avoid duplication.</p>"},{"location":"api/tenets/core/nlp/keyword_extractor/#tenets.core.nlp.keyword_extractor-classes","title":"Classes","text":""},{"location":"api/tenets/core/nlp/keyword_extractor/#tenets.core.nlp.keyword_extractor.SimpleRAKE","title":"SimpleRAKE","text":"Python<pre><code>SimpleRAKE(stopwords: Set[str] = None, max_length: int = 3)\n</code></pre> <p>Simple RAKE-like keyword extraction without NLTK dependencies.</p> <p>Implements the core RAKE algorithm without requiring NLTK's punkt tokenizer. Uses simple regex-based sentence splitting and word tokenization.</p> <p>Initialize SimpleRAKE.</p> PARAMETER DESCRIPTION <code>stopwords</code> <p>Set of stopwords to use</p> <p> TYPE: <code>Set[str]</code> DEFAULT: <code>None</code> </p> <code>max_length</code> <p>Maximum n-gram length</p> <p> TYPE: <code>int</code> DEFAULT: <code>3</code> </p>"},{"location":"api/tenets/core/nlp/keyword_extractor/#tenets.core.nlp.keyword_extractor.SimpleRAKE-functions","title":"Functions","text":""},{"location":"api/tenets/core/nlp/keyword_extractor/#tenets.core.nlp.keyword_extractor.SimpleRAKE.extract_keywords_from_text","title":"extract_keywords_from_text","text":"Python<pre><code>extract_keywords_from_text(text: str)\n</code></pre> <p>Extract keywords from text.</p> PARAMETER DESCRIPTION <code>text</code> <p>Input text</p> <p> TYPE: <code>str</code> </p>"},{"location":"api/tenets/core/nlp/keyword_extractor/#tenets.core.nlp.keyword_extractor.SimpleRAKE.get_ranked_phrases_with_scores","title":"get_ranked_phrases_with_scores","text":"Python<pre><code>get_ranked_phrases_with_scores()\n</code></pre> <p>Get ranked phrases with scores.</p> RETURNS DESCRIPTION <p>List of (score, phrase) tuples</p>"},{"location":"api/tenets/core/nlp/keyword_extractor/#tenets.core.nlp.keyword_extractor.KeywordExtractor","title":"KeywordExtractor","text":"Python<pre><code>KeywordExtractor(use_rake: bool = True, use_yake: bool = True, language: str = 'en', use_stopwords: bool = True, stopword_set: str = 'prompt')\n</code></pre> <p>Multi-method keyword extraction with automatic fallback.</p> <p>Provides robust keyword extraction using multiple algorithms with automatic fallback based on availability and Python version compatibility. Prioritizes fast, accurate methods while ensuring compatibility across Python versions.</p> Methods are attempted in order <ol> <li>RAKE (Rapid Automatic Keyword Extraction) - Primary method, fast and    Python 3.13+ compatible</li> <li>YAKE (Yet Another Keyword Extractor) - Secondary method, only for    Python &lt; 3.13 due to compatibility issues</li> <li>TF-IDF - Custom implementation, always available</li> <li>Frequency-based - Final fallback, simple but effective</li> </ol> ATTRIBUTE DESCRIPTION <code>use_rake</code> <p>Whether RAKE extraction is enabled and available.</p> <p> TYPE: <code>bool</code> </p> <code>use_yake</code> <p>Whether YAKE extraction is enabled and available.</p> <p> TYPE: <code>bool</code> </p> <code>language</code> <p>Language code for extraction (e.g., 'en' for English).</p> <p> TYPE: <code>str</code> </p> <code>use_stopwords</code> <p>Whether to filter stopwords during extraction.</p> <p> TYPE: <code>bool</code> </p> <code>stopword_set</code> <p>Which stopword set to use ('code' or 'prompt').</p> <p> TYPE: <code>str</code> </p> <code>rake_extractor</code> <p>RAKE extractor instance if available.</p> <p> TYPE: <code>Rake | None</code> </p> <code>yake_extractor</code> <p>YAKE instance if available.</p> <p> TYPE: <code>KeywordExtractor | None</code> </p> <code>tokenizer</code> <p>Tokenizer for fallback extraction.</p> <p> TYPE: <code>TextTokenizer</code> </p> <code>stopwords</code> <p>Set of stopwords if filtering is enabled.</p> <p> TYPE: <code>Set[str] | None</code> </p> Example <p>extractor = KeywordExtractor() keywords = extractor.extract(\"implement OAuth2 authentication\") print(keywords) ['oauth2 authentication', 'implement', 'authentication']</p> Note <p>On Python 3.13+, YAKE is automatically disabled due to a known infinite loop bug. RAKE is used as the primary extractor instead, providing similar quality with better performance.</p> <p>Initialize keyword extractor with configurable extraction methods.</p> PARAMETER DESCRIPTION <code>use_rake</code> <p>Enable RAKE extraction if available. RAKE is fast and works well with technical text. Defaults to True.</p> <p> TYPE: <code>bool</code> DEFAULT: <code>True</code> </p> <code>use_yake</code> <p>Enable YAKE extraction if available. Automatically disabled on Python 3.13+ due to compatibility issues. Defaults to True.</p> <p> TYPE: <code>bool</code> DEFAULT: <code>True</code> </p> <code>language</code> <p>Language code for extraction algorithms. Currently supports 'en' (English). Other languages may work but are not officially tested. Defaults to 'en'.</p> <p> TYPE: <code>str</code> DEFAULT: <code>'en'</code> </p> <code>use_stopwords</code> <p>Whether to filter common stopwords during extraction. This can improve keyword quality but may miss some contextual phrases. Defaults to True.</p> <p> TYPE: <code>bool</code> DEFAULT: <code>True</code> </p> <code>stopword_set</code> <p>Which stopword set to use. Options are: - 'prompt': Aggressive filtering for user prompts (200+ words) - 'code': Minimal filtering for code analysis (30 words) Defaults to 'prompt'.</p> <p> TYPE: <code>str</code> DEFAULT: <code>'prompt'</code> </p> RAISES DESCRIPTION <code>None</code> <p>Gracefully handles missing dependencies and logs warnings.</p> Note <p>The extractor automatically detects available libraries and Python version to choose the best extraction method. If RAKE and YAKE are unavailable, it falls back to TF-IDF and frequency-based extraction.</p>"},{"location":"api/tenets/core/nlp/keyword_extractor/#tenets.core.nlp.keyword_extractor.KeywordExtractor--get-keywords-with-scores","title":"Get keywords with scores","text":"<p>keywords_with_scores = extractor.extract( ...     \"implement OAuth2 authentication\", ...     include_scores=True ... ) print(keywords_with_scores) [('oauth2 authentication', 0.9), ('implement', 0.7), ...]</p>"},{"location":"api/tenets/core/nlp/keyword_extractor/#tenets.core.nlp.keyword_extractor.KeywordExtractor-functions","title":"Functions","text":""},{"location":"api/tenets/core/nlp/keyword_extractor/#tenets.core.nlp.keyword_extractor.KeywordExtractor.extract","title":"extract","text":"Python<pre><code>extract(text: str, max_keywords: int = 20, include_scores: bool = False) -&gt; Union[List[str], List[Tuple[str, float]]]\n</code></pre> <p>Extract keywords from text using the best available method.</p> <p>Attempts extraction methods in priority order (RAKE \u2192 YAKE \u2192 TF-IDF \u2192 Frequency) until one succeeds. Each method returns normalized scores between 0 and 1, with higher scores indicating more relevant keywords.</p> PARAMETER DESCRIPTION <code>text</code> <p>Input text to extract keywords from. Can be any length, but very long texts may be truncated by some algorithms.</p> <p> TYPE: <code>str</code> </p> <code>max_keywords</code> <p>Maximum number of keywords to return. Keywords are sorted by relevance score. Defaults to 20.</p> <p> TYPE: <code>int</code> DEFAULT: <code>20</code> </p> <code>include_scores</code> <p>If True, return (keyword, score) tuples. If False, return only keyword strings. Defaults to False.</p> <p> TYPE: <code>bool</code> DEFAULT: <code>False</code> </p> RETURNS DESCRIPTION <code>Union[List[str], List[Tuple[str, float]]]</code> <p>Union[List[str], List[Tuple[str, float]]]: - If include_scores=False: List of keyword strings sorted by   relevance (e.g., ['oauth2', 'authentication', 'implement']) - If include_scores=True: List of (keyword, score) tuples where   scores are normalized between 0 and 1 (e.g.,   [('oauth2', 0.95), ('authentication', 0.87), ...])</p> <p>Examples:</p> Python Console Session<pre><code>&gt;&gt;&gt; extractor = KeywordExtractor()\n&gt;&gt;&gt; # Simple keyword extraction\n&gt;&gt;&gt; keywords = extractor.extract(\"Python web framework Django\")\n&gt;&gt;&gt; print(keywords)\n['django', 'python web framework', 'web framework']\n</code></pre> Python Console Session<pre><code>&gt;&gt;&gt; # With scores for ranking\n&gt;&gt;&gt; scored = extractor.extract(\"Python web framework Django\",\n...                           max_keywords=5, include_scores=True)\n&gt;&gt;&gt; for keyword, score in scored:\n...     print(f\"{keyword}: {score:.2f}\")\ndjango: 0.95\npython web framework: 0.87\nweb framework: 0.82\n</code></pre> Note <p>Empty input returns an empty list. All extraction methods handle various text formats including code, documentation, and natural language. Scores are normalized for consistency across methods.</p>"},{"location":"api/tenets/core/nlp/keyword_extractor/#tenets.core.nlp.keyword_extractor.TFIDFCalculator","title":"TFIDFCalculator","text":"Python<pre><code>TFIDFCalculator(use_stopwords: bool = False, stopword_set: str = 'code')\n</code></pre> <p>TF-IDF calculator with code-aware tokenization.</p> <p>Implements Term Frequency-Inverse Document Frequency scoring optimized for code search. Uses vector space model with cosine similarity for ranking.</p> <p>Key features: - Code-aware tokenization using NLP tokenizers - Configurable stopword filtering - Sublinear TF scaling to reduce impact of very frequent terms - L2 normalization for cosine similarity - Efficient sparse vector representation</p> <p>Initialize TF-IDF calculator.</p> PARAMETER DESCRIPTION <code>use_stopwords</code> <p>Whether to filter stopwords</p> <p> TYPE: <code>bool</code> DEFAULT: <code>False</code> </p> <code>stopword_set</code> <p>Which stopword set to use ('code', 'prompt')</p> <p> TYPE: <code>str</code> DEFAULT: <code>'code'</code> </p>"},{"location":"api/tenets/core/nlp/keyword_extractor/#tenets.core.nlp.keyword_extractor.TFIDFCalculator-functions","title":"Functions","text":""},{"location":"api/tenets/core/nlp/keyword_extractor/#tenets.core.nlp.keyword_extractor.TFIDFCalculator.tokenize","title":"tokenize","text":"Python<pre><code>tokenize(text: str) -&gt; List[str]\n</code></pre> <p>Tokenize text using code-aware tokenizer.</p> PARAMETER DESCRIPTION <code>text</code> <p>Input text to tokenize</p> <p> TYPE: <code>str</code> </p> RETURNS DESCRIPTION <code>List[str]</code> <p>List of normalized tokens</p>"},{"location":"api/tenets/core/nlp/keyword_extractor/#tenets.core.nlp.keyword_extractor.TFIDFCalculator.compute_tf","title":"compute_tf","text":"Python<pre><code>compute_tf(tokens: List[str], use_sublinear: bool = True) -&gt; Dict[str, float]\n</code></pre> <p>Compute term frequency with optional sublinear scaling.</p> PARAMETER DESCRIPTION <code>tokens</code> <p>List of tokens from document</p> <p> TYPE: <code>List[str]</code> </p> <code>use_sublinear</code> <p>Use log scaling (1 + log(tf)) to reduce impact of           very frequent terms</p> <p> TYPE: <code>bool</code> DEFAULT: <code>True</code> </p> RETURNS DESCRIPTION <code>Dict[str, float]</code> <p>Dictionary mapping terms to TF scores</p>"},{"location":"api/tenets/core/nlp/keyword_extractor/#tenets.core.nlp.keyword_extractor.TFIDFCalculator.compute_idf","title":"compute_idf","text":"Python<pre><code>compute_idf(term: str) -&gt; float\n</code></pre> <p>Compute inverse document frequency for a term.</p> PARAMETER DESCRIPTION <code>term</code> <p>Term to compute IDF for</p> <p> TYPE: <code>str</code> </p> RETURNS DESCRIPTION <code>float</code> <p>IDF value</p>"},{"location":"api/tenets/core/nlp/keyword_extractor/#tenets.core.nlp.keyword_extractor.TFIDFCalculator.add_document","title":"add_document","text":"Python<pre><code>add_document(doc_id: str, text: str) -&gt; Dict[str, float]\n</code></pre> <p>Add document to corpus and compute TF-IDF vector.</p> PARAMETER DESCRIPTION <code>doc_id</code> <p>Unique document identifier</p> <p> TYPE: <code>str</code> </p> <code>text</code> <p>Document text content</p> <p> TYPE: <code>str</code> </p> RETURNS DESCRIPTION <code>Dict[str, float]</code> <p>TF-IDF vector for the document</p>"},{"location":"api/tenets/core/nlp/keyword_extractor/#tenets.core.nlp.keyword_extractor.TFIDFCalculator.compute_similarity","title":"compute_similarity","text":"Python<pre><code>compute_similarity(query_text: str, doc_id: str) -&gt; float\n</code></pre> <p>Compute cosine similarity between query and document.</p> PARAMETER DESCRIPTION <code>query_text</code> <p>Query text</p> <p> TYPE: <code>str</code> </p> <code>doc_id</code> <p>Document identifier</p> <p> TYPE: <code>str</code> </p> RETURNS DESCRIPTION <code>float</code> <p>Cosine similarity score (0-1)</p>"},{"location":"api/tenets/core/nlp/keyword_extractor/#tenets.core.nlp.keyword_extractor.TFIDFCalculator.build_corpus","title":"build_corpus","text":"Python<pre><code>build_corpus(documents: List[Tuple[str, str]]) -&gt; None\n</code></pre> <p>Build TF-IDF corpus from multiple documents.</p> PARAMETER DESCRIPTION <code>documents</code> <p>List of (doc_id, text) tuples</p> <p> TYPE: <code>List[Tuple[str, str]]</code> </p>"},{"location":"api/tenets/core/nlp/keyword_extractor/#tenets.core.nlp.keyword_extractor.TFIDFCalculator.get_top_terms","title":"get_top_terms","text":"Python<pre><code>get_top_terms(doc_id: str, n: int = 10) -&gt; List[Tuple[str, float]]\n</code></pre> <p>Return top-n terms by TF-IDF weight for a document.</p> PARAMETER DESCRIPTION <code>doc_id</code> <p>Document identifier</p> <p> TYPE: <code>str</code> </p> <code>n</code> <p>Max number of terms to return</p> <p> TYPE: <code>int</code> DEFAULT: <code>10</code> </p> RETURNS DESCRIPTION <code>List[Tuple[str, float]]</code> <p>List of (term, score) sorted by descending score.</p>"},{"location":"api/tenets/core/nlp/keyword_extractor/#tenets.core.nlp.keyword_extractor.BM25Calculator","title":"BM25Calculator","text":"Python<pre><code>BM25Calculator(k1: float = 1.2, b: float = 0.75, use_stopwords: bool = False, stopword_set: str = 'code')\n</code></pre> <p>BM25 ranking algorithm implementation.</p> <p>BM25 (Best Matching 25) is a probabilistic ranking function that often outperforms TF-IDF for information retrieval. Uses NLP tokenizers.</p> <p>Initialize BM25 calculator.</p> PARAMETER DESCRIPTION <code>k1</code> <p>Controls term frequency saturation</p> <p> TYPE: <code>float</code> DEFAULT: <code>1.2</code> </p> <code>b</code> <p>Controls length normalization</p> <p> TYPE: <code>float</code> DEFAULT: <code>0.75</code> </p> <code>use_stopwords</code> <p>Whether to filter stopwords</p> <p> TYPE: <code>bool</code> DEFAULT: <code>False</code> </p> <code>stopword_set</code> <p>Which stopword set to use</p> <p> TYPE: <code>str</code> DEFAULT: <code>'code'</code> </p>"},{"location":"api/tenets/core/nlp/keyword_extractor/#tenets.core.nlp.keyword_extractor.BM25Calculator-functions","title":"Functions","text":""},{"location":"api/tenets/core/nlp/keyword_extractor/#tenets.core.nlp.keyword_extractor.BM25Calculator.tokenize","title":"tokenize","text":"Python<pre><code>tokenize(text: str) -&gt; List[str]\n</code></pre> <p>Tokenize text using NLP tokenizer.</p> PARAMETER DESCRIPTION <code>text</code> <p>Input text</p> <p> TYPE: <code>str</code> </p> RETURNS DESCRIPTION <code>List[str]</code> <p>List of tokens</p>"},{"location":"api/tenets/core/nlp/keyword_extractor/#tenets.core.nlp.keyword_extractor.BM25Calculator.add_document","title":"add_document","text":"Python<pre><code>add_document(doc_id: str, text: str) -&gt; None\n</code></pre> <p>Add document to BM25 corpus.</p> PARAMETER DESCRIPTION <code>doc_id</code> <p>Unique document identifier</p> <p> TYPE: <code>str</code> </p> <code>text</code> <p>Document text content</p> <p> TYPE: <code>str</code> </p>"},{"location":"api/tenets/core/nlp/keyword_extractor/#tenets.core.nlp.keyword_extractor.BM25Calculator.compute_idf","title":"compute_idf","text":"Python<pre><code>compute_idf(term: str) -&gt; float\n</code></pre> <p>Compute IDF component for BM25.</p> PARAMETER DESCRIPTION <code>term</code> <p>Term to compute IDF for</p> <p> TYPE: <code>str</code> </p> RETURNS DESCRIPTION <code>float</code> <p>IDF value</p>"},{"location":"api/tenets/core/nlp/keyword_extractor/#tenets.core.nlp.keyword_extractor.BM25Calculator.score_document","title":"score_document","text":"Python<pre><code>score_document(query_tokens: List[str], doc_id: str) -&gt; float\n</code></pre> <p>Calculate BM25 score for a document.</p> PARAMETER DESCRIPTION <code>query_tokens</code> <p>Tokenized query</p> <p> TYPE: <code>List[str]</code> </p> <code>doc_id</code> <p>Document identifier</p> <p> TYPE: <code>str</code> </p> RETURNS DESCRIPTION <code>float</code> <p>BM25 score</p>"},{"location":"api/tenets/core/nlp/keyword_extractor/#tenets.core.nlp.keyword_extractor.BM25Calculator.search","title":"search","text":"Python<pre><code>search(query: str, top_k: int = 10) -&gt; List[Tuple[str, float]]\n</code></pre> <p>Search documents using BM25 ranking.</p> PARAMETER DESCRIPTION <code>query</code> <p>Search query</p> <p> TYPE: <code>str</code> </p> <code>top_k</code> <p>Number of top results to return</p> <p> TYPE: <code>int</code> DEFAULT: <code>10</code> </p> RETURNS DESCRIPTION <code>List[Tuple[str, float]]</code> <p>List of (doc_id, score) tuples sorted by score</p>"},{"location":"api/tenets/core/nlp/keyword_extractor/#tenets.core.nlp.keyword_extractor.BM25Calculator.build_corpus","title":"build_corpus","text":"Python<pre><code>build_corpus(documents: List[Tuple[str, str]]) -&gt; None\n</code></pre> <p>Build BM25 corpus from multiple documents.</p> PARAMETER DESCRIPTION <code>documents</code> <p>List of (doc_id, text) tuples</p> <p> TYPE: <code>List[Tuple[str, str]]</code> </p>"},{"location":"api/tenets/core/nlp/keyword_extractor/#tenets.core.nlp.keyword_extractor.TFIDFExtractor","title":"TFIDFExtractor","text":"Python<pre><code>TFIDFExtractor(use_stopwords: bool = True, stopword_set: str = 'prompt')\n</code></pre> <p>Simple TF-IDF vectorizer with NLP tokenization.</p> <p>Provides a scikit-learn-like interface with fit/transform methods returning dense vectors. Uses TextTokenizer for general text.</p> <p>Initialize the extractor.</p> PARAMETER DESCRIPTION <code>use_stopwords</code> <p>Whether to filter stopwords</p> <p> TYPE: <code>bool</code> DEFAULT: <code>True</code> </p> <code>stopword_set</code> <p>Which stopword set to use ('prompt'|'code')</p> <p> TYPE: <code>str</code> DEFAULT: <code>'prompt'</code> </p>"},{"location":"api/tenets/core/nlp/keyword_extractor/#tenets.core.nlp.keyword_extractor.TFIDFExtractor-functions","title":"Functions","text":""},{"location":"api/tenets/core/nlp/keyword_extractor/#tenets.core.nlp.keyword_extractor.TFIDFExtractor.fit","title":"fit","text":"Python<pre><code>fit(documents: List[str]) -&gt; TFIDFExtractor\n</code></pre> <p>Learn vocabulary and IDF from documents.</p> PARAMETER DESCRIPTION <code>documents</code> <p>List of input texts</p> <p> TYPE: <code>List[str]</code> </p> RETURNS DESCRIPTION <code>TFIDFExtractor</code> <p>self</p>"},{"location":"api/tenets/core/nlp/keyword_extractor/#tenets.core.nlp.keyword_extractor.TFIDFExtractor.transform","title":"transform","text":"Python<pre><code>transform(documents: List[str]) -&gt; List[List[float]]\n</code></pre> <p>Transform documents to dense TF-IDF vectors.</p> PARAMETER DESCRIPTION <code>documents</code> <p>List of input texts</p> <p> TYPE: <code>List[str]</code> </p> RETURNS DESCRIPTION <code>List[List[float]]</code> <p>List of dense vectors (each aligned to the learned vocabulary)</p>"},{"location":"api/tenets/core/nlp/keyword_extractor/#tenets.core.nlp.keyword_extractor.TFIDFExtractor.fit_transform","title":"fit_transform","text":"Python<pre><code>fit_transform(documents: List[str]) -&gt; List[List[float]]\n</code></pre> <p>Fit to documents, then transform them.</p>"},{"location":"api/tenets/core/nlp/keyword_extractor/#tenets.core.nlp.keyword_extractor.TFIDFExtractor.get_feature_names","title":"get_feature_names","text":"Python<pre><code>get_feature_names() -&gt; List[str]\n</code></pre> <p>Return the learned vocabulary as a list of feature names.</p>"},{"location":"api/tenets/core/nlp/keyword_extractor/#tenets.core.nlp.keyword_extractor-functions","title":"Functions","text":""},{"location":"api/tenets/core/nlp/ml_utils/","title":"Ml Utils","text":""},{"location":"api/tenets/core/nlp/ml_utils/#tenets.core.nlp.ml_utils","title":"tenets.core.nlp.ml_utils","text":"<p>Machine learning utilities for ranking.</p> <p>This module provides ML-based ranking capabilities using NLP components. All embedding and similarity logic is handled by the NLP package to avoid duplication.</p>"},{"location":"api/tenets/core/nlp/ml_utils/#tenets.core.nlp.ml_utils-classes","title":"Classes","text":""},{"location":"api/tenets/core/nlp/ml_utils/#tenets.core.nlp.ml_utils.EmbeddingModel","title":"EmbeddingModel","text":"Python<pre><code>EmbeddingModel(model_name: str = 'all-MiniLM-L6-v2', cache_dir: Optional[Path] = None, device: Optional[str] = None)\n</code></pre> <p>Wrapper for embedding models using NLP components.</p> <p>Provides a unified interface for different embedding models with built-in caching and batch processing capabilities.</p> <p>Initialize embedding model.</p> PARAMETER DESCRIPTION <code>model_name</code> <p>Name of the model to load</p> <p> TYPE: <code>str</code> DEFAULT: <code>'all-MiniLM-L6-v2'</code> </p> <code>cache_dir</code> <p>Directory for caching embeddings</p> <p> TYPE: <code>Optional[Path]</code> DEFAULT: <code>None</code> </p> <code>device</code> <p>Device to run on ('cpu', 'cuda', or None for auto)</p> <p> TYPE: <code>Optional[str]</code> DEFAULT: <code>None</code> </p>"},{"location":"api/tenets/core/nlp/ml_utils/#tenets.core.nlp.ml_utils.EmbeddingModel-functions","title":"Functions","text":""},{"location":"api/tenets/core/nlp/ml_utils/#tenets.core.nlp.ml_utils.EmbeddingModel.encode","title":"encode","text":"Python<pre><code>encode(texts: Union[str, List[str]], batch_size: int = 32, show_progress: bool = False, use_cache: bool = True) -&gt; Union[list, Any]\n</code></pre> <p>Encode texts to embeddings.</p> PARAMETER DESCRIPTION <code>texts</code> <p>Text or list of texts to encode</p> <p> TYPE: <code>Union[str, List[str]]</code> </p> <code>batch_size</code> <p>Batch size for encoding</p> <p> TYPE: <code>int</code> DEFAULT: <code>32</code> </p> <code>show_progress</code> <p>Show progress bar</p> <p> TYPE: <code>bool</code> DEFAULT: <code>False</code> </p> <code>use_cache</code> <p>Use cached embeddings if available</p> <p> TYPE: <code>bool</code> DEFAULT: <code>True</code> </p> RETURNS DESCRIPTION <code>Union[list, Any]</code> <p>Numpy array of embeddings or fallback list</p>"},{"location":"api/tenets/core/nlp/ml_utils/#tenets.core.nlp.ml_utils.NeuralReranker","title":"NeuralReranker","text":"Python<pre><code>NeuralReranker(model_name: str = 'cross-encoder/ms-marco-MiniLM-L-6-v2')\n</code></pre> <p>Neural reranking model for improved ranking.</p> <p>Uses cross-encoder models to rerank initial results for better accuracy. This is more accurate than bi-encoders but slower.</p> <p>Initialize reranker.</p> PARAMETER DESCRIPTION <code>model_name</code> <p>Cross-encoder model name</p> <p> TYPE: <code>str</code> DEFAULT: <code>'cross-encoder/ms-marco-MiniLM-L-6-v2'</code> </p>"},{"location":"api/tenets/core/nlp/ml_utils/#tenets.core.nlp.ml_utils.NeuralReranker-functions","title":"Functions","text":""},{"location":"api/tenets/core/nlp/ml_utils/#tenets.core.nlp.ml_utils.NeuralReranker.rerank","title":"rerank","text":"Python<pre><code>rerank(query: str, documents: List[Tuple[str, float]], top_k: int = 10) -&gt; List[Tuple[str, float]]\n</code></pre> <p>Rerank documents using cross-encoder.</p> PARAMETER DESCRIPTION <code>query</code> <p>Query text</p> <p> TYPE: <code>str</code> </p> <code>documents</code> <p>List of (document_text, initial_score) tuples</p> <p> TYPE: <code>List[Tuple[str, float]]</code> </p> <code>top_k</code> <p>Number of top results to rerank</p> <p> TYPE: <code>int</code> DEFAULT: <code>10</code> </p> RETURNS DESCRIPTION <code>List[Tuple[str, float]]</code> <p>Reranked list of (document_text, score) tuples</p>"},{"location":"api/tenets/core/nlp/ml_utils/#tenets.core.nlp.ml_utils-functions","title":"Functions","text":""},{"location":"api/tenets/core/nlp/ml_utils/#tenets.core.nlp.ml_utils.cosine_similarity","title":"cosine_similarity","text":"Python<pre><code>cosine_similarity(vec1, vec2) -&gt; float\n</code></pre> <p>Compute cosine similarity between two vectors.</p> PARAMETER DESCRIPTION <code>vec1</code> <p>First vector (can be list, array, or dict for sparse vectors)</p> <p> </p> <code>vec2</code> <p>Second vector (can be list, array, or dict for sparse vectors)</p> <p> </p> RETURNS DESCRIPTION <code>float</code> <p>Cosine similarity (-1 to 1)</p>"},{"location":"api/tenets/core/nlp/ml_utils/#tenets.core.nlp.ml_utils.load_embedding_model","title":"load_embedding_model","text":"Python<pre><code>load_embedding_model(model_name: Optional[str] = None, cache_dir: Optional[Path] = None, device: Optional[str] = None) -&gt; Optional[EmbeddingModel]\n</code></pre> <p>Load an embedding model.</p> PARAMETER DESCRIPTION <code>model_name</code> <p>Model name (default: all-MiniLM-L6-v2)</p> <p> TYPE: <code>Optional[str]</code> DEFAULT: <code>None</code> </p> <code>cache_dir</code> <p>Directory for caching</p> <p> TYPE: <code>Optional[Path]</code> DEFAULT: <code>None</code> </p> <code>device</code> <p>Device to run on</p> <p> TYPE: <code>Optional[str]</code> DEFAULT: <code>None</code> </p> RETURNS DESCRIPTION <code>Optional[EmbeddingModel]</code> <p>EmbeddingModel instance or None if unavailable</p>"},{"location":"api/tenets/core/nlp/ml_utils/#tenets.core.nlp.ml_utils.compute_similarity","title":"compute_similarity","text":"Python<pre><code>compute_similarity(model: EmbeddingModel, text1: str, text2: str, cache: Optional[Dict[str, Any]] = None) -&gt; float\n</code></pre> <p>Compute semantic similarity between two texts.</p> PARAMETER DESCRIPTION <code>model</code> <p>Embedding model</p> <p> TYPE: <code>EmbeddingModel</code> </p> <code>text1</code> <p>First text</p> <p> TYPE: <code>str</code> </p> <code>text2</code> <p>Second text</p> <p> TYPE: <code>str</code> </p> <code>cache</code> <p>Optional cache dictionary (unused, for API compatibility)</p> <p> TYPE: <code>Optional[Dict[str, Any]]</code> DEFAULT: <code>None</code> </p> RETURNS DESCRIPTION <code>float</code> <p>Similarity score (0-1)</p>"},{"location":"api/tenets/core/nlp/ml_utils/#tenets.core.nlp.ml_utils.batch_similarity","title":"batch_similarity","text":"Python<pre><code>batch_similarity(model: EmbeddingModel, query: str, documents: List[str], batch_size: int = 32) -&gt; List[float]\n</code></pre> <p>Compute similarity between query and multiple documents.</p> PARAMETER DESCRIPTION <code>model</code> <p>Embedding model</p> <p> TYPE: <code>EmbeddingModel</code> </p> <code>query</code> <p>Query text</p> <p> TYPE: <code>str</code> </p> <code>documents</code> <p>List of documents</p> <p> TYPE: <code>List[str]</code> </p> <code>batch_size</code> <p>Batch size for encoding</p> <p> TYPE: <code>int</code> DEFAULT: <code>32</code> </p> RETURNS DESCRIPTION <code>List[float]</code> <p>List of similarity scores</p>"},{"location":"api/tenets/core/nlp/ml_utils/#tenets.core.nlp.ml_utils.check_ml_dependencies","title":"check_ml_dependencies","text":"Python<pre><code>check_ml_dependencies() -&gt; Dict[str, bool]\n</code></pre> <p>Check which ML dependencies are available.</p> RETURNS DESCRIPTION <code>Dict[str, bool]</code> <p>Dictionary of dependency availability</p>"},{"location":"api/tenets/core/nlp/ml_utils/#tenets.core.nlp.ml_utils.get_available_models","title":"get_available_models","text":"Python<pre><code>get_available_models() -&gt; List[str]\n</code></pre> <p>Get list of available embedding models.</p> RETURNS DESCRIPTION <code>List[str]</code> <p>List of model names</p>"},{"location":"api/tenets/core/nlp/ml_utils/#tenets.core.nlp.ml_utils.estimate_embedding_memory","title":"estimate_embedding_memory","text":"Python<pre><code>estimate_embedding_memory(num_files: int, embedding_dim: int = 384) -&gt; Dict[str, float]\n</code></pre> <p>Estimate memory requirements for embeddings.</p> PARAMETER DESCRIPTION <code>num_files</code> <p>Number of files to embed</p> <p> TYPE: <code>int</code> </p> <code>embedding_dim</code> <p>Dimension of embeddings</p> <p> TYPE: <code>int</code> DEFAULT: <code>384</code> </p> RETURNS DESCRIPTION <code>Dict[str, float]</code> <p>Dictionary with memory estimates</p>"},{"location":"api/tenets/core/nlp/programming_patterns/","title":"Programming Patterns","text":""},{"location":"api/tenets/core/nlp/programming_patterns/#tenets.core.nlp.programming_patterns","title":"tenets.core.nlp.programming_patterns","text":"<p>Centralized programming patterns loader for NLP.</p> <p>This module loads programming patterns from the JSON file and provides utilities for pattern matching. Consolidates duplicate logic from parser.py and strategies.py.</p>"},{"location":"api/tenets/core/nlp/programming_patterns/#tenets.core.nlp.programming_patterns-classes","title":"Classes","text":""},{"location":"api/tenets/core/nlp/programming_patterns/#tenets.core.nlp.programming_patterns.ProgrammingPatterns","title":"ProgrammingPatterns","text":"Python<pre><code>ProgrammingPatterns(patterns_file: Optional[Path] = None)\n</code></pre> <p>Loads and manages programming patterns from JSON.</p> <p>This class provides centralized access to programming patterns, eliminating duplication between parser.py and strategies.py.</p> ATTRIBUTE DESCRIPTION <code>patterns</code> <p>Dictionary of pattern categories loaded from JSON</p> <p> </p> <code>logger</code> <p>Logger instance</p> <p> </p> <code>compiled_patterns</code> <p>Cache of compiled regex patterns</p> <p> </p> <p>Initialize programming patterns from JSON file.</p> PARAMETER DESCRIPTION <code>patterns_file</code> <p>Path to patterns JSON file (uses default if None)</p> <p> TYPE: <code>Optional[Path]</code> DEFAULT: <code>None</code> </p>"},{"location":"api/tenets/core/nlp/programming_patterns/#tenets.core.nlp.programming_patterns.ProgrammingPatterns-functions","title":"Functions","text":""},{"location":"api/tenets/core/nlp/programming_patterns/#tenets.core.nlp.programming_patterns.ProgrammingPatterns.extract_programming_keywords","title":"extract_programming_keywords","text":"Python<pre><code>extract_programming_keywords(text: str) -&gt; List[str]\n</code></pre> <p>Extract programming-specific keywords from text.</p> <p>This replaces the duplicate methods in parser.py and strategies.py.</p> PARAMETER DESCRIPTION <code>text</code> <p>Input text to extract keywords from</p> <p> TYPE: <code>str</code> </p> RETURNS DESCRIPTION <code>List[str]</code> <p>List of unique programming keywords found</p>"},{"location":"api/tenets/core/nlp/programming_patterns/#tenets.core.nlp.programming_patterns.ProgrammingPatterns.analyze_code_patterns","title":"analyze_code_patterns","text":"Python<pre><code>analyze_code_patterns(content: str, keywords: List[str]) -&gt; Dict[str, float]\n</code></pre> <p>Analyze code for pattern matches and scoring.</p> PARAMETER DESCRIPTION <code>content</code> <p>File content to analyze</p> <p> TYPE: <code>str</code> </p> <code>keywords</code> <p>Keywords from prompt for relevance checking</p> <p> TYPE: <code>List[str]</code> </p> RETURNS DESCRIPTION <code>Dict[str, float]</code> <p>Dictionary of pattern scores by category</p>"},{"location":"api/tenets/core/nlp/programming_patterns/#tenets.core.nlp.programming_patterns.ProgrammingPatterns.get_pattern_categories","title":"get_pattern_categories","text":"Python<pre><code>get_pattern_categories() -&gt; List[str]\n</code></pre> <p>Get list of all pattern categories.</p> RETURNS DESCRIPTION <code>List[str]</code> <p>List of category names</p>"},{"location":"api/tenets/core/nlp/programming_patterns/#tenets.core.nlp.programming_patterns.ProgrammingPatterns.get_category_keywords","title":"get_category_keywords","text":"Python<pre><code>get_category_keywords(category: str) -&gt; List[str]\n</code></pre> <p>Get keywords for a specific category.</p> PARAMETER DESCRIPTION <code>category</code> <p>Category name</p> <p> TYPE: <code>str</code> </p> RETURNS DESCRIPTION <code>List[str]</code> <p>List of keywords for the category</p>"},{"location":"api/tenets/core/nlp/programming_patterns/#tenets.core.nlp.programming_patterns.ProgrammingPatterns.get_category_importance","title":"get_category_importance","text":"Python<pre><code>get_category_importance(category: str) -&gt; float\n</code></pre> <p>Get importance score for a category.</p> PARAMETER DESCRIPTION <code>category</code> <p>Category name</p> <p> TYPE: <code>str</code> </p> RETURNS DESCRIPTION <code>float</code> <p>Importance score (0-1)</p>"},{"location":"api/tenets/core/nlp/programming_patterns/#tenets.core.nlp.programming_patterns.ProgrammingPatterns.match_patterns","title":"match_patterns","text":"Python<pre><code>match_patterns(text: str, category: str) -&gt; List[Tuple[str, int, int]]\n</code></pre> <p>Find all pattern matches in text for a category.</p> PARAMETER DESCRIPTION <code>text</code> <p>Text to search</p> <p> TYPE: <code>str</code> </p> <code>category</code> <p>Pattern category</p> <p> TYPE: <code>str</code> </p> RETURNS DESCRIPTION <code>List[Tuple[str, int, int]]</code> <p>List of (matched_text, start_pos, end_pos) tuples</p>"},{"location":"api/tenets/core/nlp/programming_patterns/#tenets.core.nlp.programming_patterns-functions","title":"Functions","text":""},{"location":"api/tenets/core/nlp/programming_patterns/#tenets.core.nlp.programming_patterns.get_programming_patterns","title":"get_programming_patterns","text":"Python<pre><code>get_programming_patterns() -&gt; ProgrammingPatterns\n</code></pre> <p>Get singleton instance of programming patterns.</p> RETURNS DESCRIPTION <code>ProgrammingPatterns</code> <p>ProgrammingPatterns instance</p>"},{"location":"api/tenets/core/nlp/programming_patterns/#tenets.core.nlp.programming_patterns.extract_programming_keywords","title":"extract_programming_keywords","text":"Python<pre><code>extract_programming_keywords(text: str) -&gt; List[str]\n</code></pre> <p>Convenience function to extract programming keywords.</p> PARAMETER DESCRIPTION <code>text</code> <p>Input text</p> <p> TYPE: <code>str</code> </p> RETURNS DESCRIPTION <code>List[str]</code> <p>List of programming keywords</p>"},{"location":"api/tenets/core/nlp/programming_patterns/#tenets.core.nlp.programming_patterns.analyze_code_patterns","title":"analyze_code_patterns","text":"Python<pre><code>analyze_code_patterns(content: str, keywords: List[str]) -&gt; Dict[str, float]\n</code></pre> <p>Convenience function to analyze code patterns.</p> PARAMETER DESCRIPTION <code>content</code> <p>File content</p> <p> TYPE: <code>str</code> </p> <code>keywords</code> <p>Prompt keywords</p> <p> TYPE: <code>List[str]</code> </p> RETURNS DESCRIPTION <code>Dict[str, float]</code> <p>Dictionary of pattern scores</p>"},{"location":"api/tenets/core/nlp/similarity/","title":"Similarity","text":""},{"location":"api/tenets/core/nlp/similarity/#tenets.core.nlp.similarity","title":"tenets.core.nlp.similarity","text":"<p>Similarity computation utilities.</p> <p>This module provides various similarity metrics including cosine similarity and semantic similarity using embeddings.</p>"},{"location":"api/tenets/core/nlp/similarity/#tenets.core.nlp.similarity-classes","title":"Classes","text":""},{"location":"api/tenets/core/nlp/similarity/#tenets.core.nlp.similarity.SemanticSimilarity","title":"SemanticSimilarity","text":"Python<pre><code>SemanticSimilarity(model: Optional[object] = None, cache_embeddings: bool = True)\n</code></pre> <p>Compute semantic similarity using embeddings.</p> <p>Initialize semantic similarity.</p> PARAMETER DESCRIPTION <code>model</code> <p>Embedding model to use (creates default if None)</p> <p> TYPE: <code>Optional[object]</code> DEFAULT: <code>None</code> </p> <code>cache_embeddings</code> <p>Cache computed embeddings</p> <p> TYPE: <code>bool</code> DEFAULT: <code>True</code> </p>"},{"location":"api/tenets/core/nlp/similarity/#tenets.core.nlp.similarity.SemanticSimilarity-functions","title":"Functions","text":""},{"location":"api/tenets/core/nlp/similarity/#tenets.core.nlp.similarity.SemanticSimilarity.compute","title":"compute","text":"Python<pre><code>compute(text1: str, text2: str, metric: str = 'cosine') -&gt; float\n</code></pre> <p>Compute semantic similarity between two texts.</p> PARAMETER DESCRIPTION <code>text1</code> <p>First text</p> <p> TYPE: <code>str</code> </p> <code>text2</code> <p>Second text</p> <p> TYPE: <code>str</code> </p> <code>metric</code> <p>Similarity metric ('cosine', 'euclidean', 'manhattan')</p> <p> TYPE: <code>str</code> DEFAULT: <code>'cosine'</code> </p> RETURNS DESCRIPTION <code>float</code> <p>Similarity score</p>"},{"location":"api/tenets/core/nlp/similarity/#tenets.core.nlp.similarity.SemanticSimilarity.compute_batch","title":"compute_batch","text":"Python<pre><code>compute_batch(query: str, documents: List[str], metric: str = 'cosine', top_k: Optional[int] = None) -&gt; List[Tuple[int, float]]\n</code></pre> <p>Compute similarity between query and multiple documents.</p> PARAMETER DESCRIPTION <code>query</code> <p>Query text</p> <p> TYPE: <code>str</code> </p> <code>documents</code> <p>List of documents</p> <p> TYPE: <code>List[str]</code> </p> <code>metric</code> <p>Similarity metric</p> <p> TYPE: <code>str</code> DEFAULT: <code>'cosine'</code> </p> <code>top_k</code> <p>Return only top K results</p> <p> TYPE: <code>Optional[int]</code> DEFAULT: <code>None</code> </p> RETURNS DESCRIPTION <code>List[Tuple[int, float]]</code> <p>List of (index, similarity) tuples sorted by similarity</p>"},{"location":"api/tenets/core/nlp/similarity/#tenets.core.nlp.similarity.SemanticSimilarity.find_similar","title":"find_similar","text":"Python<pre><code>find_similar(query: str, documents: List[str], threshold: float = 0.7, metric: str = 'cosine') -&gt; List[Tuple[int, float]]\n</code></pre> <p>Find documents similar to query above threshold.</p> PARAMETER DESCRIPTION <code>query</code> <p>Query text</p> <p> TYPE: <code>str</code> </p> <code>documents</code> <p>List of documents</p> <p> TYPE: <code>List[str]</code> </p> <code>threshold</code> <p>Similarity threshold</p> <p> TYPE: <code>float</code> DEFAULT: <code>0.7</code> </p> <code>metric</code> <p>Similarity metric</p> <p> TYPE: <code>str</code> DEFAULT: <code>'cosine'</code> </p> RETURNS DESCRIPTION <code>List[Tuple[int, float]]</code> <p>List of (index, similarity) for documents above threshold</p>"},{"location":"api/tenets/core/nlp/similarity/#tenets.core.nlp.similarity.SemanticSimilarity.clear_cache","title":"clear_cache","text":"Python<pre><code>clear_cache()\n</code></pre> <p>Clear embedding cache.</p>"},{"location":"api/tenets/core/nlp/similarity/#tenets.core.nlp.similarity-functions","title":"Functions","text":""},{"location":"api/tenets/core/nlp/similarity/#tenets.core.nlp.similarity.cosine_similarity","title":"cosine_similarity","text":"Python<pre><code>cosine_similarity(vec1, vec2) -&gt; float\n</code></pre> <p>Compute cosine similarity between two vectors.</p> PARAMETER DESCRIPTION <code>vec1</code> <p>First vector (can be list, array, or dict for sparse vectors)</p> <p> </p> <code>vec2</code> <p>Second vector (can be list, array, or dict for sparse vectors)</p> <p> </p> RETURNS DESCRIPTION <code>float</code> <p>Cosine similarity (-1 to 1)</p>"},{"location":"api/tenets/core/nlp/similarity/#tenets.core.nlp.similarity.sparse_cosine_similarity","title":"sparse_cosine_similarity","text":"Python<pre><code>sparse_cosine_similarity(vec1: dict, vec2: dict) -&gt; float\n</code></pre> <p>Compute cosine similarity between two sparse vectors.</p> <p>Sparse vectors are represented as dictionaries mapping indices/keys to values. This is efficient for high-dimensional vectors with many zero values.</p> PARAMETER DESCRIPTION <code>vec1</code> <p>First sparse vector as {key: value} dict</p> <p> TYPE: <code>dict</code> </p> <code>vec2</code> <p>Second sparse vector as {key: value} dict</p> <p> TYPE: <code>dict</code> </p> RETURNS DESCRIPTION <code>float</code> <p>Cosine similarity (-1 to 1)</p>"},{"location":"api/tenets/core/nlp/similarity/#tenets.core.nlp.similarity.euclidean_distance","title":"euclidean_distance","text":"Python<pre><code>euclidean_distance(vec1, vec2) -&gt; float\n</code></pre> <p>Compute Euclidean distance between two vectors.</p> PARAMETER DESCRIPTION <code>vec1</code> <p>First vector</p> <p> </p> <code>vec2</code> <p>Second vector</p> <p> </p> RETURNS DESCRIPTION <code>float</code> <p>Euclidean distance (&gt;= 0)</p>"},{"location":"api/tenets/core/nlp/similarity/#tenets.core.nlp.similarity.manhattan_distance","title":"manhattan_distance","text":"Python<pre><code>manhattan_distance(vec1, vec2) -&gt; float\n</code></pre> <p>Compute Manhattan (L1) distance between two vectors.</p> PARAMETER DESCRIPTION <code>vec1</code> <p>First vector</p> <p> </p> <code>vec2</code> <p>Second vector</p> <p> </p> RETURNS DESCRIPTION <code>float</code> <p>Manhattan distance (&gt;= 0)</p>"},{"location":"api/tenets/core/nlp/stopwords/","title":"Stopwords","text":""},{"location":"api/tenets/core/nlp/stopwords/#tenets.core.nlp.stopwords","title":"tenets.core.nlp.stopwords","text":"<p>Stopword management for different contexts.</p> <p>This module manages multiple stopword sets for different purposes: - Minimal set for code search (preserve accuracy) - Aggressive set for prompt parsing (extract intent) - Custom sets for specific domains</p>"},{"location":"api/tenets/core/nlp/stopwords/#tenets.core.nlp.stopwords-classes","title":"Classes","text":""},{"location":"api/tenets/core/nlp/stopwords/#tenets.core.nlp.stopwords.StopwordSet","title":"StopwordSet  <code>dataclass</code>","text":"Python<pre><code>StopwordSet(name: str, words: Set[str], description: str, source_file: Optional[Path] = None)\n</code></pre> <p>A set of stopwords with metadata.</p> ATTRIBUTE DESCRIPTION <code>name</code> <p>Name of this stopword set</p> <p> TYPE: <code>str</code> </p> <code>words</code> <p>Set of stopword strings</p> <p> TYPE: <code>Set[str]</code> </p> <code>description</code> <p>What this set is used for</p> <p> TYPE: <code>str</code> </p> <code>source_file</code> <p>Path to source file</p> <p> TYPE: <code>Optional[Path]</code> </p>"},{"location":"api/tenets/core/nlp/stopwords/#tenets.core.nlp.stopwords.StopwordSet-functions","title":"Functions","text":""},{"location":"api/tenets/core/nlp/stopwords/#tenets.core.nlp.stopwords.StopwordSet.filter","title":"filter","text":"Python<pre><code>filter(words: List[str]) -&gt; List[str]\n</code></pre> <p>Filter stopwords from word list.</p> PARAMETER DESCRIPTION <code>words</code> <p>List of words to filter</p> <p> TYPE: <code>List[str]</code> </p> RETURNS DESCRIPTION <code>List[str]</code> <p>Filtered list without stopwords</p>"},{"location":"api/tenets/core/nlp/stopwords/#tenets.core.nlp.stopwords.StopwordManager","title":"StopwordManager","text":"Python<pre><code>StopwordManager(data_dir: Optional[Path] = None)\n</code></pre> <p>Manages multiple stopword sets for different contexts.</p> <p>Initialize stopword manager.</p> PARAMETER DESCRIPTION <code>data_dir</code> <p>Directory containing stopword files</p> <p> TYPE: <code>Optional[Path]</code> DEFAULT: <code>None</code> </p>"},{"location":"api/tenets/core/nlp/stopwords/#tenets.core.nlp.stopwords.StopwordManager-functions","title":"Functions","text":""},{"location":"api/tenets/core/nlp/stopwords/#tenets.core.nlp.stopwords.StopwordManager.get_set","title":"get_set","text":"Python<pre><code>get_set(name: str) -&gt; Optional[StopwordSet]\n</code></pre> <p>Get a stopword set by name.</p> PARAMETER DESCRIPTION <code>name</code> <p>Name of stopword set ('code', 'prompt', etc.)</p> <p> TYPE: <code>str</code> </p> RETURNS DESCRIPTION <code>Optional[StopwordSet]</code> <p>StopwordSet or None if not found</p>"},{"location":"api/tenets/core/nlp/stopwords/#tenets.core.nlp.stopwords.StopwordManager.add_custom_set","title":"add_custom_set","text":"Python<pre><code>add_custom_set(name: str, words: Set[str], description: str = '') -&gt; StopwordSet\n</code></pre> <p>Add a custom stopword set.</p> PARAMETER DESCRIPTION <code>name</code> <p>Name for the set</p> <p> TYPE: <code>str</code> </p> <code>words</code> <p>Set of stopword strings</p> <p> TYPE: <code>Set[str]</code> </p> <code>description</code> <p>What this set is for</p> <p> TYPE: <code>str</code> DEFAULT: <code>''</code> </p> RETURNS DESCRIPTION <code>StopwordSet</code> <p>Created StopwordSet</p>"},{"location":"api/tenets/core/nlp/stopwords/#tenets.core.nlp.stopwords.StopwordManager.combine_sets","title":"combine_sets","text":"Python<pre><code>combine_sets(sets: List[str], name: str = 'combined') -&gt; StopwordSet\n</code></pre> <p>Combine multiple stopword sets.</p> PARAMETER DESCRIPTION <code>sets</code> <p>Names of sets to combine</p> <p> TYPE: <code>List[str]</code> </p> <code>name</code> <p>Name for combined set</p> <p> TYPE: <code>str</code> DEFAULT: <code>'combined'</code> </p> RETURNS DESCRIPTION <code>StopwordSet</code> <p>Combined StopwordSet</p>"},{"location":"api/tenets/core/nlp/stopwords/#tenets.core.nlp.stopwords-functions","title":"Functions","text":""},{"location":"api/tenets/core/nlp/tfidf/","title":"Tfidf","text":""},{"location":"api/tenets/core/nlp/tfidf/#tenets.core.nlp.tfidf","title":"tenets.core.nlp.tfidf","text":"<p>TF-IDF calculator for relevance ranking.</p> <p>This module provides TF-IDF text similarity as an optional fallback to the primary BM25 ranking algorithm. The TF-IDF implementation reuses centralized logic from keyword_extractor.</p>"},{"location":"api/tenets/core/nlp/tfidf/#tenets.core.nlp.tfidf-classes","title":"Classes","text":""},{"location":"api/tenets/core/nlp/tfidf/#tenets.core.nlp.tfidf.TFIDFCalculator","title":"TFIDFCalculator","text":"Python<pre><code>TFIDFCalculator(use_stopwords: bool = False)\n</code></pre> <p>TF-IDF calculator for ranking.</p> <p>Simplified wrapper around NLP TFIDFCalculator to maintain existing ranking API while using centralized logic.</p> <p>Initialize TF-IDF calculator.</p> PARAMETER DESCRIPTION <code>use_stopwords</code> <p>Whether to filter stopwords (uses 'code' set)</p> <p> TYPE: <code>bool</code> DEFAULT: <code>False</code> </p>"},{"location":"api/tenets/core/nlp/tfidf/#tenets.core.nlp.tfidf.TFIDFCalculator-attributes","title":"Attributes","text":""},{"location":"api/tenets/core/nlp/tfidf/#tenets.core.nlp.tfidf.TFIDFCalculator.document_vectors","title":"document_vectors  <code>property</code>","text":"Python<pre><code>document_vectors: Dict[str, Dict[str, float]]\n</code></pre> <p>Get document vectors.</p>"},{"location":"api/tenets/core/nlp/tfidf/#tenets.core.nlp.tfidf.TFIDFCalculator.document_norms","title":"document_norms  <code>property</code>","text":"Python<pre><code>document_norms: Dict[str, float]\n</code></pre> <p>Get document vector norms.</p>"},{"location":"api/tenets/core/nlp/tfidf/#tenets.core.nlp.tfidf.TFIDFCalculator.vocabulary","title":"vocabulary  <code>property</code>","text":"Python<pre><code>vocabulary: set\n</code></pre> <p>Get vocabulary.</p>"},{"location":"api/tenets/core/nlp/tfidf/#tenets.core.nlp.tfidf.TFIDFCalculator-functions","title":"Functions","text":""},{"location":"api/tenets/core/nlp/tfidf/#tenets.core.nlp.tfidf.TFIDFCalculator.tokenize","title":"tokenize","text":"Python<pre><code>tokenize(text: str) -&gt; List[str]\n</code></pre> <p>Tokenize text using NLP tokenizer.</p> PARAMETER DESCRIPTION <code>text</code> <p>Input text</p> <p> TYPE: <code>str</code> </p> RETURNS DESCRIPTION <code>List[str]</code> <p>List of tokens</p>"},{"location":"api/tenets/core/nlp/tfidf/#tenets.core.nlp.tfidf.TFIDFCalculator.add_document","title":"add_document","text":"Python<pre><code>add_document(doc_id: str, text: str) -&gt; Dict[str, float]\n</code></pre> <p>Add document to corpus.</p> PARAMETER DESCRIPTION <code>doc_id</code> <p>Document identifier</p> <p> TYPE: <code>str</code> </p> <code>text</code> <p>Document content</p> <p> TYPE: <code>str</code> </p> RETURNS DESCRIPTION <code>Dict[str, float]</code> <p>TF-IDF vector for document</p>"},{"location":"api/tenets/core/nlp/tfidf/#tenets.core.nlp.tfidf.TFIDFCalculator.compute_similarity","title":"compute_similarity","text":"Python<pre><code>compute_similarity(query_text: str, doc_id: str) -&gt; float\n</code></pre> <p>Compute similarity between query and document.</p> PARAMETER DESCRIPTION <code>query_text</code> <p>Query text</p> <p> TYPE: <code>str</code> </p> <code>doc_id</code> <p>Document identifier</p> <p> TYPE: <code>str</code> </p> RETURNS DESCRIPTION <code>float</code> <p>Cosine similarity score (0-1)</p>"},{"location":"api/tenets/core/nlp/tfidf/#tenets.core.nlp.tfidf.TFIDFCalculator.get_top_terms","title":"get_top_terms","text":"Python<pre><code>get_top_terms(doc_id: str, n: int = 10) -&gt; List[Tuple[str, float]]\n</code></pre> <p>Return the top-n TF-IDF terms for a given document.</p> PARAMETER DESCRIPTION <code>doc_id</code> <p>Document identifier</p> <p> TYPE: <code>str</code> </p> <code>n</code> <p>Maximum number of terms to return</p> <p> TYPE: <code>int</code> DEFAULT: <code>10</code> </p> RETURNS DESCRIPTION <code>List[Tuple[str, float]]</code> <p>List of (term, score) sorted by score descending</p>"},{"location":"api/tenets/core/nlp/tfidf/#tenets.core.nlp.tfidf.TFIDFCalculator.build_corpus","title":"build_corpus","text":"Python<pre><code>build_corpus(documents: List[Tuple[str, str]]) -&gt; None\n</code></pre> <p>Build corpus from documents.</p> PARAMETER DESCRIPTION <code>documents</code> <p>List of (doc_id, text) tuples</p> <p> TYPE: <code>List[Tuple[str, str]]</code> </p>"},{"location":"api/tenets/core/nlp/tfidf/#tenets.core.nlp.tfidf-functions","title":"Functions","text":""},{"location":"api/tenets/core/nlp/tokenizer/","title":"Tokenizer","text":""},{"location":"api/tenets/core/nlp/tokenizer/#tenets.core.nlp.tokenizer","title":"tenets.core.nlp.tokenizer","text":"<p>Tokenization utilities for code and text.</p> <p>This module provides tokenizers that understand programming language constructs and can handle camelCase, snake_case, and other patterns.</p>"},{"location":"api/tenets/core/nlp/tokenizer/#tenets.core.nlp.tokenizer-classes","title":"Classes","text":""},{"location":"api/tenets/core/nlp/tokenizer/#tenets.core.nlp.tokenizer.CodeTokenizer","title":"CodeTokenizer","text":"Python<pre><code>CodeTokenizer(use_stopwords: bool = False)\n</code></pre> <p>Tokenizer optimized for source code.</p> <p>Handles: - camelCase and PascalCase splitting - snake_case splitting - Preserves original tokens for exact matching - Language-specific keywords - Optional stopword filtering</p> <p>Initialize code tokenizer.</p> PARAMETER DESCRIPTION <code>use_stopwords</code> <p>Whether to filter stopwords</p> <p> TYPE: <code>bool</code> DEFAULT: <code>False</code> </p>"},{"location":"api/tenets/core/nlp/tokenizer/#tenets.core.nlp.tokenizer.CodeTokenizer-functions","title":"Functions","text":""},{"location":"api/tenets/core/nlp/tokenizer/#tenets.core.nlp.tokenizer.CodeTokenizer.tokenize","title":"tokenize","text":"Python<pre><code>tokenize(text: str, language: Optional[str] = None, preserve_original: bool = True) -&gt; List[str]\n</code></pre> <p>Tokenize code text.</p> PARAMETER DESCRIPTION <code>text</code> <p>Code to tokenize</p> <p> TYPE: <code>str</code> </p> <code>language</code> <p>Programming language (for language-specific handling)</p> <p> TYPE: <code>Optional[str]</code> DEFAULT: <code>None</code> </p> <code>preserve_original</code> <p>Keep original tokens alongside splits</p> <p> TYPE: <code>bool</code> DEFAULT: <code>True</code> </p> RETURNS DESCRIPTION <code>List[str]</code> <p>List of tokens</p>"},{"location":"api/tenets/core/nlp/tokenizer/#tenets.core.nlp.tokenizer.CodeTokenizer.tokenize_identifier","title":"tokenize_identifier","text":"Python<pre><code>tokenize_identifier(identifier: str) -&gt; List[str]\n</code></pre> <p>Tokenize a single identifier (function/class/variable name).</p> PARAMETER DESCRIPTION <code>identifier</code> <p>Identifier to tokenize</p> <p> TYPE: <code>str</code> </p> RETURNS DESCRIPTION <code>List[str]</code> <p>List of component tokens</p>"},{"location":"api/tenets/core/nlp/tokenizer/#tenets.core.nlp.tokenizer.TextTokenizer","title":"TextTokenizer","text":"Python<pre><code>TextTokenizer(use_stopwords: bool = True)\n</code></pre> <p>Tokenizer for natural language text (prompts, comments, docs).</p> <p>More aggressive than CodeTokenizer, designed for understanding user intent rather than exact matching.</p> <p>Initialize text tokenizer.</p> PARAMETER DESCRIPTION <code>use_stopwords</code> <p>Whether to filter stopwords (default True)</p> <p> TYPE: <code>bool</code> DEFAULT: <code>True</code> </p>"},{"location":"api/tenets/core/nlp/tokenizer/#tenets.core.nlp.tokenizer.TextTokenizer-functions","title":"Functions","text":""},{"location":"api/tenets/core/nlp/tokenizer/#tenets.core.nlp.tokenizer.TextTokenizer.tokenize","title":"tokenize","text":"Python<pre><code>tokenize(text: str, min_length: int = 2) -&gt; List[str]\n</code></pre> <p>Tokenize natural language text.</p> PARAMETER DESCRIPTION <code>text</code> <p>Text to tokenize</p> <p> TYPE: <code>str</code> </p> <code>min_length</code> <p>Minimum token length</p> <p> TYPE: <code>int</code> DEFAULT: <code>2</code> </p> RETURNS DESCRIPTION <code>List[str]</code> <p>List of tokens</p>"},{"location":"api/tenets/core/nlp/tokenizer/#tenets.core.nlp.tokenizer.TextTokenizer.extract_ngrams","title":"extract_ngrams","text":"Python<pre><code>extract_ngrams(text: str, n: int = 2) -&gt; List[str]\n</code></pre> <p>Extract n-grams from text.</p> PARAMETER DESCRIPTION <code>text</code> <p>Input text</p> <p> TYPE: <code>str</code> </p> <code>n</code> <p>Size of n-grams</p> <p> TYPE: <code>int</code> DEFAULT: <code>2</code> </p> RETURNS DESCRIPTION <code>List[str]</code> <p>List of n-grams</p>"},{"location":"api/tenets/core/nlp/tokenizer/#tenets.core.nlp.tokenizer-functions","title":"Functions","text":""},{"location":"api/tenets/core/prompt/cache/","title":"Cache","text":""},{"location":"api/tenets/core/prompt/cache/#tenets.core.prompt.cache","title":"tenets.core.prompt.cache","text":"<p>Caching system for prompt parsing results.</p> <p>Provides intelligent caching for parsed prompts, external content fetches, and entity recognition results with proper invalidation strategies.</p>"},{"location":"api/tenets/core/prompt/cache/#tenets.core.prompt.cache-classes","title":"Classes","text":""},{"location":"api/tenets/core/prompt/cache/#tenets.core.prompt.cache.CacheEntry","title":"CacheEntry  <code>dataclass</code>","text":"Python<pre><code>CacheEntry(key: str, value: Any, created_at: datetime, accessed_at: datetime, ttl_seconds: int, hit_count: int = 0, metadata: Dict[str, Any] = None)\n</code></pre> <p>A cache entry with metadata.</p>"},{"location":"api/tenets/core/prompt/cache/#tenets.core.prompt.cache.CacheEntry-functions","title":"Functions","text":""},{"location":"api/tenets/core/prompt/cache/#tenets.core.prompt.cache.CacheEntry.is_expired","title":"is_expired","text":"Python<pre><code>is_expired() -&gt; bool\n</code></pre> <p>Check if this entry has expired.</p>"},{"location":"api/tenets/core/prompt/cache/#tenets.core.prompt.cache.CacheEntry.touch","title":"touch","text":"Python<pre><code>touch()\n</code></pre> <p>Update access time and increment hit count.</p>"},{"location":"api/tenets/core/prompt/cache/#tenets.core.prompt.cache.PromptCache","title":"PromptCache","text":"Python<pre><code>PromptCache(cache_manager: Optional[Any] = None, enable_memory_cache: bool = True, enable_disk_cache: bool = True, memory_cache_size: int = 100)\n</code></pre> <p>Intelligent caching for prompt parsing operations.</p> <p>Initialize prompt cache.</p> PARAMETER DESCRIPTION <code>cache_manager</code> <p>External cache manager to use</p> <p> TYPE: <code>Optional[Any]</code> DEFAULT: <code>None</code> </p> <code>enable_memory_cache</code> <p>Whether to use in-memory caching</p> <p> TYPE: <code>bool</code> DEFAULT: <code>True</code> </p> <code>enable_disk_cache</code> <p>Whether to use disk caching</p> <p> TYPE: <code>bool</code> DEFAULT: <code>True</code> </p> <code>memory_cache_size</code> <p>Maximum items in memory cache</p> <p> TYPE: <code>int</code> DEFAULT: <code>100</code> </p>"},{"location":"api/tenets/core/prompt/cache/#tenets.core.prompt.cache.PromptCache-functions","title":"Functions","text":""},{"location":"api/tenets/core/prompt/cache/#tenets.core.prompt.cache.PromptCache.get","title":"get","text":"Python<pre><code>get(key: str, check_disk: bool = True) -&gt; Optional[Any]\n</code></pre> <p>Get a value from cache.</p> PARAMETER DESCRIPTION <code>key</code> <p>Cache key</p> <p> TYPE: <code>str</code> </p> <code>check_disk</code> <p>Whether to check disk cache if not in memory</p> <p> TYPE: <code>bool</code> DEFAULT: <code>True</code> </p> RETURNS DESCRIPTION <code>Optional[Any]</code> <p>Cached value or None if not found/expired</p>"},{"location":"api/tenets/core/prompt/cache/#tenets.core.prompt.cache.PromptCache.put","title":"put","text":"Python<pre><code>put(key: str, value: Any, ttl_seconds: Optional[int] = None, metadata: Optional[Dict[str, Any]] = None, write_disk: bool = True) -&gt; None\n</code></pre> <p>Put a value in cache.</p> PARAMETER DESCRIPTION <code>key</code> <p>Cache key</p> <p> TYPE: <code>str</code> </p> <code>value</code> <p>Value to cache</p> <p> TYPE: <code>Any</code> </p> <code>ttl_seconds</code> <p>TTL in seconds (uses default if not specified)</p> <p> TYPE: <code>Optional[int]</code> DEFAULT: <code>None</code> </p> <code>metadata</code> <p>Additional metadata for TTL calculation</p> <p> TYPE: <code>Optional[Dict[str, Any]]</code> DEFAULT: <code>None</code> </p> <code>write_disk</code> <p>Whether to write to disk cache</p> <p> TYPE: <code>bool</code> DEFAULT: <code>True</code> </p>"},{"location":"api/tenets/core/prompt/cache/#tenets.core.prompt.cache.PromptCache.cache_parsed_prompt","title":"cache_parsed_prompt","text":"Python<pre><code>cache_parsed_prompt(prompt: str, result: Any, metadata: Optional[Dict[str, Any]] = None) -&gt; None\n</code></pre> <p>Cache a parsed prompt result.</p> PARAMETER DESCRIPTION <code>prompt</code> <p>Original prompt text</p> <p> TYPE: <code>str</code> </p> <code>result</code> <p>Parsing result</p> <p> TYPE: <code>Any</code> </p> <code>metadata</code> <p>Additional metadata</p> <p> TYPE: <code>Optional[Dict[str, Any]]</code> DEFAULT: <code>None</code> </p>"},{"location":"api/tenets/core/prompt/cache/#tenets.core.prompt.cache.PromptCache.get_parsed_prompt","title":"get_parsed_prompt","text":"Python<pre><code>get_parsed_prompt(prompt: str) -&gt; Optional[Any]\n</code></pre> <p>Get cached parsed prompt result.</p> PARAMETER DESCRIPTION <code>prompt</code> <p>Original prompt text</p> <p> TYPE: <code>str</code> </p> RETURNS DESCRIPTION <code>Optional[Any]</code> <p>Cached result or None</p>"},{"location":"api/tenets/core/prompt/cache/#tenets.core.prompt.cache.PromptCache.cache_external_content","title":"cache_external_content","text":"Python<pre><code>cache_external_content(url: str, content: Any, metadata: Optional[Dict[str, Any]] = None) -&gt; None\n</code></pre> <p>Cache external content fetch result.</p> PARAMETER DESCRIPTION <code>url</code> <p>URL that was fetched</p> <p> TYPE: <code>str</code> </p> <code>content</code> <p>Fetched content</p> <p> TYPE: <code>Any</code> </p> <code>metadata</code> <p>Additional metadata (source, state, etc.)</p> <p> TYPE: <code>Optional[Dict[str, Any]]</code> DEFAULT: <code>None</code> </p>"},{"location":"api/tenets/core/prompt/cache/#tenets.core.prompt.cache.PromptCache.get_external_content","title":"get_external_content","text":"Python<pre><code>get_external_content(url: str) -&gt; Optional[Any]\n</code></pre> <p>Get cached external content.</p> PARAMETER DESCRIPTION <code>url</code> <p>URL to check</p> <p> TYPE: <code>str</code> </p> RETURNS DESCRIPTION <code>Optional[Any]</code> <p>Cached content or None</p>"},{"location":"api/tenets/core/prompt/cache/#tenets.core.prompt.cache.PromptCache.cache_entities","title":"cache_entities","text":"Python<pre><code>cache_entities(text: str, entities: List[Any], confidence: float = 0.0) -&gt; None\n</code></pre> <p>Cache entity recognition results.</p> PARAMETER DESCRIPTION <code>text</code> <p>Text that was analyzed</p> <p> TYPE: <code>str</code> </p> <code>entities</code> <p>Recognized entities</p> <p> TYPE: <code>List[Any]</code> </p> <code>confidence</code> <p>Average confidence score</p> <p> TYPE: <code>float</code> DEFAULT: <code>0.0</code> </p>"},{"location":"api/tenets/core/prompt/cache/#tenets.core.prompt.cache.PromptCache.get_entities","title":"get_entities","text":"Python<pre><code>get_entities(text: str) -&gt; Optional[List[Any]]\n</code></pre> <p>Get cached entity recognition results.</p> PARAMETER DESCRIPTION <code>text</code> <p>Text to check</p> <p> TYPE: <code>str</code> </p> RETURNS DESCRIPTION <code>Optional[List[Any]]</code> <p>Cached entities or None</p>"},{"location":"api/tenets/core/prompt/cache/#tenets.core.prompt.cache.PromptCache.cache_intent","title":"cache_intent","text":"Python<pre><code>cache_intent(text: str, intent: Any, confidence: float = 0.0) -&gt; None\n</code></pre> <p>Cache intent detection result.</p> PARAMETER DESCRIPTION <code>text</code> <p>Text that was analyzed</p> <p> TYPE: <code>str</code> </p> <code>intent</code> <p>Detected intent</p> <p> TYPE: <code>Any</code> </p> <code>confidence</code> <p>Confidence score</p> <p> TYPE: <code>float</code> DEFAULT: <code>0.0</code> </p>"},{"location":"api/tenets/core/prompt/cache/#tenets.core.prompt.cache.PromptCache.get_intent","title":"get_intent","text":"Python<pre><code>get_intent(text: str) -&gt; Optional[Any]\n</code></pre> <p>Get cached intent detection result.</p> PARAMETER DESCRIPTION <code>text</code> <p>Text to check</p> <p> TYPE: <code>str</code> </p> RETURNS DESCRIPTION <code>Optional[Any]</code> <p>Cached intent or None</p>"},{"location":"api/tenets/core/prompt/cache/#tenets.core.prompt.cache.PromptCache.invalidate","title":"invalidate","text":"Python<pre><code>invalidate(pattern: str) -&gt; int\n</code></pre> <p>Invalidate cache entries matching a pattern.</p> PARAMETER DESCRIPTION <code>pattern</code> <p>Key pattern to match (prefix)</p> <p> TYPE: <code>str</code> </p> RETURNS DESCRIPTION <code>int</code> <p>Number of entries invalidated</p>"},{"location":"api/tenets/core/prompt/cache/#tenets.core.prompt.cache.PromptCache.clear_all","title":"clear_all","text":"Python<pre><code>clear_all() -&gt; None\n</code></pre> <p>Clear all cache entries.</p>"},{"location":"api/tenets/core/prompt/cache/#tenets.core.prompt.cache.PromptCache.cleanup_expired","title":"cleanup_expired","text":"Python<pre><code>cleanup_expired() -&gt; int\n</code></pre> <p>Remove expired entries from cache.</p> RETURNS DESCRIPTION <code>int</code> <p>Number of entries removed</p>"},{"location":"api/tenets/core/prompt/cache/#tenets.core.prompt.cache.PromptCache.get_stats","title":"get_stats","text":"Python<pre><code>get_stats() -&gt; Dict[str, Any]\n</code></pre> <p>Get cache statistics.</p> RETURNS DESCRIPTION <code>Dict[str, Any]</code> <p>Cache statistics dictionary</p>"},{"location":"api/tenets/core/prompt/cache/#tenets.core.prompt.cache.PromptCache.warm_cache","title":"warm_cache","text":"Python<pre><code>warm_cache(common_prompts: List[str]) -&gt; None\n</code></pre> <p>Pre-warm cache with common prompts.</p> PARAMETER DESCRIPTION <code>common_prompts</code> <p>List of common prompts to pre-cache</p> <p> TYPE: <code>List[str]</code> </p>"},{"location":"api/tenets/core/prompt/cache/#tenets.core.prompt.cache-functions","title":"Functions","text":""},{"location":"api/tenets/core/prompt/entity_recognizer/","title":"Entity Recognizer","text":""},{"location":"api/tenets/core/prompt/entity_recognizer/#tenets.core.prompt.entity_recognizer","title":"tenets.core.prompt.entity_recognizer","text":"<p>Hybrid entity recognition system.</p> <p>Combines fast regex-based extraction with optional NLP-based NER for improved accuracy. Includes confidence scoring and fuzzy matching.</p>"},{"location":"api/tenets/core/prompt/entity_recognizer/#tenets.core.prompt.entity_recognizer-classes","title":"Classes","text":""},{"location":"api/tenets/core/prompt/entity_recognizer/#tenets.core.prompt.entity_recognizer.Entity","title":"Entity  <code>dataclass</code>","text":"Python<pre><code>Entity(name: str, type: str, confidence: float, context: str = '', start_pos: int = -1, end_pos: int = -1, source: str = 'regex', metadata: Dict[str, Any] = dict())\n</code></pre> <p>Recognized entity with confidence and context.</p>"},{"location":"api/tenets/core/prompt/entity_recognizer/#tenets.core.prompt.entity_recognizer.EntityPatternMatcher","title":"EntityPatternMatcher","text":"Python<pre><code>EntityPatternMatcher(patterns_file: Optional[Path] = None)\n</code></pre> <p>Regex-based entity pattern matching.</p> <p>Initialize with entity patterns.</p> PARAMETER DESCRIPTION <code>patterns_file</code> <p>Path to entity patterns JSON file</p> <p> TYPE: <code>Optional[Path]</code> DEFAULT: <code>None</code> </p>"},{"location":"api/tenets/core/prompt/entity_recognizer/#tenets.core.prompt.entity_recognizer.EntityPatternMatcher-functions","title":"Functions","text":""},{"location":"api/tenets/core/prompt/entity_recognizer/#tenets.core.prompt.entity_recognizer.EntityPatternMatcher.extract","title":"extract","text":"Python<pre><code>extract(text: str) -&gt; List[Entity]\n</code></pre> <p>Extract entities using regex patterns.</p> PARAMETER DESCRIPTION <code>text</code> <p>Text to extract entities from</p> <p> TYPE: <code>str</code> </p> RETURNS DESCRIPTION <code>List[Entity]</code> <p>List of extracted entities</p>"},{"location":"api/tenets/core/prompt/entity_recognizer/#tenets.core.prompt.entity_recognizer.NLPEntityRecognizer","title":"NLPEntityRecognizer","text":"Python<pre><code>NLPEntityRecognizer(model_name: str = 'en_core_web_sm')\n</code></pre> <p>NLP-based named entity recognition using spaCy.</p> <p>Initialize NLP entity recognizer.</p> PARAMETER DESCRIPTION <code>model_name</code> <p>spaCy model to use</p> <p> TYPE: <code>str</code> DEFAULT: <code>'en_core_web_sm'</code> </p>"},{"location":"api/tenets/core/prompt/entity_recognizer/#tenets.core.prompt.entity_recognizer.NLPEntityRecognizer-functions","title":"Functions","text":""},{"location":"api/tenets/core/prompt/entity_recognizer/#tenets.core.prompt.entity_recognizer.NLPEntityRecognizer.extract","title":"extract","text":"Python<pre><code>extract(text: str) -&gt; List[Entity]\n</code></pre> <p>Extract entities using NLP.</p> PARAMETER DESCRIPTION <code>text</code> <p>Text to extract entities from</p> <p> TYPE: <code>str</code> </p> RETURNS DESCRIPTION <code>List[Entity]</code> <p>List of extracted entities</p>"},{"location":"api/tenets/core/prompt/entity_recognizer/#tenets.core.prompt.entity_recognizer.FuzzyEntityMatcher","title":"FuzzyEntityMatcher","text":"Python<pre><code>FuzzyEntityMatcher(known_entities: Optional[Dict[str, List[str]]] = None)\n</code></pre> <p>Fuzzy matching for entity recognition.</p> <p>Initialize fuzzy matcher.</p> PARAMETER DESCRIPTION <code>known_entities</code> <p>Dictionary of entity type -&gt; list of known entity names</p> <p> TYPE: <code>Optional[Dict[str, List[str]]]</code> DEFAULT: <code>None</code> </p>"},{"location":"api/tenets/core/prompt/entity_recognizer/#tenets.core.prompt.entity_recognizer.FuzzyEntityMatcher-functions","title":"Functions","text":""},{"location":"api/tenets/core/prompt/entity_recognizer/#tenets.core.prompt.entity_recognizer.FuzzyEntityMatcher.find_fuzzy_matches","title":"find_fuzzy_matches","text":"Python<pre><code>find_fuzzy_matches(text: str, threshold: float = 0.8) -&gt; List[Entity]\n</code></pre> <p>Find fuzzy matches for known entities.</p> PARAMETER DESCRIPTION <code>text</code> <p>Text to search in</p> <p> TYPE: <code>str</code> </p> <code>threshold</code> <p>Similarity threshold (0-1)</p> <p> TYPE: <code>float</code> DEFAULT: <code>0.8</code> </p> RETURNS DESCRIPTION <code>List[Entity]</code> <p>List of matched entities</p>"},{"location":"api/tenets/core/prompt/entity_recognizer/#tenets.core.prompt.entity_recognizer.HybridEntityRecognizer","title":"HybridEntityRecognizer","text":"Python<pre><code>HybridEntityRecognizer(use_nlp: bool = True, use_fuzzy: bool = True, patterns_file: Optional[Path] = None, spacy_model: str = 'en_core_web_sm', known_entities: Optional[Dict[str, List[str]]] = None)\n</code></pre> <p>Main entity recognizer combining all approaches.</p> <p>Initialize hybrid entity recognizer.</p> PARAMETER DESCRIPTION <code>use_nlp</code> <p>Whether to use NLP-based NER</p> <p> TYPE: <code>bool</code> DEFAULT: <code>True</code> </p> <code>use_fuzzy</code> <p>Whether to use fuzzy matching</p> <p> TYPE: <code>bool</code> DEFAULT: <code>True</code> </p> <code>patterns_file</code> <p>Path to entity patterns JSON</p> <p> TYPE: <code>Optional[Path]</code> DEFAULT: <code>None</code> </p> <code>spacy_model</code> <p>spaCy model name</p> <p> TYPE: <code>str</code> DEFAULT: <code>'en_core_web_sm'</code> </p> <code>known_entities</code> <p>Known entities for fuzzy matching</p> <p> TYPE: <code>Optional[Dict[str, List[str]]]</code> DEFAULT: <code>None</code> </p>"},{"location":"api/tenets/core/prompt/entity_recognizer/#tenets.core.prompt.entity_recognizer.HybridEntityRecognizer-functions","title":"Functions","text":""},{"location":"api/tenets/core/prompt/entity_recognizer/#tenets.core.prompt.entity_recognizer.HybridEntityRecognizer.recognize","title":"recognize","text":"Python<pre><code>recognize(text: str, merge_overlapping: bool = True, min_confidence: float = 0.5) -&gt; List[Entity]\n</code></pre> <p>Recognize entities using all available methods.</p> PARAMETER DESCRIPTION <code>text</code> <p>Text to extract entities from</p> <p> TYPE: <code>str</code> </p> <code>merge_overlapping</code> <p>Whether to merge overlapping entities</p> <p> TYPE: <code>bool</code> DEFAULT: <code>True</code> </p> <code>min_confidence</code> <p>Minimum confidence threshold</p> <p> TYPE: <code>float</code> DEFAULT: <code>0.5</code> </p> RETURNS DESCRIPTION <code>List[Entity]</code> <p>List of recognized entities</p>"},{"location":"api/tenets/core/prompt/entity_recognizer/#tenets.core.prompt.entity_recognizer.HybridEntityRecognizer.get_entity_summary","title":"get_entity_summary","text":"Python<pre><code>get_entity_summary(entities: List[Entity]) -&gt; Dict[str, Any]\n</code></pre> <p>Get summary statistics about recognized entities.</p> PARAMETER DESCRIPTION <code>entities</code> <p>List of entities</p> <p> TYPE: <code>List[Entity]</code> </p> RETURNS DESCRIPTION <code>Dict[str, Any]</code> <p>Summary dictionary</p>"},{"location":"api/tenets/core/prompt/entity_recognizer/#tenets.core.prompt.entity_recognizer-functions","title":"Functions","text":""},{"location":"api/tenets/core/prompt/external_sources/","title":"External Sources","text":""},{"location":"api/tenets/core/prompt/external_sources/#tenets.core.prompt.external_sources","title":"tenets.core.prompt.external_sources","text":"<p>Compatibility shim for external source handlers.</p> <p>This module was relocated to <code>tenets.utils.external_sources</code>. We re-export the public API here to maintain backward compatibility with code/tests that still import from <code>tenets.core.prompt.external_sources</code>.</p>"},{"location":"api/tenets/core/prompt/external_sources/#tenets.core.prompt.external_sources-classes","title":"Classes","text":""},{"location":"api/tenets/core/prompt/external_sources/#tenets.core.prompt.external_sources.AsanaHandler","title":"AsanaHandler","text":"Python<pre><code>AsanaHandler(cache_manager: Optional[CacheManager] = None)\n</code></pre> <p>               Bases: <code>ExternalSourceHandler</code></p> <p>Handler for Asana tasks.</p>"},{"location":"api/tenets/core/prompt/external_sources/#tenets.core.prompt.external_sources.AsanaHandler-functions","title":"Functions","text":""},{"location":"api/tenets/core/prompt/external_sources/#tenets.core.prompt.external_sources.AsanaHandler.can_handle","title":"can_handle","text":"Python<pre><code>can_handle(url: str) -&gt; bool\n</code></pre> <p>Check if URL is an Asana URL.</p>"},{"location":"api/tenets/core/prompt/external_sources/#tenets.core.prompt.external_sources.AsanaHandler.extract_identifier","title":"extract_identifier","text":"Python<pre><code>extract_identifier(url: str) -&gt; Tuple[str, Dict[str, Any]]\n</code></pre> <p>Extract Asana task identifier from URL.</p>"},{"location":"api/tenets/core/prompt/external_sources/#tenets.core.prompt.external_sources.AsanaHandler.fetch_content","title":"fetch_content","text":"Python<pre><code>fetch_content(url: str, metadata: Dict[str, Any]) -&gt; Optional[ExternalContent]\n</code></pre> <p>Fetch content from Asana API.</p>"},{"location":"api/tenets/core/prompt/external_sources/#tenets.core.prompt.external_sources.ExternalContent","title":"ExternalContent  <code>dataclass</code>","text":"Python<pre><code>ExternalContent(title: str, body: str, metadata: Dict[str, Any], source_type: str, url: str, cached_at: Optional[datetime] = None, ttl_hours: int = 24)\n</code></pre> <p>Parsed content from an external source.</p>"},{"location":"api/tenets/core/prompt/external_sources/#tenets.core.prompt.external_sources.ExternalSourceHandler","title":"ExternalSourceHandler","text":"Python<pre><code>ExternalSourceHandler(cache_manager: Optional[CacheManager] = None)\n</code></pre> <p>               Bases: <code>ABC</code></p> <p>Base class for external source handlers.</p> <p>Initialize handler with optional cache.</p> PARAMETER DESCRIPTION <code>cache_manager</code> <p>Optional cache manager for caching fetched content</p> <p> TYPE: <code>Optional[CacheManager]</code> DEFAULT: <code>None</code> </p>"},{"location":"api/tenets/core/prompt/external_sources/#tenets.core.prompt.external_sources.ExternalSourceHandler-functions","title":"Functions","text":""},{"location":"api/tenets/core/prompt/external_sources/#tenets.core.prompt.external_sources.ExternalSourceHandler.can_handle","title":"can_handle  <code>abstractmethod</code>","text":"Python<pre><code>can_handle(url: str) -&gt; bool\n</code></pre> <p>Check if this handler can process the given URL.</p>"},{"location":"api/tenets/core/prompt/external_sources/#tenets.core.prompt.external_sources.ExternalSourceHandler.extract_identifier","title":"extract_identifier  <code>abstractmethod</code>","text":"Python<pre><code>extract_identifier(url: str) -&gt; Tuple[str, Dict[str, Any]]\n</code></pre> <p>Extract identifier and metadata from URL.</p> RETURNS DESCRIPTION <code>Tuple[str, Dict[str, Any]]</code> <p>Tuple of (identifier, metadata)</p>"},{"location":"api/tenets/core/prompt/external_sources/#tenets.core.prompt.external_sources.ExternalSourceHandler.fetch_content","title":"fetch_content  <code>abstractmethod</code>","text":"Python<pre><code>fetch_content(url: str, metadata: Dict[str, Any]) -&gt; Optional[ExternalContent]\n</code></pre> <p>Fetch content from the external source.</p>"},{"location":"api/tenets/core/prompt/external_sources/#tenets.core.prompt.external_sources.ExternalSourceHandler.get_cached_content","title":"get_cached_content","text":"Python<pre><code>get_cached_content(url: str) -&gt; Optional[ExternalContent]\n</code></pre> <p>Get cached content if available and valid.</p> PARAMETER DESCRIPTION <code>url</code> <p>URL to check cache for</p> <p> TYPE: <code>str</code> </p> RETURNS DESCRIPTION <code>Optional[ExternalContent]</code> <p>Cached content or None if not cached/expired</p>"},{"location":"api/tenets/core/prompt/external_sources/#tenets.core.prompt.external_sources.ExternalSourceHandler.cache_content","title":"cache_content","text":"Python<pre><code>cache_content(url: str, content: ExternalContent) -&gt; None\n</code></pre> <p>Cache fetched content.</p> PARAMETER DESCRIPTION <code>url</code> <p>URL as cache key</p> <p> TYPE: <code>str</code> </p> <code>content</code> <p>Content to cache</p> <p> TYPE: <code>ExternalContent</code> </p>"},{"location":"api/tenets/core/prompt/external_sources/#tenets.core.prompt.external_sources.ExternalSourceHandler.process","title":"process","text":"Python<pre><code>process(url: str) -&gt; Optional[ExternalContent]\n</code></pre> <p>Process URL with caching support.</p> PARAMETER DESCRIPTION <code>url</code> <p>URL to process</p> <p> TYPE: <code>str</code> </p> RETURNS DESCRIPTION <code>Optional[ExternalContent]</code> <p>External content or None if failed</p>"},{"location":"api/tenets/core/prompt/external_sources/#tenets.core.prompt.external_sources.ExternalSourceManager","title":"ExternalSourceManager","text":"Python<pre><code>ExternalSourceManager(cache_manager: Optional[CacheManager] = None)\n</code></pre> <p>Manages all external source handlers.</p> <p>Initialize with all available handlers.</p> PARAMETER DESCRIPTION <code>cache_manager</code> <p>Optional cache manager for handlers</p> <p> TYPE: <code>Optional[CacheManager]</code> DEFAULT: <code>None</code> </p>"},{"location":"api/tenets/core/prompt/external_sources/#tenets.core.prompt.external_sources.ExternalSourceManager-functions","title":"Functions","text":""},{"location":"api/tenets/core/prompt/external_sources/#tenets.core.prompt.external_sources.ExternalSourceManager.process_url","title":"process_url","text":"Python<pre><code>process_url(url: str) -&gt; Optional[ExternalContent]\n</code></pre> <p>Process a URL with the appropriate handler.</p> PARAMETER DESCRIPTION <code>url</code> <p>URL to process</p> <p> TYPE: <code>str</code> </p> RETURNS DESCRIPTION <code>Optional[ExternalContent]</code> <p>External content or None if no handler can process it</p>"},{"location":"api/tenets/core/prompt/external_sources/#tenets.core.prompt.external_sources.ExternalSourceManager.extract_reference","title":"extract_reference","text":"Python<pre><code>extract_reference(text: str) -&gt; Optional[Tuple[str, str, Dict[str, Any]]]\n</code></pre> <p>Extract external reference from text.</p> PARAMETER DESCRIPTION <code>text</code> <p>Text that may contain a URL</p> <p> TYPE: <code>str</code> </p> RETURNS DESCRIPTION <code>Optional[Tuple[str, str, Dict[str, Any]]]</code> <p>Tuple of (url, identifier, metadata) or None</p>"},{"location":"api/tenets/core/prompt/external_sources/#tenets.core.prompt.external_sources.GitHubHandler","title":"GitHubHandler","text":"Python<pre><code>GitHubHandler(cache_manager: Optional[CacheManager] = None)\n</code></pre> <p>               Bases: <code>ExternalSourceHandler</code></p> <p>Handler for GitHub issues, PRs, discussions, and gists.</p>"},{"location":"api/tenets/core/prompt/external_sources/#tenets.core.prompt.external_sources.GitHubHandler-functions","title":"Functions","text":""},{"location":"api/tenets/core/prompt/external_sources/#tenets.core.prompt.external_sources.GitHubHandler.can_handle","title":"can_handle","text":"Python<pre><code>can_handle(url: str) -&gt; bool\n</code></pre> <p>Check if URL is a GitHub URL.</p>"},{"location":"api/tenets/core/prompt/external_sources/#tenets.core.prompt.external_sources.GitHubHandler.extract_identifier","title":"extract_identifier","text":"Python<pre><code>extract_identifier(url: str) -&gt; Tuple[str, Dict[str, Any]]\n</code></pre> <p>Extract GitHub identifier from URL.</p>"},{"location":"api/tenets/core/prompt/external_sources/#tenets.core.prompt.external_sources.GitHubHandler.fetch_content","title":"fetch_content","text":"Python<pre><code>fetch_content(url: str, metadata: Dict[str, Any]) -&gt; Optional[ExternalContent]\n</code></pre> <p>Fetch content from GitHub API.</p>"},{"location":"api/tenets/core/prompt/external_sources/#tenets.core.prompt.external_sources.GitLabHandler","title":"GitLabHandler","text":"Python<pre><code>GitLabHandler(cache_manager: Optional[CacheManager] = None)\n</code></pre> <p>               Bases: <code>ExternalSourceHandler</code></p> <p>Handler for GitLab issues, MRs, and snippets.</p>"},{"location":"api/tenets/core/prompt/external_sources/#tenets.core.prompt.external_sources.GitLabHandler-functions","title":"Functions","text":""},{"location":"api/tenets/core/prompt/external_sources/#tenets.core.prompt.external_sources.GitLabHandler.can_handle","title":"can_handle","text":"Python<pre><code>can_handle(url: str) -&gt; bool\n</code></pre> <p>Check if URL is a GitLab URL.</p>"},{"location":"api/tenets/core/prompt/external_sources/#tenets.core.prompt.external_sources.GitLabHandler.extract_identifier","title":"extract_identifier","text":"Python<pre><code>extract_identifier(url: str) -&gt; Tuple[str, Dict[str, Any]]\n</code></pre> <p>Extract GitLab identifier from URL.</p>"},{"location":"api/tenets/core/prompt/external_sources/#tenets.core.prompt.external_sources.GitLabHandler.fetch_content","title":"fetch_content","text":"Python<pre><code>fetch_content(url: str, metadata: Dict[str, Any]) -&gt; Optional[ExternalContent]\n</code></pre> <p>Fetch content from GitLab API.</p>"},{"location":"api/tenets/core/prompt/external_sources/#tenets.core.prompt.external_sources.JiraHandler","title":"JiraHandler","text":"Python<pre><code>JiraHandler(cache_manager: Optional[CacheManager] = None)\n</code></pre> <p>               Bases: <code>ExternalSourceHandler</code></p> <p>Handler for JIRA tickets.</p>"},{"location":"api/tenets/core/prompt/external_sources/#tenets.core.prompt.external_sources.JiraHandler-functions","title":"Functions","text":""},{"location":"api/tenets/core/prompt/external_sources/#tenets.core.prompt.external_sources.JiraHandler.can_handle","title":"can_handle","text":"Python<pre><code>can_handle(url: str) -&gt; bool\n</code></pre> <p>Check if URL is a JIRA URL.</p>"},{"location":"api/tenets/core/prompt/external_sources/#tenets.core.prompt.external_sources.JiraHandler.extract_identifier","title":"extract_identifier","text":"Python<pre><code>extract_identifier(url: str) -&gt; Tuple[str, Dict[str, Any]]\n</code></pre> <p>Extract JIRA ticket identifier from URL.</p>"},{"location":"api/tenets/core/prompt/external_sources/#tenets.core.prompt.external_sources.JiraHandler.fetch_content","title":"fetch_content","text":"Python<pre><code>fetch_content(url: str, metadata: Dict[str, Any]) -&gt; Optional[ExternalContent]\n</code></pre> <p>Fetch content from JIRA API.</p>"},{"location":"api/tenets/core/prompt/external_sources/#tenets.core.prompt.external_sources.LinearHandler","title":"LinearHandler","text":"Python<pre><code>LinearHandler(cache_manager: Optional[CacheManager] = None)\n</code></pre> <p>               Bases: <code>ExternalSourceHandler</code></p> <p>Handler for Linear issues.</p>"},{"location":"api/tenets/core/prompt/external_sources/#tenets.core.prompt.external_sources.LinearHandler-functions","title":"Functions","text":""},{"location":"api/tenets/core/prompt/external_sources/#tenets.core.prompt.external_sources.LinearHandler.can_handle","title":"can_handle","text":"Python<pre><code>can_handle(url: str) -&gt; bool\n</code></pre> <p>Check if URL is a Linear URL.</p>"},{"location":"api/tenets/core/prompt/external_sources/#tenets.core.prompt.external_sources.LinearHandler.extract_identifier","title":"extract_identifier","text":"Python<pre><code>extract_identifier(url: str) -&gt; Tuple[str, Dict[str, Any]]\n</code></pre> <p>Extract Linear identifier from URL.</p>"},{"location":"api/tenets/core/prompt/external_sources/#tenets.core.prompt.external_sources.LinearHandler.fetch_content","title":"fetch_content","text":"Python<pre><code>fetch_content(url: str, metadata: Dict[str, Any]) -&gt; Optional[ExternalContent]\n</code></pre> <p>Fetch content from Linear API using GraphQL.</p>"},{"location":"api/tenets/core/prompt/external_sources/#tenets.core.prompt.external_sources.NotionHandler","title":"NotionHandler","text":"Python<pre><code>NotionHandler(cache_manager: Optional[CacheManager] = None)\n</code></pre> <p>               Bases: <code>ExternalSourceHandler</code></p> <p>Handler for Notion pages and databases.</p>"},{"location":"api/tenets/core/prompt/external_sources/#tenets.core.prompt.external_sources.NotionHandler-functions","title":"Functions","text":""},{"location":"api/tenets/core/prompt/external_sources/#tenets.core.prompt.external_sources.NotionHandler.can_handle","title":"can_handle","text":"Python<pre><code>can_handle(url: str) -&gt; bool\n</code></pre> <p>Check if URL is a Notion URL.</p>"},{"location":"api/tenets/core/prompt/external_sources/#tenets.core.prompt.external_sources.NotionHandler.extract_identifier","title":"extract_identifier","text":"Python<pre><code>extract_identifier(url: str) -&gt; Tuple[str, Dict[str, Any]]\n</code></pre> <p>Extract Notion page/database identifier from URL.</p>"},{"location":"api/tenets/core/prompt/external_sources/#tenets.core.prompt.external_sources.NotionHandler.fetch_content","title":"fetch_content","text":"Python<pre><code>fetch_content(url: str, metadata: Dict[str, Any]) -&gt; Optional[ExternalContent]\n</code></pre> <p>Fetch content from Notion API.</p>"},{"location":"api/tenets/core/prompt/intent_detector/","title":"Intent Detector","text":""},{"location":"api/tenets/core/prompt/intent_detector/#tenets.core.prompt.intent_detector","title":"tenets.core.prompt.intent_detector","text":"<p>ML-enhanced intent detection for prompts.</p> <p>Combines pattern-based detection with optional semantic similarity matching using embeddings for more accurate intent classification.</p>"},{"location":"api/tenets/core/prompt/intent_detector/#tenets.core.prompt.intent_detector-classes","title":"Classes","text":""},{"location":"api/tenets/core/prompt/intent_detector/#tenets.core.prompt.intent_detector.Intent","title":"Intent  <code>dataclass</code>","text":"Python<pre><code>Intent(type: str, confidence: float, evidence: List[str], keywords: List[str], metadata: Dict[str, Any], source: str)\n</code></pre> <p>Detected intent with confidence and metadata.</p>"},{"location":"api/tenets/core/prompt/intent_detector/#tenets.core.prompt.intent_detector.Intent-functions","title":"Functions","text":""},{"location":"api/tenets/core/prompt/intent_detector/#tenets.core.prompt.intent_detector.Intent.to_dict","title":"to_dict","text":"Python<pre><code>to_dict() -&gt; Dict[str, Any]\n</code></pre> <p>Convert to dictionary.</p>"},{"location":"api/tenets/core/prompt/intent_detector/#tenets.core.prompt.intent_detector.PatternBasedDetector","title":"PatternBasedDetector","text":"Python<pre><code>PatternBasedDetector(patterns_file: Optional[Path] = None)\n</code></pre> <p>Pattern-based intent detection.</p> <p>Initialize with intent patterns.</p> PARAMETER DESCRIPTION <code>patterns_file</code> <p>Path to intent patterns JSON file</p> <p> TYPE: <code>Optional[Path]</code> DEFAULT: <code>None</code> </p>"},{"location":"api/tenets/core/prompt/intent_detector/#tenets.core.prompt.intent_detector.PatternBasedDetector-functions","title":"Functions","text":""},{"location":"api/tenets/core/prompt/intent_detector/#tenets.core.prompt.intent_detector.PatternBasedDetector.detect","title":"detect","text":"Python<pre><code>detect(text: str) -&gt; List[Intent]\n</code></pre> <p>Detect intents using patterns.</p> PARAMETER DESCRIPTION <code>text</code> <p>Text to analyze</p> <p> TYPE: <code>str</code> </p> RETURNS DESCRIPTION <code>List[Intent]</code> <p>List of detected intents</p>"},{"location":"api/tenets/core/prompt/intent_detector/#tenets.core.prompt.intent_detector.SemanticIntentDetector","title":"SemanticIntentDetector","text":"Python<pre><code>SemanticIntentDetector(model_name: str = 'all-MiniLM-L6-v2')\n</code></pre> <p>ML-based semantic intent detection using embeddings.</p> <p>Initialize semantic intent detector.</p> PARAMETER DESCRIPTION <code>model_name</code> <p>Embedding model name</p> <p> TYPE: <code>str</code> DEFAULT: <code>'all-MiniLM-L6-v2'</code> </p>"},{"location":"api/tenets/core/prompt/intent_detector/#tenets.core.prompt.intent_detector.SemanticIntentDetector-functions","title":"Functions","text":""},{"location":"api/tenets/core/prompt/intent_detector/#tenets.core.prompt.intent_detector.SemanticIntentDetector.detect","title":"detect","text":"Python<pre><code>detect(text: str, threshold: float = 0.6) -&gt; List[Intent]\n</code></pre> <p>Detect intents using semantic similarity.</p> PARAMETER DESCRIPTION <code>text</code> <p>Text to analyze</p> <p> TYPE: <code>str</code> </p> <code>threshold</code> <p>Similarity threshold</p> <p> TYPE: <code>float</code> DEFAULT: <code>0.6</code> </p> RETURNS DESCRIPTION <code>List[Intent]</code> <p>List of detected intents</p>"},{"location":"api/tenets/core/prompt/intent_detector/#tenets.core.prompt.intent_detector.HybridIntentDetector","title":"HybridIntentDetector","text":"Python<pre><code>HybridIntentDetector(use_ml: bool = True, patterns_file: Optional[Path] = None, model_name: str = 'all-MiniLM-L6-v2')\n</code></pre> <p>Main intent detector combining pattern and ML approaches.</p> <p>Initialize hybrid intent detector.</p> PARAMETER DESCRIPTION <code>use_ml</code> <p>Whether to use ML-based detection</p> <p> TYPE: <code>bool</code> DEFAULT: <code>True</code> </p> <code>patterns_file</code> <p>Path to intent patterns JSON</p> <p> TYPE: <code>Optional[Path]</code> DEFAULT: <code>None</code> </p> <code>model_name</code> <p>Embedding model name for ML</p> <p> TYPE: <code>str</code> DEFAULT: <code>'all-MiniLM-L6-v2'</code> </p>"},{"location":"api/tenets/core/prompt/intent_detector/#tenets.core.prompt.intent_detector.HybridIntentDetector-functions","title":"Functions","text":""},{"location":"api/tenets/core/prompt/intent_detector/#tenets.core.prompt.intent_detector.HybridIntentDetector.detect","title":"detect","text":"Python<pre><code>detect(text: str, combine_method: str = 'weighted', pattern_weight: float = 0.75, ml_weight: float = 0.25, min_confidence: float = 0.3) -&gt; Intent\n</code></pre> <p>Detect the primary intent from text.</p> PARAMETER DESCRIPTION <code>text</code> <p>Text to analyze</p> <p> TYPE: <code>str</code> </p> <code>combine_method</code> <p>How to combine results ('weighted', 'max', 'vote')</p> <p> TYPE: <code>str</code> DEFAULT: <code>'weighted'</code> </p> <code>pattern_weight</code> <p>Weight for pattern-based detection</p> <p> TYPE: <code>float</code> DEFAULT: <code>0.75</code> </p> <code>ml_weight</code> <p>Weight for ML-based detection</p> <p> TYPE: <code>float</code> DEFAULT: <code>0.25</code> </p> <code>min_confidence</code> <p>Minimum confidence threshold</p> <p> TYPE: <code>float</code> DEFAULT: <code>0.3</code> </p> RETURNS DESCRIPTION <code>Intent</code> <p>Primary intent detected</p>"},{"location":"api/tenets/core/prompt/intent_detector/#tenets.core.prompt.intent_detector.HybridIntentDetector.detect_multiple","title":"detect_multiple","text":"Python<pre><code>detect_multiple(text: str, max_intents: int = 3, min_confidence: float = 0.3) -&gt; List[Intent]\n</code></pre> <p>Detect multiple intents from text.</p> PARAMETER DESCRIPTION <code>text</code> <p>Text to analyze</p> <p> TYPE: <code>str</code> </p> <code>max_intents</code> <p>Maximum number of intents to return</p> <p> TYPE: <code>int</code> DEFAULT: <code>3</code> </p> <code>min_confidence</code> <p>Minimum confidence threshold</p> <p> TYPE: <code>float</code> DEFAULT: <code>0.3</code> </p> RETURNS DESCRIPTION <code>List[Intent]</code> <p>List of detected intents</p>"},{"location":"api/tenets/core/prompt/intent_detector/#tenets.core.prompt.intent_detector.HybridIntentDetector.get_intent_context","title":"get_intent_context","text":"Python<pre><code>get_intent_context(intent: Intent) -&gt; Dict[str, Any]\n</code></pre> <p>Get additional context for an intent.</p> PARAMETER DESCRIPTION <code>intent</code> <p>Intent to get context for</p> <p> TYPE: <code>Intent</code> </p> RETURNS DESCRIPTION <code>Dict[str, Any]</code> <p>Context dictionary</p>"},{"location":"api/tenets/core/prompt/intent_detector/#tenets.core.prompt.intent_detector-functions","title":"Functions","text":""},{"location":"api/tenets/core/prompt/normalizer/","title":"Normalizer","text":""},{"location":"api/tenets/core/prompt/normalizer/#tenets.core.prompt.normalizer","title":"tenets.core.prompt.normalizer","text":"<p>Entity and keyword normalization utilities.</p> <p>Provides lightweight normalization (case-folding, punctuation removal, singularization, lemmatization when available) and tracks variant mappings for explainability.</p>"},{"location":"api/tenets/core/prompt/normalizer/#tenets.core.prompt.normalizer-classes","title":"Classes","text":""},{"location":"api/tenets/core/prompt/normalizer/#tenets.core.prompt.normalizer.EntityNormalizer","title":"EntityNormalizer","text":"<p>Normalize entities/keywords and record variant mappings.</p>"},{"location":"api/tenets/core/prompt/normalizer/#tenets.core.prompt.normalizer-functions","title":"Functions","text":""},{"location":"api/tenets/core/prompt/normalizer/#tenets.core.prompt.normalizer.normalize_list","title":"normalize_list","text":"Python<pre><code>normalize_list(items: List[str]) -&gt; Tuple[List[str], Dict[str, Dict[str, List[str]]]]\n</code></pre> <p>Normalize a list and return unique canonicals + per-item metadata.</p> RETURNS DESCRIPTION <code>Tuple[List[str], Dict[str, Dict[str, List[str]]]]</code> <p>(canonicals, meta_by_original) where meta contains steps and variants.</p>"},{"location":"api/tenets/core/prompt/parser/","title":"Parser","text":""},{"location":"api/tenets/core/prompt/parser/#tenets.core.prompt.parser","title":"tenets.core.prompt.parser","text":"<p>Prompt parsing and understanding system with modular components.</p> <p>This module analyzes user prompts to extract intent, keywords, entities, temporal context, and external references using a comprehensive set of specialized components and NLP techniques.</p>"},{"location":"api/tenets/core/prompt/parser/#tenets.core.prompt.parser-classes","title":"Classes","text":""},{"location":"api/tenets/core/prompt/parser/#tenets.core.prompt.parser.PromptParser","title":"PromptParser","text":"Python<pre><code>PromptParser(config: TenetsConfig, cache_manager: Optional[Any] = None, use_cache: bool = True, use_ml: bool = None, use_nlp_ner: bool = None, use_fuzzy_matching: bool = True)\n</code></pre> <p>Comprehensive prompt parser with modular components and caching.</p>"},{"location":"api/tenets/core/prompt/parser/#tenets.core.prompt.parser.PromptParser-functions","title":"Functions","text":""},{"location":"api/tenets/core/prompt/parser/#tenets.core.prompt.parser.PromptParser.get_cache_stats","title":"get_cache_stats","text":"Python<pre><code>get_cache_stats() -&gt; Optional[Dict[str, Any]]\n</code></pre> <p>Get cache statistics.</p> RETURNS DESCRIPTION <code>Optional[Dict[str, Any]]</code> <p>Dictionary with cache statistics or None if cache is disabled</p> Example <p>stats = parser.get_cache_stats() if stats: ...     print(f\"Cache hit rate: {stats['hit_rate']:.2%}\")</p>"},{"location":"api/tenets/core/prompt/parser/#tenets.core.prompt.parser.PromptParser.clear_cache","title":"clear_cache","text":"Python<pre><code>clear_cache() -&gt; None\n</code></pre> <p>Clear all cached data.</p> <p>This removes all cached parsing results, external content, entities, and intents from both memory and disk cache.</p> Example <p>parser.clear_cache() print(\"Cache cleared\")</p>"},{"location":"api/tenets/core/prompt/parser/#tenets.core.prompt.parser.PromptParser.warm_cache","title":"warm_cache","text":"Python<pre><code>warm_cache(common_prompts: List[str]) -&gt; None\n</code></pre> <p>Pre-warm cache with common prompts.</p> <p>This method pre-parses a list of common prompts to populate the cache, improving performance for frequently used queries.</p> PARAMETER DESCRIPTION <code>common_prompts</code> <p>List of common prompts to pre-parse</p> <p> TYPE: <code>List[str]</code> </p> Example <p>common = [ ...     \"implement authentication\", ...     \"fix bug\", ...     \"understand architecture\" ... ] parser.warm_cache(common)</p>"},{"location":"api/tenets/core/prompt/parser/#tenets.core.prompt.parser-functions","title":"Functions","text":""},{"location":"api/tenets/core/prompt/temporal_parser/","title":"Temporal Parser","text":""},{"location":"api/tenets/core/prompt/temporal_parser/#tenets.core.prompt.temporal_parser","title":"tenets.core.prompt.temporal_parser","text":"<p>Enhanced temporal parsing for dates, times, and ranges.</p> <p>Supports multiple date formats, natural language expressions, recurring patterns, and date ranges with comprehensive parsing capabilities.</p>"},{"location":"api/tenets/core/prompt/temporal_parser/#tenets.core.prompt.temporal_parser-classes","title":"Classes","text":""},{"location":"api/tenets/core/prompt/temporal_parser/#tenets.core.prompt.temporal_parser.TemporalExpression","title":"TemporalExpression  <code>dataclass</code>","text":"Python<pre><code>TemporalExpression(text: str, type: str, start_date: Optional[datetime], end_date: Optional[datetime], is_relative: bool, is_recurring: bool, recurrence_pattern: Optional[str], confidence: float, metadata: Dict[str, Any])\n</code></pre> <p>Parsed temporal expression with metadata.</p>"},{"location":"api/tenets/core/prompt/temporal_parser/#tenets.core.prompt.temporal_parser.TemporalExpression-attributes","title":"Attributes","text":""},{"location":"api/tenets/core/prompt/temporal_parser/#tenets.core.prompt.temporal_parser.TemporalExpression.timeframe","title":"timeframe  <code>property</code>","text":"Python<pre><code>timeframe: str\n</code></pre> <p>Get human-readable timeframe description.</p>"},{"location":"api/tenets/core/prompt/temporal_parser/#tenets.core.prompt.temporal_parser.TemporalPatternMatcher","title":"TemporalPatternMatcher","text":"Python<pre><code>TemporalPatternMatcher(patterns_file: Optional[Path] = None)\n</code></pre> <p>Pattern-based temporal expression matching.</p> <p>Initialize with temporal patterns.</p> PARAMETER DESCRIPTION <code>patterns_file</code> <p>Path to temporal patterns JSON file</p> <p> TYPE: <code>Optional[Path]</code> DEFAULT: <code>None</code> </p>"},{"location":"api/tenets/core/prompt/temporal_parser/#tenets.core.prompt.temporal_parser.TemporalParser","title":"TemporalParser","text":"Python<pre><code>TemporalParser(patterns_file: Optional[Path] = None)\n</code></pre> <p>Main temporal parser combining all approaches.</p> <p>Initialize temporal parser.</p> PARAMETER DESCRIPTION <code>patterns_file</code> <p>Path to temporal patterns JSON file</p> <p> TYPE: <code>Optional[Path]</code> DEFAULT: <code>None</code> </p>"},{"location":"api/tenets/core/prompt/temporal_parser/#tenets.core.prompt.temporal_parser.TemporalParser-functions","title":"Functions","text":""},{"location":"api/tenets/core/prompt/temporal_parser/#tenets.core.prompt.temporal_parser.TemporalParser.parse","title":"parse","text":"Python<pre><code>parse(text: str) -&gt; List[TemporalExpression]\n</code></pre> <p>Parse temporal expressions from text.</p> PARAMETER DESCRIPTION <code>text</code> <p>Text to parse</p> <p> TYPE: <code>str</code> </p> RETURNS DESCRIPTION <code>List[TemporalExpression]</code> <p>List of temporal expressions</p>"},{"location":"api/tenets/core/prompt/temporal_parser/#tenets.core.prompt.temporal_parser.TemporalParser.get_temporal_context","title":"get_temporal_context","text":"Python<pre><code>get_temporal_context(expressions: List[TemporalExpression]) -&gt; Dict[str, Any]\n</code></pre> <p>Get overall temporal context from expressions.</p> PARAMETER DESCRIPTION <code>expressions</code> <p>List of temporal expressions</p> <p> TYPE: <code>List[TemporalExpression]</code> </p> RETURNS DESCRIPTION <code>Dict[str, Any]</code> <p>Temporal context summary</p>"},{"location":"api/tenets/core/prompt/temporal_parser/#tenets.core.prompt.temporal_parser.TemporalParser.extract_temporal_features","title":"extract_temporal_features","text":"Python<pre><code>extract_temporal_features(text: str) -&gt; Dict[str, Any]\n</code></pre> <p>Extract all temporal features from text.</p> PARAMETER DESCRIPTION <code>text</code> <p>Text to analyze</p> <p> TYPE: <code>str</code> </p> RETURNS DESCRIPTION <code>Dict[str, Any]</code> <p>Dictionary with temporal features and context</p>"},{"location":"api/tenets/core/prompt/temporal_parser/#tenets.core.prompt.temporal_parser-functions","title":"Functions","text":""},{"location":"api/tenets/core/ranking/factors/","title":"Factors","text":""},{"location":"api/tenets/core/ranking/factors/#tenets.core.ranking.factors","title":"tenets.core.ranking.factors","text":"<p>Ranking factors and scored file models.</p> <p>This module defines the data structures for ranking factors and scored files. It provides a comprehensive set of factors that contribute to relevance scoring, along with utilities for calculating weighted scores and generating explanations.</p> <p>The ranking system uses multiple orthogonal factors to determine file relevance, allowing for flexible and accurate scoring across different use cases.</p>"},{"location":"api/tenets/core/ranking/factors/#tenets.core.ranking.factors-classes","title":"Classes","text":""},{"location":"api/tenets/core/ranking/factors/#tenets.core.ranking.factors.FactorWeight","title":"FactorWeight","text":"<p>               Bases: <code>Enum</code></p> <p>Standard weight presets for ranking factors.</p> <p>These presets provide balanced weights for different use cases. Can be overridden with custom weights in configuration.</p>"},{"location":"api/tenets/core/ranking/factors/#tenets.core.ranking.factors.RankingFactors","title":"RankingFactors  <code>dataclass</code>","text":"Python<pre><code>RankingFactors(keyword_match: float = 0.0, tfidf_similarity: float = 0.0, bm25_score: float = 0.0, path_relevance: float = 0.0, import_centrality: float = 0.0, dependency_depth: float = 0.0, git_recency: float = 0.0, git_frequency: float = 0.0, git_author_relevance: float = 0.0, complexity_relevance: float = 0.0, maintainability_score: float = 0.0, semantic_similarity: float = 0.0, type_relevance: float = 0.0, code_patterns: float = 0.0, ast_relevance: float = 0.0, test_coverage: float = 0.0, documentation_score: float = 0.0, custom_scores: Dict[str, float] = dict(), metadata: Dict[str, Any] = dict())\n</code></pre> <p>Comprehensive ranking factors for a file.</p> <p>Each factor represents a different dimension of relevance. The final relevance score is computed as a weighted sum of these factors.</p> <p>Factors are grouped into categories: - Text-based: keyword_match, tfidf_similarity, bm25_score - Structure-based: path_relevance, import_centrality, dependency_depth - Git-based: git_recency, git_frequency, git_author_relevance - Complexity-based: complexity_relevance, maintainability_score - Semantic: semantic_similarity (requires ML) - Pattern-based: code_patterns, ast_relevance - Custom: custom_scores for project-specific factors</p> ATTRIBUTE DESCRIPTION <code>keyword_match</code> <p>Direct keyword matching score (0-1)</p> <p> TYPE: <code>float</code> </p> <code>tfidf_similarity</code> <p>TF-IDF cosine similarity score (0-1)</p> <p> TYPE: <code>float</code> </p> <code>bm25_score</code> <p>BM25 relevance score (0-1)</p> <p> TYPE: <code>float</code> </p> <code>path_relevance</code> <p>File path relevance to query (0-1)</p> <p> TYPE: <code>float</code> </p> <code>import_centrality</code> <p>How central file is in import graph (0-1)</p> <p> TYPE: <code>float</code> </p> <code>git_recency</code> <p>How recently file was modified (0-1)</p> <p> TYPE: <code>float</code> </p> <code>git_frequency</code> <p>How frequently file changes (0-1)</p> <p> TYPE: <code>float</code> </p> <code>git_author_relevance</code> <p>Relevance based on commit authors (0-1)</p> <p> TYPE: <code>float</code> </p> <code>complexity_relevance</code> <p>Relevance based on code complexity (0-1)</p> <p> TYPE: <code>float</code> </p> <code>maintainability_score</code> <p>Code maintainability score (0-1)</p> <p> TYPE: <code>float</code> </p> <code>semantic_similarity</code> <p>ML-based semantic similarity (0-1)</p> <p> TYPE: <code>float</code> </p> <code>type_relevance</code> <p>Relevance based on file type (0-1)</p> <p> TYPE: <code>float</code> </p> <code>code_patterns</code> <p>Pattern matching score (0-1)</p> <p> TYPE: <code>float</code> </p> <code>ast_relevance</code> <p>AST structure relevance (0-1)</p> <p> TYPE: <code>float</code> </p> <code>dependency_depth</code> <p>Dependency tree depth score (0-1)</p> <p> TYPE: <code>float</code> </p> <code>test_coverage</code> <p>Test coverage relevance (0-1)</p> <p> TYPE: <code>float</code> </p> <code>documentation_score</code> <p>Documentation quality score (0-1)</p> <p> TYPE: <code>float</code> </p> <code>custom_scores</code> <p>Dictionary of custom factor scores</p> <p> TYPE: <code>Dict[str, float]</code> </p> <code>metadata</code> <p>Additional metadata about factor calculation</p> <p> TYPE: <code>Dict[str, Any]</code> </p>"},{"location":"api/tenets/core/ranking/factors/#tenets.core.ranking.factors.RankingFactors-functions","title":"Functions","text":""},{"location":"api/tenets/core/ranking/factors/#tenets.core.ranking.factors.RankingFactors.get_weighted_score","title":"get_weighted_score","text":"Python<pre><code>get_weighted_score(weights: Dict[str, float], normalize: bool = True) -&gt; float\n</code></pre> <p>Calculate weighted relevance score.</p> PARAMETER DESCRIPTION <code>weights</code> <p>Dictionary mapping factor names to weights</p> <p> TYPE: <code>Dict[str, float]</code> </p> <code>normalize</code> <p>Whether to normalize final score to [0, 1]</p> <p> TYPE: <code>bool</code> DEFAULT: <code>True</code> </p> RETURNS DESCRIPTION <code>float</code> <p>Weighted relevance score</p>"},{"location":"api/tenets/core/ranking/factors/#tenets.core.ranking.factors.RankingFactors.get_top_factors","title":"get_top_factors","text":"Python<pre><code>get_top_factors(weights: Dict[str, float], n: int = 5) -&gt; List[Tuple[str, float, float]]\n</code></pre> <p>Get the top contributing factors.</p> PARAMETER DESCRIPTION <code>weights</code> <p>Factor weights</p> <p> TYPE: <code>Dict[str, float]</code> </p> <code>n</code> <p>Number of top factors to return</p> <p> TYPE: <code>int</code> DEFAULT: <code>5</code> </p> RETURNS DESCRIPTION <code>List[Tuple[str, float, float]]</code> <p>List of (factor_name, value, contribution) tuples</p>"},{"location":"api/tenets/core/ranking/factors/#tenets.core.ranking.factors.RankingFactors.to_dict","title":"to_dict","text":"Python<pre><code>to_dict() -&gt; Dict[str, Any]\n</code></pre> <p>Convert factors to dictionary representation.</p> RETURNS DESCRIPTION <code>Dict[str, Any]</code> <p>Dictionary with all factor values</p>"},{"location":"api/tenets/core/ranking/factors/#tenets.core.ranking.factors.RankedFile","title":"RankedFile  <code>dataclass</code>","text":"Python<pre><code>RankedFile(analysis: FileAnalysis, score: float, factors: RankingFactors, explanation: str = '', confidence: float = 1.0, rank: Optional[int] = None, metadata: Dict[str, Any] = dict())\n</code></pre> <p>A file with its relevance ranking.</p> <p>Combines a FileAnalysis with ranking scores and metadata. Provides utilities for comparison, explanation generation, and result formatting.</p> ATTRIBUTE DESCRIPTION <code>analysis</code> <p>The FileAnalysis object</p> <p> TYPE: <code>FileAnalysis</code> </p> <code>score</code> <p>Overall relevance score (0-1)</p> <p> TYPE: <code>float</code> </p> <code>factors</code> <p>Detailed ranking factors</p> <p> TYPE: <code>RankingFactors</code> </p> <code>explanation</code> <p>Human-readable ranking explanation</p> <p> TYPE: <code>str</code> </p> <code>confidence</code> <p>Confidence in the ranking (0-1)</p> <p> TYPE: <code>float</code> </p> <code>rank</code> <p>Position in ranked list (1-based)</p> <p> TYPE: <code>Optional[int]</code> </p> <code>metadata</code> <p>Additional ranking metadata</p> <p> TYPE: <code>Dict[str, Any]</code> </p>"},{"location":"api/tenets/core/ranking/factors/#tenets.core.ranking.factors.RankedFile-attributes","title":"Attributes","text":""},{"location":"api/tenets/core/ranking/factors/#tenets.core.ranking.factors.RankedFile.path","title":"path  <code>property</code>","text":"Python<pre><code>path: str\n</code></pre> <p>Get file path.</p>"},{"location":"api/tenets/core/ranking/factors/#tenets.core.ranking.factors.RankedFile.file_name","title":"file_name  <code>property</code>","text":"Python<pre><code>file_name: str\n</code></pre> <p>Get file name.</p>"},{"location":"api/tenets/core/ranking/factors/#tenets.core.ranking.factors.RankedFile.language","title":"language  <code>property</code>","text":"Python<pre><code>language: str\n</code></pre> <p>Get file language.</p>"},{"location":"api/tenets/core/ranking/factors/#tenets.core.ranking.factors.RankedFile-functions","title":"Functions","text":""},{"location":"api/tenets/core/ranking/factors/#tenets.core.ranking.factors.RankedFile.generate_explanation","title":"generate_explanation","text":"Python<pre><code>generate_explanation(weights: Dict[str, float], verbose: bool = False) -&gt; str\n</code></pre> <p>Generate human-readable explanation of ranking.</p> PARAMETER DESCRIPTION <code>weights</code> <p>Factor weights used for ranking</p> <p> TYPE: <code>Dict[str, float]</code> </p> <code>verbose</code> <p>Include detailed factor breakdown</p> <p> TYPE: <code>bool</code> DEFAULT: <code>False</code> </p> RETURNS DESCRIPTION <code>str</code> <p>Explanation string</p>"},{"location":"api/tenets/core/ranking/factors/#tenets.core.ranking.factors.RankedFile.to_dict","title":"to_dict","text":"Python<pre><code>to_dict() -&gt; Dict[str, Any]\n</code></pre> <p>Convert to dictionary representation.</p> RETURNS DESCRIPTION <code>Dict[str, Any]</code> <p>Dictionary with all ranking information</p>"},{"location":"api/tenets/core/ranking/factors/#tenets.core.ranking.factors.RankingExplainer","title":"RankingExplainer","text":"Python<pre><code>RankingExplainer()\n</code></pre> <p>Utility class for generating ranking explanations.</p> <p>Provides detailed explanations of why files ranked the way they did, useful for debugging and understanding ranking behavior.</p> <p>Initialize the explainer.</p>"},{"location":"api/tenets/core/ranking/factors/#tenets.core.ranking.factors.RankingExplainer-functions","title":"Functions","text":""},{"location":"api/tenets/core/ranking/factors/#tenets.core.ranking.factors.RankingExplainer.explain_ranking","title":"explain_ranking","text":"Python<pre><code>explain_ranking(ranked_files: List[RankedFile], weights: Dict[str, float], top_n: int = 10, include_factors: bool = True) -&gt; str\n</code></pre> <p>Generate comprehensive ranking explanation.</p> PARAMETER DESCRIPTION <code>ranked_files</code> <p>List of ranked files</p> <p> TYPE: <code>List[RankedFile]</code> </p> <code>weights</code> <p>Factor weights used</p> <p> TYPE: <code>Dict[str, float]</code> </p> <code>top_n</code> <p>Number of top files to explain</p> <p> TYPE: <code>int</code> DEFAULT: <code>10</code> </p> <code>include_factors</code> <p>Include factor breakdown</p> <p> TYPE: <code>bool</code> DEFAULT: <code>True</code> </p> RETURNS DESCRIPTION <code>str</code> <p>Formatted explanation string</p>"},{"location":"api/tenets/core/ranking/factors/#tenets.core.ranking.factors.RankingExplainer.compare_rankings","title":"compare_rankings","text":"Python<pre><code>compare_rankings(rankings1: List[RankedFile], rankings2: List[RankedFile], labels: Tuple[str, str] = ('Ranking 1', 'Ranking 2')) -&gt; str\n</code></pre> <p>Compare two different rankings.</p> <p>Useful for understanding how different algorithms or weights affect ranking results.</p> PARAMETER DESCRIPTION <code>rankings1</code> <p>First ranking</p> <p> TYPE: <code>List[RankedFile]</code> </p> <code>rankings2</code> <p>Second ranking</p> <p> TYPE: <code>List[RankedFile]</code> </p> <code>labels</code> <p>Labels for the two rankings</p> <p> TYPE: <code>Tuple[str, str]</code> DEFAULT: <code>('Ranking 1', 'Ranking 2')</code> </p> RETURNS DESCRIPTION <code>str</code> <p>Comparison report</p>"},{"location":"api/tenets/core/ranking/factors/#tenets.core.ranking.factors-functions","title":"Functions","text":""},{"location":"api/tenets/core/ranking/ranker/","title":"Ranker","text":""},{"location":"api/tenets/core/ranking/ranker/#tenets.core.ranking.ranker","title":"tenets.core.ranking.ranker","text":"<p>Main relevance ranking orchestrator.</p> <p>This module provides the main RelevanceRanker class that coordinates different ranking strategies, manages corpus analysis, and produces ranked results. It supports multiple algorithms, parallel processing, and custom ranking extensions.</p> <p>The ranker is designed to be efficient, scalable, and extensible while providing high-quality relevance scoring for code search and context generation.</p>"},{"location":"api/tenets/core/ranking/ranker/#tenets.core.ranking.ranker-classes","title":"Classes","text":""},{"location":"api/tenets/core/ranking/ranker/#tenets.core.ranking.ranker.RankingAlgorithm","title":"RankingAlgorithm","text":"<p>               Bases: <code>Enum</code></p> <p>Available ranking algorithms.</p> <p>Each algorithm provides different trade-offs between speed and accuracy.</p>"},{"location":"api/tenets/core/ranking/ranker/#tenets.core.ranking.ranker.RankingStats","title":"RankingStats  <code>dataclass</code>","text":"Python<pre><code>RankingStats(total_files: int = 0, files_ranked: int = 0, files_failed: int = 0, time_elapsed: float = 0.0, algorithm_used: str = '', threshold_applied: float = 0.0, files_above_threshold: int = 0, average_score: float = 0.0, max_score: float = 0.0, min_score: float = 0.0, corpus_stats: Dict[str, Any] = None)\n</code></pre> <p>Statistics from ranking operation.</p> <p>Tracks performance metrics and diagnostic information about the ranking process for monitoring and optimization.</p> ATTRIBUTE DESCRIPTION <code>total_files</code> <p>Total number of files processed</p> <p> TYPE: <code>int</code> </p> <code>files_ranked</code> <p>Number of files successfully ranked</p> <p> TYPE: <code>int</code> </p> <code>files_failed</code> <p>Number of files that failed ranking</p> <p> TYPE: <code>int</code> </p> <code>time_elapsed</code> <p>Total time in seconds</p> <p> TYPE: <code>float</code> </p> <code>algorithm_used</code> <p>Which algorithm was used</p> <p> TYPE: <code>str</code> </p> <code>threshold_applied</code> <p>Relevance threshold used</p> <p> TYPE: <code>float</code> </p> <code>files_above_threshold</code> <p>Number of files above threshold</p> <p> TYPE: <code>int</code> </p> <code>average_score</code> <p>Average relevance score</p> <p> TYPE: <code>float</code> </p> <code>max_score</code> <p>Maximum relevance score</p> <p> TYPE: <code>float</code> </p> <code>min_score</code> <p>Minimum relevance score</p> <p> TYPE: <code>float</code> </p> <code>corpus_stats</code> <p>Dictionary of corpus statistics</p> <p> TYPE: <code>Dict[str, Any]</code> </p>"},{"location":"api/tenets/core/ranking/ranker/#tenets.core.ranking.ranker.RankingStats-functions","title":"Functions","text":""},{"location":"api/tenets/core/ranking/ranker/#tenets.core.ranking.ranker.RankingStats.to_dict","title":"to_dict","text":"Python<pre><code>to_dict() -&gt; Dict[str, Any]\n</code></pre> <p>Convert to dictionary representation.</p> RETURNS DESCRIPTION <code>Dict[str, Any]</code> <p>Dictionary with all statistics</p>"},{"location":"api/tenets/core/ranking/ranker/#tenets.core.ranking.ranker.RelevanceRanker","title":"RelevanceRanker","text":"Python<pre><code>RelevanceRanker(config: TenetsConfig, algorithm: Optional[str] = None, use_stopwords: Optional[bool] = None)\n</code></pre> <p>Main relevance ranking system.</p> <p>Orchestrates the ranking process by analyzing the corpus, selecting appropriate strategies, and producing ranked results. Supports multiple algorithms, parallel processing, and custom ranking extensions.</p> <p>The ranker follows a multi-stage process: 1. Corpus analysis (TF-IDF, import graph, statistics) 2. Strategy selection based on algorithm 3. Parallel factor calculation 4. Score aggregation and weighting 5. Filtering and sorting</p> ATTRIBUTE DESCRIPTION <code>config</code> <p>TenetsConfig instance</p> <p> </p> <code>logger</code> <p>Logger instance</p> <p> </p> <code>strategies</code> <p>Available ranking strategies</p> <p> </p> <code>custom_rankers</code> <p>Custom ranking functions</p> <p> TYPE: <code>List[Callable]</code> </p> <code>executor</code> <p>Thread pool for parallel processing</p> <p> </p> <code>stats</code> <p>Latest ranking statistics</p> <p> </p> <code>cache</code> <p>Internal cache for optimizations</p> <p> </p> <p>Initialize the relevance ranker.</p> PARAMETER DESCRIPTION <code>config</code> <p>Tenets configuration</p> <p> TYPE: <code>TenetsConfig</code> </p> <code>algorithm</code> <p>Override default algorithm</p> <p> TYPE: <code>Optional[str]</code> DEFAULT: <code>None</code> </p> <code>use_stopwords</code> <p>Override stopword filtering setting</p> <p> TYPE: <code>Optional[bool]</code> DEFAULT: <code>None</code> </p>"},{"location":"api/tenets/core/ranking/ranker/#tenets.core.ranking.ranker.RelevanceRanker-attributes","title":"Attributes","text":""},{"location":"api/tenets/core/ranking/ranker/#tenets.core.ranking.ranker.RelevanceRanker.executor","title":"executor  <code>property</code>","text":"Python<pre><code>executor\n</code></pre> <p>Lazy initialization of ThreadPoolExecutor to avoid Windows import issues.</p>"},{"location":"api/tenets/core/ranking/ranker/#tenets.core.ranking.ranker.RelevanceRanker-functions","title":"Functions","text":""},{"location":"api/tenets/core/ranking/ranker/#tenets.core.ranking.ranker.RelevanceRanker.rank_files","title":"rank_files","text":"Python<pre><code>rank_files(files: List[FileAnalysis], prompt_context: PromptContext, algorithm: Optional[str] = None, parallel: bool = True, explain: bool = False) -&gt; List[FileAnalysis]\n</code></pre> <p>Rank files by relevance to prompt.</p> <p>This is the main entry point for ranking files. It analyzes the corpus, applies the selected ranking strategy, and returns files sorted by relevance above the configured threshold.</p> PARAMETER DESCRIPTION <code>files</code> <p>List of files to rank</p> <p> TYPE: <code>List[FileAnalysis]</code> </p> <code>prompt_context</code> <p>Parsed prompt information</p> <p> TYPE: <code>PromptContext</code> </p> <code>algorithm</code> <p>Override algorithm for this ranking</p> <p> TYPE: <code>Optional[str]</code> DEFAULT: <code>None</code> </p> <code>parallel</code> <p>Whether to rank files in parallel</p> <p> TYPE: <code>bool</code> DEFAULT: <code>True</code> </p> <code>explain</code> <p>Whether to generate ranking explanations</p> <p> TYPE: <code>bool</code> DEFAULT: <code>False</code> </p> RETURNS DESCRIPTION <code>List[FileAnalysis]</code> <p>List of FileAnalysis objects sorted by relevance (highest first)</p> <code>List[FileAnalysis]</code> <p>and filtered by threshold</p> RAISES DESCRIPTION <code>ValueError</code> <p>If algorithm is invalid</p>"},{"location":"api/tenets/core/ranking/ranker/#tenets.core.ranking.ranker.RelevanceRanker.register_custom_ranker","title":"register_custom_ranker","text":"Python<pre><code>register_custom_ranker(ranker_func: Callable[[List[RankedFile], PromptContext], List[RankedFile]])\n</code></pre> <p>Register a custom ranking function.</p> <p>Custom rankers are applied after the main ranking strategy and can adjust scores based on project-specific logic.</p> PARAMETER DESCRIPTION <code>ranker_func</code> <p>Function that takes ranked files and returns modified list</p> <p> TYPE: <code>Callable[[List[RankedFile], PromptContext], List[RankedFile]]</code> </p> Example <p>def boost_tests(ranked_files, prompt_context): ...     if 'test' in prompt_context.text: ...         for rf in ranked_files: ...             if 'test' in rf.path: ...                 rf.score *= 1.5 ...     return ranked_files ranker.register_custom_ranker(boost_tests)</p>"},{"location":"api/tenets/core/ranking/ranker/#tenets.core.ranking.ranker.RelevanceRanker.get_ranking_explanation","title":"get_ranking_explanation","text":"Python<pre><code>get_ranking_explanation(ranked_files: List[RankedFile], top_n: int = 10) -&gt; str\n</code></pre> <p>Get detailed explanation of ranking results.</p> PARAMETER DESCRIPTION <code>ranked_files</code> <p>List of ranked files</p> <p> TYPE: <code>List[RankedFile]</code> </p> <code>top_n</code> <p>Number of top files to explain</p> <p> TYPE: <code>int</code> DEFAULT: <code>10</code> </p> RETURNS DESCRIPTION <code>str</code> <p>Formatted explanation string</p>"},{"location":"api/tenets/core/ranking/ranker/#tenets.core.ranking.ranker.RelevanceRanker.get_stats","title":"get_stats","text":"Python<pre><code>get_stats() -&gt; RankingStats\n</code></pre> <p>Get latest ranking statistics.</p> RETURNS DESCRIPTION <code>RankingStats</code> <p>RankingStats object</p>"},{"location":"api/tenets/core/ranking/ranker/#tenets.core.ranking.ranker.RelevanceRanker.shutdown","title":"shutdown","text":"Python<pre><code>shutdown()\n</code></pre> <p>Shutdown the ranker and clean up resources.</p>"},{"location":"api/tenets/core/ranking/ranker/#tenets.core.ranking.ranker-functions","title":"Functions","text":""},{"location":"api/tenets/core/ranking/ranker/#tenets.core.ranking.ranker.create_ranker","title":"create_ranker","text":"Python<pre><code>create_ranker(config: Optional[TenetsConfig] = None, algorithm: str = 'balanced', use_stopwords: bool = False) -&gt; RelevanceRanker\n</code></pre> <p>Create a configured relevance ranker.</p> PARAMETER DESCRIPTION <code>config</code> <p>Configuration (uses default if None)</p> <p> TYPE: <code>Optional[TenetsConfig]</code> DEFAULT: <code>None</code> </p> <code>algorithm</code> <p>Ranking algorithm to use</p> <p> TYPE: <code>str</code> DEFAULT: <code>'balanced'</code> </p> <code>use_stopwords</code> <p>Whether to filter stopwords</p> <p> TYPE: <code>bool</code> DEFAULT: <code>False</code> </p> RETURNS DESCRIPTION <code>RelevanceRanker</code> <p>Configured RelevanceRanker instance</p>"},{"location":"api/tenets/core/ranking/strategies/","title":"Strategies","text":""},{"location":"api/tenets/core/ranking/strategies/#tenets.core.ranking.strategies","title":"tenets.core.ranking.strategies","text":"<p>Ranking strategies for different use cases.</p> <p>This module implements various ranking strategies from simple keyword matching to sophisticated ML-based semantic analysis. Each strategy provides different trade-offs between speed and accuracy.</p> <p>Now uses centralized NLP components for all text processing and pattern matching. No more duplicate programming patterns or keyword extraction logic.</p>"},{"location":"api/tenets/core/ranking/strategies/#tenets.core.ranking.strategies-classes","title":"Classes","text":""},{"location":"api/tenets/core/ranking/strategies/#tenets.core.ranking.strategies.RankingStrategy","title":"RankingStrategy","text":"<p>               Bases: <code>ABC</code></p> <p>Abstract base class for ranking strategies.</p>"},{"location":"api/tenets/core/ranking/strategies/#tenets.core.ranking.strategies.RankingStrategy-attributes","title":"Attributes","text":""},{"location":"api/tenets/core/ranking/strategies/#tenets.core.ranking.strategies.RankingStrategy.name","title":"name  <code>abstractmethod</code> <code>property</code>","text":"Python<pre><code>name: str\n</code></pre> <p>Get strategy name.</p>"},{"location":"api/tenets/core/ranking/strategies/#tenets.core.ranking.strategies.RankingStrategy.description","title":"description  <code>abstractmethod</code> <code>property</code>","text":"Python<pre><code>description: str\n</code></pre> <p>Get strategy description.</p>"},{"location":"api/tenets/core/ranking/strategies/#tenets.core.ranking.strategies.RankingStrategy-functions","title":"Functions","text":""},{"location":"api/tenets/core/ranking/strategies/#tenets.core.ranking.strategies.RankingStrategy.rank_file","title":"rank_file  <code>abstractmethod</code>","text":"Python<pre><code>rank_file(file: FileAnalysis, prompt_context: PromptContext, corpus_stats: Dict[str, Any]) -&gt; RankingFactors\n</code></pre> <p>Calculate ranking factors for a file.</p>"},{"location":"api/tenets/core/ranking/strategies/#tenets.core.ranking.strategies.RankingStrategy.get_weights","title":"get_weights  <code>abstractmethod</code>","text":"Python<pre><code>get_weights() -&gt; Dict[str, float]\n</code></pre> <p>Get factor weights for this strategy.</p>"},{"location":"api/tenets/core/ranking/strategies/#tenets.core.ranking.strategies.FastRankingStrategy","title":"FastRankingStrategy","text":"Python<pre><code>FastRankingStrategy()\n</code></pre> <p>               Bases: <code>RankingStrategy</code></p> <p>Fast keyword-based ranking strategy.</p> <p>Initialize fast ranking strategy.</p>"},{"location":"api/tenets/core/ranking/strategies/#tenets.core.ranking.strategies.FastRankingStrategy-functions","title":"Functions","text":""},{"location":"api/tenets/core/ranking/strategies/#tenets.core.ranking.strategies.FastRankingStrategy.rank_file","title":"rank_file","text":"Python<pre><code>rank_file(file: FileAnalysis, prompt_context: PromptContext, corpus_stats: Dict[str, Any]) -&gt; RankingFactors\n</code></pre> <p>Fast ranking based on keywords and paths.</p>"},{"location":"api/tenets/core/ranking/strategies/#tenets.core.ranking.strategies.FastRankingStrategy.get_weights","title":"get_weights","text":"Python<pre><code>get_weights() -&gt; Dict[str, float]\n</code></pre> <p>Get weights for fast ranking.</p>"},{"location":"api/tenets/core/ranking/strategies/#tenets.core.ranking.strategies.BalancedRankingStrategy","title":"BalancedRankingStrategy","text":"Python<pre><code>BalancedRankingStrategy()\n</code></pre> <p>               Bases: <code>RankingStrategy</code></p> <p>Balanced multi-factor ranking strategy.</p> <p>Initialize balanced ranking strategy.</p>"},{"location":"api/tenets/core/ranking/strategies/#tenets.core.ranking.strategies.BalancedRankingStrategy-functions","title":"Functions","text":""},{"location":"api/tenets/core/ranking/strategies/#tenets.core.ranking.strategies.BalancedRankingStrategy.rank_file","title":"rank_file","text":"Python<pre><code>rank_file(file: FileAnalysis, prompt_context: PromptContext, corpus_stats: Dict[str, Any]) -&gt; RankingFactors\n</code></pre> <p>Balanced ranking using multiple factors.</p>"},{"location":"api/tenets/core/ranking/strategies/#tenets.core.ranking.strategies.BalancedRankingStrategy.get_weights","title":"get_weights","text":"Python<pre><code>get_weights() -&gt; Dict[str, float]\n</code></pre> <p>Get weights for balanced ranking.</p>"},{"location":"api/tenets/core/ranking/strategies/#tenets.core.ranking.strategies.ThoroughRankingStrategy","title":"ThoroughRankingStrategy","text":"Python<pre><code>ThoroughRankingStrategy()\n</code></pre> <p>               Bases: <code>RankingStrategy</code></p> <p>Thorough deep analysis ranking strategy using centralized NLP.</p> <p>Initialize thorough ranking strategy with NLP components.</p>"},{"location":"api/tenets/core/ranking/strategies/#tenets.core.ranking.strategies.ThoroughRankingStrategy-functions","title":"Functions","text":""},{"location":"api/tenets/core/ranking/strategies/#tenets.core.ranking.strategies.ThoroughRankingStrategy.rank_file","title":"rank_file","text":"Python<pre><code>rank_file(file: FileAnalysis, prompt_context: PromptContext, corpus_stats: Dict[str, Any]) -&gt; RankingFactors\n</code></pre> <p>Thorough ranking with deep analysis using centralized NLP.</p>"},{"location":"api/tenets/core/ranking/strategies/#tenets.core.ranking.strategies.ThoroughRankingStrategy.get_weights","title":"get_weights","text":"Python<pre><code>get_weights() -&gt; Dict[str, float]\n</code></pre> <p>Get weights for thorough ranking.</p>"},{"location":"api/tenets/core/ranking/strategies/#tenets.core.ranking.strategies.MLRankingStrategy","title":"MLRankingStrategy","text":"Python<pre><code>MLRankingStrategy()\n</code></pre> <p>               Bases: <code>RankingStrategy</code></p> <p>Machine Learning-based ranking strategy.</p> <p>Initialize ML ranking strategy.</p>"},{"location":"api/tenets/core/ranking/strategies/#tenets.core.ranking.strategies.MLRankingStrategy-functions","title":"Functions","text":""},{"location":"api/tenets/core/ranking/strategies/#tenets.core.ranking.strategies.MLRankingStrategy.rank_file","title":"rank_file","text":"Python<pre><code>rank_file(file: FileAnalysis, prompt_context: PromptContext, corpus_stats: Dict[str, Any]) -&gt; RankingFactors\n</code></pre> <p>ML-based ranking with semantic similarity.</p>"},{"location":"api/tenets/core/ranking/strategies/#tenets.core.ranking.strategies.MLRankingStrategy.get_weights","title":"get_weights","text":"Python<pre><code>get_weights() -&gt; Dict[str, float]\n</code></pre> <p>Get weights for ML ranking.</p>"},{"location":"api/tenets/core/ranking/strategies/#tenets.core.ranking.strategies-functions","title":"Functions","text":""},{"location":"api/tenets/core/reporting/generator/","title":"Generator","text":""},{"location":"api/tenets/core/reporting/generator/#tenets.core.reporting.generator","title":"tenets.core.reporting.generator","text":"<p>Report generation module.</p> <p>This module orchestrates report generation by combining analysis data with visualizations from the viz package. It creates structured reports in various formats without duplicating visualization logic.</p>"},{"location":"api/tenets/core/reporting/generator/#tenets.core.reporting.generator-classes","title":"Classes","text":""},{"location":"api/tenets/core/reporting/generator/#tenets.core.reporting.generator.ReportSection","title":"ReportSection  <code>dataclass</code>","text":"Python<pre><code>ReportSection(id: str, title: str, level: int = 1, order: int = 0, icon: Optional[str] = None, content: Optional[Union[str, List[str], Dict[str, Any]]] = None, metrics: Dict[str, Any] = dict(), tables: List[Dict[str, Any]] = list(), charts: List[Dict[str, Any]] = list(), code_snippets: List[Dict[str, Any]] = list(), subsections: List[ReportSection] = list(), visible: bool = True, collapsed: bool = False, collapsible: bool = False)\n</code></pre> <p>Represents a section in the report.</p> <p>A report section contains structured content including text, metrics, tables, and charts. Sections can be nested to create hierarchical report structures.</p> ATTRIBUTE DESCRIPTION <code>id</code> <p>Unique section identifier</p> <p> TYPE: <code>str</code> </p> <code>title</code> <p>Section title</p> <p> TYPE: <code>str</code> </p> <code>level</code> <p>Heading level (1-6)</p> <p> TYPE: <code>int</code> </p> <code>order</code> <p>Display order</p> <p> TYPE: <code>int</code> </p> <code>icon</code> <p>Optional icon/emoji</p> <p> TYPE: <code>Optional[str]</code> </p> <code>content</code> <p>Section text content</p> <p> TYPE: <code>Optional[Union[str, List[str], Dict[str, Any]]]</code> </p> <code>metrics</code> <p>Key metrics dictionary</p> <p> TYPE: <code>Dict[str, Any]</code> </p> <code>tables</code> <p>List of table data</p> <p> TYPE: <code>List[Dict[str, Any]]</code> </p> <code>charts</code> <p>List of chart configurations</p> <p> TYPE: <code>List[Dict[str, Any]]</code> </p> <code>code_snippets</code> <p>List of code examples</p> <p> TYPE: <code>List[Dict[str, Any]]</code> </p> <code>subsections</code> <p>Nested sections</p> <p> TYPE: <code>List[ReportSection]</code> </p> <code>visible</code> <p>Whether section is visible</p> <p> TYPE: <code>bool</code> </p> <code>collapsed</code> <p>Whether section starts collapsed</p> <p> TYPE: <code>bool</code> </p>"},{"location":"api/tenets/core/reporting/generator/#tenets.core.reporting.generator.ReportSection-functions","title":"Functions","text":""},{"location":"api/tenets/core/reporting/generator/#tenets.core.reporting.generator.ReportSection.add_metric","title":"add_metric","text":"Python<pre><code>add_metric(name: str, value: Any) -&gt; None\n</code></pre> <p>Add a metric to the section.</p> PARAMETER DESCRIPTION <code>name</code> <p>Metric name</p> <p> TYPE: <code>str</code> </p> <code>value</code> <p>Metric value</p> <p> TYPE: <code>Any</code> </p>"},{"location":"api/tenets/core/reporting/generator/#tenets.core.reporting.generator.ReportSection.add_table","title":"add_table","text":"Python<pre><code>add_table(table_data: Dict[str, Any]) -&gt; None\n</code></pre> <p>Add a table to the section.</p> PARAMETER DESCRIPTION <code>table_data</code> <p>Table configuration with headers and rows</p> <p> TYPE: <code>Dict[str, Any]</code> </p>"},{"location":"api/tenets/core/reporting/generator/#tenets.core.reporting.generator.ReportSection.add_chart","title":"add_chart","text":"Python<pre><code>add_chart(chart_config: Dict[str, Any]) -&gt; None\n</code></pre> <p>Add a chart to the section.</p> PARAMETER DESCRIPTION <code>chart_config</code> <p>Chart configuration from viz modules</p> <p> TYPE: <code>Dict[str, Any]</code> </p>"},{"location":"api/tenets/core/reporting/generator/#tenets.core.reporting.generator.ReportSection.add_subsection","title":"add_subsection","text":"Python<pre><code>add_subsection(subsection: ReportSection) -&gt; None\n</code></pre> <p>Add a subsection.</p> PARAMETER DESCRIPTION <code>subsection</code> <p>Nested section</p> <p> TYPE: <code>ReportSection</code> </p>"},{"location":"api/tenets/core/reporting/generator/#tenets.core.reporting.generator.ReportConfig","title":"ReportConfig  <code>dataclass</code>","text":"Python<pre><code>ReportConfig(title: str = 'Code Analysis Report', format: str = 'html', include_summary: bool = True, include_toc: bool = True, include_charts: bool = True, include_code_snippets: bool = True, include_recommendations: bool = True, max_items: int = 20, theme: str = 'light', footer_text: str = 'Generated by Tenets Code Analysis', custom_css: Optional[str] = None, chart_config: Optional[ChartConfig] = None, custom_logo: Optional[Path] = None)\n</code></pre> <p>Configuration for report generation.</p> <p>Controls report generation options including format, content inclusion, and visualization settings.</p> ATTRIBUTE DESCRIPTION <code>title</code> <p>Report title</p> <p> TYPE: <code>str</code> </p> <code>format</code> <p>Output format (html, markdown, json)</p> <p> TYPE: <code>str</code> </p> <code>include_summary</code> <p>Include executive summary</p> <p> TYPE: <code>bool</code> </p> <code>include_toc</code> <p>Include table of contents</p> <p> TYPE: <code>bool</code> </p> <code>include_charts</code> <p>Include visualizations</p> <p> TYPE: <code>bool</code> </p> <code>include_code_snippets</code> <p>Include code examples</p> <p> TYPE: <code>bool</code> </p> <code>include_recommendations</code> <p>Include recommendations</p> <p> TYPE: <code>bool</code> </p> <code>max_items</code> <p>Maximum items in lists</p> <p> TYPE: <code>int</code> </p> <code>theme</code> <p>Visual theme (light, dark, auto)</p> <p> TYPE: <code>str</code> </p> <code>footer_text</code> <p>Footer text</p> <p> TYPE: <code>str</code> </p> <code>custom_css</code> <p>Custom CSS for HTML reports</p> <p> TYPE: <code>Optional[str]</code> </p> <code>chart_config</code> <p>Default chart configuration</p> <p> TYPE: <code>Optional[ChartConfig]</code> </p>"},{"location":"api/tenets/core/reporting/generator/#tenets.core.reporting.generator.ReportGenerator","title":"ReportGenerator","text":"Python<pre><code>ReportGenerator(config: TenetsConfig)\n</code></pre> <p>Main report generator orchestrator.</p> <p>Coordinates report generation by combining analysis data with visualizations from the viz package. Creates structured reports without duplicating visualization logic.</p> <p>The generator follows a clear separation of concerns: - Core modules provide analysis data - Viz modules create visualizations - Generator orchestrates and structures the report</p> ATTRIBUTE DESCRIPTION <code>config</code> <p>Configuration object</p> <p> </p> <code>logger</code> <p>Logger instance</p> <p> </p> <code>sections</code> <p>List of report sections</p> <p> TYPE: <code>List[ReportSection]</code> </p> <code>metadata</code> <p>Report metadata</p> <p> TYPE: <code>Dict[str, Any]</code> </p> <p>Initialize report generator.</p> PARAMETER DESCRIPTION <code>config</code> <p>Configuration object</p> <p> TYPE: <code>TenetsConfig</code> </p>"},{"location":"api/tenets/core/reporting/generator/#tenets.core.reporting.generator.ReportGenerator-functions","title":"Functions","text":""},{"location":"api/tenets/core/reporting/generator/#tenets.core.reporting.generator.ReportGenerator.generate","title":"generate","text":"Python<pre><code>generate(data: Dict[str, Any], output_path: Path, config: Optional[ReportConfig] = None) -&gt; Path\n</code></pre> <p>Generate a report from analysis data.</p> <p>This is the main entry point for report generation. It takes analysis data, creates appropriate visualizations using viz modules, and outputs a formatted report.</p> PARAMETER DESCRIPTION <code>data</code> <p>Analysis data from core modules</p> <p> TYPE: <code>Dict[str, Any]</code> </p> <code>output_path</code> <p>Path for output file</p> <p> TYPE: <code>Path</code> </p> <code>config</code> <p>Report configuration</p> <p> TYPE: <code>Optional[ReportConfig]</code> DEFAULT: <code>None</code> </p> RETURNS DESCRIPTION <code>Path</code> <p>Path to generated report</p> <p> TYPE: <code>Path</code> </p> Example <p>generator = ReportGenerator(config) report_path = generator.generate( ...     analysis_data, ...     Path(\"report.html\"), ...     ReportConfig(include_charts=True) ... )</p>"},{"location":"api/tenets/core/reporting/generator/#tenets.core.reporting.generator-functions","title":"Functions","text":""},{"location":"api/tenets/core/reporting/html_reporter/","title":"Html Reporter","text":""},{"location":"api/tenets/core/reporting/html_reporter/#tenets.core.reporting.html_reporter","title":"tenets.core.reporting.html_reporter","text":"<p>HTML report generator module.</p> <p>This module provides HTML report generation functionality with rich visualizations, interactive charts, and professional styling. It creates standalone HTML reports that can be viewed in any modern web browser.</p> <p>The HTML reporter generates responsive, interactive reports with embedded JavaScript visualizations and customizable themes.</p>"},{"location":"api/tenets/core/reporting/html_reporter/#tenets.core.reporting.html_reporter-classes","title":"Classes","text":""},{"location":"api/tenets/core/reporting/html_reporter/#tenets.core.reporting.html_reporter.HTMLTemplate","title":"HTMLTemplate","text":"Python<pre><code>HTMLTemplate(theme: str = 'default', custom_css: Optional[str] = None, include_charts: bool = True)\n</code></pre> <p>HTML template generator for reports.</p> <p>Provides template generation for various report components including the main layout, charts, tables, and interactive elements.</p> ATTRIBUTE DESCRIPTION <code>theme</code> <p>Visual theme name</p> <p> </p> <code>custom_css</code> <p>Custom CSS styles</p> <p> </p> <code>include_charts</code> <p>Whether to include chart libraries</p> <p> </p> <p>Initialize HTML template.</p> PARAMETER DESCRIPTION <code>theme</code> <p>Theme name</p> <p> TYPE: <code>str</code> DEFAULT: <code>'default'</code> </p> <code>custom_css</code> <p>Custom CSS styles</p> <p> TYPE: <code>Optional[str]</code> DEFAULT: <code>None</code> </p> <code>include_charts</code> <p>Include chart libraries</p> <p> TYPE: <code>bool</code> DEFAULT: <code>True</code> </p>"},{"location":"api/tenets/core/reporting/html_reporter/#tenets.core.reporting.html_reporter.HTMLTemplate-functions","title":"Functions","text":""},{"location":"api/tenets/core/reporting/html_reporter/#tenets.core.reporting.html_reporter.HTMLTemplate.get_base_template","title":"get_base_template","text":"Python<pre><code>get_base_template() -&gt; str\n</code></pre> <p>Get base HTML template.</p> RETURNS DESCRIPTION <code>str</code> <p>Base HTML template</p> <p> TYPE: <code>str</code> </p>"},{"location":"api/tenets/core/reporting/html_reporter/#tenets.core.reporting.html_reporter.HTMLTemplate.get_styles","title":"get_styles","text":"Python<pre><code>get_styles() -&gt; str\n</code></pre> <p>Get CSS styles for the report.</p> RETURNS DESCRIPTION <code>str</code> <p>CSS styles</p> <p> TYPE: <code>str</code> </p>"},{"location":"api/tenets/core/reporting/html_reporter/#tenets.core.reporting.html_reporter.HTMLTemplate.get_scripts","title":"get_scripts","text":"Python<pre><code>get_scripts() -&gt; str\n</code></pre> <p>Get JavaScript libraries and scripts.</p> RETURNS DESCRIPTION <code>str</code> <p>Script tags</p> <p> TYPE: <code>str</code> </p>"},{"location":"api/tenets/core/reporting/html_reporter/#tenets.core.reporting.html_reporter.HTMLTemplate.get_navigation","title":"get_navigation","text":"Python<pre><code>get_navigation(sections: List[ReportSection]) -&gt; str\n</code></pre> <p>Generate navigation menu.</p> PARAMETER DESCRIPTION <code>sections</code> <p>Report sections</p> <p> TYPE: <code>List[ReportSection]</code> </p> RETURNS DESCRIPTION <code>str</code> <p>Navigation HTML</p> <p> TYPE: <code>str</code> </p>"},{"location":"api/tenets/core/reporting/html_reporter/#tenets.core.reporting.html_reporter.HTMLReporter","title":"HTMLReporter","text":"Python<pre><code>HTMLReporter(config: TenetsConfig)\n</code></pre> <p>HTML report generator.</p> <p>Generates standalone HTML reports with rich visualizations and interactive elements from analysis results.</p> ATTRIBUTE DESCRIPTION <code>config</code> <p>Configuration object</p> <p> </p> <code>logger</code> <p>Logger instance</p> <p> </p> <code>template</code> <p>HTML template generator</p> <p> </p> <p>Initialize HTML reporter.</p> PARAMETER DESCRIPTION <code>config</code> <p>TenetsConfig instance</p> <p> TYPE: <code>TenetsConfig</code> </p>"},{"location":"api/tenets/core/reporting/html_reporter/#tenets.core.reporting.html_reporter.HTMLReporter-functions","title":"Functions","text":""},{"location":"api/tenets/core/reporting/html_reporter/#tenets.core.reporting.html_reporter.HTMLReporter.generate","title":"generate","text":"Python<pre><code>generate(sections: List[ReportSection], metadata: Dict[str, Any], output_path: Path, report_config: ReportConfig) -&gt; Path\n</code></pre> <p>Generate HTML report.</p> PARAMETER DESCRIPTION <code>sections</code> <p>Report sections</p> <p> TYPE: <code>List[ReportSection]</code> </p> <code>metadata</code> <p>Report metadata</p> <p> TYPE: <code>Dict[str, Any]</code> </p> <code>output_path</code> <p>Output file path</p> <p> TYPE: <code>Path</code> </p> <code>report_config</code> <p>Report configuration</p> <p> TYPE: <code>ReportConfig</code> </p> RETURNS DESCRIPTION <code>Path</code> <p>Path to generated report</p> <p> TYPE: <code>Path</code> </p>"},{"location":"api/tenets/core/reporting/html_reporter/#tenets.core.reporting.html_reporter-functions","title":"Functions","text":""},{"location":"api/tenets/core/reporting/html_reporter/#tenets.core.reporting.html_reporter.create_html_report","title":"create_html_report","text":"Python<pre><code>create_html_report(sections: List[ReportSection], output_path: Path, title: str = 'Code Analysis Report', config: Optional[TenetsConfig] = None) -&gt; Path\n</code></pre> <p>Convenience function to create HTML report.</p> PARAMETER DESCRIPTION <code>sections</code> <p>Report sections</p> <p> TYPE: <code>List[ReportSection]</code> </p> <code>output_path</code> <p>Output path</p> <p> TYPE: <code>Path</code> </p> <code>title</code> <p>Report title</p> <p> TYPE: <code>str</code> DEFAULT: <code>'Code Analysis Report'</code> </p> <code>config</code> <p>Optional configuration</p> <p> TYPE: <code>Optional[TenetsConfig]</code> DEFAULT: <code>None</code> </p> RETURNS DESCRIPTION <code>Path</code> <p>Path to generated report</p> <p> TYPE: <code>Path</code> </p>"},{"location":"api/tenets/core/reporting/html_reporter/#tenets.core.reporting.html_reporter.create_dashboard","title":"create_dashboard","text":"Python<pre><code>create_dashboard(analysis_results: Dict[str, Any], output_path: Path, config: Optional[TenetsConfig] = None) -&gt; Path\n</code></pre> <p>Create an interactive dashboard.</p> PARAMETER DESCRIPTION <code>analysis_results</code> <p>Analysis results</p> <p> TYPE: <code>Dict[str, Any]</code> </p> <code>output_path</code> <p>Output path</p> <p> TYPE: <code>Path</code> </p> <code>config</code> <p>Optional configuration</p> <p> TYPE: <code>Optional[TenetsConfig]</code> DEFAULT: <code>None</code> </p> RETURNS DESCRIPTION <code>Path</code> <p>Path to dashboard</p> <p> TYPE: <code>Path</code> </p>"},{"location":"api/tenets/core/reporting/markdown_reporter/","title":"Markdown Reporter","text":""},{"location":"api/tenets/core/reporting/markdown_reporter/#tenets.core.reporting.markdown_reporter","title":"tenets.core.reporting.markdown_reporter","text":"<p>Markdown report generator module.</p> <p>This module provides Markdown report generation functionality for creating plain text reports that can be viewed in any text editor, converted to other formats, or integrated with documentation systems.</p> <p>The Markdown reporter generates clean, readable reports with support for tables, code blocks, and structured content.</p>"},{"location":"api/tenets/core/reporting/markdown_reporter/#tenets.core.reporting.markdown_reporter-classes","title":"Classes","text":""},{"location":"api/tenets/core/reporting/markdown_reporter/#tenets.core.reporting.markdown_reporter.MarkdownReporter","title":"MarkdownReporter","text":"Python<pre><code>MarkdownReporter(config: TenetsConfig)\n</code></pre> <p>Markdown report generator.</p> <p>Generates Markdown-formatted reports from analysis results, suitable for documentation, GitHub, and other Markdown-supporting platforms.</p> ATTRIBUTE DESCRIPTION <code>config</code> <p>Configuration object</p> <p> </p> <code>logger</code> <p>Logger instance</p> <p> </p> <code>toc_entries</code> <p>Table of contents entries</p> <p> TYPE: <code>List[str]</code> </p> <p>Initialize Markdown reporter.</p> PARAMETER DESCRIPTION <code>config</code> <p>TenetsConfig instance</p> <p> TYPE: <code>TenetsConfig</code> </p>"},{"location":"api/tenets/core/reporting/markdown_reporter/#tenets.core.reporting.markdown_reporter.MarkdownReporter-functions","title":"Functions","text":""},{"location":"api/tenets/core/reporting/markdown_reporter/#tenets.core.reporting.markdown_reporter.MarkdownReporter.generate","title":"generate","text":"Python<pre><code>generate(sections: List[ReportSection], metadata: Dict[str, Any], output_path: Path, report_config: ReportConfig) -&gt; Path\n</code></pre> <p>Generate Markdown report.</p> PARAMETER DESCRIPTION <code>sections</code> <p>Report sections</p> <p> TYPE: <code>List[ReportSection]</code> </p> <code>metadata</code> <p>Report metadata</p> <p> TYPE: <code>Dict[str, Any]</code> </p> <code>output_path</code> <p>Output file path</p> <p> TYPE: <code>Path</code> </p> <code>report_config</code> <p>Report configuration</p> <p> TYPE: <code>ReportConfig</code> </p> RETURNS DESCRIPTION <code>Path</code> <p>Path to generated report</p> <p> TYPE: <code>Path</code> </p> Example <p>reporter = MarkdownReporter(config) report_path = reporter.generate( ...     sections, ...     metadata, ...     Path(\"report.md\") ... )</p>"},{"location":"api/tenets/core/reporting/markdown_reporter/#tenets.core.reporting.markdown_reporter-functions","title":"Functions","text":""},{"location":"api/tenets/core/reporting/markdown_reporter/#tenets.core.reporting.markdown_reporter.create_markdown_report","title":"create_markdown_report","text":"Python<pre><code>create_markdown_report(sections: List[ReportSection], output_path: Path, title: str = 'Code Analysis Report', config: Optional[TenetsConfig] = None) -&gt; Path\n</code></pre> <p>Convenience function to create Markdown report.</p> PARAMETER DESCRIPTION <code>sections</code> <p>Report sections</p> <p> TYPE: <code>List[ReportSection]</code> </p> <code>output_path</code> <p>Output path</p> <p> TYPE: <code>Path</code> </p> <code>title</code> <p>Report title</p> <p> TYPE: <code>str</code> DEFAULT: <code>'Code Analysis Report'</code> </p> <code>config</code> <p>Optional configuration</p> <p> TYPE: <code>Optional[TenetsConfig]</code> DEFAULT: <code>None</code> </p> RETURNS DESCRIPTION <code>Path</code> <p>Path to generated report</p> <p> TYPE: <code>Path</code> </p> Example <p>from tenets.core.reporting.markdown_reporter import create_markdown_report report_path = create_markdown_report( ...     sections, ...     Path(\"report.md\"), ...     title=\"Analysis Report\" ... )</p>"},{"location":"api/tenets/core/reporting/markdown_reporter/#tenets.core.reporting.markdown_reporter.format_markdown_table","title":"format_markdown_table","text":"Python<pre><code>format_markdown_table(headers: List[str], rows: List[List[Any]], alignment: Optional[List[str]] = None) -&gt; str\n</code></pre> <p>Format data as a Markdown table.</p> PARAMETER DESCRIPTION <code>headers</code> <p>Table headers</p> <p> TYPE: <code>List[str]</code> </p> <code>rows</code> <p>Table rows</p> <p> TYPE: <code>List[List[Any]]</code> </p> <code>alignment</code> <p>Column alignment (left, right, center)</p> <p> TYPE: <code>Optional[List[str]]</code> DEFAULT: <code>None</code> </p> RETURNS DESCRIPTION <code>str</code> <p>Formatted Markdown table</p> <p> TYPE: <code>str</code> </p> Example <p>from tenets.core.reporting.markdown_reporter import format_markdown_table table = format_markdown_table( ...     [\"Name\", \"Value\", \"Status\"], ...     [[\"Test\", 42, \"Pass\"], [\"Demo\", 17, \"Fail\"]] ... ) print(table)</p>"},{"location":"api/tenets/core/reporting/markdown_reporter/#tenets.core.reporting.markdown_reporter.create_markdown_summary","title":"create_markdown_summary","text":"Python<pre><code>create_markdown_summary(analysis_results: Dict[str, Any], max_length: int = 1000) -&gt; str\n</code></pre> <p>Create a Markdown summary of analysis results.</p> PARAMETER DESCRIPTION <code>analysis_results</code> <p>Analysis results</p> <p> TYPE: <code>Dict[str, Any]</code> </p> <code>max_length</code> <p>Maximum length in characters</p> <p> TYPE: <code>int</code> DEFAULT: <code>1000</code> </p> RETURNS DESCRIPTION <code>str</code> <p>Markdown summary</p> <p> TYPE: <code>str</code> </p> Example <p>from tenets.core.reporting.markdown_reporter import create_markdown_summary summary = create_markdown_summary(analysis_results) print(summary)</p>"},{"location":"api/tenets/core/reporting/visualizer/","title":"Visualizer","text":""},{"location":"api/tenets/core/reporting/visualizer/#tenets.core.reporting.visualizer","title":"tenets.core.reporting.visualizer","text":"<p>Visualization module for report generation.</p> <p>This module provides chart and graph generation functionality for creating visual representations of analysis data. It supports various chart types and can generate both static and interactive visualizations.</p> <p>The visualizer creates data visualizations that help understand code metrics, trends, and patterns at a glance.</p>"},{"location":"api/tenets/core/reporting/visualizer/#tenets.core.reporting.visualizer-classes","title":"Classes","text":""},{"location":"api/tenets/core/reporting/visualizer/#tenets.core.reporting.visualizer.ChartGenerator","title":"ChartGenerator","text":"Python<pre><code>ChartGenerator(config: TenetsConfig)\n</code></pre> <p>Generator for various chart types.</p> <p>Creates chart configurations and data structures for visualization libraries like Chart.js, D3.js, or server-side rendering.</p> ATTRIBUTE DESCRIPTION <code>config</code> <p>Configuration object</p> <p> </p> <code>logger</code> <p>Logger instance</p> <p> </p> <code>color_palette</code> <p>Default color palette</p> <p> </p> <p>Initialize chart generator.</p> PARAMETER DESCRIPTION <code>config</code> <p>TenetsConfig instance</p> <p> TYPE: <code>TenetsConfig</code> </p>"},{"location":"api/tenets/core/reporting/visualizer/#tenets.core.reporting.visualizer.ChartGenerator-functions","title":"Functions","text":""},{"location":"api/tenets/core/reporting/visualizer/#tenets.core.reporting.visualizer.ChartGenerator.create_bar_chart","title":"create_bar_chart","text":"Python<pre><code>create_bar_chart(labels: List[str], values: List[Union[int, float]], title: str = '', x_label: str = '', y_label: str = '', colors: Optional[List[str]] = None, horizontal: bool = False) -&gt; Dict[str, Any]\n</code></pre> <p>Create a bar chart configuration.</p> PARAMETER DESCRIPTION <code>labels</code> <p>Bar labels</p> <p> TYPE: <code>List[str]</code> </p> <code>values</code> <p>Bar values</p> <p> TYPE: <code>List[Union[int, float]]</code> </p> <code>title</code> <p>Chart title</p> <p> TYPE: <code>str</code> DEFAULT: <code>''</code> </p> <code>x_label</code> <p>X-axis label</p> <p> TYPE: <code>str</code> DEFAULT: <code>''</code> </p> <code>y_label</code> <p>Y-axis label</p> <p> TYPE: <code>str</code> DEFAULT: <code>''</code> </p> <code>colors</code> <p>Custom colors</p> <p> TYPE: <code>Optional[List[str]]</code> DEFAULT: <code>None</code> </p> <code>horizontal</code> <p>Use horizontal bars</p> <p> TYPE: <code>bool</code> DEFAULT: <code>False</code> </p> RETURNS DESCRIPTION <code>Dict[str, Any]</code> <p>Dict[str, Any]: Chart configuration</p> Example <p>generator = ChartGenerator(config) chart = generator.create_bar_chart( ...     [\"Low\", \"Medium\", \"High\"], ...     [10, 25, 5], ...     title=\"Issue Distribution\" ... )</p>"},{"location":"api/tenets/core/reporting/visualizer/#tenets.core.reporting.visualizer.ChartGenerator.create_line_chart","title":"create_line_chart","text":"Python<pre><code>create_line_chart(labels: List[str], datasets: List[Dict[str, Any]], title: str = '', x_label: str = '', y_label: str = '', smooth: bool = True) -&gt; Dict[str, Any]\n</code></pre> <p>Create a line chart configuration.</p> PARAMETER DESCRIPTION <code>labels</code> <p>X-axis labels</p> <p> TYPE: <code>List[str]</code> </p> <code>datasets</code> <p>List of dataset configurations</p> <p> TYPE: <code>List[Dict[str, Any]]</code> </p> <code>title</code> <p>Chart title</p> <p> TYPE: <code>str</code> DEFAULT: <code>''</code> </p> <code>x_label</code> <p>X-axis label</p> <p> TYPE: <code>str</code> DEFAULT: <code>''</code> </p> <code>y_label</code> <p>Y-axis label</p> <p> TYPE: <code>str</code> DEFAULT: <code>''</code> </p> <code>smooth</code> <p>Use smooth lines</p> <p> TYPE: <code>bool</code> DEFAULT: <code>True</code> </p> RETURNS DESCRIPTION <code>Dict[str, Any]</code> <p>Dict[str, Any]: Chart configuration</p> Example <p>chart = generator.create_line_chart( ...     [\"Jan\", \"Feb\", \"Mar\"], ...     [ ...         {\"label\": \"Bugs\", \"data\": [10, 8, 12]}, ...         {\"label\": \"Features\", \"data\": [5, 7, 9]} ...     ], ...     title=\"Monthly Trends\" ... )</p>"},{"location":"api/tenets/core/reporting/visualizer/#tenets.core.reporting.visualizer.ChartGenerator.create_pie_chart","title":"create_pie_chart","text":"Python<pre><code>create_pie_chart(labels: List[str], values: List[Union[int, float]], title: str = '', colors: Optional[List[str]] = None, as_donut: bool = False) -&gt; Dict[str, Any]\n</code></pre> <p>Create a pie chart configuration.</p> PARAMETER DESCRIPTION <code>labels</code> <p>Slice labels</p> <p> TYPE: <code>List[str]</code> </p> <code>values</code> <p>Slice values</p> <p> TYPE: <code>List[Union[int, float]]</code> </p> <code>title</code> <p>Chart title</p> <p> TYPE: <code>str</code> DEFAULT: <code>''</code> </p> <code>colors</code> <p>Custom colors</p> <p> TYPE: <code>Optional[List[str]]</code> DEFAULT: <code>None</code> </p> <code>as_donut</code> <p>Create as donut chart</p> <p> TYPE: <code>bool</code> DEFAULT: <code>False</code> </p> RETURNS DESCRIPTION <code>Dict[str, Any]</code> <p>Dict[str, Any]: Chart configuration</p> Example <p>chart = generator.create_pie_chart( ...     [\"Python\", \"JavaScript\", \"Java\"], ...     [450, 320, 180], ...     title=\"Language Distribution\" ... )</p>"},{"location":"api/tenets/core/reporting/visualizer/#tenets.core.reporting.visualizer.ChartGenerator.create_scatter_plot","title":"create_scatter_plot","text":"Python<pre><code>create_scatter_plot(data_points: List[Tuple[float, float]], title: str = '', x_label: str = '', y_label: str = '', point_labels: Optional[List[str]] = None, colors: Optional[List[str]] = None) -&gt; Dict[str, Any]\n</code></pre> <p>Create a scatter plot configuration.</p> PARAMETER DESCRIPTION <code>data_points</code> <p>List of (x, y) tuples</p> <p> TYPE: <code>List[Tuple[float, float]]</code> </p> <code>title</code> <p>Chart title</p> <p> TYPE: <code>str</code> DEFAULT: <code>''</code> </p> <code>x_label</code> <p>X-axis label</p> <p> TYPE: <code>str</code> DEFAULT: <code>''</code> </p> <code>y_label</code> <p>Y-axis label</p> <p> TYPE: <code>str</code> DEFAULT: <code>''</code> </p> <code>point_labels</code> <p>Labels for points</p> <p> TYPE: <code>Optional[List[str]]</code> DEFAULT: <code>None</code> </p> <code>colors</code> <p>Point colors</p> <p> TYPE: <code>Optional[List[str]]</code> DEFAULT: <code>None</code> </p> RETURNS DESCRIPTION <code>Dict[str, Any]</code> <p>Dict[str, Any]: Chart configuration</p> Example <p>chart = generator.create_scatter_plot( ...     [(10, 5), (20, 8), (15, 12)], ...     title=\"Complexity vs Size\", ...     x_label=\"Lines of Code\", ...     y_label=\"Complexity\" ... )</p>"},{"location":"api/tenets/core/reporting/visualizer/#tenets.core.reporting.visualizer.ChartGenerator.create_radar_chart","title":"create_radar_chart","text":"Python<pre><code>create_radar_chart(labels: List[str], datasets: List[Dict[str, Any]], title: str = '', max_value: Optional[float] = None) -&gt; Dict[str, Any]\n</code></pre> <p>Create a radar chart configuration.</p> PARAMETER DESCRIPTION <code>labels</code> <p>Axis labels</p> <p> TYPE: <code>List[str]</code> </p> <code>datasets</code> <p>List of dataset configurations</p> <p> TYPE: <code>List[Dict[str, Any]]</code> </p> <code>title</code> <p>Chart title</p> <p> TYPE: <code>str</code> DEFAULT: <code>''</code> </p> <code>max_value</code> <p>Maximum value for axes</p> <p> TYPE: <code>Optional[float]</code> DEFAULT: <code>None</code> </p> RETURNS DESCRIPTION <code>Dict[str, Any]</code> <p>Dict[str, Any]: Chart configuration</p> Example <p>chart = generator.create_radar_chart( ...     [\"Quality\", \"Performance\", \"Security\", \"Maintainability\"], ...     [{\"label\": \"Current\", \"data\": [7, 8, 6, 9]}], ...     title=\"Code Metrics\" ... )</p>"},{"location":"api/tenets/core/reporting/visualizer/#tenets.core.reporting.visualizer.ChartGenerator.create_gauge_chart","title":"create_gauge_chart","text":"Python<pre><code>create_gauge_chart(value: float, max_value: float = 100, title: str = '', thresholds: Optional[List[Tuple[float, str]]] = None) -&gt; Dict[str, Any]\n</code></pre> <p>Create a gauge chart configuration.</p> PARAMETER DESCRIPTION <code>value</code> <p>Current value</p> <p> TYPE: <code>float</code> </p> <code>max_value</code> <p>Maximum value</p> <p> TYPE: <code>float</code> DEFAULT: <code>100</code> </p> <code>title</code> <p>Chart title</p> <p> TYPE: <code>str</code> DEFAULT: <code>''</code> </p> <code>thresholds</code> <p>List of (value, color) thresholds</p> <p> TYPE: <code>Optional[List[Tuple[float, str]]]</code> DEFAULT: <code>None</code> </p> RETURNS DESCRIPTION <code>Dict[str, Any]</code> <p>Dict[str, Any]: Chart configuration</p> Example <p>chart = generator.create_gauge_chart( ...     75, ...     100, ...     title=\"Health Score\", ...     thresholds=[(60, \"yellow\"), (80, \"green\")] ... )</p>"},{"location":"api/tenets/core/reporting/visualizer/#tenets.core.reporting.visualizer.ChartGenerator.create_stacked_bar_chart","title":"create_stacked_bar_chart","text":"Python<pre><code>create_stacked_bar_chart(labels: List[str], datasets: List[Dict[str, Any]], title: str = '', x_label: str = '', y_label: str = '', horizontal: bool = False) -&gt; Dict[str, Any]\n</code></pre> <p>Create a stacked bar chart configuration.</p> PARAMETER DESCRIPTION <code>labels</code> <p>Bar labels</p> <p> TYPE: <code>List[str]</code> </p> <code>datasets</code> <p>List of dataset configurations</p> <p> TYPE: <code>List[Dict[str, Any]]</code> </p> <code>title</code> <p>Chart title</p> <p> TYPE: <code>str</code> DEFAULT: <code>''</code> </p> <code>x_label</code> <p>X-axis label</p> <p> TYPE: <code>str</code> DEFAULT: <code>''</code> </p> <code>y_label</code> <p>Y-axis label</p> <p> TYPE: <code>str</code> DEFAULT: <code>''</code> </p> <code>horizontal</code> <p>Use horizontal bars</p> <p> TYPE: <code>bool</code> DEFAULT: <code>False</code> </p> RETURNS DESCRIPTION <code>Dict[str, Any]</code> <p>Dict[str, Any]: Chart configuration</p> Example <p>chart = generator.create_stacked_bar_chart( ...     [\"Sprint 1\", \"Sprint 2\", \"Sprint 3\"], ...     [ ...         {\"label\": \"Completed\", \"data\": [8, 10, 12]}, ...         {\"label\": \"In Progress\", \"data\": [3, 2, 4]}, ...         {\"label\": \"Blocked\", \"data\": [1, 0, 2]} ...     ], ...     title=\"Sprint Progress\" ... )</p>"},{"location":"api/tenets/core/reporting/visualizer/#tenets.core.reporting.visualizer.ChartGenerator.create_bubble_chart","title":"create_bubble_chart","text":"Python<pre><code>create_bubble_chart(data_points: List[Tuple[float, float, float]], title: str = '', x_label: str = '', y_label: str = '', bubble_labels: Optional[List[str]] = None) -&gt; Dict[str, Any]\n</code></pre> <p>Create a bubble chart configuration.</p> PARAMETER DESCRIPTION <code>data_points</code> <p>List of (x, y, size) tuples</p> <p> TYPE: <code>List[Tuple[float, float, float]]</code> </p> <code>title</code> <p>Chart title</p> <p> TYPE: <code>str</code> DEFAULT: <code>''</code> </p> <code>x_label</code> <p>X-axis label</p> <p> TYPE: <code>str</code> DEFAULT: <code>''</code> </p> <code>y_label</code> <p>Y-axis label</p> <p> TYPE: <code>str</code> DEFAULT: <code>''</code> </p> <code>bubble_labels</code> <p>Labels for bubbles</p> <p> TYPE: <code>Optional[List[str]]</code> DEFAULT: <code>None</code> </p> RETURNS DESCRIPTION <code>Dict[str, Any]</code> <p>Dict[str, Any]: Chart configuration</p> Example <p>chart = generator.create_bubble_chart( ...     [(10, 5, 20), (20, 8, 35), (15, 12, 15)], ...     title=\"File Analysis\", ...     x_label=\"Complexity\", ...     y_label=\"Changes\" ... )</p>"},{"location":"api/tenets/core/reporting/visualizer/#tenets.core.reporting.visualizer-functions","title":"Functions","text":""},{"location":"api/tenets/core/reporting/visualizer/#tenets.core.reporting.visualizer.create_chart","title":"create_chart","text":"Python<pre><code>create_chart(chart_type: str, data: Dict[str, Any], title: str = '', config: Optional[TenetsConfig] = None) -&gt; Dict[str, Any]\n</code></pre> <p>Convenience function to create a chart.</p> PARAMETER DESCRIPTION <code>chart_type</code> <p>Type of chart (bar, line, pie, etc.)</p> <p> TYPE: <code>str</code> </p> <code>data</code> <p>Chart data</p> <p> TYPE: <code>Dict[str, Any]</code> </p> <code>title</code> <p>Chart title</p> <p> TYPE: <code>str</code> DEFAULT: <code>''</code> </p> <code>config</code> <p>Optional configuration</p> <p> TYPE: <code>Optional[TenetsConfig]</code> DEFAULT: <code>None</code> </p> RETURNS DESCRIPTION <code>Dict[str, Any]</code> <p>Dict[str, Any]: Chart configuration</p> Example <p>from tenets.core.reporting.visualizer import create_chart chart = create_chart( ...     \"bar\", ...     {\"labels\": [\"A\", \"B\", \"C\"], \"values\": [1, 2, 3]}, ...     title=\"Sample Chart\" ... )</p>"},{"location":"api/tenets/core/reporting/visualizer/#tenets.core.reporting.visualizer.create_heatmap","title":"create_heatmap","text":"Python<pre><code>create_heatmap(matrix_data: List[List[float]], x_labels: List[str], y_labels: List[str], title: str = '', color_scale: str = 'viridis') -&gt; Dict[str, Any]\n</code></pre> <p>Create a heatmap visualization.</p> PARAMETER DESCRIPTION <code>matrix_data</code> <p>2D matrix of values</p> <p> TYPE: <code>List[List[float]]</code> </p> <code>x_labels</code> <p>X-axis labels</p> <p> TYPE: <code>List[str]</code> </p> <code>y_labels</code> <p>Y-axis labels</p> <p> TYPE: <code>List[str]</code> </p> <code>title</code> <p>Chart title</p> <p> TYPE: <code>str</code> DEFAULT: <code>''</code> </p> <code>color_scale</code> <p>Color scale name</p> <p> TYPE: <code>str</code> DEFAULT: <code>'viridis'</code> </p> RETURNS DESCRIPTION <code>Dict[str, Any]</code> <p>Dict[str, Any]: Heatmap configuration</p> Example <p>from tenets.core.reporting.visualizer import create_heatmap heatmap = create_heatmap( ...     [[1, 2, 3], [4, 5, 6], [7, 8, 9]], ...     [\"A\", \"B\", \"C\"], ...     [\"X\", \"Y\", \"Z\"], ...     title=\"Correlation Matrix\" ... )</p>"},{"location":"api/tenets/core/reporting/visualizer/#tenets.core.reporting.visualizer.create_timeline","title":"create_timeline","text":"Python<pre><code>create_timeline(events: List[Dict[str, Any]], title: str = '', start_date: Optional[datetime] = None, end_date: Optional[datetime] = None) -&gt; Dict[str, Any]\n</code></pre> <p>Create a timeline visualization.</p> PARAMETER DESCRIPTION <code>events</code> <p>List of event dictionaries with 'date' and 'label' keys</p> <p> TYPE: <code>List[Dict[str, Any]]</code> </p> <code>title</code> <p>Timeline title</p> <p> TYPE: <code>str</code> DEFAULT: <code>''</code> </p> <code>start_date</code> <p>Timeline start date</p> <p> TYPE: <code>Optional[datetime]</code> DEFAULT: <code>None</code> </p> <code>end_date</code> <p>Timeline end date</p> <p> TYPE: <code>Optional[datetime]</code> DEFAULT: <code>None</code> </p> RETURNS DESCRIPTION <code>Dict[str, Any]</code> <p>Dict[str, Any]: Timeline configuration</p> Example <p>from tenets.core.reporting.visualizer import create_timeline timeline = create_timeline( ...     [ ...         {\"date\": \"2024-01-01\", \"label\": \"Project Start\"}, ...         {\"date\": \"2024-02-15\", \"label\": \"First Release\"} ...     ], ...     title=\"Project Timeline\" ... )</p>"},{"location":"api/tenets/core/reporting/visualizer/#tenets.core.reporting.visualizer.create_network_graph","title":"create_network_graph","text":"Python<pre><code>create_network_graph(nodes: List[Dict[str, Any]], edges: List[Dict[str, Any]], title: str = '', layout: str = 'force') -&gt; Dict[str, Any]\n</code></pre> <p>Create a network graph visualization.</p> PARAMETER DESCRIPTION <code>nodes</code> <p>List of node dictionaries with 'id' and 'label' keys</p> <p> TYPE: <code>List[Dict[str, Any]]</code> </p> <code>edges</code> <p>List of edge dictionaries with 'source' and 'target' keys</p> <p> TYPE: <code>List[Dict[str, Any]]</code> </p> <code>title</code> <p>Graph title</p> <p> TYPE: <code>str</code> DEFAULT: <code>''</code> </p> <code>layout</code> <p>Layout algorithm (force, circular, hierarchical)</p> <p> TYPE: <code>str</code> DEFAULT: <code>'force'</code> </p> RETURNS DESCRIPTION <code>Dict[str, Any]</code> <p>Dict[str, Any]: Network graph configuration</p> Example <p>from tenets.core.reporting.visualizer import create_network_graph graph = create_network_graph( ...     nodes=[ ...         {\"id\": \"A\", \"label\": \"Node A\"}, ...         {\"id\": \"B\", \"label\": \"Node B\"} ...     ], ...     edges=[ ...         {\"source\": \"A\", \"target\": \"B\", \"weight\": 1} ...     ], ...     title=\"Dependency Graph\" ... )</p>"},{"location":"api/tenets/core/reporting/visualizer/#tenets.core.reporting.visualizer.create_treemap","title":"create_treemap","text":"Python<pre><code>create_treemap(hierarchical_data: Dict[str, Any], title: str = '', value_key: str = 'value', label_key: str = 'name') -&gt; Dict[str, Any]\n</code></pre> <p>Create a treemap visualization.</p> PARAMETER DESCRIPTION <code>hierarchical_data</code> <p>Hierarchical data structure</p> <p> TYPE: <code>Dict[str, Any]</code> </p> <code>title</code> <p>Chart title</p> <p> TYPE: <code>str</code> DEFAULT: <code>''</code> </p> <code>value_key</code> <p>Key for value in data</p> <p> TYPE: <code>str</code> DEFAULT: <code>'value'</code> </p> <code>label_key</code> <p>Key for label in data</p> <p> TYPE: <code>str</code> DEFAULT: <code>'name'</code> </p> RETURNS DESCRIPTION <code>Dict[str, Any]</code> <p>Dict[str, Any]: Treemap configuration</p> Example <p>from tenets.core.reporting.visualizer import create_treemap treemap = create_treemap( ...     { ...         \"name\": \"root\", ...         \"children\": [ ...             {\"name\": \"A\", \"value\": 10}, ...             {\"name\": \"B\", \"value\": 20} ...         ] ...     }, ...     title=\"Code Distribution\" ... )</p>"},{"location":"api/tenets/core/session/session/","title":"Session","text":""},{"location":"api/tenets/core/session/session/#tenets.core.session.session","title":"tenets.core.session.session","text":"<p>Session manager with optional SQLite persistence.</p> <p>Uses an in-memory dict by default. When provided a TenetsConfig, it will persist sessions and context entries via storage.SessionDB while keeping an in-memory mirror for fast access.</p> <p>This layer is intentionally thin: persistent semantics live in <code>tenets.storage.session_db.SessionDB</code>.</p>"},{"location":"api/tenets/core/session/session/#tenets.core.session.session-classes","title":"Classes","text":""},{"location":"api/tenets/core/session/session/#tenets.core.session.session.SessionManager","title":"SessionManager  <code>dataclass</code>","text":"Python<pre><code>SessionManager(config: Optional[TenetsConfig] = None)\n</code></pre> <p>High-level session manager used by the CLI and core flows.</p>"},{"location":"api/tenets/core/session/session/#tenets.core.session.session.SessionManager-functions","title":"Functions","text":""},{"location":"api/tenets/core/session/session/#tenets.core.session.session.SessionManager.delete","title":"delete","text":"Python<pre><code>delete(name: str) -&gt; bool\n</code></pre> <p>Delete a session by name from persistence (if configured) and memory.</p>"},{"location":"api/tenets/core/session/session/#tenets.core.session.session-functions","title":"Functions","text":""},{"location":"api/tenets/core/summarizer/llm/","title":"Llm","text":""},{"location":"api/tenets/core/summarizer/llm/#tenets.core.summarizer.llm","title":"tenets.core.summarizer.llm","text":"<p>LLM-based summarization strategies.</p> <p>This module provides integration with Large Language Models (LLMs) for high-quality summarization. Supports OpenAI, Anthropic, and OpenRouter APIs.</p> <p>NOTE: These strategies incur API costs. Use with caution and appropriate rate limiting. Always check pricing before using in production.</p>"},{"location":"api/tenets/core/summarizer/llm/#tenets.core.summarizer.llm-classes","title":"Classes","text":""},{"location":"api/tenets/core/summarizer/llm/#tenets.core.summarizer.llm.LLMProvider","title":"LLMProvider","text":"<p>               Bases: <code>Enum</code></p> <p>Supported LLM providers.</p>"},{"location":"api/tenets/core/summarizer/llm/#tenets.core.summarizer.llm.LLMConfig","title":"LLMConfig  <code>dataclass</code>","text":"Python<pre><code>LLMConfig(provider: LLMProvider = LLMProvider.OPENAI, model: str = 'gpt-4o-mini', api_key: Optional[str] = None, base_url: Optional[str] = None, temperature: float = 0.3, max_tokens: int = 500, system_prompt: str = 'You are an expert at summarizing code and technical documentation. \\nYour summaries are concise, accurate, and preserve critical technical details.', user_prompt: str = 'Summarize the following text to approximately {target_percent}% of its original length. \\nFocus on the most important information and maintain technical accuracy.\\n\\nText to summarize:\\n{text}\\n\\nSummary:', retry_attempts: int = 3, retry_delay: float = 1.0, timeout: float = 30.0)\n</code></pre> <p>Configuration for LLM summarization.</p> ATTRIBUTE DESCRIPTION <code>provider</code> <p>LLM provider to use</p> <p> TYPE: <code>LLMProvider</code> </p> <code>model</code> <p>Model name/ID</p> <p> TYPE: <code>str</code> </p> <code>api_key</code> <p>API key (if not in environment)</p> <p> TYPE: <code>Optional[str]</code> </p> <code>base_url</code> <p>Base URL for API (for custom endpoints)</p> <p> TYPE: <code>Optional[str]</code> </p> <code>temperature</code> <p>Sampling temperature (0-1)</p> <p> TYPE: <code>float</code> </p> <code>max_tokens</code> <p>Maximum tokens in response</p> <p> TYPE: <code>int</code> </p> <code>system_prompt</code> <p>System prompt template</p> <p> TYPE: <code>str</code> </p> <code>user_prompt</code> <p>User prompt template</p> <p> TYPE: <code>str</code> </p> <code>retry_attempts</code> <p>Number of retry attempts</p> <p> TYPE: <code>int</code> </p> <code>retry_delay</code> <p>Delay between retries in seconds</p> <p> TYPE: <code>float</code> </p> <code>timeout</code> <p>Request timeout in seconds</p> <p> TYPE: <code>float</code> </p>"},{"location":"api/tenets/core/summarizer/llm/#tenets.core.summarizer.llm.LLMConfig-functions","title":"Functions","text":""},{"location":"api/tenets/core/summarizer/llm/#tenets.core.summarizer.llm.LLMConfig.get_api_key","title":"get_api_key","text":"Python<pre><code>get_api_key() -&gt; Optional[str]\n</code></pre> <p>Get API key from config or environment.</p> RETURNS DESCRIPTION <code>Optional[str]</code> <p>API key or None</p>"},{"location":"api/tenets/core/summarizer/llm/#tenets.core.summarizer.llm.LLMSummarizer","title":"LLMSummarizer","text":"Python<pre><code>LLMSummarizer(config: Optional[LLMConfig] = None)\n</code></pre> <p>Base class for LLM-based summarization.</p> <p>Provides common functionality for different LLM providers. Handles API calls, retries, and error handling.</p> <p>Initialize LLM summarizer.</p> PARAMETER DESCRIPTION <code>config</code> <p>LLM configuration</p> <p> TYPE: <code>Optional[LLMConfig]</code> DEFAULT: <code>None</code> </p>"},{"location":"api/tenets/core/summarizer/llm/#tenets.core.summarizer.llm.LLMSummarizer-functions","title":"Functions","text":""},{"location":"api/tenets/core/summarizer/llm/#tenets.core.summarizer.llm.LLMSummarizer.summarize","title":"summarize","text":"Python<pre><code>summarize(text: str, target_ratio: float = 0.3, max_length: Optional[int] = None, min_length: Optional[int] = None, custom_prompt: Optional[str] = None) -&gt; str\n</code></pre> <p>Summarize text using LLM.</p> PARAMETER DESCRIPTION <code>text</code> <p>Text to summarize</p> <p> TYPE: <code>str</code> </p> <code>target_ratio</code> <p>Target compression ratio</p> <p> TYPE: <code>float</code> DEFAULT: <code>0.3</code> </p> <code>max_length</code> <p>Maximum summary length</p> <p> TYPE: <code>Optional[int]</code> DEFAULT: <code>None</code> </p> <code>min_length</code> <p>Minimum summary length</p> <p> TYPE: <code>Optional[int]</code> DEFAULT: <code>None</code> </p> <code>custom_prompt</code> <p>Custom prompt override</p> <p> TYPE: <code>Optional[str]</code> DEFAULT: <code>None</code> </p> RETURNS DESCRIPTION <code>str</code> <p>Summarized text</p> RAISES DESCRIPTION <code>RuntimeError</code> <p>If API call fails after retries</p>"},{"location":"api/tenets/core/summarizer/llm/#tenets.core.summarizer.llm.LLMSummarizer.estimate_cost","title":"estimate_cost","text":"Python<pre><code>estimate_cost(text: str) -&gt; Dict[str, float]\n</code></pre> <p>Estimate cost of summarization.</p> PARAMETER DESCRIPTION <code>text</code> <p>Text to summarize</p> <p> TYPE: <code>str</code> </p> RETURNS DESCRIPTION <code>Dict[str, float]</code> <p>Dictionary with cost estimates</p>"},{"location":"api/tenets/core/summarizer/llm/#tenets.core.summarizer.llm.LLMSummaryStrategy","title":"LLMSummaryStrategy","text":"Python<pre><code>LLMSummaryStrategy(provider: Union[str, LLMProvider] = LLMProvider.OPENAI, model: str = 'gpt-4o-mini', api_key: Optional[str] = None)\n</code></pre> <p>LLM-based summarization strategy for use with Summarizer.</p> <p>Wraps LLMSummarizer to match the SummarizationStrategy interface.</p> <p>WARNING: This strategy incurs API costs. Always estimate costs before use.</p> <p>Initialize LLM strategy.</p> PARAMETER DESCRIPTION <code>provider</code> <p>LLM provider name or enum</p> <p> TYPE: <code>Union[str, LLMProvider]</code> DEFAULT: <code>OPENAI</code> </p> <code>model</code> <p>Model to use</p> <p> TYPE: <code>str</code> DEFAULT: <code>'gpt-4o-mini'</code> </p> <code>api_key</code> <p>API key (if not in environment)</p> <p> TYPE: <code>Optional[str]</code> DEFAULT: <code>None</code> </p>"},{"location":"api/tenets/core/summarizer/llm/#tenets.core.summarizer.llm.LLMSummaryStrategy-functions","title":"Functions","text":""},{"location":"api/tenets/core/summarizer/llm/#tenets.core.summarizer.llm.LLMSummaryStrategy.summarize","title":"summarize","text":"Python<pre><code>summarize(text: str, target_ratio: float = 0.3, max_length: Optional[int] = None, min_length: Optional[int] = None) -&gt; str\n</code></pre> <p>Summarize text using LLM.</p> PARAMETER DESCRIPTION <code>text</code> <p>Input text</p> <p> TYPE: <code>str</code> </p> <code>target_ratio</code> <p>Target compression ratio</p> <p> TYPE: <code>float</code> DEFAULT: <code>0.3</code> </p> <code>max_length</code> <p>Maximum summary length</p> <p> TYPE: <code>Optional[int]</code> DEFAULT: <code>None</code> </p> <code>min_length</code> <p>Minimum summary length</p> <p> TYPE: <code>Optional[int]</code> DEFAULT: <code>None</code> </p> RETURNS DESCRIPTION <code>str</code> <p>LLM-generated summary</p>"},{"location":"api/tenets/core/summarizer/llm/#tenets.core.summarizer.llm.LLMSummaryStrategy.estimate_cost","title":"estimate_cost","text":"Python<pre><code>estimate_cost(text: str) -&gt; Dict[str, float]\n</code></pre> <p>Estimate cost for summarizing text.</p> PARAMETER DESCRIPTION <code>text</code> <p>Text to summarize</p> <p> TYPE: <code>str</code> </p> RETURNS DESCRIPTION <code>Dict[str, float]</code> <p>Cost estimate dictionary</p>"},{"location":"api/tenets/core/summarizer/llm/#tenets.core.summarizer.llm-functions","title":"Functions","text":""},{"location":"api/tenets/core/summarizer/llm/#tenets.core.summarizer.llm.create_llm_summarizer","title":"create_llm_summarizer","text":"Python<pre><code>create_llm_summarizer(provider: str = 'openai', model: Optional[str] = None, api_key: Optional[str] = None) -&gt; LLMSummaryStrategy\n</code></pre> <p>Create an LLM summarizer with defaults.</p> PARAMETER DESCRIPTION <code>provider</code> <p>Provider name (openai, anthropic, openrouter)</p> <p> TYPE: <code>str</code> DEFAULT: <code>'openai'</code> </p> <code>model</code> <p>Model name (uses provider default if None)</p> <p> TYPE: <code>Optional[str]</code> DEFAULT: <code>None</code> </p> <code>api_key</code> <p>API key (uses environment if None)</p> <p> TYPE: <code>Optional[str]</code> DEFAULT: <code>None</code> </p> RETURNS DESCRIPTION <code>LLMSummaryStrategy</code> <p>Configured LLMSummaryStrategy</p> <p>summarizer = create_llm_summarizer(\"openai\", \"gpt-4o-mini\")     &gt;&gt;&gt; summary = summarizer.summarize(long_text, target_ratio=0.2)</p>"},{"location":"api/tenets/core/summarizer/strategies/","title":"Strategies","text":""},{"location":"api/tenets/core/summarizer/strategies/#tenets.core.summarizer.strategies","title":"tenets.core.summarizer.strategies","text":"<p>Summarization strategies with NLP integration.</p> <p>This module provides various summarization strategies that leverage the centralized NLP components for improved text processing and analysis.</p> <p>Strategies: - ExtractiveStrategy: Selects important sentences using NLP keyword extraction - CompressiveStrategy: Removes redundancy using NLP tokenization - TextRankStrategy: Graph-based ranking with NLP preprocessing - TransformerStrategy: Neural summarization (requires ML) - NLPEnhancedStrategy: Advanced strategy using all NLP features</p>"},{"location":"api/tenets/core/summarizer/strategies/#tenets.core.summarizer.strategies-classes","title":"Classes","text":""},{"location":"api/tenets/core/summarizer/strategies/#tenets.core.summarizer.strategies.SummarizationStrategy","title":"SummarizationStrategy","text":"<p>               Bases: <code>ABC</code></p> <p>Abstract base class for summarization strategies.</p>"},{"location":"api/tenets/core/summarizer/strategies/#tenets.core.summarizer.strategies.SummarizationStrategy-functions","title":"Functions","text":""},{"location":"api/tenets/core/summarizer/strategies/#tenets.core.summarizer.strategies.SummarizationStrategy.summarize","title":"summarize  <code>abstractmethod</code>","text":"Python<pre><code>summarize(text: str, target_ratio: float = 0.3, max_length: Optional[int] = None, min_length: Optional[int] = None) -&gt; str\n</code></pre> <p>Summarize text.</p> PARAMETER DESCRIPTION <code>text</code> <p>Input text</p> <p> TYPE: <code>str</code> </p> <code>target_ratio</code> <p>Target compression ratio</p> <p> TYPE: <code>float</code> DEFAULT: <code>0.3</code> </p> <code>max_length</code> <p>Maximum summary length</p> <p> TYPE: <code>Optional[int]</code> DEFAULT: <code>None</code> </p> <code>min_length</code> <p>Minimum summary length</p> <p> TYPE: <code>Optional[int]</code> DEFAULT: <code>None</code> </p> RETURNS DESCRIPTION <code>str</code> <p>Summarized text</p>"},{"location":"api/tenets/core/summarizer/strategies/#tenets.core.summarizer.strategies.ExtractiveStrategy","title":"ExtractiveStrategy","text":"Python<pre><code>ExtractiveStrategy(use_nlp: bool = True)\n</code></pre> <p>               Bases: <code>SummarizationStrategy</code></p> <p>Extractive summarization using NLP components.</p> <p>Selects the most important sentences based on keyword density, position, and optionally semantic similarity. Uses centralized NLP components for improved sentence scoring.</p> <p>Initialize extractive strategy.</p> PARAMETER DESCRIPTION <code>use_nlp</code> <p>Whether to use NLP components for enhanced extraction</p> <p> TYPE: <code>bool</code> DEFAULT: <code>True</code> </p>"},{"location":"api/tenets/core/summarizer/strategies/#tenets.core.summarizer.strategies.ExtractiveStrategy-functions","title":"Functions","text":""},{"location":"api/tenets/core/summarizer/strategies/#tenets.core.summarizer.strategies.ExtractiveStrategy.summarize","title":"summarize","text":"Python<pre><code>summarize(text: str, target_ratio: float = 0.3, max_length: Optional[int] = None, min_length: Optional[int] = None) -&gt; str\n</code></pre> <p>Extract important sentences to create summary.</p> PARAMETER DESCRIPTION <code>text</code> <p>Input text</p> <p> TYPE: <code>str</code> </p> <code>target_ratio</code> <p>Target compression ratio</p> <p> TYPE: <code>float</code> DEFAULT: <code>0.3</code> </p> <code>max_length</code> <p>Maximum summary length</p> <p> TYPE: <code>Optional[int]</code> DEFAULT: <code>None</code> </p> <code>min_length</code> <p>Minimum summary length</p> <p> TYPE: <code>Optional[int]</code> DEFAULT: <code>None</code> </p> RETURNS DESCRIPTION <code>str</code> <p>Extractive summary</p>"},{"location":"api/tenets/core/summarizer/strategies/#tenets.core.summarizer.strategies.CompressiveStrategy","title":"CompressiveStrategy","text":"Python<pre><code>CompressiveStrategy(use_nlp: bool = True)\n</code></pre> <p>               Bases: <code>SummarizationStrategy</code></p> <p>Compressive summarization using NLP tokenization.</p> <p>Removes redundant words and phrases while maintaining meaning. Uses NLP tokenizer for better word processing.</p> <p>Initialize compressive strategy.</p> PARAMETER DESCRIPTION <code>use_nlp</code> <p>Whether to use NLP components</p> <p> TYPE: <code>bool</code> DEFAULT: <code>True</code> </p>"},{"location":"api/tenets/core/summarizer/strategies/#tenets.core.summarizer.strategies.CompressiveStrategy-functions","title":"Functions","text":""},{"location":"api/tenets/core/summarizer/strategies/#tenets.core.summarizer.strategies.CompressiveStrategy.summarize","title":"summarize","text":"Python<pre><code>summarize(text: str, target_ratio: float = 0.3, max_length: Optional[int] = None, min_length: Optional[int] = None) -&gt; str\n</code></pre> <p>Compress text by removing redundancy.</p> PARAMETER DESCRIPTION <code>text</code> <p>Input text</p> <p> TYPE: <code>str</code> </p> <code>target_ratio</code> <p>Target compression ratio</p> <p> TYPE: <code>float</code> DEFAULT: <code>0.3</code> </p> <code>max_length</code> <p>Maximum summary length</p> <p> TYPE: <code>Optional[int]</code> DEFAULT: <code>None</code> </p> <code>min_length</code> <p>Minimum summary length</p> <p> TYPE: <code>Optional[int]</code> DEFAULT: <code>None</code> </p> RETURNS DESCRIPTION <code>str</code> <p>Compressed text</p>"},{"location":"api/tenets/core/summarizer/strategies/#tenets.core.summarizer.strategies.TextRankStrategy","title":"TextRankStrategy","text":"Python<pre><code>TextRankStrategy(use_nlp: bool = True)\n</code></pre> <p>               Bases: <code>SummarizationStrategy</code></p> <p>TextRank summarization with NLP preprocessing.</p> <p>Graph-based ranking algorithm that uses NLP components for better text preprocessing and similarity computation.</p> <p>Initialize TextRank strategy.</p> PARAMETER DESCRIPTION <code>use_nlp</code> <p>Whether to use NLP components</p> <p> TYPE: <code>bool</code> DEFAULT: <code>True</code> </p>"},{"location":"api/tenets/core/summarizer/strategies/#tenets.core.summarizer.strategies.TextRankStrategy-functions","title":"Functions","text":""},{"location":"api/tenets/core/summarizer/strategies/#tenets.core.summarizer.strategies.TextRankStrategy.summarize","title":"summarize","text":"Python<pre><code>summarize(text: str, target_ratio: float = 0.3, max_length: Optional[int] = None, min_length: Optional[int] = None) -&gt; str\n</code></pre> <p>Summarize using TextRank algorithm.</p> PARAMETER DESCRIPTION <code>text</code> <p>Input text</p> <p> TYPE: <code>str</code> </p> <code>target_ratio</code> <p>Target compression ratio</p> <p> TYPE: <code>float</code> DEFAULT: <code>0.3</code> </p> <code>max_length</code> <p>Maximum summary length</p> <p> TYPE: <code>Optional[int]</code> DEFAULT: <code>None</code> </p> <code>min_length</code> <p>Minimum summary length</p> <p> TYPE: <code>Optional[int]</code> DEFAULT: <code>None</code> </p> RETURNS DESCRIPTION <code>str</code> <p>TextRank summary</p>"},{"location":"api/tenets/core/summarizer/strategies/#tenets.core.summarizer.strategies.TransformerStrategy","title":"TransformerStrategy","text":"Python<pre><code>TransformerStrategy(model_name: str = 'facebook/bart-large-cnn')\n</code></pre> <p>               Bases: <code>SummarizationStrategy</code></p> <p>Transformer-based neural summarization.</p> <p>Uses pre-trained transformer models for high-quality abstractive summarization.</p> <p>Initialize transformer strategy.</p> PARAMETER DESCRIPTION <code>model_name</code> <p>HuggingFace model name</p> <p> TYPE: <code>str</code> DEFAULT: <code>'facebook/bart-large-cnn'</code> </p>"},{"location":"api/tenets/core/summarizer/strategies/#tenets.core.summarizer.strategies.TransformerStrategy-functions","title":"Functions","text":""},{"location":"api/tenets/core/summarizer/strategies/#tenets.core.summarizer.strategies.TransformerStrategy.summarize","title":"summarize","text":"Python<pre><code>summarize(text: str, target_ratio: float = 0.3, max_length: Optional[int] = None, min_length: Optional[int] = None) -&gt; str\n</code></pre> <p>Summarize using transformer model.</p> PARAMETER DESCRIPTION <code>text</code> <p>Input text</p> <p> TYPE: <code>str</code> </p> <code>target_ratio</code> <p>Target compression ratio</p> <p> TYPE: <code>float</code> DEFAULT: <code>0.3</code> </p> <code>max_length</code> <p>Maximum summary length</p> <p> TYPE: <code>Optional[int]</code> DEFAULT: <code>None</code> </p> <code>min_length</code> <p>Minimum summary length</p> <p> TYPE: <code>Optional[int]</code> DEFAULT: <code>None</code> </p> RETURNS DESCRIPTION <code>str</code> <p>Neural summary</p>"},{"location":"api/tenets/core/summarizer/strategies/#tenets.core.summarizer.strategies.NLPEnhancedStrategy","title":"NLPEnhancedStrategy","text":"Python<pre><code>NLPEnhancedStrategy()\n</code></pre> <p>               Bases: <code>SummarizationStrategy</code></p> <p>Advanced summarization using all NLP features.</p> <p>Combines multiple NLP components for advanced extractive summarization with semantic understanding.</p> <p>Initialize NLP-enhanced strategy.</p>"},{"location":"api/tenets/core/summarizer/strategies/#tenets.core.summarizer.strategies.NLPEnhancedStrategy-functions","title":"Functions","text":""},{"location":"api/tenets/core/summarizer/strategies/#tenets.core.summarizer.strategies.NLPEnhancedStrategy.summarize","title":"summarize","text":"Python<pre><code>summarize(text: str, target_ratio: float = 0.3, max_length: Optional[int] = None, min_length: Optional[int] = None) -&gt; str\n</code></pre> <p>Summarize using comprehensive NLP analysis.</p> PARAMETER DESCRIPTION <code>text</code> <p>Input text</p> <p> TYPE: <code>str</code> </p> <code>target_ratio</code> <p>Target compression ratio</p> <p> TYPE: <code>float</code> DEFAULT: <code>0.3</code> </p> <code>max_length</code> <p>Maximum summary length</p> <p> TYPE: <code>Optional[int]</code> DEFAULT: <code>None</code> </p> <code>min_length</code> <p>Minimum summary length</p> <p> TYPE: <code>Optional[int]</code> DEFAULT: <code>None</code> </p> RETURNS DESCRIPTION <code>str</code> <p>NLP-enhanced summary</p>"},{"location":"api/tenets/core/summarizer/strategies/#tenets.core.summarizer.strategies-functions","title":"Functions","text":""},{"location":"api/tenets/core/summarizer/summarizer/","title":"Summarizer","text":""},{"location":"api/tenets/core/summarizer/summarizer/#tenets.core.summarizer.summarizer","title":"tenets.core.summarizer.summarizer","text":"<p>Main summarizer orchestrator for content compression.</p> <p>This module provides the main Summarizer class that coordinates different summarization strategies to compress code, documentation, and other text content while preserving important information.</p> <p>The summarizer supports multiple strategies: - Extractive: Selects important sentences - Compressive: Removes redundant content - TextRank: Graph-based ranking - Transformer: Neural summarization (requires ML) - LLM: Large language model summarization (costs $)</p>"},{"location":"api/tenets/core/summarizer/summarizer/#tenets.core.summarizer.summarizer-classes","title":"Classes","text":""},{"location":"api/tenets/core/summarizer/summarizer/#tenets.core.summarizer.summarizer.SummarizationMode","title":"SummarizationMode","text":"<p>               Bases: <code>Enum</code></p> <p>Available summarization modes.</p>"},{"location":"api/tenets/core/summarizer/summarizer/#tenets.core.summarizer.summarizer.SummarizationResult","title":"SummarizationResult  <code>dataclass</code>","text":"Python<pre><code>SummarizationResult(original_text: str, summary: str, original_length: int, summary_length: int, compression_ratio: float, strategy_used: str, time_elapsed: float, metadata: Dict[str, Any] = None)\n</code></pre> <p>Result from summarization operation.</p> ATTRIBUTE DESCRIPTION <code>original_text</code> <p>Original text</p> <p> TYPE: <code>str</code> </p> <code>summary</code> <p>Summarized text</p> <p> TYPE: <code>str</code> </p> <code>original_length</code> <p>Original text length</p> <p> TYPE: <code>int</code> </p> <code>summary_length</code> <p>Summary length</p> <p> TYPE: <code>int</code> </p> <code>compression_ratio</code> <p>Actual compression ratio achieved</p> <p> TYPE: <code>float</code> </p> <code>strategy_used</code> <p>Which strategy was used</p> <p> TYPE: <code>str</code> </p> <code>time_elapsed</code> <p>Time taken to summarize</p> <p> TYPE: <code>float</code> </p> <code>metadata</code> <p>Additional metadata</p> <p> TYPE: <code>Dict[str, Any]</code> </p>"},{"location":"api/tenets/core/summarizer/summarizer/#tenets.core.summarizer.summarizer.SummarizationResult-attributes","title":"Attributes","text":""},{"location":"api/tenets/core/summarizer/summarizer/#tenets.core.summarizer.summarizer.SummarizationResult.reduction_percent","title":"reduction_percent  <code>property</code>","text":"Python<pre><code>reduction_percent: float\n</code></pre> <p>Get reduction percentage.</p>"},{"location":"api/tenets/core/summarizer/summarizer/#tenets.core.summarizer.summarizer.SummarizationResult-functions","title":"Functions","text":""},{"location":"api/tenets/core/summarizer/summarizer/#tenets.core.summarizer.summarizer.SummarizationResult.to_dict","title":"to_dict","text":"Python<pre><code>to_dict() -&gt; Dict[str, Any]\n</code></pre> <p>Convert to dictionary.</p>"},{"location":"api/tenets/core/summarizer/summarizer/#tenets.core.summarizer.summarizer.BatchSummarizationResult","title":"BatchSummarizationResult  <code>dataclass</code>","text":"Python<pre><code>BatchSummarizationResult(results: List[SummarizationResult], total_original_length: int, total_summary_length: int, overall_compression_ratio: float, total_time_elapsed: float, files_processed: int, files_failed: int)\n</code></pre> <p>Result from batch summarization.</p>"},{"location":"api/tenets/core/summarizer/summarizer/#tenets.core.summarizer.summarizer.BatchSummarizationResult-functions","title":"Functions","text":""},{"location":"api/tenets/core/summarizer/summarizer/#tenets.core.summarizer.summarizer.BatchSummarizationResult.to_dict","title":"to_dict","text":"Python<pre><code>to_dict() -&gt; Dict[str, Any]\n</code></pre> <p>Convert to dictionary.</p>"},{"location":"api/tenets/core/summarizer/summarizer/#tenets.core.summarizer.summarizer.Summarizer","title":"Summarizer","text":"Python<pre><code>Summarizer(config: Optional[TenetsConfig] = None, default_mode: Optional[str] = None, enable_cache: bool = True)\n</code></pre> <p>Main summarization orchestrator.</p> <p>Coordinates different summarization strategies and provides a unified interface for content compression. Supports single and batch processing, strategy selection, and caching.</p> ATTRIBUTE DESCRIPTION <code>config</code> <p>TenetsConfig instance</p> <p> </p> <code>logger</code> <p>Logger instance</p> <p> </p> <code>strategies</code> <p>Available summarization strategies</p> <p> TYPE: <code>Dict[SummarizationMode, SummarizationStrategy]</code> </p> <code>cache</code> <p>Summary cache for repeated content</p> <p> TYPE: <code>Dict[str, SummarizationResult]</code> </p> <code>stats</code> <p>Summarization statistics</p> <p> </p> <p>Initialize summarizer.</p> PARAMETER DESCRIPTION <code>config</code> <p>Tenets configuration</p> <p> TYPE: <code>Optional[TenetsConfig]</code> DEFAULT: <code>None</code> </p> <code>default_mode</code> <p>Default summarization mode</p> <p> TYPE: <code>Optional[str]</code> DEFAULT: <code>None</code> </p> <code>enable_cache</code> <p>Whether to enable caching</p> <p> TYPE: <code>bool</code> DEFAULT: <code>True</code> </p>"},{"location":"api/tenets/core/summarizer/summarizer/#tenets.core.summarizer.summarizer.Summarizer-functions","title":"Functions","text":""},{"location":"api/tenets/core/summarizer/summarizer/#tenets.core.summarizer.summarizer.Summarizer.summarize","title":"summarize","text":"Python<pre><code>summarize(text: str, mode: Optional[Union[str, SummarizationMode]] = None, target_ratio: float = 0.3, max_length: Optional[int] = None, min_length: Optional[int] = None, force_strategy: Optional[SummarizationStrategy] = None) -&gt; SummarizationResult\n</code></pre> <p>Summarize text content.</p> PARAMETER DESCRIPTION <code>text</code> <p>Text to summarize</p> <p> TYPE: <code>str</code> </p> <code>mode</code> <p>Summarization mode (uses default if None)</p> <p> TYPE: <code>Optional[Union[str, SummarizationMode]]</code> DEFAULT: <code>None</code> </p> <code>target_ratio</code> <p>Target compression ratio (0.3 = 30% of original)</p> <p> TYPE: <code>float</code> DEFAULT: <code>0.3</code> </p> <code>max_length</code> <p>Maximum summary length in characters</p> <p> TYPE: <code>Optional[int]</code> DEFAULT: <code>None</code> </p> <code>min_length</code> <p>Minimum summary length in characters</p> <p> TYPE: <code>Optional[int]</code> DEFAULT: <code>None</code> </p> <code>force_strategy</code> <p>Force specific strategy instance</p> <p> TYPE: <code>Optional[SummarizationStrategy]</code> DEFAULT: <code>None</code> </p> RETURNS DESCRIPTION <code>SummarizationResult</code> <p>SummarizationResult with summary and metadata</p> Example <p>summarizer = Summarizer() result = summarizer.summarize( ...     long_text, ...     mode=\"extractive\", ...     target_ratio=0.25 ... ) print(f\"Reduced by {result.reduction_percent:.1f}%\")</p>"},{"location":"api/tenets/core/summarizer/summarizer/#tenets.core.summarizer.summarizer.Summarizer.summarize_file","title":"summarize_file","text":"Python<pre><code>summarize_file(file: FileAnalysis, mode: Optional[Union[str, SummarizationMode]] = None, target_ratio: float = 0.3, preserve_structure: bool = True, prompt_keywords: Optional[List[str]] = None) -&gt; SummarizationResult\n</code></pre> <p>Summarize a code file intelligently.</p> <p>Handles code files specially by preserving important elements like class/function signatures while summarizing implementations. Enhanced with context-aware documentation summarization that preserves relevant sections based on prompt keywords.</p> PARAMETER DESCRIPTION <code>file</code> <p>FileAnalysis object</p> <p> TYPE: <code>FileAnalysis</code> </p> <code>mode</code> <p>Summarization mode</p> <p> TYPE: <code>Optional[Union[str, SummarizationMode]]</code> DEFAULT: <code>None</code> </p> <code>target_ratio</code> <p>Target compression ratio</p> <p> TYPE: <code>float</code> DEFAULT: <code>0.3</code> </p> <code>preserve_structure</code> <p>Whether to preserve code structure</p> <p> TYPE: <code>bool</code> DEFAULT: <code>True</code> </p> <code>prompt_keywords</code> <p>Keywords from user prompt for context-aware summarization</p> <p> TYPE: <code>Optional[List[str]]</code> DEFAULT: <code>None</code> </p> RETURNS DESCRIPTION <code>SummarizationResult</code> <p>SummarizationResult</p>"},{"location":"api/tenets/core/summarizer/summarizer/#tenets.core.summarizer.summarizer.Summarizer.batch_summarize","title":"batch_summarize","text":"Python<pre><code>batch_summarize(texts: List[Union[str, FileAnalysis]], mode: Optional[Union[str, SummarizationMode]] = None, target_ratio: float = 0.3, parallel: bool = True, prompt_keywords: Optional[List[str]] = None) -&gt; BatchSummarizationResult\n</code></pre> <p>Summarize multiple texts in batch.</p> PARAMETER DESCRIPTION <code>texts</code> <p>List of texts or FileAnalysis objects</p> <p> TYPE: <code>List[Union[str, FileAnalysis]]</code> </p> <code>mode</code> <p>Summarization mode</p> <p> TYPE: <code>Optional[Union[str, SummarizationMode]]</code> DEFAULT: <code>None</code> </p> <code>target_ratio</code> <p>Target compression ratio</p> <p> TYPE: <code>float</code> DEFAULT: <code>0.3</code> </p> <code>parallel</code> <p>Whether to process in parallel</p> <p> TYPE: <code>bool</code> DEFAULT: <code>True</code> </p> <code>prompt_keywords</code> <p>Keywords from user prompt for context-aware documentation summarization</p> <p> TYPE: <code>Optional[List[str]]</code> DEFAULT: <code>None</code> </p> RETURNS DESCRIPTION <code>BatchSummarizationResult</code> <p>BatchSummarizationResult</p>"},{"location":"api/tenets/core/summarizer/summarizer/#tenets.core.summarizer.summarizer.Summarizer.clear_cache","title":"clear_cache","text":"Python<pre><code>clear_cache()\n</code></pre> <p>Clear the summary cache.</p>"},{"location":"api/tenets/core/summarizer/summarizer/#tenets.core.summarizer.summarizer.Summarizer.get_stats","title":"get_stats","text":"Python<pre><code>get_stats() -&gt; Dict[str, Any]\n</code></pre> <p>Get summarization statistics.</p> RETURNS DESCRIPTION <code>Dict[str, Any]</code> <p>Dictionary of statistics</p>"},{"location":"api/tenets/core/summarizer/summarizer/#tenets.core.summarizer.summarizer.FileSummarizer","title":"FileSummarizer","text":"Python<pre><code>FileSummarizer(model: Optional[str] = None)\n</code></pre> <p>Backward-compatible file summarizer used by tests.</p> <p>This lightweight class focuses on extracting a concise summary from a single file using deterministic heuristics (docstrings, leading comments, or head lines). It integrates with Tenets token utilities and returns the <code>FileSummary</code> model expected by the tests.</p>"},{"location":"api/tenets/core/summarizer/summarizer/#tenets.core.summarizer.summarizer.FileSummarizer-functions","title":"Functions","text":""},{"location":"api/tenets/core/summarizer/summarizer/#tenets.core.summarizer.summarizer.FileSummarizer.summarize_file","title":"summarize_file","text":"Python<pre><code>summarize_file(path: Union[str, Path], max_lines: int = 50)\n</code></pre> <p>Summarize a file from disk into a FileSummary.</p> PARAMETER DESCRIPTION <code>path</code> <p>Path to the file</p> <p> TYPE: <code>Union[str, Path]</code> </p> <code>max_lines</code> <p>Maximum number of lines in the summary</p> <p> TYPE: <code>int</code> DEFAULT: <code>50</code> </p> RETURNS DESCRIPTION <code>FileSummary</code> <p>summary object with metadata</p>"},{"location":"api/tenets/core/summarizer/summarizer/#tenets.core.summarizer.summarizer-functions","title":"Functions","text":""},{"location":"api/tenets/models/analysis/","title":"Analysis","text":""},{"location":"api/tenets/models/analysis/#tenets.models.analysis","title":"tenets.models.analysis","text":"<p>Code analysis data models used by the analyzer system.</p> <p>This module contains all data structures used by the code analysis subsystem, including file analysis results, project metrics, and dependency graphs.</p>"},{"location":"api/tenets/models/analysis/#tenets.models.analysis-classes","title":"Classes","text":""},{"location":"api/tenets/models/analysis/#tenets.models.analysis.ImportInfo","title":"ImportInfo  <code>dataclass</code>","text":"Python<pre><code>ImportInfo(module: str, alias: Optional[str] = None, line: int = 0, type: str = 'import', is_relative: bool = False, level: int = 0, from_module: Optional[str] = None, is_stdlib: bool = False, is_stl: bool = False, conditional: bool = False, is_project_header: bool = False, is_project_file: bool = False, has_include_guard: bool = False, uses_pragma_once: bool = False, import_clause: Optional[str] = None, original_name: Optional[str] = None, is_wildcard: bool = False, category: Optional[str] = None, package: Optional[str] = None, namespace: Optional[str] = None, import_type: Optional[str] = None, is_file_include: bool = False, is_dynamic: bool = False, reloads: bool = False, is_gem: bool = False, is_autoload: bool = False, lazy_load: bool = False, is_unity: bool = False, namespace_context: Optional[str] = None, is_project_reference: bool = False, is_external: bool = False, is_module_declaration: bool = False, is_glob: bool = False, is_dev_dependency: bool = False, is_dependency: bool = False, version: Optional[str] = None, loads_all_gems: bool = False, is_renamed: bool = False, is_given: bool = False, is_resource: bool = False, resource_type: Optional[str] = None, is_runtime_load: bool = False, is_inheritance: bool = False, parent_type: Optional[str] = None, associated_class: Optional[str] = None, is_editor_script: bool = False, is_package_declaration: bool = False, is_package: bool = False, is_dart_core: bool = False, is_deferred: bool = False, show_symbols: List[str] = list(), hide_symbols: List[str] = list(), is_part_file: bool = False, is_library_part: bool = False, is_library_declaration: bool = False, package_context: Optional[str] = None, is_android: bool = False, integrity: Optional[str] = None, crossorigin: Optional[str] = None, is_async: bool = False, is_defer: bool = False, is_module: bool = False, as_type: Optional[str] = None, media_query: Optional[str] = None, layer: Optional[str] = None, supports: Optional[str] = None, config: Optional[str] = None, visibility: Optional[str] = None, composes: Optional[str] = None, is_apple: bool = False, is_apple_framework: bool = False, is_testable: bool = False, is_exported: bool = False, import_kind: Optional[str] = None)\n</code></pre> <p>Information about an import statement in code.</p> <p>Represents imports across different languages (import, require, include, use).</p> ATTRIBUTE DESCRIPTION <code>module</code> <p>The imported module/package name</p> <p> TYPE: <code>str</code> </p> <code>alias</code> <p>Any alias assigned to the import</p> <p> TYPE: <code>Optional[str]</code> </p> <code>line</code> <p>Line number where import appears</p> <p> TYPE: <code>int</code> </p> <code>type</code> <p>Type of import (import, from, require, include)</p> <p> TYPE: <code>str</code> </p> <code>is_relative</code> <p>Whether this is a relative import</p> <p> TYPE: <code>bool</code> </p> <code>level</code> <p>Relative import level (Python), 0 for absolute</p> <p> TYPE: <code>int</code> </p> <code>from_module</code> <p>Module specified in a 'from X import ...' statement</p> <p> TYPE: <code>Optional[str]</code> </p>"},{"location":"api/tenets/models/analysis/#tenets.models.analysis.ImportInfo-functions","title":"Functions","text":""},{"location":"api/tenets/models/analysis/#tenets.models.analysis.ImportInfo.to_dict","title":"to_dict","text":"Python<pre><code>to_dict() -&gt; Dict[str, Any]\n</code></pre> <p>Convert to dictionary representation.</p> RETURNS DESCRIPTION <code>Dict[str, Any]</code> <p>Dict containing all import information</p>"},{"location":"api/tenets/models/analysis/#tenets.models.analysis.ComplexityMetrics","title":"ComplexityMetrics  <code>dataclass</code>","text":"Python<pre><code>ComplexityMetrics(cyclomatic: int = 1, cognitive: int = 0, halstead_volume: float = 0.0, halstead_difficulty: float = 0.0, maintainability_index: float = 100.0, line_count: int = 0, function_count: int = 0, class_count: int = 0, max_depth: int = 0, comment_ratio: float = 0.0, code_lines: int = 0, comment_lines: int = 0, character_count: int = 0, key_count: int = 0, section_count: int = 0, tag_count: int = 0, header_count: int = 0, column_count: int = 0, row_count: int = 0, template_count: int = 0, template_specializations: int = 0, macro_count: int = 0, ifdef_count: int = 0, include_count: int = 0, new_count: int = 0, delete_count: int = 0, malloc_count: int = 0, free_count: int = 0, unique_ptr_count: int = 0, shared_ptr_count: int = 0, weak_ptr_count: int = 0, uses_raii: bool = False, memory_safety_score: float = 1.0, interface_count: int = 0, type_count: int = 0, enum_count: int = 0, record_count: int = 0, method_count: int = 0, try_blocks: int = 0, catch_blocks: int = 0, finally_blocks: int = 0, throws_declarations: int = 0, annotation_count: int = 0, extends_count: int = 0, implements_count: int = 0, lambda_count: int = 0, stream_operations: int = 0, unsafe_blocks: int = 0, unsafe_functions: int = 0, unsafe_traits: int = 0, unsafe_impl: int = 0, unsafe_score: int = 0, lifetime_annotations: int = 0, lifetime_bounds: int = 0, generic_types: int = 0, trait_bounds: int = 0, async_functions: int = 0, await_points: int = 0, result_types: int = 0, option_types: int = 0, unwrap_calls: int = 0, expect_calls: int = 0, question_marks: int = 0, macro_invocations: int = 0, derive_macros: int = 0, test_count: int = 0, bench_count: int = 0, assertion_count: int = 0, combine_operators: int = 0, task_count: int = 0, task_groups: int = 0, await_calls: int = 0, optional_types: int = 0, force_unwraps: int = 0, optional_chaining: int = 0, nil_coalescing: int = 0, guard_statements: int = 0, if_let_bindings: int = 0, guard_let_bindings: int = 0, published_wrappers: int = 0, combine_publishers: int = 0, combine_subscriptions: int = 0, trait_count: int = 0, object_count: int = 0, case_class_count: int = 0, match_expressions: int = 0, case_clauses: int = 0, pattern_guards: int = 0, higher_order_functions: int = 0, for_comprehensions: int = 0, partial_functions: int = 0, type_parameters: int = 0, variance_annotations: int = 0, type_aliases: int = 0, existential_types: int = 0, implicit_defs: int = 0, implicit_params: int = 0, implicit_conversions: int = 0, future_usage: int = 0, actor_usage: int = 0, async_await: int = 0, immutable_collections: int = 0, mutable_collections: int = 0, throw_statements: int = 0, option_usage: int = 0, either_usage: int = 0, try_usage: int = 0, signal_count: int = 0, export_count: int = 0, onready_count: int = 0, node_ref_count: int = 0, get_node_count: int = 0, connect_count: int = 0, emit_count: int = 0, lifecycle_count: int = 0, rpc_count: int = 0, typed_vars: int = 0, typed_funcs: int = 0, return_types: int = 0, has_csp: bool = False, has_integrity_checks: bool = False, has_https_links: int = 0, delegation_count: int = 0, lazy_properties: int = 0, observable_properties: int = 0, lateinit_count: int = 0)\n</code></pre> <p>Code complexity metrics for analysis.</p> <p>Contains various complexity measurements used to assess code quality and maintainability.</p> ATTRIBUTE DESCRIPTION <code>cyclomatic</code> <p>McCabe cyclomatic complexity</p> <p> TYPE: <code>int</code> </p> <code>cognitive</code> <p>Cognitive complexity score</p> <p> TYPE: <code>int</code> </p> <code>halstead_volume</code> <p>Halstead volume metric</p> <p> TYPE: <code>float</code> </p> <code>halstead_difficulty</code> <p>Halstead difficulty metric</p> <p> TYPE: <code>float</code> </p> <code>maintainability_index</code> <p>Maintainability index (0-100)</p> <p> TYPE: <code>float</code> </p> <code>line_count</code> <p>Total number of lines</p> <p> TYPE: <code>int</code> </p> <code>function_count</code> <p>Number of functions</p> <p> TYPE: <code>int</code> </p> <code>class_count</code> <p>Number of classes</p> <p> TYPE: <code>int</code> </p> <code>max_depth</code> <p>Maximum nesting depth</p> <p> TYPE: <code>int</code> </p> <code>comment_ratio</code> <p>Ratio of comments to code</p> <p> TYPE: <code>float</code> </p> <code>code_lines</code> <p>Number of actual code lines</p> <p> TYPE: <code>int</code> </p> <code>comment_lines</code> <p>Number of comment lines</p> <p> TYPE: <code>int</code> </p> <code>character_count</code> <p>Total number of characters</p> <p> TYPE: <code>int</code> </p> <code>key_count</code> <p>Number of key/value pairs (for config files)</p> <p> TYPE: <code>int</code> </p> <code>section_count</code> <p>Number of sections (for structured files)</p> <p> TYPE: <code>int</code> </p> <code>tag_count</code> <p>Number of tags (for markup languages)</p> <p> TYPE: <code>int</code> </p> <code>header_count</code> <p>Number of headers (for document files)</p> <p> TYPE: <code>int</code> </p> <code>column_count</code> <p>Number of columns (for tabular data)</p> <p> TYPE: <code>int</code> </p> <code>row_count</code> <p>Number of rows (for tabular data)</p> <p> TYPE: <code>int</code> </p>"},{"location":"api/tenets/models/analysis/#tenets.models.analysis.ComplexityMetrics-functions","title":"Functions","text":""},{"location":"api/tenets/models/analysis/#tenets.models.analysis.ComplexityMetrics.to_dict","title":"to_dict","text":"Python<pre><code>to_dict() -&gt; Dict[str, Any]\n</code></pre> <p>Convert to dictionary representation.</p> RETURNS DESCRIPTION <code>Dict[str, Any]</code> <p>Dict containing all metrics</p>"},{"location":"api/tenets/models/analysis/#tenets.models.analysis.FunctionInfo","title":"FunctionInfo  <code>dataclass</code>","text":"Python<pre><code>FunctionInfo(name: str, line_start: int = 0, line_end: int = 0, parameters: List[str] = list(), complexity: int = 1, line: int = 0, end_line: int = 0, is_toplevel: bool = False, args: List[str] = list(), decorators: List[str] = list(), is_async: bool = False, docstring: Optional[str] = None, return_type: Optional[str] = None, is_constructor: bool = False, is_abstract: bool = False, is_static: bool = False, is_class: bool = False, is_property: bool = False, is_private: bool = False, is_generator: bool = False, is_exported: bool = False, is_arrow: bool = False, generics: Optional[str] = None, is_inline: bool = False, is_constexpr: bool = False, is_template: bool = False, is_extern: bool = False, is_unsafe: bool = False, is_const: bool = False, is_public: bool = False, visibility: Optional[str] = None, modifiers: List[str] = list(), type_parameters: Optional[str] = None, receiver_type: Optional[str] = None, is_extension: bool = False, is_suspend: bool = False, is_operator: bool = False, is_infix: bool = False, is_implicit: bool = False, is_curried: bool = False, is_lifecycle: bool = False, is_virtual: bool = False, access_level: Optional[str] = None, is_throwing: bool = False, where_clause: Optional[str] = None)\n</code></pre> <p>Information about a function or method.</p> <p>Represents functions, methods, procedures across languages.</p> ATTRIBUTE DESCRIPTION <code>name</code> <p>Function/method name</p> <p> TYPE: <code>str</code> </p> <code>line_start</code> <p>Starting line number</p> <p> TYPE: <code>int</code> </p> <code>line_end</code> <p>Ending line number</p> <p> TYPE: <code>int</code> </p> <code>parameters</code> <p>List of parameter names</p> <p> TYPE: <code>List[str]</code> </p> <code>complexity</code> <p>Cyclomatic complexity of the function</p> <p> TYPE: <code>int</code> </p> <code>line</code> <p>Compatibility alias for line_start</p> <p> TYPE: <code>int</code> </p> <code>end_line</code> <p>Compatibility alias for line_end</p> <p> TYPE: <code>int</code> </p> <code>is_toplevel</code> <p>Whether function is top-level (for some analyzers)</p> <p> TYPE: <code>bool</code> </p> <code>args</code> <p>Argument strings with type hints (analyzer compatibility)</p> <p> TYPE: <code>List[str]</code> </p> <code>decorators</code> <p>Decorators applied to the function</p> <p> TYPE: <code>List[str]</code> </p> <code>is_async</code> <p>Whether the function is async</p> <p> TYPE: <code>bool</code> </p> <code>docstring</code> <p>Function docstring</p> <p> TYPE: <code>Optional[str]</code> </p> <code>return_type</code> <p>Return type annotation</p> <p> TYPE: <code>Optional[str]</code> </p>"},{"location":"api/tenets/models/analysis/#tenets.models.analysis.FunctionInfo-functions","title":"Functions","text":""},{"location":"api/tenets/models/analysis/#tenets.models.analysis.FunctionInfo.to_dict","title":"to_dict","text":"Python<pre><code>to_dict() -&gt; Dict[str, Any]\n</code></pre> <p>Convert to dictionary representation.</p> RETURNS DESCRIPTION <code>Dict[str, Any]</code> <p>Dict containing function information</p>"},{"location":"api/tenets/models/analysis/#tenets.models.analysis.ClassInfo","title":"ClassInfo  <code>dataclass</code>","text":"Python<pre><code>ClassInfo(name: str, line_start: int = 0, line_end: int = 0, methods: List[FunctionInfo] = list(), base_classes: List[str] = list(), line: int = 0, decorators: List[str] = list(), docstring: Optional[str] = None, is_abstract: bool = False, metaclass: Optional[str] = None, attributes: List[Dict[str, Any]] = list(), end_line: int = 0, bases: List[str] = list(), fields: List[Dict[str, Any]] = list(), interfaces: List[str] = list(), visibility: Optional[str] = None, modifiers: List[str] = list(), generics: Optional[str] = None, inner_classes: List[str] = list(), struct_type: Optional[str] = None, is_public: bool = False, is_struct: bool = False, is_template: bool = False, is_exported: bool = False, properties: List[Dict[str, Any]] = list(), events: List[Dict[str, Any]] = list(), type_parameters: Optional[str] = None, constructor_params: List[Dict[str, Any]] = list(), mixins: List[str] = list(), included_modules: List[str] = list(), extended_modules: List[str] = list(), delegates: Dict[str, str] = dict(), companion_object: Optional[Dict[str, Any]] = dict(), nested_classes: List[Dict[str, Any]] = dict(), has_companion: bool = False, is_case_class: bool = False, is_data_class: bool = False, is_sealed: bool = False, is_enum: bool = False, is_inner: bool = False, is_value_class: bool = False, android_type: Optional[str] = None, traits_used: List[Dict[str, Any]] = list(), constants: List[Any] = list(), constructors: List[Dict[str, Any]] = list(), is_widget: bool = False, widget_type: Optional[str] = None, access_level: Optional[str] = None, is_open: bool = False, is_final: bool = False, superclass: Optional[str] = None, protocols: List[str] = list(), nested_types: List[Dict[str, Any]] = list(), ui_type: Optional[str] = None, is_inner_class: bool = False, is_singleton: bool = False, is_monobehaviour: bool = False, is_scriptable_object: bool = False, unity_methods: List[str] = list(), coroutines: List[str] = list())\n</code></pre> <p>Information about a class or similar construct.</p> <p>Represents classes, structs, interfaces across languages.</p> ATTRIBUTE DESCRIPTION <code>name</code> <p>Class/struct/interface name</p> <p> TYPE: <code>str</code> </p> <code>line_start</code> <p>Starting line number</p> <p> TYPE: <code>int</code> </p> <code>line_end</code> <p>Ending line number</p> <p> TYPE: <code>int</code> </p> <code>methods</code> <p>List of methods in the class</p> <p> TYPE: <code>List[FunctionInfo]</code> </p> <code>base_classes</code> <p>List of base/parent class names</p> <p> TYPE: <code>List[str]</code> </p> <code>line</code> <p>Compatibility alias for line_start</p> <p> TYPE: <code>int</code> </p> <code>decorators</code> <p>Decorator names applied to the class</p> <p> TYPE: <code>List[str]</code> </p> <code>docstring</code> <p>Class docstring</p> <p> TYPE: <code>Optional[str]</code> </p> <code>is_abstract</code> <p>Whether class is abstract</p> <p> TYPE: <code>bool</code> </p> <code>metaclass</code> <p>Metaclass name</p> <p> TYPE: <code>Optional[str]</code> </p> <code>attributes</code> <p>Collected class attributes</p> <p> TYPE: <code>List[Dict[str, Any]]</code> </p> <code>end_line</code> <p>Compatibility alias for line_end</p> <p> TYPE: <code>int</code> </p> <code>bases</code> <p>Compatibility alias accepted by some analyzers/tests</p> <p> TYPE: <code>List[str]</code> </p>"},{"location":"api/tenets/models/analysis/#tenets.models.analysis.ClassInfo-functions","title":"Functions","text":""},{"location":"api/tenets/models/analysis/#tenets.models.analysis.ClassInfo.to_dict","title":"to_dict","text":"Python<pre><code>to_dict() -&gt; Dict[str, Any]\n</code></pre> <p>Convert to dictionary representation.</p> RETURNS DESCRIPTION <code>Dict[str, Any]</code> <p>Dict containing class information with serialized methods</p>"},{"location":"api/tenets/models/analysis/#tenets.models.analysis.CodeStructure","title":"CodeStructure  <code>dataclass</code>","text":"Python<pre><code>CodeStructure(classes: List[ClassInfo] = list(), functions: List[FunctionInfo] = list(), imports: List[ImportInfo] = list(), file_type: str = 'text', sections: List[Dict[str, Any]] = list(), variables: List[Dict[str, Any]] = list(), constants: List[str] = list(), todos: List[Dict[str, Any]] = list(), block_count: int = 0, indent_levels: Dict[str, Any] = dict(), type_aliases: List[Dict[str, Any]] = list(), namespace: Optional[str] = None, is_unity_script: bool = False, language_variant: Optional[str] = None, namespaces: List[Dict[str, Any]] = list(), templates: List[Dict[str, Any]] = list(), macros: List[Dict[str, Any]] = list(), unions: List[Dict[str, Any]] = list(), structs: List[Dict[str, Any]] = list(), operator_overloads: int = 0, uses_stl: bool = False, smart_pointers: List[str] = list(), lambda_count: int = 0, interfaces: List[Dict[str, Any]] = list(), types: List[Dict[str, Any]] = list(), enums: List[Dict[str, Any]] = list(), modules: List[Dict[str, Any]] = list(), framework: Optional[str] = None, package: Optional[str] = None, records: List[Dict[str, Any]] = list(), annotations: List[str] = list(), anonymous_classes_count: int = 0, components: List[Dict[str, Any]] = list(), is_library: bool = False, is_binary: bool = False, aliases: List[Dict[str, Any]] = list(), is_test: bool = False, traits: List[Dict[str, Any]] = list(), impl_blocks: List[Dict[str, Any]] = list(), statics: List[Dict[str, Any]] = list(), derives: List[str] = list(), unsafe_blocks: int = 0, async_functions: int = 0, test_functions: int = 0, bench_functions: int = 0, crate_type: Optional[str] = None, await_points: int = 0, unsafe_functions: int = 0, objects: List[Dict[str, Any]] = list(), scala_version: Optional[int] = None, given_instances: int = 0, using_clauses: int = 0, extension_methods: int = 0, extension_functions: int = 0, match_expressions: int = 0, case_statements: int = 0, for_comprehensions: int = 0, yield_expressions: int = 0, implicit_defs: int = 0, implicit_params: int = 0, lambda_expressions: int = 0, partial_functions: int = 0, is_android: bool = False, suspend_functions: int = 0, coroutine_launches: int = 0, flow_usage: int = 0, nullable_types: int = 0, null_assertions: int = 0, safe_calls: int = 0, elvis_operators: int = 0, scope_functions: int = 0, is_tool_script: bool = False, class_name: Optional[str] = None, parent_class: Optional[str] = None, godot_version: Optional[int] = None, signals: List[Dict[str, Any]] = list(), export_vars: List[Dict[str, Any]] = list(), onready_vars: List[Dict[str, Any]] = list(), setget_properties: List[Dict[str, Any]] = list(), node_references: int = 0, get_node_calls: int = 0, connect_calls: int = 0, emit_signal_calls: int = 0, is_custom_resource: bool = False, is_flutter: bool = False, mixins: List[Dict[str, Any]] = list(), extensions: List[Dict[str, Any]] = list(), typedefs: List[Dict[str, Any]] = list(), has_main: bool = False, is_test_file: bool = False, is_ios: bool = False, is_swiftui: bool = False, is_uikit: bool = False, protocols: List[Dict[str, Any]] = list(), actors: List[Dict[str, Any]] = list(), task_count: int = 0, await_count: int = 0, optional_count: int = 0, force_unwrap_count: int = 0, optional_chaining_count: int = 0, nil_coalescing_count: int = 0, guard_count: int = 0, if_let_count: int = 0, guard_let_count: int = 0, actor_count: int = 0, property_wrappers: int = 0, result_builders: int = 0, combine_publishers: int = 0, combine_operators: int = 0, swiftui_views: int = 0, view_modifiers: int = 0, body_count: int = 0, form_count: int = 0, input_count: int = 0, alt_texts: int = 0)\n</code></pre> <p>Represents the structure of a code file.</p> <p>Contains organized information about code elements found in a file.</p> ATTRIBUTE DESCRIPTION <code>classes</code> <p>List of classes in the file</p> <p> TYPE: <code>List[ClassInfo]</code> </p> <code>functions</code> <p>List of standalone functions</p> <p> TYPE: <code>List[FunctionInfo]</code> </p> <code>imports</code> <p>List of import statements</p> <p> TYPE: <code>List[ImportInfo]</code> </p> <code>file_type</code> <p>Type of the file (e.g., script, module, package)</p> <p> TYPE: <code>str</code> </p> <code>sections</code> <p>List of sections or blocks in the code</p> <p> TYPE: <code>List[Dict[str, Any]]</code> </p> <code>variables</code> <p>List of variables used</p> <p> TYPE: <code>List[Dict[str, Any]]</code> </p> <code>constants</code> <p>List of constants</p> <p> TYPE: <code>List[str]</code> </p> <code>todos</code> <p>List of TODO comments or annotations</p> <p> TYPE: <code>List[Dict[str, Any]]</code> </p> <code>block_count</code> <p>Total number of code blocks</p> <p> TYPE: <code>int</code> </p> <code>indent_levels</code> <p>Indentation levels used in the code</p> <p> TYPE: <code>Dict[str, Any]</code> </p> <code>type_aliases</code> <p>List of type alias definitions (Python 3.10+)</p> <p> TYPE: <code>List[Dict[str, Any]]</code> </p>"},{"location":"api/tenets/models/analysis/#tenets.models.analysis.CodeStructure-functions","title":"Functions","text":""},{"location":"api/tenets/models/analysis/#tenets.models.analysis.CodeStructure.to_dict","title":"to_dict","text":"Python<pre><code>to_dict() -&gt; Dict[str, Any]\n</code></pre> <p>Convert to dictionary representation.</p> RETURNS DESCRIPTION <code>Dict[str, Any]</code> <p>Dict containing all structural information</p>"},{"location":"api/tenets/models/analysis/#tenets.models.analysis.FileAnalysis","title":"FileAnalysis  <code>dataclass</code>","text":"Python<pre><code>FileAnalysis(path: str, content: str = '', size: int = 0, lines: int = 0, language: str = 'unknown', file_name: str = '', file_extension: str = '', last_modified: Optional[datetime] = None, hash: Optional[str] = None, imports: List[ImportInfo] = list(), exports: List[Dict[str, Any]] = list(), structure: Optional[CodeStructure] = None, complexity: Optional[ComplexityMetrics] = None, classes: List[ClassInfo] = list(), functions: List[FunctionInfo] = list(), keywords: List[str] = list(), git_info: Optional[Dict[str, Any]] = None, relevance_score: float = 0.0, quality_score: float = 0.0, error: Optional[str] = None)\n</code></pre> <p>Complete analysis results for a single file.</p> <p>Contains all information extracted from analyzing a source code file, including structure, complexity, and metadata.</p> ATTRIBUTE DESCRIPTION <code>path</code> <p>File path</p> <p> TYPE: <code>str</code> </p> <code>content</code> <p>File content</p> <p> TYPE: <code>str</code> </p> <code>size</code> <p>File size in bytes</p> <p> TYPE: <code>int</code> </p> <code>lines</code> <p>Number of lines</p> <p> TYPE: <code>int</code> </p> <code>language</code> <p>Programming language</p> <p> TYPE: <code>str</code> </p> <code>file_name</code> <p>Name of the file</p> <p> TYPE: <code>str</code> </p> <code>file_extension</code> <p>File extension</p> <p> TYPE: <code>str</code> </p> <code>last_modified</code> <p>Last modification time</p> <p> TYPE: <code>Optional[datetime]</code> </p> <code>hash</code> <p>Content hash</p> <p> TYPE: <code>Optional[str]</code> </p> <code>imports</code> <p>List of imports</p> <p> TYPE: <code>List[ImportInfo]</code> </p> <code>exports</code> <p>List of exports</p> <p> TYPE: <code>List[Dict[str, Any]]</code> </p> <code>structure</code> <p>Code structure information</p> <p> TYPE: <code>Optional[CodeStructure]</code> </p> <code>complexity</code> <p>Complexity metrics</p> <p> TYPE: <code>Optional[ComplexityMetrics]</code> </p> <code>classes</code> <p>List of classes (convenience accessor)</p> <p> TYPE: <code>List[ClassInfo]</code> </p> <code>functions</code> <p>List of functions (convenience accessor)</p> <p> TYPE: <code>List[FunctionInfo]</code> </p> <code>keywords</code> <p>Extracted keywords</p> <p> TYPE: <code>List[str]</code> </p> <code>relevance_score</code> <p>Relevance score for ranking</p> <p> TYPE: <code>float</code> </p> <code>quality_score</code> <p>Code quality score</p> <p> TYPE: <code>float</code> </p> <code>error</code> <p>Any error encountered during analysis</p> <p> TYPE: <code>Optional[str]</code> </p>"},{"location":"api/tenets/models/analysis/#tenets.models.analysis.FileAnalysis-functions","title":"Functions","text":""},{"location":"api/tenets/models/analysis/#tenets.models.analysis.FileAnalysis.to_dict","title":"to_dict","text":"Python<pre><code>to_dict() -&gt; Dict[str, Any]\n</code></pre> <p>Convert to dictionary representation.</p> RETURNS DESCRIPTION <code>Dict[str, Any]</code> <p>Dict containing all file analysis data</p>"},{"location":"api/tenets/models/analysis/#tenets.models.analysis.FileAnalysis.from_dict","title":"from_dict  <code>classmethod</code>","text":"Python<pre><code>from_dict(data: Dict[str, Any]) -&gt; FileAnalysis\n</code></pre> <p>Create FileAnalysis from dictionary.</p> PARAMETER DESCRIPTION <code>data</code> <p>Dictionary containing file analysis data</p> <p> TYPE: <code>Dict[str, Any]</code> </p> RETURNS DESCRIPTION <code>FileAnalysis</code> <p>FileAnalysis instance</p>"},{"location":"api/tenets/models/analysis/#tenets.models.analysis.DependencyGraph","title":"DependencyGraph  <code>dataclass</code>","text":"Python<pre><code>DependencyGraph(nodes: Dict[str, Any] = dict(), edges: List[tuple] = list(), cycles: List[List[str]] = list())\n</code></pre> <p>Represents project dependency graph.</p> <p>Tracks dependencies between files and modules in the project.</p> ATTRIBUTE DESCRIPTION <code>nodes</code> <p>Dictionary of node ID to node data</p> <p> TYPE: <code>Dict[str, Any]</code> </p> <code>edges</code> <p>List of edges (from_id, to_id, edge_data)</p> <p> TYPE: <code>List[tuple]</code> </p> <code>cycles</code> <p>List of detected dependency cycles</p> <p> TYPE: <code>List[List[str]]</code> </p>"},{"location":"api/tenets/models/analysis/#tenets.models.analysis.DependencyGraph-functions","title":"Functions","text":""},{"location":"api/tenets/models/analysis/#tenets.models.analysis.DependencyGraph.add_node","title":"add_node","text":"Python<pre><code>add_node(node_id: str, data: Any) -&gt; None\n</code></pre> <p>Add a node to the dependency graph.</p> PARAMETER DESCRIPTION <code>node_id</code> <p>Unique identifier for the node</p> <p> TYPE: <code>str</code> </p> <code>data</code> <p>Node data (typically FileAnalysis)</p> <p> TYPE: <code>Any</code> </p>"},{"location":"api/tenets/models/analysis/#tenets.models.analysis.DependencyGraph.add_edge","title":"add_edge","text":"Python<pre><code>add_edge(from_id: str, to_id: str, import_info: Optional[ImportInfo] = None) -&gt; None\n</code></pre> <p>Add an edge representing a dependency.</p> PARAMETER DESCRIPTION <code>from_id</code> <p>Source node ID</p> <p> TYPE: <code>str</code> </p> <code>to_id</code> <p>Target node ID</p> <p> TYPE: <code>str</code> </p> <code>import_info</code> <p>Optional import information</p> <p> TYPE: <code>Optional[ImportInfo]</code> DEFAULT: <code>None</code> </p>"},{"location":"api/tenets/models/analysis/#tenets.models.analysis.DependencyGraph.calculate_metrics","title":"calculate_metrics","text":"Python<pre><code>calculate_metrics() -&gt; None\n</code></pre> <p>Calculate graph metrics like centrality and cycles.</p> <p>Updates internal metrics based on current graph structure.</p>"},{"location":"api/tenets/models/analysis/#tenets.models.analysis.DependencyGraph.to_dict","title":"to_dict","text":"Python<pre><code>to_dict() -&gt; Dict[str, Any]\n</code></pre> <p>Convert to dictionary representation.</p> RETURNS DESCRIPTION <code>Dict[str, Any]</code> <p>Dict containing graph structure</p>"},{"location":"api/tenets/models/analysis/#tenets.models.analysis.ProjectAnalysis","title":"ProjectAnalysis  <code>dataclass</code>","text":"Python<pre><code>ProjectAnalysis(path: str, name: str, files: List[FileAnalysis] = list(), total_files: int = 0, analyzed_files: int = 0, failed_files: int = 0, total_lines: int = 0, total_code_lines: int = 0, total_comment_lines: int = 0, average_complexity: float = 0.0, total_functions: int = 0, total_classes: int = 0, languages: Dict[str, int] = dict(), language_distribution: Dict[str, float] = dict(), frameworks: List[str] = list(), project_type: str = 'unknown', dependency_graph: Optional[DependencyGraph] = None, summary: Dict[str, Any] = dict())\n</code></pre> <p>Analysis results for an entire project.</p> <p>Aggregates file-level analysis into project-wide metrics and insights.</p> ATTRIBUTE DESCRIPTION <code>path</code> <p>Project root path</p> <p> TYPE: <code>str</code> </p> <code>name</code> <p>Project name</p> <p> TYPE: <code>str</code> </p> <code>files</code> <p>List of analyzed files</p> <p> TYPE: <code>List[FileAnalysis]</code> </p> <code>total_files</code> <p>Total number of files</p> <p> TYPE: <code>int</code> </p> <code>analyzed_files</code> <p>Number of successfully analyzed files</p> <p> TYPE: <code>int</code> </p> <code>failed_files</code> <p>Number of files that failed analysis</p> <p> TYPE: <code>int</code> </p> <code>total_lines</code> <p>Total lines of code</p> <p> TYPE: <code>int</code> </p> <code>total_code_lines</code> <p>Total non-blank, non-comment lines</p> <p> TYPE: <code>int</code> </p> <code>total_comment_lines</code> <p>Total comment lines</p> <p> TYPE: <code>int</code> </p> <code>average_complexity</code> <p>Average cyclomatic complexity</p> <p> TYPE: <code>float</code> </p> <code>total_functions</code> <p>Total number of functions</p> <p> TYPE: <code>int</code> </p> <code>total_classes</code> <p>Total number of classes</p> <p> TYPE: <code>int</code> </p> <code>languages</code> <p>Language distribution (language -&gt; file count)</p> <p> TYPE: <code>Dict[str, int]</code> </p> <code>language_distribution</code> <p>Percentage distribution of languages</p> <p> TYPE: <code>Dict[str, float]</code> </p> <code>frameworks</code> <p>Detected frameworks</p> <p> TYPE: <code>List[str]</code> </p> <code>project_type</code> <p>Type of project (web, library, cli, etc.)</p> <p> TYPE: <code>str</code> </p> <code>dependency_graph</code> <p>Project dependency graph</p> <p> TYPE: <code>Optional[DependencyGraph]</code> </p> <code>summary</code> <p>Project summary dictionary</p> <p> TYPE: <code>Dict[str, Any]</code> </p>"},{"location":"api/tenets/models/analysis/#tenets.models.analysis.ProjectAnalysis-functions","title":"Functions","text":""},{"location":"api/tenets/models/analysis/#tenets.models.analysis.ProjectAnalysis.to_dict","title":"to_dict","text":"Python<pre><code>to_dict() -&gt; Dict[str, Any]\n</code></pre> <p>Convert to dictionary representation.</p> RETURNS DESCRIPTION <code>Dict[str, Any]</code> <p>Dict containing all project analysis data</p>"},{"location":"api/tenets/models/analysis/#tenets.models.analysis.AnalysisReport","title":"AnalysisReport  <code>dataclass</code>","text":"Python<pre><code>AnalysisReport(timestamp: datetime = datetime.now(), format: str = 'json', content: str = '', statistics: Dict[str, Any] = dict(), output_path: Optional[str] = None)\n</code></pre> <p>Report generated from analysis results.</p> <p>Formatted output of analysis results for different consumers.</p> ATTRIBUTE DESCRIPTION <code>timestamp</code> <p>When report was generated</p> <p> TYPE: <code>datetime</code> </p> <code>format</code> <p>Report format (json, html, markdown, csv)</p> <p> TYPE: <code>str</code> </p> <code>content</code> <p>Report content</p> <p> TYPE: <code>str</code> </p> <code>statistics</code> <p>Analysis statistics</p> <p> TYPE: <code>Dict[str, Any]</code> </p> <code>output_path</code> <p>Where report was saved (if applicable)</p> <p> TYPE: <code>Optional[str]</code> </p>"},{"location":"api/tenets/models/analysis/#tenets.models.analysis.AnalysisReport-functions","title":"Functions","text":""},{"location":"api/tenets/models/analysis/#tenets.models.analysis.AnalysisReport.to_dict","title":"to_dict","text":"Python<pre><code>to_dict() -&gt; Dict[str, Any]\n</code></pre> <p>Convert to dictionary representation.</p> RETURNS DESCRIPTION <code>Dict[str, Any]</code> <p>Dict containing report information</p>"},{"location":"api/tenets/models/context/","title":"Context","text":""},{"location":"api/tenets/models/context/#tenets.models.context","title":"tenets.models.context","text":"<p>Context models for prompt processing and result handling.</p> <p>This module defines the data structures for managing context throughout the distillation and instillation process.</p>"},{"location":"api/tenets/models/context/#tenets.models.context-classes","title":"Classes","text":""},{"location":"api/tenets/models/context/#tenets.models.context.TaskType","title":"TaskType","text":"<p>               Bases: <code>Enum</code></p> <p>Types of tasks detected in prompts.</p>"},{"location":"api/tenets/models/context/#tenets.models.context.TaskType-functions","title":"Functions","text":""},{"location":"api/tenets/models/context/#tenets.models.context.TaskType.from_string","title":"from_string  <code>classmethod</code>","text":"Python<pre><code>from_string(value: str) -&gt; TaskType\n</code></pre> <p>Create TaskType from string value.</p>"},{"location":"api/tenets/models/context/#tenets.models.context.PromptContext","title":"PromptContext  <code>dataclass</code>","text":"Python<pre><code>PromptContext(text: str, original: Optional[str] = None, keywords: list[str] = list(), task_type: str = 'general', intent: str = 'understand', entities: list[dict[str, Any]] = list(), file_patterns: list[str] = list(), focus_areas: list[str] = list(), temporal_context: Optional[dict[str, Any]] = None, scope: dict[str, Any] = dict(), external_context: Optional[dict[str, Any]] = None, metadata: dict[str, Any] = dict(), confidence_scores: dict[str, float] = dict(), session_id: Optional[str] = None, timestamp: datetime = datetime.now(), include_tests: bool = False)\n</code></pre> <p>Context extracted from user prompt.</p> <p>Contains all information parsed from the prompt to guide file selection and ranking. This is the primary data structure that flows through the system after prompt parsing.</p> ATTRIBUTE DESCRIPTION <code>text</code> <p>The processed prompt text (cleaned and normalized)</p> <p> TYPE: <code>str</code> </p> <code>original</code> <p>Original input (may be URL or raw text)</p> <p> TYPE: <code>Optional[str]</code> </p> <code>keywords</code> <p>Extracted keywords for searching</p> <p> TYPE: <code>list[str]</code> </p> <code>task_type</code> <p>Type of task detected</p> <p> TYPE: <code>str</code> </p> <code>intent</code> <p>User intent classification</p> <p> TYPE: <code>str</code> </p> <code>entities</code> <p>Named entities found (classes, functions, modules)</p> <p> TYPE: <code>list[dict[str, Any]]</code> </p> <code>file_patterns</code> <p>File patterns to match (.py, test_, etc)</p> <p> TYPE: <code>list[str]</code> </p> <code>focus_areas</code> <p>Areas to focus on (auth, api, database, etc)</p> <p> TYPE: <code>list[str]</code> </p> <code>temporal_context</code> <p>Time-related context (recent, yesterday, etc)</p> <p> TYPE: <code>Optional[dict[str, Any]]</code> </p> <code>scope</code> <p>Scope indicators (modules, directories, exclusions)</p> <p> TYPE: <code>dict[str, Any]</code> </p> <code>external_context</code> <p>Context from external sources (GitHub, JIRA)</p> <p> TYPE: <code>Optional[dict[str, Any]]</code> </p> <code>metadata</code> <p>Additional metadata for processing</p> <p> TYPE: <code>dict[str, Any]</code> </p> <code>confidence_scores</code> <p>Confidence scores for various extractions</p> <p> TYPE: <code>dict[str, float]</code> </p> <code>session_id</code> <p>Associated session if any</p> <p> TYPE: <code>Optional[str]</code> </p> <code>timestamp</code> <p>When context was created</p> <p> TYPE: <code>datetime</code> </p>"},{"location":"api/tenets/models/context/#tenets.models.context.PromptContext-functions","title":"Functions","text":""},{"location":"api/tenets/models/context/#tenets.models.context.PromptContext.add_keyword","title":"add_keyword","text":"Python<pre><code>add_keyword(keyword: str, confidence: float = 1.0) -&gt; None\n</code></pre> <p>Add a keyword with confidence score.</p>"},{"location":"api/tenets/models/context/#tenets.models.context.PromptContext.add_entity","title":"add_entity","text":"Python<pre><code>add_entity(name: str, entity_type: str, confidence: float = 1.0) -&gt; None\n</code></pre> <p>Add an entity with type and confidence.</p>"},{"location":"api/tenets/models/context/#tenets.models.context.PromptContext.add_focus_area","title":"add_focus_area","text":"Python<pre><code>add_focus_area(area: str) -&gt; None\n</code></pre> <p>Add a focus area if not already present.</p>"},{"location":"api/tenets/models/context/#tenets.models.context.PromptContext.merge_with","title":"merge_with","text":"Python<pre><code>merge_with(other: PromptContext) -&gt; PromptContext\n</code></pre> <p>Merge this context with another.</p>"},{"location":"api/tenets/models/context/#tenets.models.context.PromptContext.to_dict","title":"to_dict","text":"Python<pre><code>to_dict() -&gt; dict[str, Any]\n</code></pre> <p>Convert to dictionary representation.</p>"},{"location":"api/tenets/models/context/#tenets.models.context.PromptContext.from_dict","title":"from_dict  <code>classmethod</code>","text":"Python<pre><code>from_dict(data: dict[str, Any]) -&gt; PromptContext\n</code></pre> <p>Create PromptContext from dictionary.</p>"},{"location":"api/tenets/models/context/#tenets.models.context.PromptContext.get_hash","title":"get_hash","text":"Python<pre><code>get_hash() -&gt; str\n</code></pre> <p>Compute a deterministic cache key for this prompt context.</p> <p>The hash incorporates the normalized prompt text, task type, and the ordered list of unique keywords. MD5 is chosen (with <code>usedforsecurity=False</code>) for speed; collision risk is acceptable for internal memoization.</p> RETURNS DESCRIPTION <code>str</code> <p>Hex digest suitable for use as an internal cache key.</p> <p> TYPE: <code>str</code> </p>"},{"location":"api/tenets/models/context/#tenets.models.context.ContextResult","title":"ContextResult  <code>dataclass</code>","text":"Python<pre><code>ContextResult(content: Optional[str] = None, context: Optional[str] = None, format: str = 'markdown', token_count: int = 0, files: list[str] = list(), files_included: list[str] = list(), files_summarized: list[str] = list(), metadata: dict[str, Any] = dict(), session_id: Optional[str] = None, timestamp: datetime = datetime.now(), statistics: dict[str, Any] = dict(), prompt_context: Optional[PromptContext] = None, cost_estimate: Optional[dict[str, float]] = None, warnings: list[str] = list(), errors: list[str] = list())\n</code></pre> <p>Result of context generation.</p> <p>Contains the generated context ready for consumption by LLMs or other tools. This is the final output of the distillation process.</p> ATTRIBUTE DESCRIPTION <code>content</code> <p>The generated context content (preferred alias)</p> <p> TYPE: <code>Optional[str]</code> </p> <code>context</code> <p>Backward-compatible alias for content</p> <p> TYPE: <code>Optional[str]</code> </p> <code>format</code> <p>Output format (markdown, xml, json)</p> <p> TYPE: <code>str</code> </p> <code>token_count</code> <p>Number of tokens in context</p> <p> TYPE: <code>int</code> </p> <code>files</code> <p>List of included file paths (preferred alias)</p> <p> TYPE: <code>list[str]</code> </p> <code>files_included</code> <p>Backward-compatible alias for files</p> <p> TYPE: <code>list[str]</code> </p> <code>files_summarized</code> <p>List of summarized file paths</p> <p> TYPE: <code>list[str]</code> </p> <code>metadata</code> <p>Additional metadata about generation, including: - timing: Dict with duration info (if timing enabled)     - duration: float seconds     - formatted_duration: Human-readable string (e.g. \"2.34s\")     - start_datetime: ISO format start time     - end_datetime: ISO format end time</p> <p> TYPE: <code>dict[str, Any]</code> </p> <code>session_id</code> <p>Session this belongs to</p> <p> TYPE: <code>Optional[str]</code> </p> <code>timestamp</code> <p>When context was generated</p> <p> TYPE: <code>datetime</code> </p> <code>statistics</code> <p>Generation statistics</p> <p> TYPE: <code>dict[str, Any]</code> </p> <code>prompt_context</code> <p>Original prompt context</p> <p> TYPE: <code>Optional[PromptContext]</code> </p> <code>cost_estimate</code> <p>Estimated cost for LLM usage</p> <p> TYPE: <code>Optional[dict[str, float]]</code> </p> <code>warnings</code> <p>Any warnings during generation</p> <p> TYPE: <code>list[str]</code> </p> <code>errors</code> <p>Any errors during generation</p> <p> TYPE: <code>list[str]</code> </p>"},{"location":"api/tenets/models/context/#tenets.models.context.ContextResult-functions","title":"Functions","text":""},{"location":"api/tenets/models/context/#tenets.models.context.ContextResult.add_warning","title":"add_warning","text":"Python<pre><code>add_warning(warning: str) -&gt; None\n</code></pre> <p>Add a warning message.</p>"},{"location":"api/tenets/models/context/#tenets.models.context.ContextResult.add_error","title":"add_error","text":"Python<pre><code>add_error(error: str) -&gt; None\n</code></pre> <p>Add an error message.</p>"},{"location":"api/tenets/models/context/#tenets.models.context.ContextResult.update_statistics","title":"update_statistics","text":"Python<pre><code>update_statistics(key: str, value: Any) -&gt; None\n</code></pre> <p>Update a statistic value.</p>"},{"location":"api/tenets/models/context/#tenets.models.context.ContextResult.to_dict","title":"to_dict","text":"Python<pre><code>to_dict() -&gt; dict[str, Any]\n</code></pre> <p>Convert to dictionary representation.</p>"},{"location":"api/tenets/models/context/#tenets.models.context.ContextResult.from_dict","title":"from_dict  <code>classmethod</code>","text":"Python<pre><code>from_dict(data: dict[str, Any]) -&gt; ContextResult\n</code></pre> <p>Create from dictionary.</p>"},{"location":"api/tenets/models/context/#tenets.models.context.ContextResult.save_to_file","title":"save_to_file","text":"Python<pre><code>save_to_file(path: Union[str, Path]) -&gt; None\n</code></pre> <p>Save context result to file.</p>"},{"location":"api/tenets/models/context/#tenets.models.context.ContextResult.get_summary","title":"get_summary","text":"Python<pre><code>get_summary() -&gt; str\n</code></pre> <p>Get a summary of the context result.</p>"},{"location":"api/tenets/models/context/#tenets.models.context.SessionContext","title":"SessionContext  <code>dataclass</code>","text":"Python<pre><code>SessionContext(session_id: str, name: str = '', project_root: Optional[Path] = None, shown_files: set[str] = set(), ignored_files: set[str] = set(), context_history: list[ContextResult] = list(), current_focus: list[str] = list(), tenets_applied: list[str] = list(), created_at: datetime = datetime.now(), updated_at: datetime = datetime.now(), metadata: dict[str, Any] = dict(), ai_requests: list[dict[str, Any]] = list(), branch: Optional[str] = None, pinned_files: set[str] = set())\n</code></pre> <p>Context for a session.</p> <p>Maintains state across multiple prompts in a session for incremental context building and state management.</p> ATTRIBUTE DESCRIPTION <code>session_id</code> <p>Unique session identifier</p> <p> TYPE: <code>str</code> </p> <code>name</code> <p>Human-readable session name</p> <p> TYPE: <code>str</code> </p> <code>project_root</code> <p>Root path of the project</p> <p> TYPE: <code>Optional[Path]</code> </p> <code>shown_files</code> <p>Files explicitly shown</p> <p> TYPE: <code>set[str]</code> </p> <code>ignored_files</code> <p>Files to ignore</p> <p> TYPE: <code>set[str]</code> </p> <code>context_history</code> <p>History of contexts</p> <p> TYPE: <code>list[ContextResult]</code> </p> <code>current_focus</code> <p>Current focus areas</p> <p> TYPE: <code>list[str]</code> </p> <code>tenets_applied</code> <p>Tenets applied in session</p> <p> TYPE: <code>list[str]</code> </p> <code>created_at</code> <p>When session was created</p> <p> TYPE: <code>datetime</code> </p> <code>updated_at</code> <p>Last update time</p> <p> TYPE: <code>datetime</code> </p> <code>metadata</code> <p>Session metadata</p> <p> TYPE: <code>dict[str, Any]</code> </p> <code>ai_requests</code> <p>History of AI requests</p> <p> TYPE: <code>list[dict[str, Any]]</code> </p> <code>branch</code> <p>Git branch if applicable</p> <p> TYPE: <code>Optional[str]</code> </p>"},{"location":"api/tenets/models/context/#tenets.models.context.SessionContext-functions","title":"Functions","text":""},{"location":"api/tenets/models/context/#tenets.models.context.SessionContext.add_shown_file","title":"add_shown_file","text":"Python<pre><code>add_shown_file(file_path: str) -&gt; None\n</code></pre> <p>Mark file as shown.</p>"},{"location":"api/tenets/models/context/#tenets.models.context.SessionContext.add_ignored_file","title":"add_ignored_file","text":"Python<pre><code>add_ignored_file(file_path: str) -&gt; None\n</code></pre> <p>Mark file as ignored.</p>"},{"location":"api/tenets/models/context/#tenets.models.context.SessionContext.add_context","title":"add_context","text":"Python<pre><code>add_context(context: ContextResult) -&gt; None\n</code></pre> <p>Add context to history.</p>"},{"location":"api/tenets/models/context/#tenets.models.context.SessionContext.add_ai_request","title":"add_ai_request","text":"Python<pre><code>add_ai_request(request_type: str, request_data: dict[str, Any]) -&gt; None\n</code></pre> <p>Record an AI request.</p>"},{"location":"api/tenets/models/context/#tenets.models.context.SessionContext.add_pinned_file","title":"add_pinned_file","text":"Python<pre><code>add_pinned_file(file_path: str) -&gt; None\n</code></pre> <p>Pin a file so it is always considered for future distill operations.</p> PARAMETER DESCRIPTION <code>file_path</code> <p>Absolute or project-relative path to the file.</p> <p> TYPE: <code>str</code> </p>"},{"location":"api/tenets/models/context/#tenets.models.context.SessionContext.list_pinned_files","title":"list_pinned_files","text":"Python<pre><code>list_pinned_files() -&gt; list[str]\n</code></pre> <p>Return pinned file paths.</p>"},{"location":"api/tenets/models/context/#tenets.models.context.SessionContext.get_latest_context","title":"get_latest_context","text":"Python<pre><code>get_latest_context() -&gt; Optional[ContextResult]\n</code></pre> <p>Get the most recent context.</p>"},{"location":"api/tenets/models/context/#tenets.models.context.SessionContext.should_show_file","title":"should_show_file","text":"Python<pre><code>should_show_file(file_path: str) -&gt; bool\n</code></pre> <p>Check if file should be shown based on session state.</p>"},{"location":"api/tenets/models/context/#tenets.models.context.SessionContext.to_dict","title":"to_dict","text":"Python<pre><code>to_dict() -&gt; dict[str, Any]\n</code></pre> <p>Convert to dictionary representation.</p>"},{"location":"api/tenets/models/context/#tenets.models.context.SessionContext.from_dict","title":"from_dict  <code>classmethod</code>","text":"Python<pre><code>from_dict(data: dict[str, Any]) -&gt; SessionContext\n</code></pre> <p>Create from dictionary.</p>"},{"location":"api/tenets/models/llm/","title":"Llm","text":""},{"location":"api/tenets/models/llm/#tenets.models.llm","title":"tenets.models.llm","text":"<p>LLM pricing and limits.</p> <p>Centralized reference for model pricing and token limits. Values are best-effort and can be overridden at runtime.</p>"},{"location":"api/tenets/models/llm/#tenets.models.llm-functions","title":"Functions","text":""},{"location":"api/tenets/models/llm/#tenets.models.llm.get_model_pricing","title":"get_model_pricing","text":"Python<pre><code>get_model_pricing(model: Optional[str]) -&gt; ModelPricing\n</code></pre> <p>Return pricing for a model or a conservative default.</p> PARAMETER DESCRIPTION <code>model</code> <p>Model name (e.g., \"gpt-4o\", \"claude-3-opus\"). If None or unknown, returns a zero-cost placeholder suitable for dry runs.</p> <p> TYPE: <code>Optional[str]</code> </p> RETURNS DESCRIPTION <code>ModelPricing</code> <p>Pricing per 1K input and output tokens.</p> <p> TYPE: <code>ModelPricing</code> </p>"},{"location":"api/tenets/models/llm/#tenets.models.llm.get_model_limits","title":"get_model_limits","text":"Python<pre><code>get_model_limits(model: Optional[str]) -&gt; ModelLimits\n</code></pre> <p>Return token limits for a model or a conservative default.</p> PARAMETER DESCRIPTION <code>model</code> <p>Model name. If None or unknown, returns a safe default budget.</p> <p> TYPE: <code>Optional[str]</code> </p> RETURNS DESCRIPTION <code>ModelLimits</code> <p>Maximum context and output tokens.</p> <p> TYPE: <code>ModelLimits</code> </p>"},{"location":"api/tenets/models/llm/#tenets.models.llm.estimate_cost","title":"estimate_cost","text":"Python<pre><code>estimate_cost(input_tokens: int, output_tokens: int, model: Optional[str]) -&gt; dict[str, float]\n</code></pre> <p>Estimate API cost for a given token usage and model.</p> PARAMETER DESCRIPTION <code>input_tokens</code> <p>Number of prompt/input tokens.</p> <p> TYPE: <code>int</code> </p> <code>output_tokens</code> <p>Expected number of completion/output tokens.</p> <p> TYPE: <code>int</code> </p> <code>model</code> <p>Target model name used to look up pricing.</p> <p> TYPE: <code>Optional[str]</code> </p> RETURNS DESCRIPTION <code>dict</code> <p>Cost breakdown with keys: input_tokens, output_tokens,</p> <p> TYPE: <code>dict[str, float]</code> </p> <code>dict[str, float]</code> <p>input_cost, output_cost, total_cost.</p>"},{"location":"api/tenets/models/llm/#tenets.models.llm.list_supported_models","title":"list_supported_models","text":"Python<pre><code>list_supported_models() -&gt; list[dict[str, object]]\n</code></pre> <p>List known models with provider, limits, and pricing.</p> RETURNS DESCRIPTION <code>list[dict[str, object]]</code> <p>A list of dicts: name, provider, context_tokens, input_price, output_price</p>"},{"location":"api/tenets/models/summary/","title":"Summary","text":""},{"location":"api/tenets/models/summary/#tenets.models.summary","title":"tenets.models.summary","text":"<p>Summary models for file condensation.</p> <p>This module defines data structures for managing file summaries when content needs to be condensed to fit within token limits.</p>"},{"location":"api/tenets/models/summary/#tenets.models.summary-classes","title":"Classes","text":""},{"location":"api/tenets/models/summary/#tenets.models.summary.SummaryStrategy","title":"SummaryStrategy","text":"<p>               Bases: <code>Enum</code></p> <p>Strategies for summarizing files.</p>"},{"location":"api/tenets/models/summary/#tenets.models.summary.SummaryStrategy-functions","title":"Functions","text":""},{"location":"api/tenets/models/summary/#tenets.models.summary.SummaryStrategy.get_default","title":"get_default  <code>classmethod</code>","text":"Python<pre><code>get_default() -&gt; SummaryStrategy\n</code></pre> <p>Get default summarization strategy.</p>"},{"location":"api/tenets/models/summary/#tenets.models.summary.SummaryStrategy.get_priority","title":"get_priority","text":"Python<pre><code>get_priority() -&gt; int\n</code></pre> <p>Get priority for strategy selection.</p>"},{"location":"api/tenets/models/summary/#tenets.models.summary.SummarySection","title":"SummarySection  <code>dataclass</code>","text":"Python<pre><code>SummarySection(name: str, content: str, line_start: int = 0, line_end: int = 0, importance: float = 1.0, preserved_fully: bool = True, tokens: int = 0, metadata: Dict[str, Any] = dict())\n</code></pre> <p>A section within a file summary.</p> <p>Represents a specific section of code that was extracted for inclusion in the summary.</p> ATTRIBUTE DESCRIPTION <code>name</code> <p>Section name (e.g., \"imports\", \"class_definitions\")</p> <p> TYPE: <code>str</code> </p> <code>content</code> <p>Section content</p> <p> TYPE: <code>str</code> </p> <code>line_start</code> <p>Starting line in original file</p> <p> TYPE: <code>int</code> </p> <code>line_end</code> <p>Ending line in original file</p> <p> TYPE: <code>int</code> </p> <code>importance</code> <p>Importance score (0-1)</p> <p> TYPE: <code>float</code> </p> <code>preserved_fully</code> <p>Whether section was preserved in full</p> <p> TYPE: <code>bool</code> </p> <code>tokens</code> <p>Token count for this section</p> <p> TYPE: <code>int</code> </p> <code>metadata</code> <p>Additional section metadata</p> <p> TYPE: <code>Dict[str, Any]</code> </p>"},{"location":"api/tenets/models/summary/#tenets.models.summary.SummarySection-functions","title":"Functions","text":""},{"location":"api/tenets/models/summary/#tenets.models.summary.SummarySection.truncate","title":"truncate","text":"Python<pre><code>truncate(max_tokens: int) -&gt; SummarySection\n</code></pre> <p>Truncate section to fit within token limit.</p>"},{"location":"api/tenets/models/summary/#tenets.models.summary.SummarySection.to_dict","title":"to_dict","text":"Python<pre><code>to_dict() -&gt; Dict[str, Any]\n</code></pre> <p>Convert to dictionary representation.</p>"},{"location":"api/tenets/models/summary/#tenets.models.summary.SummarySection.from_dict","title":"from_dict  <code>classmethod</code>","text":"Python<pre><code>from_dict(data: Dict[str, Any]) -&gt; SummarySection\n</code></pre> <p>Create from dictionary.</p>"},{"location":"api/tenets/models/summary/#tenets.models.summary.FileSummary","title":"FileSummary  <code>dataclass</code>","text":"Python<pre><code>FileSummary(content: str = '', was_summarized: bool = True, original_tokens: int = 0, summary_tokens: int = 0, original_lines: int = 0, summary_lines: int = 0, preserved_sections: List[str] = list(), ignored_sections: List[str] = list(), sections: List[SummarySection] = list(), strategy: str = 'extract', compression_ratio: float = 0.0, instructions: List[str] = list(), metadata: Dict[str, Any] = dict(), file_path: Optional[str] = None, path: Optional[str] = None, summary: Optional[str] = None, token_count: int = 0, timestamp: datetime = datetime.now())\n</code></pre> <p>Summary of a file's content.</p> <p>Represents a condensed version of a file when the full content would exceed token limits. Contains sections, metadata, and instructions for AI assistants.</p> ATTRIBUTE DESCRIPTION <code>content</code> <p>Summarized content</p> <p> TYPE: <code>str</code> </p> <code>was_summarized</code> <p>Whether content was summarized</p> <p> TYPE: <code>bool</code> </p> <code>original_tokens</code> <p>Token count of original</p> <p> TYPE: <code>int</code> </p> <code>summary_tokens</code> <p>Token count of summary</p> <p> TYPE: <code>int</code> </p> <code>original_lines</code> <p>Line count of original</p> <p> TYPE: <code>int</code> </p> <code>summary_lines</code> <p>Line count of summary</p> <p> TYPE: <code>int</code> </p> <code>preserved_sections</code> <p>Sections that were preserved</p> <p> TYPE: <code>List[str]</code> </p> <code>ignored_sections</code> <p>Sections that were omitted</p> <p> TYPE: <code>List[str]</code> </p> <code>sections</code> <p>List of summary sections</p> <p> TYPE: <code>List[SummarySection]</code> </p> <code>strategy</code> <p>Strategy used for summarization</p> <p> TYPE: <code>str</code> </p> <code>compression_ratio</code> <p>Ratio of summary to original</p> <p> TYPE: <code>float</code> </p> <code>instructions</code> <p>Instructions for AI about summary</p> <p> TYPE: <code>List[str]</code> </p> <code>metadata</code> <p>Additional metadata</p> <p> TYPE: <code>Dict[str, Any]</code> </p> <code>file_path</code> <p>Original file path</p> <p> TYPE: <code>Optional[str]</code> </p> <code>timestamp</code> <p>When summary was created</p> <p> TYPE: <code>datetime</code> </p> <code>Compatibility</code> <p> TYPE: <code>fields</code> </p> <code>-</code> <p>legacy alias for file_path</p> <p> TYPE: <code>path</code> </p> <code>-</code> <p>legacy alias for content</p> <p> TYPE: <code>summary</code> </p> <code>-</code> <p>legacy alias for summary_tokens</p> <p> TYPE: <code>token_count</code> </p>"},{"location":"api/tenets/models/summary/#tenets.models.summary.FileSummary-functions","title":"Functions","text":""},{"location":"api/tenets/models/summary/#tenets.models.summary.FileSummary.add_instruction","title":"add_instruction","text":"Python<pre><code>add_instruction(instruction: str) -&gt; None\n</code></pre> <p>Add an instruction for the AI about this summary.</p>"},{"location":"api/tenets/models/summary/#tenets.models.summary.FileSummary.add_default_instructions","title":"add_default_instructions","text":"Python<pre><code>add_default_instructions() -&gt; None\n</code></pre> <p>Add default instructions based on summary characteristics.</p>"},{"location":"api/tenets/models/summary/#tenets.models.summary.FileSummary.add_metadata","title":"add_metadata","text":"Python<pre><code>add_metadata(metadata: Dict[str, Any]) -&gt; None\n</code></pre> <p>Add metadata about the summary.</p>"},{"location":"api/tenets/models/summary/#tenets.models.summary.FileSummary.add_section","title":"add_section","text":"Python<pre><code>add_section(section: SummarySection) -&gt; None\n</code></pre> <p>Add a section to the summary.</p>"},{"location":"api/tenets/models/summary/#tenets.models.summary.FileSummary.get_section","title":"get_section","text":"Python<pre><code>get_section(name: str) -&gt; Optional[SummarySection]\n</code></pre> <p>Get a specific section by name.</p>"},{"location":"api/tenets/models/summary/#tenets.models.summary.FileSummary.merge_sections","title":"merge_sections","text":"Python<pre><code>merge_sections() -&gt; str\n</code></pre> <p>Merge all sections into final content.</p>"},{"location":"api/tenets/models/summary/#tenets.models.summary.FileSummary.to_dict","title":"to_dict","text":"Python<pre><code>to_dict() -&gt; Dict[str, Any]\n</code></pre> <p>Convert to dictionary representation.</p>"},{"location":"api/tenets/models/summary/#tenets.models.summary.FileSummary.from_dict","title":"from_dict  <code>classmethod</code>","text":"Python<pre><code>from_dict(data: Dict[str, Any]) -&gt; FileSummary\n</code></pre> <p>Create from dictionary.</p>"},{"location":"api/tenets/models/summary/#tenets.models.summary.ProjectSummary","title":"ProjectSummary  <code>dataclass</code>","text":"Python<pre><code>ProjectSummary(name: str, description: str = '', structure: Dict[str, Any] = dict(), key_files: List[str] = list(), key_directories: List[str] = list(), technologies: List[str] = list(), frameworks: List[str] = list(), patterns: List[str] = list(), dependencies: List[str] = list(), statistics: Dict[str, Any] = dict(), recent_activity: Dict[str, Any] = dict(), team_info: Dict[str, Any] = dict(), metadata: Dict[str, Any] = dict(), timestamp: datetime = datetime.now())\n</code></pre> <p>Summary of an entire project.</p> <p>High-level summary for initial context or overview, providing a bird's eye view of the project structure and characteristics.</p> ATTRIBUTE DESCRIPTION <code>name</code> <p>Project name</p> <p> TYPE: <code>str</code> </p> <code>description</code> <p>Project description</p> <p> TYPE: <code>str</code> </p> <code>structure</code> <p>Project structure overview</p> <p> TYPE: <code>Dict[str, Any]</code> </p> <code>key_files</code> <p>Most important files</p> <p> TYPE: <code>List[str]</code> </p> <code>key_directories</code> <p>Important directories</p> <p> TYPE: <code>List[str]</code> </p> <code>technologies</code> <p>Technologies used</p> <p> TYPE: <code>List[str]</code> </p> <code>frameworks</code> <p>Frameworks detected</p> <p> TYPE: <code>List[str]</code> </p> <code>patterns</code> <p>Architectural patterns detected</p> <p> TYPE: <code>List[str]</code> </p> <code>dependencies</code> <p>Key dependencies</p> <p> TYPE: <code>List[str]</code> </p> <code>statistics</code> <p>Project statistics</p> <p> TYPE: <code>Dict[str, Any]</code> </p> <code>recent_activity</code> <p>Recent development activity</p> <p> TYPE: <code>Dict[str, Any]</code> </p> <code>team_info</code> <p>Team/contributor information</p> <p> TYPE: <code>Dict[str, Any]</code> </p> <code>metadata</code> <p>Additional metadata</p> <p> TYPE: <code>Dict[str, Any]</code> </p> <code>timestamp</code> <p>When summary was created</p> <p> TYPE: <code>datetime</code> </p>"},{"location":"api/tenets/models/summary/#tenets.models.summary.ProjectSummary-functions","title":"Functions","text":""},{"location":"api/tenets/models/summary/#tenets.models.summary.ProjectSummary.add_technology","title":"add_technology","text":"Python<pre><code>add_technology(tech: str) -&gt; None\n</code></pre> <p>Add a detected technology.</p>"},{"location":"api/tenets/models/summary/#tenets.models.summary.ProjectSummary.add_framework","title":"add_framework","text":"Python<pre><code>add_framework(framework: str) -&gt; None\n</code></pre> <p>Add a detected framework.</p>"},{"location":"api/tenets/models/summary/#tenets.models.summary.ProjectSummary.add_pattern","title":"add_pattern","text":"Python<pre><code>add_pattern(pattern: str) -&gt; None\n</code></pre> <p>Add a detected architectural pattern.</p>"},{"location":"api/tenets/models/summary/#tenets.models.summary.ProjectSummary.update_statistics","title":"update_statistics","text":"Python<pre><code>update_statistics(key: str, value: Any) -&gt; None\n</code></pre> <p>Update a statistic value.</p>"},{"location":"api/tenets/models/summary/#tenets.models.summary.ProjectSummary.to_markdown","title":"to_markdown","text":"Python<pre><code>to_markdown() -&gt; str\n</code></pre> <p>Generate markdown representation of project summary.</p>"},{"location":"api/tenets/models/summary/#tenets.models.summary.ProjectSummary.to_dict","title":"to_dict","text":"Python<pre><code>to_dict() -&gt; Dict[str, Any]\n</code></pre> <p>Convert to dictionary representation.</p>"},{"location":"api/tenets/models/summary/#tenets.models.summary.ProjectSummary.from_dict","title":"from_dict  <code>classmethod</code>","text":"Python<pre><code>from_dict(data: Dict[str, Any]) -&gt; ProjectSummary\n</code></pre> <p>Create from dictionary.</p>"},{"location":"api/tenets/models/tenet/","title":"Tenet","text":""},{"location":"api/tenets/models/tenet/#tenets.models.tenet","title":"tenets.models.tenet","text":"<p>Tenet (guiding principle) data model.</p> <p>This module defines the data structures for tenets - the guiding principles that can be instilled into context to maintain consistency across AI interactions.</p>"},{"location":"api/tenets/models/tenet/#tenets.models.tenet-classes","title":"Classes","text":""},{"location":"api/tenets/models/tenet/#tenets.models.tenet.Priority","title":"Priority","text":"<p>               Bases: <code>Enum</code></p> <p>Tenet priority levels.</p>"},{"location":"api/tenets/models/tenet/#tenets.models.tenet.Priority-attributes","title":"Attributes","text":""},{"location":"api/tenets/models/tenet/#tenets.models.tenet.Priority.weight","title":"weight  <code>property</code>","text":"Python<pre><code>weight: float\n</code></pre> <p>Get numerical weight for priority.</p>"},{"location":"api/tenets/models/tenet/#tenets.models.tenet.TenetStatus","title":"TenetStatus","text":"<p>               Bases: <code>Enum</code></p> <p>Tenet status in the system.</p>"},{"location":"api/tenets/models/tenet/#tenets.models.tenet.TenetCategory","title":"TenetCategory","text":"<p>               Bases: <code>Enum</code></p> <p>Common tenet categories.</p>"},{"location":"api/tenets/models/tenet/#tenets.models.tenet.TenetMetrics","title":"TenetMetrics  <code>dataclass</code>","text":"Python<pre><code>TenetMetrics(injection_count: int = 0, last_injected: Optional[datetime] = None, contexts_appeared_in: int = 0, compliance_score: float = 0.0, reinforcement_needed: bool = False)\n</code></pre> <p>Metrics for tracking tenet effectiveness.</p>"},{"location":"api/tenets/models/tenet/#tenets.models.tenet.TenetMetrics-functions","title":"Functions","text":""},{"location":"api/tenets/models/tenet/#tenets.models.tenet.TenetMetrics.update_injection","title":"update_injection","text":"Python<pre><code>update_injection() -&gt; None\n</code></pre> <p>Update metrics after injection.</p>"},{"location":"api/tenets/models/tenet/#tenets.models.tenet.InjectionStrategy","title":"InjectionStrategy  <code>dataclass</code>","text":"Python<pre><code>InjectionStrategy(frequency: str = 'adaptive', position: str = 'strategic', max_per_context: int = 3, min_tokens_between: int = 1000)\n</code></pre> <p>Strategy for how a tenet should be injected.</p>"},{"location":"api/tenets/models/tenet/#tenets.models.tenet.InjectionStrategy-functions","title":"Functions","text":""},{"location":"api/tenets/models/tenet/#tenets.models.tenet.InjectionStrategy.should_inject","title":"should_inject","text":"Python<pre><code>should_inject(context_length: int, already_injected: int) -&gt; bool\n</code></pre> <p>Determine if tenet should be injected.</p>"},{"location":"api/tenets/models/tenet/#tenets.models.tenet.Tenet","title":"Tenet  <code>dataclass</code>","text":"Python<pre><code>Tenet(id: str = (lambda: str(uuid.uuid4()))(), content: str = '', priority: Priority = Priority.MEDIUM, category: Optional[TenetCategory] = None, status: TenetStatus = TenetStatus.PENDING, created_at: datetime = datetime.now(), instilled_at: Optional[datetime] = None, updated_at: datetime = datetime.now(), session_bindings: list[str] = list(), author: Optional[str] = None, metrics: TenetMetrics = TenetMetrics(), injection_strategy: InjectionStrategy = InjectionStrategy(), metadata: dict[str, Any] = dict())\n</code></pre> <p>A guiding principle for code development.</p> <p>Tenets are persistent instructions that guide AI interactions to maintain consistency across multiple prompts and sessions.</p> ATTRIBUTE DESCRIPTION <code>id</code> <p>Unique identifier</p> <p> TYPE: <code>str</code> </p> <code>content</code> <p>The principle text</p> <p> TYPE: <code>str</code> </p> <code>priority</code> <p>Importance level</p> <p> TYPE: <code>Priority</code> </p> <code>category</code> <p>Classification category</p> <p> TYPE: <code>Optional[TenetCategory]</code> </p> <code>status</code> <p>Current status (pending, instilled, archived)</p> <p> TYPE: <code>TenetStatus</code> </p> <code>created_at</code> <p>When the tenet was created</p> <p> TYPE: <code>datetime</code> </p> <code>instilled_at</code> <p>When first instilled into context</p> <p> TYPE: <code>Optional[datetime]</code> </p> <code>updated_at</code> <p>Last modification time</p> <p> TYPE: <code>datetime</code> </p> <code>session_bindings</code> <p>Sessions this tenet applies to</p> <p> TYPE: <code>list[str]</code> </p> <code>author</code> <p>Who created the tenet</p> <p> TYPE: <code>Optional[str]</code> </p> <code>metrics</code> <p>Usage and effectiveness metrics</p> <p> TYPE: <code>TenetMetrics</code> </p> <code>injection_strategy</code> <p>How this tenet should be injected</p> <p> TYPE: <code>InjectionStrategy</code> </p> <code>metadata</code> <p>Additional custom data</p> <p> TYPE: <code>dict[str, Any]</code> </p> Example <p>tenet = Tenet( ...     content=\"Always use type hints in Python code\", ...     priority=Priority.HIGH, ...     category=TenetCategory.STYLE ... )</p>"},{"location":"api/tenets/models/tenet/#tenets.models.tenet.Tenet-functions","title":"Functions","text":""},{"location":"api/tenets/models/tenet/#tenets.models.tenet.Tenet.instill","title":"instill","text":"Python<pre><code>instill() -&gt; None\n</code></pre> <p>Mark tenet as instilled.</p>"},{"location":"api/tenets/models/tenet/#tenets.models.tenet.Tenet.archive","title":"archive","text":"Python<pre><code>archive() -&gt; None\n</code></pre> <p>Archive this tenet.</p>"},{"location":"api/tenets/models/tenet/#tenets.models.tenet.Tenet.bind_to_session","title":"bind_to_session","text":"Python<pre><code>bind_to_session(session_id: str) -&gt; None\n</code></pre> <p>Bind tenet to a specific session.</p>"},{"location":"api/tenets/models/tenet/#tenets.models.tenet.Tenet.unbind_from_session","title":"unbind_from_session","text":"Python<pre><code>unbind_from_session(session_id: str) -&gt; None\n</code></pre> <p>Remove session binding.</p>"},{"location":"api/tenets/models/tenet/#tenets.models.tenet.Tenet.applies_to_session","title":"applies_to_session","text":"Python<pre><code>applies_to_session(session_id: Optional[str]) -&gt; bool\n</code></pre> <p>Check if tenet applies to a session.</p>"},{"location":"api/tenets/models/tenet/#tenets.models.tenet.Tenet.should_inject","title":"should_inject","text":"Python<pre><code>should_inject(context_length: int, already_injected: int) -&gt; bool\n</code></pre> <p>Determine if this tenet should be injected.</p>"},{"location":"api/tenets/models/tenet/#tenets.models.tenet.Tenet.format_for_injection","title":"format_for_injection","text":"Python<pre><code>format_for_injection() -&gt; str\n</code></pre> <p>Format tenet content for injection into context.</p>"},{"location":"api/tenets/models/tenet/#tenets.models.tenet.Tenet.to_dict","title":"to_dict","text":"Python<pre><code>to_dict() -&gt; dict[str, Any]\n</code></pre> <p>Convert to dictionary representation.</p>"},{"location":"api/tenets/models/tenet/#tenets.models.tenet.Tenet.from_dict","title":"from_dict  <code>classmethod</code>","text":"Python<pre><code>from_dict(data: dict[str, Any]) -&gt; Tenet\n</code></pre> <p>Create Tenet from dictionary.</p>"},{"location":"api/tenets/models/tenet/#tenets.models.tenet.TenetCollection","title":"TenetCollection  <code>dataclass</code>","text":"Python<pre><code>TenetCollection(name: str, description: str = '', tenets: list[Tenet] = list(), created_at: datetime = datetime.now(), tags: list[str] = list())\n</code></pre> <p>A collection of related tenets.</p>"},{"location":"api/tenets/models/tenet/#tenets.models.tenet.TenetCollection-functions","title":"Functions","text":""},{"location":"api/tenets/models/tenet/#tenets.models.tenet.TenetCollection.add_tenet","title":"add_tenet","text":"Python<pre><code>add_tenet(tenet: Tenet) -&gt; None\n</code></pre> <p>Add a tenet to the collection.</p>"},{"location":"api/tenets/models/tenet/#tenets.models.tenet.TenetCollection.remove_tenet","title":"remove_tenet","text":"Python<pre><code>remove_tenet(tenet_id: str) -&gt; bool\n</code></pre> <p>Remove a tenet by ID.</p>"},{"location":"api/tenets/models/tenet/#tenets.models.tenet.TenetCollection.get_by_category","title":"get_by_category","text":"Python<pre><code>get_by_category(category: TenetCategory) -&gt; list[Tenet]\n</code></pre> <p>Get all tenets of a specific category.</p>"},{"location":"api/tenets/models/tenet/#tenets.models.tenet.TenetCollection.get_by_priority","title":"get_by_priority","text":"Python<pre><code>get_by_priority(priority: Priority) -&gt; list[Tenet]\n</code></pre> <p>Get all tenets of a specific priority.</p>"},{"location":"api/tenets/models/tenet/#tenets.models.tenet.TenetCollection.to_dict","title":"to_dict","text":"Python<pre><code>to_dict() -&gt; dict[str, Any]\n</code></pre> <p>Convert to dictionary representation.</p>"},{"location":"api/tenets/storage/cache/","title":"Cache","text":""},{"location":"api/tenets/storage/cache/#tenets.storage.cache","title":"tenets.storage.cache","text":"<p>Caching system for file analysis and other expensive operations.</p> <p>This module provides a multi-level caching system with memory and disk caches to speed up repeated operations.</p>"},{"location":"api/tenets/storage/cache/#tenets.storage.cache-classes","title":"Classes","text":""},{"location":"api/tenets/storage/cache/#tenets.storage.cache.MemoryCache","title":"MemoryCache","text":"Python<pre><code>MemoryCache(max_size: int = 1000)\n</code></pre> <p>In-memory LRU cache for hot data.</p> <p>Initialize memory cache.</p> PARAMETER DESCRIPTION <code>max_size</code> <p>Maximum number of items to cache</p> <p> TYPE: <code>int</code> DEFAULT: <code>1000</code> </p>"},{"location":"api/tenets/storage/cache/#tenets.storage.cache.MemoryCache-functions","title":"Functions","text":""},{"location":"api/tenets/storage/cache/#tenets.storage.cache.MemoryCache.get","title":"get","text":"Python<pre><code>get(key: str) -&gt; Optional[Any]\n</code></pre> <p>Get item from cache.</p>"},{"location":"api/tenets/storage/cache/#tenets.storage.cache.MemoryCache.put","title":"put","text":"Python<pre><code>put(key: str, value: Any) -&gt; None\n</code></pre> <p>Put item in cache.</p>"},{"location":"api/tenets/storage/cache/#tenets.storage.cache.MemoryCache.delete","title":"delete","text":"Python<pre><code>delete(key: str) -&gt; None\n</code></pre> <p>Delete a key from the memory cache if present.</p>"},{"location":"api/tenets/storage/cache/#tenets.storage.cache.MemoryCache.clear","title":"clear","text":"Python<pre><code>clear() -&gt; None\n</code></pre> <p>Clear the cache.</p>"},{"location":"api/tenets/storage/cache/#tenets.storage.cache.DiskCache","title":"DiskCache","text":"Python<pre><code>DiskCache(cache_dir: Path, name: str = 'cache')\n</code></pre> <p>SQLite-based disk cache for persistent storage.</p> <p>Initialize disk cache.</p> PARAMETER DESCRIPTION <code>cache_dir</code> <p>Directory for cache storage</p> <p> TYPE: <code>Path</code> </p> <code>name</code> <p>Cache database name</p> <p> TYPE: <code>str</code> DEFAULT: <code>'cache'</code> </p>"},{"location":"api/tenets/storage/cache/#tenets.storage.cache.DiskCache-functions","title":"Functions","text":""},{"location":"api/tenets/storage/cache/#tenets.storage.cache.DiskCache.get","title":"get","text":"Python<pre><code>get(key: str) -&gt; Optional[Any]\n</code></pre> <p>Get item from cache.</p>"},{"location":"api/tenets/storage/cache/#tenets.storage.cache.DiskCache.put","title":"put","text":"Python<pre><code>put(key: str, value: Any, ttl: Optional[int] = None, metadata: Optional[dict] = None) -&gt; None\n</code></pre> <p>Put item in cache.</p> PARAMETER DESCRIPTION <code>key</code> <p>Cache key</p> <p> TYPE: <code>str</code> </p> <code>value</code> <p>Value to cache</p> <p> TYPE: <code>Any</code> </p> <code>ttl</code> <p>Time to live in seconds</p> <p> TYPE: <code>Optional[int]</code> DEFAULT: <code>None</code> </p> <code>metadata</code> <p>Optional metadata</p> <p> TYPE: <code>Optional[dict]</code> DEFAULT: <code>None</code> </p>"},{"location":"api/tenets/storage/cache/#tenets.storage.cache.DiskCache.delete","title":"delete","text":"Python<pre><code>delete(key: str) -&gt; bool\n</code></pre> <p>Delete item from cache.</p>"},{"location":"api/tenets/storage/cache/#tenets.storage.cache.DiskCache.clear","title":"clear","text":"Python<pre><code>clear() -&gt; None\n</code></pre> <p>Clear all cache entries.</p>"},{"location":"api/tenets/storage/cache/#tenets.storage.cache.DiskCache.cleanup","title":"cleanup","text":"Python<pre><code>cleanup(max_age_days: int = 7, max_size_mb: int = 1000) -&gt; int\n</code></pre> <p>Clean up old or expired entries.</p> PARAMETER DESCRIPTION <code>max_age_days</code> <p>Delete entries older than this</p> <p> TYPE: <code>int</code> DEFAULT: <code>7</code> </p> <code>max_size_mb</code> <p>Target maximum cache size in MB</p> <p> TYPE: <code>int</code> DEFAULT: <code>1000</code> </p> RETURNS DESCRIPTION <code>int</code> <p>Number of entries deleted</p>"},{"location":"api/tenets/storage/cache/#tenets.storage.cache.DiskCache.close","title":"close","text":"Python<pre><code>close() -&gt; None\n</code></pre> <p>Close any open resources (no-op; uses per-call connections).</p>"},{"location":"api/tenets/storage/cache/#tenets.storage.cache.AnalysisCache","title":"AnalysisCache","text":"Python<pre><code>AnalysisCache(cache_dir: Path)\n</code></pre> <p>Specialized cache for file analysis results.</p> <p>Initialize analysis cache.</p> PARAMETER DESCRIPTION <code>cache_dir</code> <p>Directory for cache storage</p> <p> TYPE: <code>Path</code> </p>"},{"location":"api/tenets/storage/cache/#tenets.storage.cache.AnalysisCache-functions","title":"Functions","text":""},{"location":"api/tenets/storage/cache/#tenets.storage.cache.AnalysisCache.get_file_analysis","title":"get_file_analysis","text":"Python<pre><code>get_file_analysis(file_path: Path) -&gt; Optional[FileAnalysis]\n</code></pre> <p>Get cached analysis for a file.</p> PARAMETER DESCRIPTION <code>file_path</code> <p>Path to the file</p> <p> TYPE: <code>Path</code> </p> RETURNS DESCRIPTION <code>Optional[FileAnalysis]</code> <p>Cached FileAnalysis or None</p>"},{"location":"api/tenets/storage/cache/#tenets.storage.cache.AnalysisCache.put_file_analysis","title":"put_file_analysis","text":"Python<pre><code>put_file_analysis(file_path: Path, analysis: FileAnalysis) -&gt; None\n</code></pre> <p>Cache file analysis.</p> PARAMETER DESCRIPTION <code>file_path</code> <p>Path to the file</p> <p> TYPE: <code>Path</code> </p> <code>analysis</code> <p>Analysis to cache</p> <p> TYPE: <code>FileAnalysis</code> </p>"},{"location":"api/tenets/storage/cache/#tenets.storage.cache.AnalysisCache.close","title":"close","text":"Python<pre><code>close() -&gt; None\n</code></pre> <p>Close underlying caches.</p>"},{"location":"api/tenets/storage/cache/#tenets.storage.cache.CacheManager","title":"CacheManager","text":"Python<pre><code>CacheManager(config: TenetsConfig)\n</code></pre> <p>Manages all caching operations.</p> <p>Initialize cache manager.</p> PARAMETER DESCRIPTION <code>config</code> <p>Tenets configuration</p> <p> TYPE: <code>TenetsConfig</code> </p>"},{"location":"api/tenets/storage/cache/#tenets.storage.cache.CacheManager-functions","title":"Functions","text":""},{"location":"api/tenets/storage/cache/#tenets.storage.cache.CacheManager.get_or_compute","title":"get_or_compute","text":"Python<pre><code>get_or_compute(key: str, compute_fn: Callable[[], T], ttl: Optional[int] = None, use_memory: bool = True) -&gt; T\n</code></pre> <p>Get from cache or compute if missing.</p> PARAMETER DESCRIPTION <code>key</code> <p>Cache key</p> <p> TYPE: <code>str</code> </p> <code>compute_fn</code> <p>Function to compute value if not cached</p> <p> TYPE: <code>Callable[[], T]</code> </p> <code>ttl</code> <p>Time to live in seconds</p> <p> TYPE: <code>Optional[int]</code> DEFAULT: <code>None</code> </p> <code>use_memory</code> <p>Whether to use memory cache</p> <p> TYPE: <code>bool</code> DEFAULT: <code>True</code> </p> RETURNS DESCRIPTION <code>T</code> <p>Cached or computed value</p>"},{"location":"api/tenets/storage/cache/#tenets.storage.cache.CacheManager.invalidate","title":"invalidate","text":"Python<pre><code>invalidate(key: str) -&gt; None\n</code></pre> <p>Invalidate cache entry.</p>"},{"location":"api/tenets/storage/cache/#tenets.storage.cache.CacheManager.clear_all","title":"clear_all","text":"Python<pre><code>clear_all() -&gt; None\n</code></pre> <p>Clear all caches.</p>"},{"location":"api/tenets/storage/cache/#tenets.storage.cache.CacheManager.cleanup","title":"cleanup","text":"Python<pre><code>cleanup() -&gt; dict[str, int]\n</code></pre> <p>Clean up old cache entries.</p> RETURNS DESCRIPTION <code>dict[str, int]</code> <p>Statistics about cleanup</p>"},{"location":"api/tenets/storage/cache/#tenets.storage.cache-functions","title":"Functions","text":""},{"location":"api/tenets/storage/session_db/","title":"Session Db","text":""},{"location":"api/tenets/storage/session_db/#tenets.storage.session_db","title":"tenets.storage.session_db","text":"<p>Session storage using SQLite.</p> <p>Persists session metadata and context chunks into the main Tenets DB located in the cache directory resolved by TenetsConfig.</p> <p>This module centralizes all persistence for interactive sessions. It is safe to use in environments where the installed package directory may be read-only (e.g., pip installs) because the SQLite database lives under Tenets' cache directory.</p>"},{"location":"api/tenets/storage/session_db/#tenets.storage.session_db-classes","title":"Classes","text":""},{"location":"api/tenets/storage/session_db/#tenets.storage.session_db.SessionDB","title":"SessionDB","text":"Python<pre><code>SessionDB(config: TenetsConfig)\n</code></pre> <p>SQLite-backed session storage.</p> Manages two tables <ul> <li>sessions(id, name, created_at, metadata)</li> <li>session_context(id, session_id, kind, content, created_at)</li> </ul> <p>class explicitly removes child rows where appropriate.</p>"},{"location":"api/tenets/storage/session_db/#tenets.storage.session_db.SessionDB-functions","title":"Functions","text":""},{"location":"api/tenets/storage/session_db/#tenets.storage.session_db.SessionDB.get_active_session","title":"get_active_session","text":"Python<pre><code>get_active_session() -&gt; Optional[SessionRecord]\n</code></pre> <p>Return the currently active session, if any.</p> <p>Chooses the most recently created active session if multiple are marked active.</p>"},{"location":"api/tenets/storage/session_db/#tenets.storage.session_db.SessionDB.add_context","title":"add_context","text":"Python<pre><code>add_context(session_name: str, kind: str, content: str) -&gt; None\n</code></pre> <p>Append a context artifact to a session.</p> PARAMETER DESCRIPTION <code>session_name</code> <p>Friendly name of the session.</p> <p> TYPE: <code>str</code> </p> <code>kind</code> <p>Type tag for the content (e.g., \"context_result\").</p> <p> TYPE: <code>str</code> </p> <code>content</code> <p>Serialized content (JSON string or text).</p> <p> TYPE: <code>str</code> </p>"},{"location":"api/tenets/storage/session_db/#tenets.storage.session_db.SessionDB.delete_session","title":"delete_session","text":"Python<pre><code>delete_session(name: str, purge_context: bool = True) -&gt; bool\n</code></pre> <p>Delete a session record by name.</p> <p>This removes the session row and, by default, all related entries from <code>session_context</code>.</p> PARAMETER DESCRIPTION <code>name</code> <p>Session name to delete.</p> <p> TYPE: <code>str</code> </p> <code>purge_context</code> <p>When True (default), also remove all associated rows from <code>session_context</code>.</p> <p> TYPE: <code>bool</code> DEFAULT: <code>True</code> </p> RETURNS DESCRIPTION <code>bool</code> <p>True if a session row was deleted; False if no session matched.</p>"},{"location":"api/tenets/storage/session_db/#tenets.storage.session_db.SessionDB.delete_all_sessions","title":"delete_all_sessions","text":"Python<pre><code>delete_all_sessions(purge_context: bool = True) -&gt; int\n</code></pre> <p>Delete all sessions. Returns the number of sessions removed.</p> <p>If purge_context is True, also clears all session_context rows.</p>"},{"location":"api/tenets/storage/session_db/#tenets.storage.session_db.SessionDB.update_session_metadata","title":"update_session_metadata","text":"Python<pre><code>update_session_metadata(name: str, updates: dict[str, Any]) -&gt; bool\n</code></pre> <p>Merge <code>updates</code> into the session's metadata JSON.</p> <p>Returns True if the session exists and was updated.</p>"},{"location":"api/tenets/storage/session_db/#tenets.storage.session_db.SessionDB.set_active","title":"set_active","text":"Python<pre><code>set_active(name: str, active: bool) -&gt; bool\n</code></pre> <p>Mark a session as active/inactive via metadata.</p> <p>When activating a session, all other sessions are marked inactive to guarantee there is at most one active session at a time.</p>"},{"location":"api/tenets/storage/session_db/#tenets.storage.session_db-functions","title":"Functions","text":""},{"location":"api/tenets/storage/sqlite/","title":"Sqlite","text":""},{"location":"api/tenets/storage/sqlite/#tenets.storage.sqlite","title":"tenets.storage.sqlite","text":"<p>SQLite storage utilities for Tenets.</p> <p>This module centralizes SQLite database path resolution, connection management, and pragmas. All persistent storage (sessions, tenets, config state) should use this utility to open connections inside the configured cache directory.</p> <p>By default, the cache directory is resolved by TenetsConfig. Do not write inside the installed package directory. When Tenets is installed via pip, the package location may be read-only; the cache directory will be user- or project-local and writable.</p>"},{"location":"api/tenets/storage/sqlite/#tenets.storage.sqlite-classes","title":"Classes","text":""},{"location":"api/tenets/storage/sqlite/#tenets.storage.sqlite.SQLitePaths","title":"SQLitePaths  <code>dataclass</code>","text":"Python<pre><code>SQLitePaths(root: Path, main_db: Path)\n</code></pre> <p>Resolved paths for SQLite databases.</p> ATTRIBUTE DESCRIPTION <code>root</code> <p>The cache directory root where DB files live.</p> <p> TYPE: <code>Path</code> </p> <code>main_db</code> <p>Path to the main Tenets database file.</p> <p> TYPE: <code>Path</code> </p>"},{"location":"api/tenets/storage/sqlite/#tenets.storage.sqlite.Database","title":"Database","text":"Python<pre><code>Database(config: TenetsConfig)\n</code></pre> <p>SQLite database manager applying Tenets pragmas.</p> <p>Use this to obtain connections to the main Tenets DB file located in the configured cache directory.</p>"},{"location":"api/tenets/storage/sqlite/#tenets.storage.sqlite.Database-functions","title":"Functions","text":""},{"location":"api/tenets/storage/sqlite/#tenets.storage.sqlite.Database.connect","title":"connect","text":"Python<pre><code>connect(db_path: Optional[Path] = None) -&gt; sqlite3.Connection\n</code></pre> <p>Open a SQLite connection with configured PRAGMAs applied.</p> PARAMETER DESCRIPTION <code>db_path</code> <p>Optional custom DB path; defaults to main DB path.</p> <p> TYPE: <code>Optional[Path]</code> DEFAULT: <code>None</code> </p>"},{"location":"api/tenets/storage/sqlite/#tenets.storage.sqlite-functions","title":"Functions","text":""},{"location":"api/tenets/utils/external_sources/","title":"External Sources","text":""},{"location":"api/tenets/utils/external_sources/#tenets.utils.external_sources","title":"tenets.utils.external_sources","text":"<p>External source handlers for various platforms.</p> <p>This module provides handlers for fetching and parsing content from external sources like GitHub, GitLab, JIRA, Linear, Asana, Notion, etc.</p>"},{"location":"api/tenets/utils/external_sources/#tenets.utils.external_sources-classes","title":"Classes","text":""},{"location":"api/tenets/utils/external_sources/#tenets.utils.external_sources.ExternalContent","title":"ExternalContent  <code>dataclass</code>","text":"Python<pre><code>ExternalContent(title: str, body: str, metadata: Dict[str, Any], source_type: str, url: str, cached_at: Optional[datetime] = None, ttl_hours: int = 24)\n</code></pre> <p>Parsed content from an external source.</p>"},{"location":"api/tenets/utils/external_sources/#tenets.utils.external_sources.ExternalSourceHandler","title":"ExternalSourceHandler","text":"Python<pre><code>ExternalSourceHandler(cache_manager: Optional[CacheManager] = None)\n</code></pre> <p>               Bases: <code>ABC</code></p> <p>Base class for external source handlers.</p> <p>Initialize handler with optional cache.</p> PARAMETER DESCRIPTION <code>cache_manager</code> <p>Optional cache manager for caching fetched content</p> <p> TYPE: <code>Optional[CacheManager]</code> DEFAULT: <code>None</code> </p>"},{"location":"api/tenets/utils/external_sources/#tenets.utils.external_sources.ExternalSourceHandler-functions","title":"Functions","text":""},{"location":"api/tenets/utils/external_sources/#tenets.utils.external_sources.ExternalSourceHandler.can_handle","title":"can_handle  <code>abstractmethod</code>","text":"Python<pre><code>can_handle(url: str) -&gt; bool\n</code></pre> <p>Check if this handler can process the given URL.</p>"},{"location":"api/tenets/utils/external_sources/#tenets.utils.external_sources.ExternalSourceHandler.extract_identifier","title":"extract_identifier  <code>abstractmethod</code>","text":"Python<pre><code>extract_identifier(url: str) -&gt; Tuple[str, Dict[str, Any]]\n</code></pre> <p>Extract identifier and metadata from URL.</p> RETURNS DESCRIPTION <code>Tuple[str, Dict[str, Any]]</code> <p>Tuple of (identifier, metadata)</p>"},{"location":"api/tenets/utils/external_sources/#tenets.utils.external_sources.ExternalSourceHandler.fetch_content","title":"fetch_content  <code>abstractmethod</code>","text":"Python<pre><code>fetch_content(url: str, metadata: Dict[str, Any]) -&gt; Optional[ExternalContent]\n</code></pre> <p>Fetch content from the external source.</p>"},{"location":"api/tenets/utils/external_sources/#tenets.utils.external_sources.ExternalSourceHandler.get_cached_content","title":"get_cached_content","text":"Python<pre><code>get_cached_content(url: str) -&gt; Optional[ExternalContent]\n</code></pre> <p>Get cached content if available and valid.</p> PARAMETER DESCRIPTION <code>url</code> <p>URL to check cache for</p> <p> TYPE: <code>str</code> </p> RETURNS DESCRIPTION <code>Optional[ExternalContent]</code> <p>Cached content or None if not cached/expired</p>"},{"location":"api/tenets/utils/external_sources/#tenets.utils.external_sources.ExternalSourceHandler.cache_content","title":"cache_content","text":"Python<pre><code>cache_content(url: str, content: ExternalContent) -&gt; None\n</code></pre> <p>Cache fetched content.</p> PARAMETER DESCRIPTION <code>url</code> <p>URL as cache key</p> <p> TYPE: <code>str</code> </p> <code>content</code> <p>Content to cache</p> <p> TYPE: <code>ExternalContent</code> </p>"},{"location":"api/tenets/utils/external_sources/#tenets.utils.external_sources.ExternalSourceHandler.process","title":"process","text":"Python<pre><code>process(url: str) -&gt; Optional[ExternalContent]\n</code></pre> <p>Process URL with caching support.</p> PARAMETER DESCRIPTION <code>url</code> <p>URL to process</p> <p> TYPE: <code>str</code> </p> RETURNS DESCRIPTION <code>Optional[ExternalContent]</code> <p>External content or None if failed</p>"},{"location":"api/tenets/utils/external_sources/#tenets.utils.external_sources.GitHubHandler","title":"GitHubHandler","text":"Python<pre><code>GitHubHandler(cache_manager: Optional[CacheManager] = None)\n</code></pre> <p>               Bases: <code>ExternalSourceHandler</code></p> <p>Handler for GitHub issues, PRs, discussions, and gists.</p>"},{"location":"api/tenets/utils/external_sources/#tenets.utils.external_sources.GitHubHandler-functions","title":"Functions","text":""},{"location":"api/tenets/utils/external_sources/#tenets.utils.external_sources.GitHubHandler.can_handle","title":"can_handle","text":"Python<pre><code>can_handle(url: str) -&gt; bool\n</code></pre> <p>Check if URL is a GitHub URL.</p>"},{"location":"api/tenets/utils/external_sources/#tenets.utils.external_sources.GitHubHandler.extract_identifier","title":"extract_identifier","text":"Python<pre><code>extract_identifier(url: str) -&gt; Tuple[str, Dict[str, Any]]\n</code></pre> <p>Extract GitHub identifier from URL.</p>"},{"location":"api/tenets/utils/external_sources/#tenets.utils.external_sources.GitHubHandler.fetch_content","title":"fetch_content","text":"Python<pre><code>fetch_content(url: str, metadata: Dict[str, Any]) -&gt; Optional[ExternalContent]\n</code></pre> <p>Fetch content from GitHub API.</p>"},{"location":"api/tenets/utils/external_sources/#tenets.utils.external_sources.GitLabHandler","title":"GitLabHandler","text":"Python<pre><code>GitLabHandler(cache_manager: Optional[CacheManager] = None)\n</code></pre> <p>               Bases: <code>ExternalSourceHandler</code></p> <p>Handler for GitLab issues, MRs, and snippets.</p>"},{"location":"api/tenets/utils/external_sources/#tenets.utils.external_sources.GitLabHandler-functions","title":"Functions","text":""},{"location":"api/tenets/utils/external_sources/#tenets.utils.external_sources.GitLabHandler.can_handle","title":"can_handle","text":"Python<pre><code>can_handle(url: str) -&gt; bool\n</code></pre> <p>Check if URL is a GitLab URL.</p>"},{"location":"api/tenets/utils/external_sources/#tenets.utils.external_sources.GitLabHandler.extract_identifier","title":"extract_identifier","text":"Python<pre><code>extract_identifier(url: str) -&gt; Tuple[str, Dict[str, Any]]\n</code></pre> <p>Extract GitLab identifier from URL.</p>"},{"location":"api/tenets/utils/external_sources/#tenets.utils.external_sources.GitLabHandler.fetch_content","title":"fetch_content","text":"Python<pre><code>fetch_content(url: str, metadata: Dict[str, Any]) -&gt; Optional[ExternalContent]\n</code></pre> <p>Fetch content from GitLab API.</p>"},{"location":"api/tenets/utils/external_sources/#tenets.utils.external_sources.JiraHandler","title":"JiraHandler","text":"Python<pre><code>JiraHandler(cache_manager: Optional[CacheManager] = None)\n</code></pre> <p>               Bases: <code>ExternalSourceHandler</code></p> <p>Handler for JIRA tickets.</p>"},{"location":"api/tenets/utils/external_sources/#tenets.utils.external_sources.JiraHandler-functions","title":"Functions","text":""},{"location":"api/tenets/utils/external_sources/#tenets.utils.external_sources.JiraHandler.can_handle","title":"can_handle","text":"Python<pre><code>can_handle(url: str) -&gt; bool\n</code></pre> <p>Check if URL is a JIRA URL.</p>"},{"location":"api/tenets/utils/external_sources/#tenets.utils.external_sources.JiraHandler.extract_identifier","title":"extract_identifier","text":"Python<pre><code>extract_identifier(url: str) -&gt; Tuple[str, Dict[str, Any]]\n</code></pre> <p>Extract JIRA ticket identifier from URL.</p>"},{"location":"api/tenets/utils/external_sources/#tenets.utils.external_sources.JiraHandler.fetch_content","title":"fetch_content","text":"Python<pre><code>fetch_content(url: str, metadata: Dict[str, Any]) -&gt; Optional[ExternalContent]\n</code></pre> <p>Fetch content from JIRA API.</p>"},{"location":"api/tenets/utils/external_sources/#tenets.utils.external_sources.LinearHandler","title":"LinearHandler","text":"Python<pre><code>LinearHandler(cache_manager: Optional[CacheManager] = None)\n</code></pre> <p>               Bases: <code>ExternalSourceHandler</code></p> <p>Handler for Linear issues.</p>"},{"location":"api/tenets/utils/external_sources/#tenets.utils.external_sources.LinearHandler-functions","title":"Functions","text":""},{"location":"api/tenets/utils/external_sources/#tenets.utils.external_sources.LinearHandler.can_handle","title":"can_handle","text":"Python<pre><code>can_handle(url: str) -&gt; bool\n</code></pre> <p>Check if URL is a Linear URL.</p>"},{"location":"api/tenets/utils/external_sources/#tenets.utils.external_sources.LinearHandler.extract_identifier","title":"extract_identifier","text":"Python<pre><code>extract_identifier(url: str) -&gt; Tuple[str, Dict[str, Any]]\n</code></pre> <p>Extract Linear identifier from URL.</p>"},{"location":"api/tenets/utils/external_sources/#tenets.utils.external_sources.LinearHandler.fetch_content","title":"fetch_content","text":"Python<pre><code>fetch_content(url: str, metadata: Dict[str, Any]) -&gt; Optional[ExternalContent]\n</code></pre> <p>Fetch content from Linear API using GraphQL.</p>"},{"location":"api/tenets/utils/external_sources/#tenets.utils.external_sources.AsanaHandler","title":"AsanaHandler","text":"Python<pre><code>AsanaHandler(cache_manager: Optional[CacheManager] = None)\n</code></pre> <p>               Bases: <code>ExternalSourceHandler</code></p> <p>Handler for Asana tasks.</p>"},{"location":"api/tenets/utils/external_sources/#tenets.utils.external_sources.AsanaHandler-functions","title":"Functions","text":""},{"location":"api/tenets/utils/external_sources/#tenets.utils.external_sources.AsanaHandler.can_handle","title":"can_handle","text":"Python<pre><code>can_handle(url: str) -&gt; bool\n</code></pre> <p>Check if URL is an Asana URL.</p>"},{"location":"api/tenets/utils/external_sources/#tenets.utils.external_sources.AsanaHandler.extract_identifier","title":"extract_identifier","text":"Python<pre><code>extract_identifier(url: str) -&gt; Tuple[str, Dict[str, Any]]\n</code></pre> <p>Extract Asana task identifier from URL.</p>"},{"location":"api/tenets/utils/external_sources/#tenets.utils.external_sources.AsanaHandler.fetch_content","title":"fetch_content","text":"Python<pre><code>fetch_content(url: str, metadata: Dict[str, Any]) -&gt; Optional[ExternalContent]\n</code></pre> <p>Fetch content from Asana API.</p>"},{"location":"api/tenets/utils/external_sources/#tenets.utils.external_sources.NotionHandler","title":"NotionHandler","text":"Python<pre><code>NotionHandler(cache_manager: Optional[CacheManager] = None)\n</code></pre> <p>               Bases: <code>ExternalSourceHandler</code></p> <p>Handler for Notion pages and databases.</p>"},{"location":"api/tenets/utils/external_sources/#tenets.utils.external_sources.NotionHandler-functions","title":"Functions","text":""},{"location":"api/tenets/utils/external_sources/#tenets.utils.external_sources.NotionHandler.can_handle","title":"can_handle","text":"Python<pre><code>can_handle(url: str) -&gt; bool\n</code></pre> <p>Check if URL is a Notion URL.</p>"},{"location":"api/tenets/utils/external_sources/#tenets.utils.external_sources.NotionHandler.extract_identifier","title":"extract_identifier","text":"Python<pre><code>extract_identifier(url: str) -&gt; Tuple[str, Dict[str, Any]]\n</code></pre> <p>Extract Notion page/database identifier from URL.</p>"},{"location":"api/tenets/utils/external_sources/#tenets.utils.external_sources.NotionHandler.fetch_content","title":"fetch_content","text":"Python<pre><code>fetch_content(url: str, metadata: Dict[str, Any]) -&gt; Optional[ExternalContent]\n</code></pre> <p>Fetch content from Notion API.</p>"},{"location":"api/tenets/utils/external_sources/#tenets.utils.external_sources.ExternalSourceManager","title":"ExternalSourceManager","text":"Python<pre><code>ExternalSourceManager(cache_manager: Optional[CacheManager] = None)\n</code></pre> <p>Manages all external source handlers.</p> <p>Initialize with all available handlers.</p> PARAMETER DESCRIPTION <code>cache_manager</code> <p>Optional cache manager for handlers</p> <p> TYPE: <code>Optional[CacheManager]</code> DEFAULT: <code>None</code> </p>"},{"location":"api/tenets/utils/external_sources/#tenets.utils.external_sources.ExternalSourceManager-functions","title":"Functions","text":""},{"location":"api/tenets/utils/external_sources/#tenets.utils.external_sources.ExternalSourceManager.process_url","title":"process_url","text":"Python<pre><code>process_url(url: str) -&gt; Optional[ExternalContent]\n</code></pre> <p>Process a URL with the appropriate handler.</p> PARAMETER DESCRIPTION <code>url</code> <p>URL to process</p> <p> TYPE: <code>str</code> </p> RETURNS DESCRIPTION <code>Optional[ExternalContent]</code> <p>External content or None if no handler can process it</p>"},{"location":"api/tenets/utils/external_sources/#tenets.utils.external_sources.ExternalSourceManager.extract_reference","title":"extract_reference","text":"Python<pre><code>extract_reference(text: str) -&gt; Optional[Tuple[str, str, Dict[str, Any]]]\n</code></pre> <p>Extract external reference from text.</p> PARAMETER DESCRIPTION <code>text</code> <p>Text that may contain a URL</p> <p> TYPE: <code>str</code> </p> RETURNS DESCRIPTION <code>Optional[Tuple[str, str, Dict[str, Any]]]</code> <p>Tuple of (url, identifier, metadata) or None</p>"},{"location":"api/tenets/utils/external_sources/#tenets.utils.external_sources-functions","title":"Functions","text":""},{"location":"api/tenets/utils/logger/","title":"Logger","text":""},{"location":"api/tenets/utils/logger/#tenets.utils.logger","title":"tenets.utils.logger","text":"<p>Logging utilities for Tenets.</p> <p>Provides a single entrypoint <code>get_logger</code> that configures Rich logging once and returns child loggers for modules.</p>"},{"location":"api/tenets/utils/logger/#tenets.utils.logger-functions","title":"Functions","text":""},{"location":"api/tenets/utils/logger/#tenets.utils.logger.get_logger","title":"get_logger","text":"Python<pre><code>get_logger(name: Optional[str] = None, level: Optional[int] = None) -&gt; logging.Logger\n</code></pre> <p>Return a configured logger.</p> Environment variables <ul> <li>TENETS_LOG_LEVEL: DEBUG|INFO|WARNING|ERROR|CRITICAL</li> </ul>"},{"location":"api/tenets/utils/multiprocessing/","title":"Multiprocessing","text":""},{"location":"api/tenets/utils/multiprocessing/#tenets.utils.multiprocessing","title":"tenets.utils.multiprocessing","text":"<p>Multiprocessing utilities for intelligent worker allocation.</p> <p>This module provides utilities for determining optimal worker counts based on system resources while being respectful of user's machine.</p>"},{"location":"api/tenets/utils/multiprocessing/#tenets.utils.multiprocessing-functions","title":"Functions","text":""},{"location":"api/tenets/utils/multiprocessing/#tenets.utils.multiprocessing.get_optimal_workers","title":"get_optimal_workers","text":"Python<pre><code>get_optimal_workers(config_workers: Optional[int] = None, min_workers: int = 1, max_workers: Optional[int] = None, reserve_cores: int = 2, workload_type: str = 'balanced') -&gt; int\n</code></pre> <p>Determine optimal number of workers for multiprocessing.</p> <p>This function intelligently determines worker count by: - Auto-detecting CPU cores - Reserving cores for system/user tasks - Respecting configured limits - Adjusting based on workload type</p> PARAMETER DESCRIPTION <code>config_workers</code> <p>User-configured worker count (None for auto)</p> <p> TYPE: <code>Optional[int]</code> DEFAULT: <code>None</code> </p> <code>min_workers</code> <p>Minimum workers to use</p> <p> TYPE: <code>int</code> DEFAULT: <code>1</code> </p> <code>max_workers</code> <p>Maximum workers allowed (None for no limit)</p> <p> TYPE: <code>Optional[int]</code> DEFAULT: <code>None</code> </p> <code>reserve_cores</code> <p>Number of cores to reserve for system (default: 2)</p> <p> TYPE: <code>int</code> DEFAULT: <code>2</code> </p> <code>workload_type</code> <p>Type of workload - \"light\", \"balanced\", \"heavy\"</p> <p> TYPE: <code>str</code> DEFAULT: <code>'balanced'</code> </p> RETURNS DESCRIPTION <code>int</code> <p>Optimal number of workers to use</p>"},{"location":"api/tenets/utils/multiprocessing/#tenets.utils.multiprocessing.get_scanner_workers","title":"get_scanner_workers","text":"Python<pre><code>get_scanner_workers(config) -&gt; int\n</code></pre> <p>Get optimal worker count for file scanning.</p> <p>File scanning is I/O bound, so we can use more workers.</p>"},{"location":"api/tenets/utils/multiprocessing/#tenets.utils.multiprocessing.get_ranking_workers","title":"get_ranking_workers","text":"Python<pre><code>get_ranking_workers(config) -&gt; int\n</code></pre> <p>Get optimal worker count for ranking.</p> <p>Ranking is CPU bound, so we need to be more conservative.</p>"},{"location":"api/tenets/utils/multiprocessing/#tenets.utils.multiprocessing.get_analysis_workers","title":"get_analysis_workers","text":"Python<pre><code>get_analysis_workers(config) -&gt; int\n</code></pre> <p>Get optimal worker count for code analysis.</p> <p>Code analysis is CPU bound but varies by file size.</p>"},{"location":"api/tenets/utils/multiprocessing/#tenets.utils.multiprocessing.log_worker_info","title":"log_worker_info","text":"Python<pre><code>log_worker_info(logger, component: str, workers: int, cpu_count: Optional[int] = None)\n</code></pre> <p>Log worker configuration information.</p> PARAMETER DESCRIPTION <code>logger</code> <p>Logger instance</p> <p> </p> <code>component</code> <p>Component name (e.g., \"Scanner\", \"Ranker\")</p> <p> TYPE: <code>str</code> </p> <code>workers</code> <p>Number of workers being used</p> <p> TYPE: <code>int</code> </p> <code>cpu_count</code> <p>Total CPU count (will be detected if not provided)</p> <p> TYPE: <code>Optional[int]</code> DEFAULT: <code>None</code> </p>"},{"location":"api/tenets/utils/scanner/","title":"Scanner","text":""},{"location":"api/tenets/utils/scanner/#tenets.utils.scanner","title":"tenets.utils.scanner","text":"<p>File scanning utilities.</p> <p>This module provides functionality for discovering files in a codebase, respecting ignore patterns and filtering rules.</p>"},{"location":"api/tenets/utils/scanner/#tenets.utils.scanner-classes","title":"Classes","text":""},{"location":"api/tenets/utils/scanner/#tenets.utils.scanner.FileScanner","title":"FileScanner","text":"Python<pre><code>FileScanner(config: TenetsConfig)\n</code></pre> <p>Scans directories for files matching criteria.</p> <p>Initialize the scanner.</p> PARAMETER DESCRIPTION <code>config</code> <p>Tenets configuration</p> <p> TYPE: <code>TenetsConfig</code> </p>"},{"location":"api/tenets/utils/scanner/#tenets.utils.scanner.FileScanner-functions","title":"Functions","text":""},{"location":"api/tenets/utils/scanner/#tenets.utils.scanner.FileScanner.scan","title":"scan","text":"Python<pre><code>scan(paths: List[Path], include_patterns: Optional[List[str]] = None, exclude_patterns: Optional[List[str]] = None, follow_symlinks: bool = False, respect_gitignore: bool = True, max_file_size: Optional[int] = None) -&gt; List[Path]\n</code></pre> <p>Scan paths for files matching criteria.</p> PARAMETER DESCRIPTION <code>paths</code> <p>Paths to scan (files or directories)</p> <p> TYPE: <code>List[Path]</code> </p> <code>include_patterns</code> <p>Patterns of files to include (e.g., \"*.py\")</p> <p> TYPE: <code>Optional[List[str]]</code> DEFAULT: <code>None</code> </p> <code>exclude_patterns</code> <p>Additional patterns to exclude</p> <p> TYPE: <code>Optional[List[str]]</code> DEFAULT: <code>None</code> </p> <code>follow_symlinks</code> <p>Whether to follow symbolic links</p> <p> TYPE: <code>bool</code> DEFAULT: <code>False</code> </p> <code>respect_gitignore</code> <p>Whether to respect .gitignore files</p> <p> TYPE: <code>bool</code> DEFAULT: <code>True</code> </p> <code>max_file_size</code> <p>Maximum file size in bytes</p> <p> TYPE: <code>Optional[int]</code> DEFAULT: <code>None</code> </p> RETURNS DESCRIPTION <code>List[Path]</code> <p>List of file paths found</p>"},{"location":"api/tenets/utils/scanner/#tenets.utils.scanner.FileScanner.find_files_by_name","title":"find_files_by_name","text":"Python<pre><code>find_files_by_name(root: Path, name_pattern: str, case_sensitive: bool = False) -&gt; List[Path]\n</code></pre> <p>Find files matching a name pattern.</p> PARAMETER DESCRIPTION <code>root</code> <p>Root directory to search</p> <p> TYPE: <code>Path</code> </p> <code>name_pattern</code> <p>Pattern to match (supports wildcards)</p> <p> TYPE: <code>str</code> </p> <code>case_sensitive</code> <p>Whether to match case-sensitively</p> <p> TYPE: <code>bool</code> DEFAULT: <code>False</code> </p> RETURNS DESCRIPTION <code>List[Path]</code> <p>List of matching file paths</p>"},{"location":"api/tenets/utils/scanner/#tenets.utils.scanner.FileScanner.find_files_by_content","title":"find_files_by_content","text":"Python<pre><code>find_files_by_content(root: Path, content_pattern: str, file_patterns: Optional[List[str]] = None, case_sensitive: bool = False) -&gt; List[Path]\n</code></pre> <p>Find files containing specific content.</p> PARAMETER DESCRIPTION <code>root</code> <p>Root directory to search</p> <p> TYPE: <code>Path</code> </p> <code>content_pattern</code> <p>Text to search for</p> <p> TYPE: <code>str</code> </p> <code>file_patterns</code> <p>File patterns to search in</p> <p> TYPE: <code>Optional[List[str]]</code> DEFAULT: <code>None</code> </p> <code>case_sensitive</code> <p>Whether to match case-sensitively</p> <p> TYPE: <code>bool</code> DEFAULT: <code>False</code> </p> RETURNS DESCRIPTION <code>List[Path]</code> <p>List of files containing the pattern</p>"},{"location":"api/tenets/utils/scanner/#tenets.utils.scanner-functions","title":"Functions","text":""},{"location":"api/tenets/utils/timing/","title":"Timing","text":""},{"location":"api/tenets/utils/timing/#tenets.utils.timing","title":"tenets.utils.timing","text":"<p>Timing utilities for CLI commands with intelligent duration formatting.</p> <p>This module provides comprehensive timing utilities including: - Intelligent duration formatting (\u03bcs, ms, s, m, h) - Decorator for timing functions and methods - Context manager for timing code blocks - Benchmarking utilities - CLI command timers with console output</p> <p>Examples:</p> <p>Using the timing decorator::</p> Text Only<pre><code>from tenets.utils.timing import timed\n\n@timed()\ndef process_files(files):\n    # Function automatically timed\n    return analyze(files)\n\n# With custom options\n@timed(name=\"Analysis\", log_output=True, include_args=True)\ndef analyze_codebase(path, mode=\"fast\"):\n    return results\n</code></pre> <p>Using context manager::</p> Text Only<pre><code>from tenets.utils.timing import timed_operation\n\nwith timed_operation(\"Building context\") as timer:\n    result = build_context()\n    # Access timing: timer.duration\n</code></pre> <p>Direct timing::</p> Text Only<pre><code>from tenets.utils.timing import CommandTimer\n\ntimer = CommandTimer()\ntimer.start(\"Processing...\")\n# ... do work ...\nresult = timer.stop(\"Complete\")\nprint(f\"Took {result.formatted_duration}\")\n</code></pre>"},{"location":"api/tenets/utils/timing/#tenets.utils.timing-classes","title":"Classes","text":""},{"location":"api/tenets/utils/timing/#tenets.utils.timing.TimingResult","title":"TimingResult  <code>dataclass</code>","text":"Python<pre><code>TimingResult(start_time: float, end_time: float, duration: float, formatted_duration: str, start_datetime: datetime, end_datetime: datetime)\n</code></pre> <p>Container for timing information.</p>"},{"location":"api/tenets/utils/timing/#tenets.utils.timing.TimingResult-functions","title":"Functions","text":""},{"location":"api/tenets/utils/timing/#tenets.utils.timing.TimingResult.to_dict","title":"to_dict","text":"Python<pre><code>to_dict() -&gt; Dict[str, Any]\n</code></pre> <p>Convert to dictionary for JSON serialization.</p> RETURNS DESCRIPTION <code>Dict[str, Any]</code> <p>Dictionary with timing data including ISO format timestamps</p>"},{"location":"api/tenets/utils/timing/#tenets.utils.timing.CommandTimer","title":"CommandTimer","text":"Python<pre><code>CommandTimer(console: Optional[Any] = None, quiet: bool = False)\n</code></pre> <p>Timer for CLI commands with formatted output.</p> <p>Initialize command timer.</p> PARAMETER DESCRIPTION <code>console</code> <p>Rich console for output</p> <p> TYPE: <code>Optional[Any]</code> DEFAULT: <code>None</code> </p> <code>quiet</code> <p>If True, suppress timing output</p> <p> TYPE: <code>bool</code> DEFAULT: <code>False</code> </p>"},{"location":"api/tenets/utils/timing/#tenets.utils.timing.CommandTimer-functions","title":"Functions","text":""},{"location":"api/tenets/utils/timing/#tenets.utils.timing.CommandTimer.start","title":"start","text":"Python<pre><code>start(message: Optional[str] = None) -&gt; None\n</code></pre> <p>Start the timer.</p> PARAMETER DESCRIPTION <code>message</code> <p>Optional message to display when starting</p> <p> TYPE: <code>Optional[str]</code> DEFAULT: <code>None</code> </p>"},{"location":"api/tenets/utils/timing/#tenets.utils.timing.CommandTimer.stop","title":"stop","text":"Python<pre><code>stop(message: Optional[str] = None) -&gt; TimingResult\n</code></pre> <p>Stop the timer and return timing information.</p> PARAMETER DESCRIPTION <code>message</code> <p>Optional message to display when stopping</p> <p> TYPE: <code>Optional[str]</code> DEFAULT: <code>None</code> </p> RETURNS DESCRIPTION <code>TimingResult</code> <p>TimingResult with all timing information</p>"},{"location":"api/tenets/utils/timing/#tenets.utils.timing.CommandTimer.display_summary","title":"display_summary","text":"Python<pre><code>display_summary(result: Optional[TimingResult] = None) -&gt; None\n</code></pre> <p>Display a timing summary.</p> PARAMETER DESCRIPTION <code>result</code> <p>TimingResult to display (uses last result if None)</p> <p> TYPE: <code>Optional[TimingResult]</code> DEFAULT: <code>None</code> </p>"},{"location":"api/tenets/utils/timing/#tenets.utils.timing.TimedMixin","title":"TimedMixin","text":"Python<pre><code>TimedMixin(*args, **kwargs)\n</code></pre> <p>Mixin class to add timing capabilities to any class.</p> Example <p>class MyAnalyzer(TimedMixin):     def analyze(self, data):         with self.timed_method(\"analysis\"):             return process(data)</p> Text Only<pre><code>def get_timing_summary(self):\n    return self.format_timing_summary()\n</code></pre> <p>Initialize timing tracking.</p>"},{"location":"api/tenets/utils/timing/#tenets.utils.timing.TimedMixin-functions","title":"Functions","text":""},{"location":"api/tenets/utils/timing/#tenets.utils.timing.TimedMixin.timed_method","title":"timed_method","text":"Python<pre><code>timed_method(name: str, quiet: bool = True)\n</code></pre> <p>Context manager for timing a method.</p> PARAMETER DESCRIPTION <code>name</code> <p>Name of the operation</p> <p> TYPE: <code>str</code> </p> <code>quiet</code> <p>If True, suppress output</p> <p> TYPE: <code>bool</code> DEFAULT: <code>True</code> </p> YIELDS DESCRIPTION <p>CommandTimer instance</p>"},{"location":"api/tenets/utils/timing/#tenets.utils.timing.TimedMixin.get_total_time","title":"get_total_time","text":"Python<pre><code>get_total_time() -&gt; float\n</code></pre> <p>Get total time spent in timed operations.</p> RETURNS DESCRIPTION <code>float</code> <p>Total duration in seconds</p>"},{"location":"api/tenets/utils/timing/#tenets.utils.timing.TimedMixin.get_timing_summary","title":"get_timing_summary","text":"Python<pre><code>get_timing_summary() -&gt; Dict[str, Any]\n</code></pre> <p>Get summary of all timing data.</p> RETURNS DESCRIPTION <code>Dict[str, Any]</code> <p>Dictionary with timing statistics</p>"},{"location":"api/tenets/utils/timing/#tenets.utils.timing.TimedMixin.format_timing_summary","title":"format_timing_summary","text":"Python<pre><code>format_timing_summary() -&gt; str\n</code></pre> <p>Format timing summary as a string.</p> RETURNS DESCRIPTION <code>str</code> <p>Formatted timing summary</p>"},{"location":"api/tenets/utils/timing/#tenets.utils.timing-functions","title":"Functions","text":""},{"location":"api/tenets/utils/timing/#tenets.utils.timing.format_duration","title":"format_duration","text":"Python<pre><code>format_duration(seconds: float) -&gt; str\n</code></pre> <p>Format duration intelligently based on length.</p> PARAMETER DESCRIPTION <code>seconds</code> <p>Duration in seconds</p> <p> TYPE: <code>float</code> </p> RETURNS DESCRIPTION <code>str</code> <p>Formatted string with appropriate units</p> <p>Examples:</p> <p>0.123 -&gt; \"123ms\" 1.5 -&gt; \"1.50s\" 65 -&gt; \"1m 5s\" 3665 -&gt; \"1h 1m 5s\"</p>"},{"location":"api/tenets/utils/timing/#tenets.utils.timing.format_time_range","title":"format_time_range","text":"Python<pre><code>format_time_range(start: datetime, end: datetime) -&gt; str\n</code></pre> <p>Format a time range for display.</p> PARAMETER DESCRIPTION <code>start</code> <p>Start datetime</p> <p> TYPE: <code>datetime</code> </p> <code>end</code> <p>End datetime</p> <p> TYPE: <code>datetime</code> </p> RETURNS DESCRIPTION <code>str</code> <p>Formatted time range string</p> <p>Examples:</p> <p>Same day: \"10:30:45 - 10:31:23\" Different days: \"2024-01-15 10:30:45 - 2024-01-16 08:15:23\"</p>"},{"location":"api/tenets/utils/timing/#tenets.utils.timing.timed_operation","title":"timed_operation","text":"Python<pre><code>timed_operation(name: str, console: Optional[Any] = None, quiet: bool = False, show_summary: bool = False)\n</code></pre> <p>Context manager for timing operations.</p> PARAMETER DESCRIPTION <code>name</code> <p>Name of the operation</p> <p> TYPE: <code>str</code> </p> <code>console</code> <p>Rich console for output</p> <p> TYPE: <code>Optional[Any]</code> DEFAULT: <code>None</code> </p> <code>quiet</code> <p>If True, suppress output</p> <p> TYPE: <code>bool</code> DEFAULT: <code>False</code> </p> <code>show_summary</code> <p>If True, show timing summary at end</p> <p> TYPE: <code>bool</code> DEFAULT: <code>False</code> </p> YIELDS DESCRIPTION <p>CommandTimer instance</p> Example <p>with timed_operation(\"Building context\", console) as timer:     # ... do work ...     pass</p>"},{"location":"api/tenets/utils/timing/#tenets.utils.timing.format_progress_time","title":"format_progress_time","text":"Python<pre><code>format_progress_time(elapsed: float, total: Optional[float] = None) -&gt; str\n</code></pre> <p>Format elapsed time with optional ETA.</p> PARAMETER DESCRIPTION <code>elapsed</code> <p>Elapsed time in seconds</p> <p> TYPE: <code>float</code> </p> <code>total</code> <p>Total expected time (for ETA calculation)</p> <p> TYPE: <code>Optional[float]</code> DEFAULT: <code>None</code> </p> RETURNS DESCRIPTION <code>str</code> <p>Formatted string with elapsed and optional ETA</p>"},{"location":"api/tenets/utils/timing/#tenets.utils.timing.timed","title":"timed","text":"Python<pre><code>timed(name: Optional[str] = None, log_output: bool = False, console: Optional[Any] = None, quiet: bool = False, include_args: bool = False, include_result: bool = False, threshold_ms: Optional[float] = None) -&gt; Callable\n</code></pre> <p>Decorator to time function execution.</p> PARAMETER DESCRIPTION <code>name</code> <p>Custom name for the operation (defaults to function name)</p> <p> TYPE: <code>Optional[str]</code> DEFAULT: <code>None</code> </p> <code>log_output</code> <p>If True, log timing to logger</p> <p> TYPE: <code>bool</code> DEFAULT: <code>False</code> </p> <code>console</code> <p>Rich console for output (creates one if needed and not quiet)</p> <p> TYPE: <code>Optional[Any]</code> DEFAULT: <code>None</code> </p> <code>quiet</code> <p>If True, suppress all output</p> <p> TYPE: <code>bool</code> DEFAULT: <code>False</code> </p> <code>include_args</code> <p>If True, include function arguments in output</p> <p> TYPE: <code>bool</code> DEFAULT: <code>False</code> </p> <code>include_result</code> <p>If True, include return value info in output</p> <p> TYPE: <code>bool</code> DEFAULT: <code>False</code> </p> <code>threshold_ms</code> <p>Only log if duration exceeds this threshold (milliseconds)</p> <p> TYPE: <code>Optional[float]</code> DEFAULT: <code>None</code> </p> RETURNS DESCRIPTION <code>Callable</code> <p>Decorated function that tracks timing</p> <p>Examples:</p> <p>Basic usage::</p> Text Only<pre><code>@timed()\ndef process_data(data):\n    return transform(data)\n</code></pre> <p>With logging::</p> Text Only<pre><code>@timed(log_output=True, threshold_ms=100)\ndef slow_operation():\n    # Only logs if takes &gt; 100ms\n    time.sleep(0.2)\n</code></pre> <p>With arguments::</p> Text Only<pre><code>@timed(include_args=True, include_result=True)\ndef api_call(endpoint, method=\"GET\"):\n    # Logs: \"api_call(endpoint='/users', method='GET') -&gt; 200 (45ms)\"\n    return response\n</code></pre> <p>Class methods::</p> Text Only<pre><code>class Processor:\n    @timed(name=\"Processing\")\n    def process(self, items):\n        return [self.transform(i) for i in items]\n</code></pre> Note <p>The timing information is also attached to the function as <code>func._last_timing</code> for programmatic access.</p>"},{"location":"api/tenets/utils/timing/#tenets.utils.timing.benchmark_operation","title":"benchmark_operation","text":"Python<pre><code>benchmark_operation(func, *args, iterations: int = 1, **kwargs) -&gt; Tuple[Any, TimingResult]\n</code></pre> <p>Benchmark a function execution.</p> PARAMETER DESCRIPTION <code>func</code> <p>Function to benchmark</p> <p> </p> <code>*args</code> <p>Arguments to pass to function</p> <p> DEFAULT: <code>()</code> </p> <code>iterations</code> <p>Number of iterations for averaging</p> <p> TYPE: <code>int</code> DEFAULT: <code>1</code> </p> <code>**kwargs</code> <p>Keyword arguments to pass to function</p> <p> DEFAULT: <code>{}</code> </p> RETURNS DESCRIPTION <code>Tuple[Any, TimingResult]</code> <p>Tuple of (function result, timing result)</p>"},{"location":"api/tenets/utils/tokens/","title":"Tokens","text":""},{"location":"api/tenets/utils/tokens/#tenets.utils.tokens","title":"tenets.utils.tokens","text":"<p>Token utilities.</p> <p>Lightweight helpers for token counting and text chunking used across the project. When available, this module uses the optional <code>tiktoken</code> package for accurate tokenization. If <code>tiktoken</code> is not installed, a conservative heuristic (~4 characters per token) is used instead.</p> <p>Notes: - This module is dependency-light by design. <code>tiktoken</code> is optional. - The fallback heuristic intentionally overestimates in some cases to   keep chunk sizes well under model limits.</p>"},{"location":"api/tenets/utils/tokens/#tenets.utils.tokens-functions","title":"Functions","text":""},{"location":"api/tenets/utils/tokens/#tenets.utils.tokens.count_tokens","title":"count_tokens","text":"Python<pre><code>count_tokens(text: str, model: Optional[str] = None) -&gt; int\n</code></pre> <p>Approximate the number of tokens in a string.</p> <p>Uses <code>tiktoken</code> for accurate counts when available; otherwise falls back to a simple heuristic (~4 characters per token).</p> PARAMETER DESCRIPTION <code>text</code> <p>Input text to tokenize.</p> <p> TYPE: <code>str</code> </p> <code>model</code> <p>Optional model name used to select an appropriate tokenizer (only relevant when <code>tiktoken</code> is available).</p> <p> TYPE: <code>Optional[str]</code> DEFAULT: <code>None</code> </p> RETURNS DESCRIPTION <code>int</code> <p>Approximate number of tokens in <code>text</code>.</p> <p>Examples:</p> Python Console Session<pre><code>&gt;&gt;&gt; count_tokens(\"hello world\") &gt; 0\nTrue\n</code></pre>"},{"location":"api/tenets/utils/tokens/#tenets.utils.tokens.get_model_max_tokens","title":"get_model_max_tokens","text":"Python<pre><code>get_model_max_tokens(model: Optional[str]) -&gt; int\n</code></pre> <p>Return a conservative maximum context size (in tokens) for a model.</p> <p>This is a best-effort mapping that may lag behind provider updates. Values are deliberately conservative to avoid overruns when accounting for prompts, system messages, and tool outputs.</p> PARAMETER DESCRIPTION <code>model</code> <p>Optional model name. If None or unknown, a safe default is used.</p> <p> TYPE: <code>Optional[str]</code> </p> RETURNS DESCRIPTION <code>int</code> <p>Maximum supported tokens for the given model, or a default of 100,000</p> <code>int</code> <p>when the model is unspecified/unknown.</p>"},{"location":"api/tenets/utils/tokens/#tenets.utils.tokens.chunk_text","title":"chunk_text","text":"Python<pre><code>chunk_text(text: str, max_tokens: int, model: Optional[str] = None) -&gt; List[str]\n</code></pre> <p>Split text into chunks whose token counts do not exceed <code>max_tokens</code>.</p> <p>Chunking is line-aware: the input is split on line boundaries and lines are accumulated until the next line would exceed <code>max_tokens</code>. This preserves readability and structure for code or prose.</p> <p>If the text contains no newlines and exceeds the budget, a char-based splitter is used to enforce the limit while preserving content.</p>"},{"location":"api/tenets/viz/base/","title":"Base","text":""},{"location":"api/tenets/viz/base/#tenets.viz.base","title":"tenets.viz.base","text":"<p>Base visualization module providing common functionality.</p> <p>This module provides the base classes and utilities for all visualization components. It includes chart configuration, color management, and common visualization patterns used throughout the viz package.</p>"},{"location":"api/tenets/viz/base/#tenets.viz.base-classes","title":"Classes","text":""},{"location":"api/tenets/viz/base/#tenets.viz.base.ChartType","title":"ChartType","text":"<p>               Bases: <code>Enum</code></p> <p>Supported chart types.</p>"},{"location":"api/tenets/viz/base/#tenets.viz.base.DisplayFormat","title":"DisplayFormat","text":"<p>               Bases: <code>Enum</code></p> <p>Supported display formats.</p>"},{"location":"api/tenets/viz/base/#tenets.viz.base.ChartConfig","title":"ChartConfig  <code>dataclass</code>","text":"Python<pre><code>ChartConfig(type: ChartType, title: str = '', width: int = 800, height: int = 400, colors: Optional[List[str]] = None, theme: str = 'light', interactive: bool = True, show_legend: bool = True, show_grid: bool = True, animation: bool = True, responsive: bool = True, export_options: List[str] = (lambda: ['png', 'svg'])())\n</code></pre> <p>Configuration for chart generation.</p> ATTRIBUTE DESCRIPTION <code>type</code> <p>Type of chart to generate</p> <p> TYPE: <code>ChartType</code> </p> <code>title</code> <p>Chart title</p> <p> TYPE: <code>str</code> </p> <code>width</code> <p>Chart width in pixels</p> <p> TYPE: <code>int</code> </p> <code>height</code> <p>Chart height in pixels</p> <p> TYPE: <code>int</code> </p> <code>colors</code> <p>Custom color palette</p> <p> TYPE: <code>Optional[List[str]]</code> </p> <code>theme</code> <p>Visual theme (light, dark, etc.)</p> <p> TYPE: <code>str</code> </p> <code>interactive</code> <p>Whether chart should be interactive</p> <p> TYPE: <code>bool</code> </p> <code>show_legend</code> <p>Whether to show legend</p> <p> TYPE: <code>bool</code> </p> <code>show_grid</code> <p>Whether to show grid lines</p> <p> TYPE: <code>bool</code> </p> <code>animation</code> <p>Whether to animate chart</p> <p> TYPE: <code>bool</code> </p> <code>responsive</code> <p>Whether chart should be responsive</p> <p> TYPE: <code>bool</code> </p> <code>export_options</code> <p>Export format options</p> <p> TYPE: <code>List[str]</code> </p>"},{"location":"api/tenets/viz/base/#tenets.viz.base.DisplayConfig","title":"DisplayConfig  <code>dataclass</code>","text":"Python<pre><code>DisplayConfig(use_colors: bool = True, use_unicode: bool = True, max_width: int = 120, max_rows: int = 50, truncate: bool = True, show_progress: bool = True, style: str = 'detailed')\n</code></pre> <p>Configuration for terminal display.</p> ATTRIBUTE DESCRIPTION <code>use_colors</code> <p>Whether to use colors in terminal</p> <p> TYPE: <code>bool</code> </p> <code>use_unicode</code> <p>Whether to use unicode characters</p> <p> TYPE: <code>bool</code> </p> <code>max_width</code> <p>Maximum display width</p> <p> TYPE: <code>int</code> </p> <code>max_rows</code> <p>Maximum rows to display</p> <p> TYPE: <code>int</code> </p> <code>truncate</code> <p>Whether to truncate long text</p> <p> TYPE: <code>bool</code> </p> <code>show_progress</code> <p>Whether to show progress indicators</p> <p> TYPE: <code>bool</code> </p> <code>style</code> <p>Display style (compact, detailed, etc.)</p> <p> TYPE: <code>str</code> </p>"},{"location":"api/tenets/viz/base/#tenets.viz.base.ColorPalette","title":"ColorPalette","text":"<p>Color palette management for visualizations.</p> <p>Provides consistent color schemes across all visualizations with support for different themes and accessibility considerations.</p>"},{"location":"api/tenets/viz/base/#tenets.viz.base.ColorPalette-functions","title":"Functions","text":""},{"location":"api/tenets/viz/base/#tenets.viz.base.ColorPalette.get_palette","title":"get_palette  <code>classmethod</code>","text":"Python<pre><code>get_palette(name: str = 'default') -&gt; List[str]\n</code></pre> <p>Get a color palette by name.</p> PARAMETER DESCRIPTION <code>name</code> <p>Palette name (default, monochrome, etc.)</p> <p> TYPE: <code>str</code> DEFAULT: <code>'default'</code> </p> RETURNS DESCRIPTION <code>List[str]</code> <p>List[str]: List of color hex codes</p>"},{"location":"api/tenets/viz/base/#tenets.viz.base.ColorPalette.get_color","title":"get_color  <code>classmethod</code>","text":"Python<pre><code>get_color(value: Any, category: str = 'default') -&gt; str\n</code></pre> <p>Get a color for a specific value.</p> PARAMETER DESCRIPTION <code>value</code> <p>Value to get color for</p> <p> TYPE: <code>Any</code> </p> <code>category</code> <p>Category (severity, health, etc.)</p> <p> TYPE: <code>str</code> DEFAULT: <code>'default'</code> </p> RETURNS DESCRIPTION <code>str</code> <p>Color hex code</p> <p> TYPE: <code>str</code> </p>"},{"location":"api/tenets/viz/base/#tenets.viz.base.ColorPalette.interpolate_color","title":"interpolate_color  <code>classmethod</code>","text":"Python<pre><code>interpolate_color(value: float, min_val: float = 0, max_val: float = 100, start_color: str = '#10b981', end_color: str = '#ef4444') -&gt; str\n</code></pre> <p>Interpolate color based on value.</p> PARAMETER DESCRIPTION <code>value</code> <p>Value to interpolate</p> <p> TYPE: <code>float</code> </p> <code>min_val</code> <p>Minimum value</p> <p> TYPE: <code>float</code> DEFAULT: <code>0</code> </p> <code>max_val</code> <p>Maximum value</p> <p> TYPE: <code>float</code> DEFAULT: <code>100</code> </p> <code>start_color</code> <p>Color for minimum value</p> <p> TYPE: <code>str</code> DEFAULT: <code>'#10b981'</code> </p> <code>end_color</code> <p>Color for maximum value</p> <p> TYPE: <code>str</code> DEFAULT: <code>'#ef4444'</code> </p> RETURNS DESCRIPTION <code>str</code> <p>Interpolated color hex code</p> <p> TYPE: <code>str</code> </p>"},{"location":"api/tenets/viz/base/#tenets.viz.base.BaseVisualizer","title":"BaseVisualizer","text":"Python<pre><code>BaseVisualizer(chart_config: Optional[ChartConfig] = None, display_config: Optional[DisplayConfig] = None)\n</code></pre> <p>Base class for all visualizers.</p> <p>Provides common functionality for creating visualizations including chart generation, color management, and data formatting.</p> ATTRIBUTE DESCRIPTION <code>logger</code> <p>Logger instance</p> <p> </p> <code>chart_config</code> <p>Default chart configuration</p> <p> </p> <code>display_config</code> <p>Default display configuration</p> <p> </p> <code>color_palette</code> <p>Color palette to use</p> <p> </p> <p>Initialize base visualizer.</p> PARAMETER DESCRIPTION <code>chart_config</code> <p>Chart configuration</p> <p> TYPE: <code>Optional[ChartConfig]</code> DEFAULT: <code>None</code> </p> <code>display_config</code> <p>Display configuration</p> <p> TYPE: <code>Optional[DisplayConfig]</code> DEFAULT: <code>None</code> </p>"},{"location":"api/tenets/viz/base/#tenets.viz.base.BaseVisualizer-functions","title":"Functions","text":""},{"location":"api/tenets/viz/base/#tenets.viz.base.BaseVisualizer.create_chart","title":"create_chart","text":"Python<pre><code>create_chart(chart_type: ChartType, data: Dict[str, Any], config: Optional[ChartConfig] = None) -&gt; Dict[str, Any]\n</code></pre> <p>Create a chart configuration.</p> PARAMETER DESCRIPTION <code>chart_type</code> <p>Type of chart</p> <p> TYPE: <code>ChartType</code> </p> <code>data</code> <p>Chart data</p> <p> TYPE: <code>Dict[str, Any]</code> </p> <code>config</code> <p>Optional chart configuration</p> <p> TYPE: <code>Optional[ChartConfig]</code> DEFAULT: <code>None</code> </p> RETURNS DESCRIPTION <code>Dict[str, Any]</code> <p>Dict[str, Any]: Chart configuration for rendering</p>"},{"location":"api/tenets/viz/base/#tenets.viz.base.BaseVisualizer.format_number","title":"format_number","text":"Python<pre><code>format_number(value: Union[int, float], precision: int = 2, use_thousands: bool = True) -&gt; str\n</code></pre> <p>Format a number for display.</p> PARAMETER DESCRIPTION <code>value</code> <p>Number to format</p> <p> TYPE: <code>Union[int, float]</code> </p> <code>precision</code> <p>Decimal precision</p> <p> TYPE: <code>int</code> DEFAULT: <code>2</code> </p> <code>use_thousands</code> <p>Use thousands separator</p> <p> TYPE: <code>bool</code> DEFAULT: <code>True</code> </p> RETURNS DESCRIPTION <code>str</code> <p>Formatted number</p> <p> TYPE: <code>str</code> </p>"},{"location":"api/tenets/viz/base/#tenets.viz.base.BaseVisualizer.format_percentage","title":"format_percentage","text":"Python<pre><code>format_percentage(value: float, precision: int = 1, include_sign: bool = False) -&gt; str\n</code></pre> <p>Format a value as percentage.</p> PARAMETER DESCRIPTION <code>value</code> <p>Value (0-1 or 0-100 depending on context)</p> <p> TYPE: <code>float</code> </p> <code>precision</code> <p>Decimal precision</p> <p> TYPE: <code>int</code> DEFAULT: <code>1</code> </p> <code>include_sign</code> <p>Include + sign for positive values</p> <p> TYPE: <code>bool</code> DEFAULT: <code>False</code> </p> RETURNS DESCRIPTION <code>str</code> <p>Formatted percentage</p> <p> TYPE: <code>str</code> </p>"},{"location":"api/tenets/viz/base/#tenets.viz.base.BaseVisualizer.export_chart","title":"export_chart","text":"Python<pre><code>export_chart(chart_config: Dict[str, Any], output_path: Path, format: str = 'json') -&gt; Path\n</code></pre> <p>Export chart configuration to file.</p> PARAMETER DESCRIPTION <code>chart_config</code> <p>Chart configuration</p> <p> TYPE: <code>Dict[str, Any]</code> </p> <code>output_path</code> <p>Output file path</p> <p> TYPE: <code>Path</code> </p> <code>format</code> <p>Export format (json, html, etc.)</p> <p> TYPE: <code>str</code> DEFAULT: <code>'json'</code> </p> RETURNS DESCRIPTION <code>Path</code> <p>Path to exported file</p> <p> TYPE: <code>Path</code> </p>"},{"location":"api/tenets/viz/base/#tenets.viz.base-functions","title":"Functions","text":""},{"location":"api/tenets/viz/complexity/","title":"Complexity","text":""},{"location":"api/tenets/viz/complexity/#tenets.viz.complexity","title":"tenets.viz.complexity","text":"<p>Complexity visualization module.</p> <p>This module provides visualization capabilities for complexity metrics, including cyclomatic complexity, cognitive complexity, and other complexity-related visualizations.</p>"},{"location":"api/tenets/viz/complexity/#tenets.viz.complexity-classes","title":"Classes","text":""},{"location":"api/tenets/viz/complexity/#tenets.viz.complexity.ComplexityVisualizer","title":"ComplexityVisualizer","text":"Python<pre><code>ComplexityVisualizer(chart_config: Optional[ChartConfig] = None, display_config: Optional[DisplayConfig] = None)\n</code></pre> <p>               Bases: <code>BaseVisualizer</code></p> <p>Visualizer for complexity metrics.</p> <p>Creates visualizations for complexity analysis results including distribution charts, heatmaps, and trend analysis.</p> <p>Initialize complexity visualizer.</p> PARAMETER DESCRIPTION <code>chart_config</code> <p>Chart configuration</p> <p> TYPE: <code>Optional[ChartConfig]</code> DEFAULT: <code>None</code> </p> <code>display_config</code> <p>Display configuration</p> <p> TYPE: <code>Optional[DisplayConfig]</code> DEFAULT: <code>None</code> </p>"},{"location":"api/tenets/viz/complexity/#tenets.viz.complexity.ComplexityVisualizer-functions","title":"Functions","text":""},{"location":"api/tenets/viz/complexity/#tenets.viz.complexity.ComplexityVisualizer.create_distribution_chart","title":"create_distribution_chart","text":"Python<pre><code>create_distribution_chart(complexity_data: Dict[str, Any], chart_type: ChartType = ChartType.BAR) -&gt; Dict[str, Any]\n</code></pre> <p>Create complexity distribution chart.</p> PARAMETER DESCRIPTION <code>complexity_data</code> <p>Complexity analysis data</p> <p> TYPE: <code>Dict[str, Any]</code> </p> <code>chart_type</code> <p>Type of chart to create</p> <p> TYPE: <code>ChartType</code> DEFAULT: <code>BAR</code> </p> RETURNS DESCRIPTION <code>Dict[str, Any]</code> <p>Dict[str, Any]: Chart configuration</p>"},{"location":"api/tenets/viz/complexity/#tenets.viz.complexity.ComplexityVisualizer.create_top_complex_chart","title":"create_top_complex_chart","text":"Python<pre><code>create_top_complex_chart(complex_items: List[Dict[str, Any]], limit: int = 10) -&gt; Dict[str, Any]\n</code></pre> <p>Create chart of top complex items.</p> PARAMETER DESCRIPTION <code>complex_items</code> <p>List of complex items with name and complexity</p> <p> TYPE: <code>List[Dict[str, Any]]</code> </p> <code>limit</code> <p>Maximum items to show</p> <p> TYPE: <code>int</code> DEFAULT: <code>10</code> </p> RETURNS DESCRIPTION <code>Dict[str, Any]</code> <p>Dict[str, Any]: Chart configuration</p>"},{"location":"api/tenets/viz/complexity/#tenets.viz.complexity.ComplexityVisualizer.create_complexity_heatmap","title":"create_complexity_heatmap","text":"Python<pre><code>create_complexity_heatmap(file_complexities: Dict[str, List[int]], max_functions: int = 50) -&gt; Dict[str, Any]\n</code></pre> <p>Create complexity heatmap for files.</p> PARAMETER DESCRIPTION <code>file_complexities</code> <p>Dictionary of file paths to complexity values</p> <p> TYPE: <code>Dict[str, List[int]]</code> </p> <code>max_functions</code> <p>Maximum functions per file to show</p> <p> TYPE: <code>int</code> DEFAULT: <code>50</code> </p> RETURNS DESCRIPTION <code>Dict[str, Any]</code> <p>Dict[str, Any]: Heatmap configuration</p>"},{"location":"api/tenets/viz/complexity/#tenets.viz.complexity.ComplexityVisualizer.create_trend_chart","title":"create_trend_chart","text":"Python<pre><code>create_trend_chart(trend_data: List[Dict[str, Any]]) -&gt; Dict[str, Any]\n</code></pre> <p>Create complexity trend chart over time.</p> PARAMETER DESCRIPTION <code>trend_data</code> <p>List of data points with date and metrics</p> <p> TYPE: <code>List[Dict[str, Any]]</code> </p> RETURNS DESCRIPTION <code>Dict[str, Any]</code> <p>Dict[str, Any]: Line chart configuration</p>"},{"location":"api/tenets/viz/complexity/#tenets.viz.complexity.ComplexityVisualizer.create_comparison_chart","title":"create_comparison_chart","text":"Python<pre><code>create_comparison_chart(current_data: Dict[str, Any], baseline_data: Dict[str, Any]) -&gt; Dict[str, Any]\n</code></pre> <p>Create comparison chart between current and baseline.</p> PARAMETER DESCRIPTION <code>current_data</code> <p>Current complexity metrics</p> <p> TYPE: <code>Dict[str, Any]</code> </p> <code>baseline_data</code> <p>Baseline complexity metrics</p> <p> TYPE: <code>Dict[str, Any]</code> </p> RETURNS DESCRIPTION <code>Dict[str, Any]</code> <p>Dict[str, Any]: Grouped bar chart configuration</p>"},{"location":"api/tenets/viz/complexity/#tenets.viz.complexity.ComplexityVisualizer.display_terminal","title":"display_terminal","text":"Python<pre><code>display_terminal(complexity_data: Dict[str, Any], show_details: bool = True) -&gt; None\n</code></pre> <p>Display complexity analysis in terminal.</p> PARAMETER DESCRIPTION <code>complexity_data</code> <p>Complexity analysis data</p> <p> TYPE: <code>Dict[str, Any]</code> </p> <code>show_details</code> <p>Whether to show detailed breakdown</p> <p> TYPE: <code>bool</code> DEFAULT: <code>True</code> </p>"},{"location":"api/tenets/viz/complexity/#tenets.viz.complexity.ComplexityVisualizer.create_radar_chart","title":"create_radar_chart","text":"Python<pre><code>create_radar_chart(metrics: Dict[str, float]) -&gt; Dict[str, Any]\n</code></pre> <p>Create radar chart for complexity metrics.</p> PARAMETER DESCRIPTION <code>metrics</code> <p>Dictionary of metric names to values</p> <p> TYPE: <code>Dict[str, float]</code> </p> RETURNS DESCRIPTION <code>Dict[str, Any]</code> <p>Dict[str, Any]: Radar chart configuration</p>"},{"location":"api/tenets/viz/contributors/","title":"Contributors","text":""},{"location":"api/tenets/viz/contributors/#tenets.viz.contributors","title":"tenets.viz.contributors","text":"<p>Contributors visualization module.</p> <p>This module provides visualization capabilities for contributor metrics, including contribution distribution, collaboration patterns, and contributor activity visualizations.</p>"},{"location":"api/tenets/viz/contributors/#tenets.viz.contributors-classes","title":"Classes","text":""},{"location":"api/tenets/viz/contributors/#tenets.viz.contributors.ContributorVisualizer","title":"ContributorVisualizer","text":"Python<pre><code>ContributorVisualizer(chart_config: Optional[ChartConfig] = None, display_config: Optional[DisplayConfig] = None)\n</code></pre> <p>               Bases: <code>BaseVisualizer</code></p> <p>Visualizer for contributor metrics.</p> <p>Creates visualizations for contributor analysis including activity charts, collaboration networks, and contribution distributions.</p> <p>Initialize contributor visualizer.</p> PARAMETER DESCRIPTION <code>chart_config</code> <p>Chart configuration</p> <p> TYPE: <code>Optional[ChartConfig]</code> DEFAULT: <code>None</code> </p> <code>display_config</code> <p>Display configuration</p> <p> TYPE: <code>Optional[DisplayConfig]</code> DEFAULT: <code>None</code> </p>"},{"location":"api/tenets/viz/contributors/#tenets.viz.contributors.ContributorVisualizer-functions","title":"Functions","text":""},{"location":"api/tenets/viz/contributors/#tenets.viz.contributors.ContributorVisualizer.create_contribution_chart","title":"create_contribution_chart","text":"Python<pre><code>create_contribution_chart(contributors: List[Dict[str, Any]], metric: str = 'commits', limit: int = 10) -&gt; Dict[str, Any]\n</code></pre> <p>Create contributor contribution chart.</p> PARAMETER DESCRIPTION <code>contributors</code> <p>List of contributor data</p> <p> TYPE: <code>List[Dict[str, Any]]</code> </p> <code>metric</code> <p>Metric to visualize (commits, lines, files)</p> <p> TYPE: <code>str</code> DEFAULT: <code>'commits'</code> </p> <code>limit</code> <p>Maximum contributors to show</p> <p> TYPE: <code>int</code> DEFAULT: <code>10</code> </p> RETURNS DESCRIPTION <code>Dict[str, Any]</code> <p>Dict[str, Any]: Chart configuration</p>"},{"location":"api/tenets/viz/contributors/#tenets.viz.contributors.ContributorVisualizer.create_activity_timeline","title":"create_activity_timeline","text":"Python<pre><code>create_activity_timeline(activity_data: List[Dict[str, Any]], contributor: Optional[str] = None) -&gt; Dict[str, Any]\n</code></pre> <p>Create contributor activity timeline.</p> PARAMETER DESCRIPTION <code>activity_data</code> <p>Activity data points with dates</p> <p> TYPE: <code>List[Dict[str, Any]]</code> </p> <code>contributor</code> <p>Specific contributor to highlight</p> <p> TYPE: <code>Optional[str]</code> DEFAULT: <code>None</code> </p> RETURNS DESCRIPTION <code>Dict[str, Any]</code> <p>Dict[str, Any]: Line chart configuration</p>"},{"location":"api/tenets/viz/contributors/#tenets.viz.contributors.ContributorVisualizer.create_collaboration_network","title":"create_collaboration_network","text":"Python<pre><code>create_collaboration_network(collaboration_data: Dict[Tuple[str, str], int], min_weight: int = 2) -&gt; Dict[str, Any]\n</code></pre> <p>Create collaboration network graph.</p> PARAMETER DESCRIPTION <code>collaboration_data</code> <p>Dictionary of (contributor1, contributor2) -&gt; weight</p> <p> TYPE: <code>Dict[Tuple[str, str], int]</code> </p> <code>min_weight</code> <p>Minimum collaboration weight to include</p> <p> TYPE: <code>int</code> DEFAULT: <code>2</code> </p> RETURNS DESCRIPTION <code>Dict[str, Any]</code> <p>Dict[str, Any]: Network graph configuration</p>"},{"location":"api/tenets/viz/contributors/#tenets.viz.contributors.ContributorVisualizer.create_distribution_pie","title":"create_distribution_pie","text":"Python<pre><code>create_distribution_pie(contributors: List[Dict[str, Any]], metric: str = 'commits', top_n: int = 5) -&gt; Dict[str, Any]\n</code></pre> <p>Create contribution distribution pie chart.</p> PARAMETER DESCRIPTION <code>contributors</code> <p>List of contributor data</p> <p> TYPE: <code>List[Dict[str, Any]]</code> </p> <code>metric</code> <p>Metric to visualize</p> <p> TYPE: <code>str</code> DEFAULT: <code>'commits'</code> </p> <code>top_n</code> <p>Number of top contributors to show individually</p> <p> TYPE: <code>int</code> DEFAULT: <code>5</code> </p> RETURNS DESCRIPTION <code>Dict[str, Any]</code> <p>Dict[str, Any]: Pie chart configuration</p>"},{"location":"api/tenets/viz/contributors/#tenets.viz.contributors.ContributorVisualizer.create_bus_factor_gauge","title":"create_bus_factor_gauge","text":"Python<pre><code>create_bus_factor_gauge(bus_factor: int, total_contributors: int) -&gt; Dict[str, Any]\n</code></pre> <p>Create bus factor gauge chart.</p> PARAMETER DESCRIPTION <code>bus_factor</code> <p>Current bus factor</p> <p> TYPE: <code>int</code> </p> <code>total_contributors</code> <p>Total number of contributors</p> <p> TYPE: <code>int</code> </p> RETURNS DESCRIPTION <code>Dict[str, Any]</code> <p>Dict[str, Any]: Gauge chart configuration</p>"},{"location":"api/tenets/viz/contributors/#tenets.viz.contributors.ContributorVisualizer.display_terminal","title":"display_terminal","text":"Python<pre><code>display_terminal(contributor_data: Dict[str, Any], show_details: bool = True) -&gt; None\n</code></pre> <p>Display contributor analysis in terminal.</p> PARAMETER DESCRIPTION <code>contributor_data</code> <p>Contributor analysis data</p> <p> TYPE: <code>Dict[str, Any]</code> </p> <code>show_details</code> <p>Whether to show detailed breakdown</p> <p> TYPE: <code>bool</code> DEFAULT: <code>True</code> </p>"},{"location":"api/tenets/viz/contributors/#tenets.viz.contributors.ContributorVisualizer.create_retention_chart","title":"create_retention_chart","text":"Python<pre><code>create_retention_chart(retention_data: List[Dict[str, Any]]) -&gt; Dict[str, Any]\n</code></pre> <p>Create contributor retention chart.</p> PARAMETER DESCRIPTION <code>retention_data</code> <p>Retention data over time</p> <p> TYPE: <code>List[Dict[str, Any]]</code> </p> RETURNS DESCRIPTION <code>Dict[str, Any]</code> <p>Dict[str, Any]: Line chart configuration</p>"},{"location":"api/tenets/viz/coupling/","title":"Coupling","text":""},{"location":"api/tenets/viz/coupling/#tenets.viz.coupling","title":"tenets.viz.coupling","text":"<p>Coupling visualization module.</p> <p>This module provides visualization capabilities for code coupling metrics, including afferent/efferent coupling, instability, and coupling networks.</p>"},{"location":"api/tenets/viz/coupling/#tenets.viz.coupling-classes","title":"Classes","text":""},{"location":"api/tenets/viz/coupling/#tenets.viz.coupling.CouplingVisualizer","title":"CouplingVisualizer","text":"Python<pre><code>CouplingVisualizer(chart_config: Optional[ChartConfig] = None, display_config: Optional[DisplayConfig] = None)\n</code></pre> <p>               Bases: <code>BaseVisualizer</code></p> <p>Visualizer for coupling metrics.</p> <p>Creates visualizations for coupling analysis including dependency graphs, coupling matrices, and stability charts.</p> <p>Initialize coupling visualizer.</p> PARAMETER DESCRIPTION <code>chart_config</code> <p>Chart configuration</p> <p> TYPE: <code>Optional[ChartConfig]</code> DEFAULT: <code>None</code> </p> <code>display_config</code> <p>Display configuration</p> <p> TYPE: <code>Optional[DisplayConfig]</code> DEFAULT: <code>None</code> </p>"},{"location":"api/tenets/viz/coupling/#tenets.viz.coupling.CouplingVisualizer-functions","title":"Functions","text":""},{"location":"api/tenets/viz/coupling/#tenets.viz.coupling.CouplingVisualizer.create_coupling_network","title":"create_coupling_network","text":"Python<pre><code>create_coupling_network(coupling_data: Dict[str, Dict[str, int]], min_coupling: int = 1, max_nodes: int = 50) -&gt; Dict[str, Any]\n</code></pre> <p>Create coupling network graph.</p> PARAMETER DESCRIPTION <code>coupling_data</code> <p>Dictionary of module -&gt; {coupled_module: strength}</p> <p> TYPE: <code>Dict[str, Dict[str, int]]</code> </p> <code>min_coupling</code> <p>Minimum coupling strength to show</p> <p> TYPE: <code>int</code> DEFAULT: <code>1</code> </p> <code>max_nodes</code> <p>Maximum nodes to display</p> <p> TYPE: <code>int</code> DEFAULT: <code>50</code> </p> RETURNS DESCRIPTION <code>Dict[str, Any]</code> <p>Dict[str, Any]: Network graph configuration</p>"},{"location":"api/tenets/viz/coupling/#tenets.viz.coupling.CouplingVisualizer.create_coupling_matrix","title":"create_coupling_matrix","text":"Python<pre><code>create_coupling_matrix(modules: List[str], coupling_matrix: List[List[int]]) -&gt; Dict[str, Any]\n</code></pre> <p>Create coupling matrix heatmap.</p> PARAMETER DESCRIPTION <code>modules</code> <p>List of module names</p> <p> TYPE: <code>List[str]</code> </p> <code>coupling_matrix</code> <p>2D matrix of coupling values</p> <p> TYPE: <code>List[List[int]]</code> </p> RETURNS DESCRIPTION <code>Dict[str, Any]</code> <p>Dict[str, Any]: Heatmap configuration</p>"},{"location":"api/tenets/viz/coupling/#tenets.viz.coupling.CouplingVisualizer.create_instability_chart","title":"create_instability_chart","text":"Python<pre><code>create_instability_chart(instability_data: List[Dict[str, Any]], limit: int = 20) -&gt; Dict[str, Any]\n</code></pre> <p>Create instability chart for modules.</p> PARAMETER DESCRIPTION <code>instability_data</code> <p>List of modules with instability metrics</p> <p> TYPE: <code>List[Dict[str, Any]]</code> </p> <code>limit</code> <p>Maximum modules to show</p> <p> TYPE: <code>int</code> DEFAULT: <code>20</code> </p> RETURNS DESCRIPTION <code>Dict[str, Any]</code> <p>Dict[str, Any]: Scatter plot configuration</p>"},{"location":"api/tenets/viz/coupling/#tenets.viz.coupling.CouplingVisualizer.create_coupling_trend","title":"create_coupling_trend","text":"Python<pre><code>create_coupling_trend(trend_data: List[Dict[str, Any]]) -&gt; Dict[str, Any]\n</code></pre> <p>Create coupling trend chart over time.</p> PARAMETER DESCRIPTION <code>trend_data</code> <p>List of data points with date and metrics</p> <p> TYPE: <code>List[Dict[str, Any]]</code> </p> RETURNS DESCRIPTION <code>Dict[str, Any]</code> <p>Dict[str, Any]: Line chart configuration</p>"},{"location":"api/tenets/viz/coupling/#tenets.viz.coupling.CouplingVisualizer.create_dependency_sunburst","title":"create_dependency_sunburst","text":"Python<pre><code>create_dependency_sunburst(hierarchy_data: Dict[str, Any]) -&gt; Dict[str, Any]\n</code></pre> <p>Create dependency sunburst chart.</p> PARAMETER DESCRIPTION <code>hierarchy_data</code> <p>Hierarchical dependency data</p> <p> TYPE: <code>Dict[str, Any]</code> </p> RETURNS DESCRIPTION <code>Dict[str, Any]</code> <p>Dict[str, Any]: Sunburst/treemap configuration</p>"},{"location":"api/tenets/viz/coupling/#tenets.viz.coupling.CouplingVisualizer.display_terminal","title":"display_terminal","text":"Python<pre><code>display_terminal(coupling_data: Dict[str, Any], show_details: bool = True) -&gt; None\n</code></pre> <p>Display coupling analysis in terminal.</p> PARAMETER DESCRIPTION <code>coupling_data</code> <p>Coupling analysis data</p> <p> TYPE: <code>Dict[str, Any]</code> </p> <code>show_details</code> <p>Whether to show detailed breakdown</p> <p> TYPE: <code>bool</code> DEFAULT: <code>True</code> </p>"},{"location":"api/tenets/viz/coupling/#tenets.viz.coupling.CouplingVisualizer.create_afferent_efferent_chart","title":"create_afferent_efferent_chart","text":"Python<pre><code>create_afferent_efferent_chart(modules: List[Dict[str, Any]], limit: int = 15) -&gt; Dict[str, Any]\n</code></pre> <p>Create afferent vs efferent coupling chart.</p> PARAMETER DESCRIPTION <code>modules</code> <p>List of modules with coupling metrics</p> <p> TYPE: <code>List[Dict[str, Any]]</code> </p> <code>limit</code> <p>Maximum modules to show</p> <p> TYPE: <code>int</code> DEFAULT: <code>15</code> </p> RETURNS DESCRIPTION <code>Dict[str, Any]</code> <p>Dict[str, Any]: Grouped bar chart configuration</p>"},{"location":"api/tenets/viz/dependencies/","title":"Dependencies","text":""},{"location":"api/tenets/viz/dependencies/#tenets.viz.dependencies","title":"tenets.viz.dependencies","text":"<p>Dependencies visualization module.</p> <p>This module provides visualization capabilities for dependency analysis, including dependency graphs, circular dependencies, and package structure.</p>"},{"location":"api/tenets/viz/dependencies/#tenets.viz.dependencies-classes","title":"Classes","text":""},{"location":"api/tenets/viz/dependencies/#tenets.viz.dependencies.DependencyVisualizer","title":"DependencyVisualizer","text":"Python<pre><code>DependencyVisualizer(chart_config: Optional[ChartConfig] = None, display_config: Optional[DisplayConfig] = None)\n</code></pre> <p>               Bases: <code>BaseVisualizer</code></p> <p>Visualizer for dependency metrics.</p> <p>Creates visualizations for dependency analysis including dependency trees, circular dependency detection, and package relationships.</p> <p>Initialize dependency visualizer.</p> PARAMETER DESCRIPTION <code>chart_config</code> <p>Chart configuration</p> <p> TYPE: <code>Optional[ChartConfig]</code> DEFAULT: <code>None</code> </p> <code>display_config</code> <p>Display configuration</p> <p> TYPE: <code>Optional[DisplayConfig]</code> DEFAULT: <code>None</code> </p>"},{"location":"api/tenets/viz/dependencies/#tenets.viz.dependencies.DependencyVisualizer-functions","title":"Functions","text":""},{"location":"api/tenets/viz/dependencies/#tenets.viz.dependencies.DependencyVisualizer.create_dependency_graph","title":"create_dependency_graph","text":"Python<pre><code>create_dependency_graph(dependencies: Dict[str, List[str]], highlight_circular: bool = True, max_nodes: int = 100) -&gt; Dict[str, Any]\n</code></pre> <p>Create dependency graph visualization.</p> PARAMETER DESCRIPTION <code>dependencies</code> <p>Dictionary of module -&gt; [dependencies]</p> <p> TYPE: <code>Dict[str, List[str]]</code> </p> <code>highlight_circular</code> <p>Whether to highlight circular dependencies</p> <p> TYPE: <code>bool</code> DEFAULT: <code>True</code> </p> <code>max_nodes</code> <p>Maximum nodes to display</p> <p> TYPE: <code>int</code> DEFAULT: <code>100</code> </p> RETURNS DESCRIPTION <code>Dict[str, Any]</code> <p>Dict[str, Any]: Network graph configuration</p>"},{"location":"api/tenets/viz/dependencies/#tenets.viz.dependencies.DependencyVisualizer.create_dependency_tree","title":"create_dependency_tree","text":"Python<pre><code>create_dependency_tree(tree_data: Dict[str, Any], max_depth: int = 5) -&gt; Dict[str, Any]\n</code></pre> <p>Create dependency tree visualization.</p> PARAMETER DESCRIPTION <code>tree_data</code> <p>Hierarchical dependency data</p> <p> TYPE: <code>Dict[str, Any]</code> </p> <code>max_depth</code> <p>Maximum tree depth to display</p> <p> TYPE: <code>int</code> DEFAULT: <code>5</code> </p> RETURNS DESCRIPTION <code>Dict[str, Any]</code> <p>Dict[str, Any]: Treemap configuration</p>"},{"location":"api/tenets/viz/dependencies/#tenets.viz.dependencies.DependencyVisualizer.create_package_sunburst","title":"create_package_sunburst","text":"Python<pre><code>create_package_sunburst(package_data: Dict[str, Any]) -&gt; Dict[str, Any]\n</code></pre> <p>Create package structure sunburst chart.</p> PARAMETER DESCRIPTION <code>package_data</code> <p>Hierarchical package data</p> <p> TYPE: <code>Dict[str, Any]</code> </p> RETURNS DESCRIPTION <code>Dict[str, Any]</code> <p>Dict[str, Any]: Sunburst/treemap configuration</p>"},{"location":"api/tenets/viz/dependencies/#tenets.viz.dependencies.DependencyVisualizer.create_circular_dependencies_chart","title":"create_circular_dependencies_chart","text":"Python<pre><code>create_circular_dependencies_chart(circular_deps: List[List[str]]) -&gt; Dict[str, Any]\n</code></pre> <p>Create circular dependencies visualization.</p> PARAMETER DESCRIPTION <code>circular_deps</code> <p>List of circular dependency chains</p> <p> TYPE: <code>List[List[str]]</code> </p> RETURNS DESCRIPTION <code>Dict[str, Any]</code> <p>Dict[str, Any]: Network graph configuration</p>"},{"location":"api/tenets/viz/dependencies/#tenets.viz.dependencies.DependencyVisualizer.create_dependency_matrix","title":"create_dependency_matrix","text":"Python<pre><code>create_dependency_matrix(modules: List[str], dependency_matrix: List[List[bool]]) -&gt; Dict[str, Any]\n</code></pre> <p>Create dependency matrix visualization.</p> PARAMETER DESCRIPTION <code>modules</code> <p>List of module names</p> <p> TYPE: <code>List[str]</code> </p> <code>dependency_matrix</code> <p>Boolean matrix of dependencies</p> <p> TYPE: <code>List[List[bool]]</code> </p> RETURNS DESCRIPTION <code>Dict[str, Any]</code> <p>Dict[str, Any]: Heatmap configuration</p>"},{"location":"api/tenets/viz/dependencies/#tenets.viz.dependencies.DependencyVisualizer.create_layer_violations_chart","title":"create_layer_violations_chart","text":"Python<pre><code>create_layer_violations_chart(violations: List[Dict[str, Any]]) -&gt; Dict[str, Any]\n</code></pre> <p>Create layer violation visualization.</p> PARAMETER DESCRIPTION <code>violations</code> <p>List of layer violations</p> <p> TYPE: <code>List[Dict[str, Any]]</code> </p> RETURNS DESCRIPTION <code>Dict[str, Any]</code> <p>Dict[str, Any]: Chart configuration</p>"},{"location":"api/tenets/viz/dependencies/#tenets.viz.dependencies.DependencyVisualizer.display_terminal","title":"display_terminal","text":"Python<pre><code>display_terminal(dependency_data: Dict[str, Any], show_details: bool = True) -&gt; None\n</code></pre> <p>Display dependency analysis in terminal.</p> PARAMETER DESCRIPTION <code>dependency_data</code> <p>Dependency analysis data</p> <p> TYPE: <code>Dict[str, Any]</code> </p> <code>show_details</code> <p>Whether to show detailed breakdown</p> <p> TYPE: <code>bool</code> DEFAULT: <code>True</code> </p>"},{"location":"api/tenets/viz/dependencies/#tenets.viz.dependencies.DependencyVisualizer.create_dependency_trend","title":"create_dependency_trend","text":"Python<pre><code>create_dependency_trend(trend_data: List[Dict[str, Any]]) -&gt; Dict[str, Any]\n</code></pre> <p>Create dependency trend chart over time.</p> PARAMETER DESCRIPTION <code>trend_data</code> <p>List of data points with date and metrics</p> <p> TYPE: <code>List[Dict[str, Any]]</code> </p> RETURNS DESCRIPTION <code>Dict[str, Any]</code> <p>Dict[str, Any]: Line chart configuration</p>"},{"location":"api/tenets/viz/displays/","title":"Displays","text":""},{"location":"api/tenets/viz/displays/#tenets.viz.displays","title":"tenets.viz.displays","text":"<p>Terminal display utilities for CLI visualization.</p> <p>This module provides rich terminal display capabilities including tables, progress bars, charts, and formatted output for CLI commands.</p>"},{"location":"api/tenets/viz/displays/#tenets.viz.displays-classes","title":"Classes","text":""},{"location":"api/tenets/viz/displays/#tenets.viz.displays.TerminalDisplay","title":"TerminalDisplay","text":"Python<pre><code>TerminalDisplay(config: Optional[DisplayConfig] = None)\n</code></pre> <p>Terminal display utilities for rich CLI output.</p> <p>Provides methods for displaying data in the terminal with colors, formatting, and various visualization styles.</p> <p>Initialize terminal display.</p> PARAMETER DESCRIPTION <code>config</code> <p>Display configuration</p> <p> TYPE: <code>Optional[DisplayConfig]</code> DEFAULT: <code>None</code> </p>"},{"location":"api/tenets/viz/displays/#tenets.viz.displays.TerminalDisplay-functions","title":"Functions","text":""},{"location":"api/tenets/viz/displays/#tenets.viz.displays.TerminalDisplay.display_header","title":"display_header","text":"Python<pre><code>display_header(title: str, subtitle: Optional[str] = None, style: str = 'single') -&gt; None\n</code></pre> <p>Display a formatted header.</p> PARAMETER DESCRIPTION <code>title</code> <p>Header title</p> <p> TYPE: <code>str</code> </p> <code>subtitle</code> <p>Optional subtitle</p> <p> TYPE: <code>Optional[str]</code> DEFAULT: <code>None</code> </p> <code>style</code> <p>Border style (single, double, heavy)</p> <p> TYPE: <code>str</code> DEFAULT: <code>'single'</code> </p>"},{"location":"api/tenets/viz/displays/#tenets.viz.displays.TerminalDisplay.display_table","title":"display_table","text":"Python<pre><code>display_table(headers: List[str], rows: List[List[Any]], title: Optional[str] = None, align: Optional[List[str]] = None) -&gt; None\n</code></pre> <p>Display a formatted table.</p> PARAMETER DESCRIPTION <code>headers</code> <p>Table headers</p> <p> TYPE: <code>List[str]</code> </p> <code>rows</code> <p>Table rows</p> <p> TYPE: <code>List[List[Any]]</code> </p> <code>title</code> <p>Optional table title</p> <p> TYPE: <code>Optional[str]</code> DEFAULT: <code>None</code> </p> <code>align</code> <p>Column alignment (left, right, center)</p> <p> TYPE: <code>Optional[List[str]]</code> DEFAULT: <code>None</code> </p>"},{"location":"api/tenets/viz/displays/#tenets.viz.displays.TerminalDisplay.display_metrics","title":"display_metrics","text":"Python<pre><code>display_metrics(metrics: Dict[str, Any], title: Optional[str] = None, columns: int = 2) -&gt; None\n</code></pre> <p>Display metrics in a grid layout.</p> PARAMETER DESCRIPTION <code>metrics</code> <p>Dictionary of metric name to value</p> <p> TYPE: <code>Dict[str, Any]</code> </p> <code>title</code> <p>Optional title</p> <p> TYPE: <code>Optional[str]</code> DEFAULT: <code>None</code> </p> <code>columns</code> <p>Number of columns</p> <p> TYPE: <code>int</code> DEFAULT: <code>2</code> </p>"},{"location":"api/tenets/viz/displays/#tenets.viz.displays.TerminalDisplay.display_distribution","title":"display_distribution","text":"Python<pre><code>display_distribution(distribution: Union[Dict[str, int], List[int]], title: Optional[str] = None, labels: Optional[List[str]] = None, char: str = '\u2588') -&gt; None\n</code></pre> <p>Display distribution as horizontal bar chart.</p> PARAMETER DESCRIPTION <code>distribution</code> <p>Distribution data</p> <p> TYPE: <code>Union[Dict[str, int], List[int]]</code> </p> <code>title</code> <p>Optional title</p> <p> TYPE: <code>Optional[str]</code> DEFAULT: <code>None</code> </p> <code>labels</code> <p>Labels for values if distribution is a list</p> <p> TYPE: <code>Optional[List[str]]</code> DEFAULT: <code>None</code> </p> <code>char</code> <p>Character to use for bars</p> <p> TYPE: <code>str</code> DEFAULT: <code>'\u2588'</code> </p>"},{"location":"api/tenets/viz/displays/#tenets.viz.displays.TerminalDisplay.display_list","title":"display_list","text":"Python<pre><code>display_list(items: List[str], title: Optional[str] = None, style: str = 'bullet') -&gt; None\n</code></pre> <p>Display a formatted list.</p> PARAMETER DESCRIPTION <code>items</code> <p>List items</p> <p> TYPE: <code>List[str]</code> </p> <code>title</code> <p>Optional title</p> <p> TYPE: <code>Optional[str]</code> DEFAULT: <code>None</code> </p> <code>style</code> <p>List style (bullet, numbered, checkbox)</p> <p> TYPE: <code>str</code> DEFAULT: <code>'bullet'</code> </p>"},{"location":"api/tenets/viz/displays/#tenets.viz.displays.TerminalDisplay.create_progress_bar","title":"create_progress_bar","text":"Python<pre><code>create_progress_bar(current: float, total: float, width: int = 30, show_percentage: bool = True) -&gt; str\n</code></pre> <p>Create a progress bar string.</p> PARAMETER DESCRIPTION <code>current</code> <p>Current value</p> <p> TYPE: <code>float</code> </p> <code>total</code> <p>Total value</p> <p> TYPE: <code>float</code> </p> <code>width</code> <p>Bar width</p> <p> TYPE: <code>int</code> DEFAULT: <code>30</code> </p> <code>show_percentage</code> <p>Whether to show percentage</p> <p> TYPE: <code>bool</code> DEFAULT: <code>True</code> </p> RETURNS DESCRIPTION <code>str</code> <p>Progress bar string</p> <p> TYPE: <code>str</code> </p>"},{"location":"api/tenets/viz/displays/#tenets.viz.displays.TerminalDisplay.display_warning","title":"display_warning","text":"Python<pre><code>display_warning(message: str) -&gt; None\n</code></pre> <p>Display a warning message.</p> PARAMETER DESCRIPTION <code>message</code> <p>Warning message</p> <p> TYPE: <code>str</code> </p>"},{"location":"api/tenets/viz/displays/#tenets.viz.displays.TerminalDisplay.display_error","title":"display_error","text":"Python<pre><code>display_error(message: str) -&gt; None\n</code></pre> <p>Display an error message.</p> PARAMETER DESCRIPTION <code>message</code> <p>Error message</p> <p> TYPE: <code>str</code> </p>"},{"location":"api/tenets/viz/displays/#tenets.viz.displays.TerminalDisplay.display_success","title":"display_success","text":"Python<pre><code>display_success(message: str) -&gt; None\n</code></pre> <p>Display a success message.</p> PARAMETER DESCRIPTION <code>message</code> <p>Success message</p> <p> TYPE: <code>str</code> </p>"},{"location":"api/tenets/viz/displays/#tenets.viz.displays.TerminalDisplay.colorize","title":"colorize","text":"Python<pre><code>colorize(text: str, color: str) -&gt; str\n</code></pre> <p>Add color to text.</p> PARAMETER DESCRIPTION <code>text</code> <p>Text to colorize</p> <p> TYPE: <code>str</code> </p> <code>color</code> <p>Color name or style</p> <p> TYPE: <code>str</code> </p> RETURNS DESCRIPTION <code>str</code> <p>Colored text</p> <p> TYPE: <code>str</code> </p>"},{"location":"api/tenets/viz/displays/#tenets.viz.displays.ProgressDisplay","title":"ProgressDisplay","text":"Python<pre><code>ProgressDisplay()\n</code></pre> <p>Progress indicator for long-running operations.</p> <p>Provides spinner and progress bar functionality for CLI operations.</p> <p>Initialize progress display.</p>"},{"location":"api/tenets/viz/displays/#tenets.viz.displays.ProgressDisplay-functions","title":"Functions","text":""},{"location":"api/tenets/viz/displays/#tenets.viz.displays.ProgressDisplay.spinner","title":"spinner","text":"Python<pre><code>spinner(message: str = 'Processing') -&gt; str\n</code></pre> <p>Get next spinner frame.</p> PARAMETER DESCRIPTION <code>message</code> <p>Message to display</p> <p> TYPE: <code>str</code> DEFAULT: <code>'Processing'</code> </p> RETURNS DESCRIPTION <code>str</code> <p>Spinner frame with message</p> <p> TYPE: <code>str</code> </p>"},{"location":"api/tenets/viz/displays/#tenets.viz.displays.ProgressDisplay.update_progress","title":"update_progress","text":"Python<pre><code>update_progress(current: int, total: int, message: str = 'Progress') -&gt; str\n</code></pre> <p>Update progress display.</p> PARAMETER DESCRIPTION <code>current</code> <p>Current item</p> <p> TYPE: <code>int</code> </p> <code>total</code> <p>Total items</p> <p> TYPE: <code>int</code> </p> <code>message</code> <p>Progress message</p> <p> TYPE: <code>str</code> DEFAULT: <code>'Progress'</code> </p> RETURNS DESCRIPTION <code>str</code> <p>Progress string</p> <p> TYPE: <code>str</code> </p>"},{"location":"api/tenets/viz/graph_generator/","title":"Graph Generator","text":""},{"location":"api/tenets/viz/graph_generator/#tenets.viz.graph_generator","title":"tenets.viz.graph_generator","text":"<p>Graph generation for dependency visualization.</p> <p>Pure-Python backends (pip-installable) are preferred: - Plotly + Kaleido for static/interactive graphs - NetworkX + Matplotlib as a fallback - Graphviz only if available (requires system binaries) - DOT/HTML text fallback otherwise</p>"},{"location":"api/tenets/viz/graph_generator/#tenets.viz.graph_generator-classes","title":"Classes","text":""},{"location":"api/tenets/viz/graph_generator/#tenets.viz.graph_generator.GraphGenerator","title":"GraphGenerator","text":"Python<pre><code>GraphGenerator()\n</code></pre> <p>Generates various graph visualizations for dependencies.</p>"},{"location":"api/tenets/viz/graph_generator/#tenets.viz.graph_generator.GraphGenerator-functions","title":"Functions","text":""},{"location":"api/tenets/viz/graph_generator/#tenets.viz.graph_generator.GraphGenerator.generate_graph","title":"generate_graph","text":"Python<pre><code>generate_graph(dependency_graph: Dict[str, List[str]], output_path: Optional[Path] = None, format: str = 'svg', layout: str = 'hierarchical', cluster_by: Optional[str] = None, max_nodes: Optional[int] = None, project_info: Optional[Dict[str, Any]] = None) -&gt; str\n</code></pre> <p>Generate a dependency graph visualization.</p> PARAMETER DESCRIPTION <code>dependency_graph</code> <p>node -&gt; list of dependencies</p> <p> TYPE: <code>Dict[str, List[str]]</code> </p> <code>output_path</code> <p>where to save; if None, return string content</p> <p> TYPE: <code>Optional[Path]</code> DEFAULT: <code>None</code> </p> <code>format</code> <p>svg, png, pdf, html, json, dot</p> <p> TYPE: <code>str</code> DEFAULT: <code>'svg'</code> </p> <code>layout</code> <p>layout hint (hierarchical, circular, shell, kamada)</p> <p> TYPE: <code>str</code> DEFAULT: <code>'hierarchical'</code> </p> <code>cluster_by</code> <p>module, directory, package</p> <p> TYPE: <code>Optional[str]</code> DEFAULT: <code>None</code> </p> <code>max_nodes</code> <p>optional cap on number of nodes</p> <p> TYPE: <code>Optional[int]</code> DEFAULT: <code>None</code> </p> <code>project_info</code> <p>optional project metadata</p> <p> TYPE: <code>Optional[Dict[str, Any]]</code> DEFAULT: <code>None</code> </p>"},{"location":"api/tenets/viz/graph_generator/#tenets.viz.graph_generator-functions","title":"Functions","text":""},{"location":"api/tenets/viz/hotspots/","title":"Hotspots","text":""},{"location":"api/tenets/viz/hotspots/#tenets.viz.hotspots","title":"tenets.viz.hotspots","text":"<p>Hotspot visualization module.</p> <p>This module provides visualization capabilities for code hotspots, including change frequency, complexity hotspots, and risk areas.</p>"},{"location":"api/tenets/viz/hotspots/#tenets.viz.hotspots-classes","title":"Classes","text":""},{"location":"api/tenets/viz/hotspots/#tenets.viz.hotspots.HotspotVisualizer","title":"HotspotVisualizer","text":"Python<pre><code>HotspotVisualizer(chart_config: Optional[ChartConfig] = None, display_config: Optional[DisplayConfig] = None)\n</code></pre> <p>               Bases: <code>BaseVisualizer</code></p> <p>Visualizer for code hotspots.</p> <p>Creates visualizations for hotspot analysis including heatmaps, bubble charts, and risk matrices.</p> <p>Initialize hotspot visualizer.</p> PARAMETER DESCRIPTION <code>chart_config</code> <p>Chart configuration</p> <p> TYPE: <code>Optional[ChartConfig]</code> DEFAULT: <code>None</code> </p> <code>display_config</code> <p>Display configuration</p> <p> TYPE: <code>Optional[DisplayConfig]</code> DEFAULT: <code>None</code> </p>"},{"location":"api/tenets/viz/hotspots/#tenets.viz.hotspots.HotspotVisualizer-functions","title":"Functions","text":""},{"location":"api/tenets/viz/hotspots/#tenets.viz.hotspots.HotspotVisualizer.create_hotspot_heatmap","title":"create_hotspot_heatmap","text":"Python<pre><code>create_hotspot_heatmap(hotspot_data: List[Dict[str, Any]], metric_x: str = 'change_frequency', metric_y: str = 'complexity') -&gt; Dict[str, Any]\n</code></pre> <p>Create hotspot heatmap.</p> PARAMETER DESCRIPTION <code>hotspot_data</code> <p>List of files with hotspot metrics</p> <p> TYPE: <code>List[Dict[str, Any]]</code> </p> <code>metric_x</code> <p>X-axis metric</p> <p> TYPE: <code>str</code> DEFAULT: <code>'change_frequency'</code> </p> <code>metric_y</code> <p>Y-axis metric</p> <p> TYPE: <code>str</code> DEFAULT: <code>'complexity'</code> </p> RETURNS DESCRIPTION <code>Dict[str, Any]</code> <p>Dict[str, Any]: Heatmap configuration</p>"},{"location":"api/tenets/viz/hotspots/#tenets.viz.hotspots.HotspotVisualizer.create_hotspot_bubble","title":"create_hotspot_bubble","text":"Python<pre><code>create_hotspot_bubble(hotspot_data: List[Dict[str, Any]], limit: int = 50) -&gt; Dict[str, Any]\n</code></pre> <p>Create hotspot bubble chart.</p> PARAMETER DESCRIPTION <code>hotspot_data</code> <p>List of files with hotspot metrics</p> <p> TYPE: <code>List[Dict[str, Any]]</code> </p> <code>limit</code> <p>Maximum bubbles to show</p> <p> TYPE: <code>int</code> DEFAULT: <code>50</code> </p> RETURNS DESCRIPTION <code>Dict[str, Any]</code> <p>Dict[str, Any]: Bubble chart configuration</p>"},{"location":"api/tenets/viz/hotspots/#tenets.viz.hotspots.HotspotVisualizer.create_risk_matrix","title":"create_risk_matrix","text":"Python<pre><code>create_risk_matrix(hotspot_data: List[Dict[str, Any]]) -&gt; Dict[str, Any]\n</code></pre> <p>Create risk matrix visualization.</p> PARAMETER DESCRIPTION <code>hotspot_data</code> <p>List of files with risk metrics</p> <p> TYPE: <code>List[Dict[str, Any]]</code> </p> RETURNS DESCRIPTION <code>Dict[str, Any]</code> <p>Dict[str, Any]: Scatter plot as risk matrix</p>"},{"location":"api/tenets/viz/hotspots/#tenets.viz.hotspots.HotspotVisualizer.create_hotspot_trend","title":"create_hotspot_trend","text":"Python<pre><code>create_hotspot_trend(trend_data: List[Dict[str, Any]]) -&gt; Dict[str, Any]\n</code></pre> <p>Create hotspot trend chart over time.</p> PARAMETER DESCRIPTION <code>trend_data</code> <p>List of data points with date and metrics</p> <p> TYPE: <code>List[Dict[str, Any]]</code> </p> RETURNS DESCRIPTION <code>Dict[str, Any]</code> <p>Dict[str, Any]: Line chart configuration</p>"},{"location":"api/tenets/viz/hotspots/#tenets.viz.hotspots.HotspotVisualizer.create_file_activity_chart","title":"create_file_activity_chart","text":"Python<pre><code>create_file_activity_chart(activity_data: List[Dict[str, Any]], limit: int = 20) -&gt; Dict[str, Any]\n</code></pre> <p>Create file activity chart.</p> PARAMETER DESCRIPTION <code>activity_data</code> <p>File activity data</p> <p> TYPE: <code>List[Dict[str, Any]]</code> </p> <code>limit</code> <p>Maximum files to show</p> <p> TYPE: <code>int</code> DEFAULT: <code>20</code> </p> RETURNS DESCRIPTION <code>Dict[str, Any]</code> <p>Dict[str, Any]: Stacked bar chart configuration</p>"},{"location":"api/tenets/viz/hotspots/#tenets.viz.hotspots.HotspotVisualizer.display_terminal","title":"display_terminal","text":"Python<pre><code>display_terminal(hotspot_data: Dict[str, Any], show_details: bool = True) -&gt; None\n</code></pre> <p>Display hotspot analysis in terminal.</p> PARAMETER DESCRIPTION <code>hotspot_data</code> <p>Hotspot analysis data</p> <p> TYPE: <code>Dict[str, Any]</code> </p> <code>show_details</code> <p>Whether to show detailed breakdown</p> <p> TYPE: <code>bool</code> DEFAULT: <code>True</code> </p>"},{"location":"api/tenets/viz/momentum/","title":"Momentum","text":""},{"location":"api/tenets/viz/momentum/#tenets.viz.momentum","title":"tenets.viz.momentum","text":"<p>Momentum visualization module.</p> <p>This module provides visualization capabilities for development momentum and velocity metrics, including burndown charts, velocity trends, and sprint analytics.</p>"},{"location":"api/tenets/viz/momentum/#tenets.viz.momentum-classes","title":"Classes","text":""},{"location":"api/tenets/viz/momentum/#tenets.viz.momentum.MomentumVisualizer","title":"MomentumVisualizer","text":"Python<pre><code>MomentumVisualizer(chart_config: Optional[ChartConfig] = None, display_config: Optional[DisplayConfig] = None)\n</code></pre> <p>               Bases: <code>BaseVisualizer</code></p> <p>Visualizer for momentum and velocity metrics.</p> <p>Creates visualizations for development velocity, sprint progress, and team momentum analytics.</p> <p>Initialize momentum visualizer.</p> PARAMETER DESCRIPTION <code>chart_config</code> <p>Chart configuration</p> <p> TYPE: <code>Optional[ChartConfig]</code> DEFAULT: <code>None</code> </p> <code>display_config</code> <p>Display configuration</p> <p> TYPE: <code>Optional[DisplayConfig]</code> DEFAULT: <code>None</code> </p>"},{"location":"api/tenets/viz/momentum/#tenets.viz.momentum.MomentumVisualizer-functions","title":"Functions","text":""},{"location":"api/tenets/viz/momentum/#tenets.viz.momentum.MomentumVisualizer.create_velocity_chart","title":"create_velocity_chart","text":"Python<pre><code>create_velocity_chart(velocity_data: List[Dict[str, Any]], show_trend: bool = True) -&gt; Dict[str, Any]\n</code></pre> <p>Create velocity trend chart.</p> PARAMETER DESCRIPTION <code>velocity_data</code> <p>List of velocity data points</p> <p> TYPE: <code>List[Dict[str, Any]]</code> </p> <code>show_trend</code> <p>Whether to show trend line</p> <p> TYPE: <code>bool</code> DEFAULT: <code>True</code> </p> RETURNS DESCRIPTION <code>Dict[str, Any]</code> <p>Dict[str, Any]: Line chart configuration</p>"},{"location":"api/tenets/viz/momentum/#tenets.viz.momentum.MomentumVisualizer.create_burndown_chart","title":"create_burndown_chart","text":"Python<pre><code>create_burndown_chart(burndown_data: Dict[str, Any]) -&gt; Dict[str, Any]\n</code></pre> <p>Create sprint burndown chart.</p> PARAMETER DESCRIPTION <code>burndown_data</code> <p>Burndown data with ideal and actual lines</p> <p> TYPE: <code>Dict[str, Any]</code> </p> RETURNS DESCRIPTION <code>Dict[str, Any]</code> <p>Dict[str, Any]: Line chart configuration</p>"},{"location":"api/tenets/viz/momentum/#tenets.viz.momentum.MomentumVisualizer.create_sprint_comparison","title":"create_sprint_comparison","text":"Python<pre><code>create_sprint_comparison(sprint_data: List[Dict[str, Any]]) -&gt; Dict[str, Any]\n</code></pre> <p>Create sprint comparison chart.</p> PARAMETER DESCRIPTION <code>sprint_data</code> <p>List of sprint metrics</p> <p> TYPE: <code>List[Dict[str, Any]]</code> </p> RETURNS DESCRIPTION <code>Dict[str, Any]</code> <p>Dict[str, Any]: Grouped bar chart configuration</p>"},{"location":"api/tenets/viz/momentum/#tenets.viz.momentum.MomentumVisualizer.create_team_velocity_radar","title":"create_team_velocity_radar","text":"Python<pre><code>create_team_velocity_radar(team_metrics: Dict[str, float]) -&gt; Dict[str, Any]\n</code></pre> <p>Create team velocity radar chart.</p> PARAMETER DESCRIPTION <code>team_metrics</code> <p>Dictionary of metric name to value</p> <p> TYPE: <code>Dict[str, float]</code> </p> RETURNS DESCRIPTION <code>Dict[str, Any]</code> <p>Dict[str, Any]: Radar chart configuration</p>"},{"location":"api/tenets/viz/momentum/#tenets.viz.momentum.MomentumVisualizer.create_cumulative_flow","title":"create_cumulative_flow","text":"Python<pre><code>create_cumulative_flow(flow_data: Dict[str, List[int]]) -&gt; Dict[str, Any]\n</code></pre> <p>Create cumulative flow diagram.</p> PARAMETER DESCRIPTION <code>flow_data</code> <p>Dictionary of status to daily counts</p> <p> TYPE: <code>Dict[str, List[int]]</code> </p> RETURNS DESCRIPTION <code>Dict[str, Any]</code> <p>Dict[str, Any]: Stacked area chart configuration</p>"},{"location":"api/tenets/viz/momentum/#tenets.viz.momentum.MomentumVisualizer.create_productivity_gauge","title":"create_productivity_gauge","text":"Python<pre><code>create_productivity_gauge(productivity_score: float) -&gt; Dict[str, Any]\n</code></pre> <p>Create productivity gauge chart.</p> PARAMETER DESCRIPTION <code>productivity_score</code> <p>Productivity score (0-100)</p> <p> TYPE: <code>float</code> </p> RETURNS DESCRIPTION <code>Dict[str, Any]</code> <p>Dict[str, Any]: Gauge chart configuration</p>"},{"location":"api/tenets/viz/momentum/#tenets.viz.momentum.MomentumVisualizer.display_terminal","title":"display_terminal","text":"Python<pre><code>display_terminal(momentum_data: Dict[str, Any], show_details: bool = True) -&gt; None\n</code></pre> <p>Display momentum analysis in terminal.</p> PARAMETER DESCRIPTION <code>momentum_data</code> <p>Momentum analysis data</p> <p> TYPE: <code>Dict[str, Any]</code> </p> <code>show_details</code> <p>Whether to show detailed breakdown</p> <p> TYPE: <code>bool</code> DEFAULT: <code>True</code> </p>"},{"location":"api/tenets/viz/momentum/#tenets.viz.momentum.MomentumVisualizer.create_contributor_velocity","title":"create_contributor_velocity","text":"Python<pre><code>create_contributor_velocity(contributor_data: List[Dict[str, Any]], limit: int = 10) -&gt; Dict[str, Any]\n</code></pre> <p>Create contributor velocity chart.</p> PARAMETER DESCRIPTION <code>contributor_data</code> <p>List of contributor velocity data</p> <p> TYPE: <code>List[Dict[str, Any]]</code> </p> <code>limit</code> <p>Maximum contributors to show</p> <p> TYPE: <code>int</code> DEFAULT: <code>10</code> </p> RETURNS DESCRIPTION <code>Dict[str, Any]</code> <p>Dict[str, Any]: Bar chart configuration</p>"},{"location":"architecture/cli-api/","title":"CLI &amp; API Architecture","text":""},{"location":"architecture/cli-api/#command-structure","title":"Command Structure","text":"YAML<pre><code># Main Commands\ntenets:\n  distill:           # Build optimal context for prompts\n    --copy           # Copy to clipboard\n    --format         # Output format (markdown, xml, json, html)\n    --max-tokens     # Token limit\n    --exclude        # Exclude patterns\n    --session        # Session name\n    --algorithm      # Ranking algorithm\n\n  examine:           # Code quality analysis\n    --show-details   # Detailed metrics\n    --hotspots       # Show maintenance hotspots\n    --ownership      # Show code ownership\n    --format         # Output format\n\n  chronicle:         # Git history analysis\n    --since          # Time range\n    --author         # Filter by author\n    --format         # Output format\n\n  momentum:          # Velocity tracking (WIP)\n    --team           # Team metrics\n    --detailed       # Detailed breakdown\n\n  session:           # Session management\n    create           # Create new session\n    list             # List sessions\n    delete           # Delete session\n\n  tenet:            # Manage guiding principles\n    add             # Add new tenet\n    list            # List tenets\n    remove          # Remove tenet\n\n  instill:          # Apply tenets and system instructions\n    --dry-run       # Preview what would be applied\n    --force         # Force application\n\n  system-instruction: # Manage system instructions\n    set             # Set instruction\n    get             # Get current\n    enable/disable  # Toggle\n</code></pre>"},{"location":"architecture/cli-api/#python-api-design","title":"Python API Design","text":"Python<pre><code>from tenets import Tenets\n\n# Initialize\ntenets = Tenets(path=\"./my-project\")\n\n# Simple usage\ncontext = tenets.distill(\"implement OAuth2 authentication\")\n\n# Advanced usage\nresult = tenets.distill(\n    prompt=\"refactor database layer\",\n    algorithm=\"ml\",\n    max_tokens=50000,\n    filters=[\"*.py\", \"!test_*\"]\n)\n\n# Session management\nsession = tenets.create_session(\"oauth-implementation\")\ncontext1 = session.distill(\"add OAuth2 support\")\ncontext2 = session.distill(\"add unit tests\", incremental=True)\n\n# Analysis tools\nexamination = tenets.examine()\nchronicle = tenets.chronicle()\nmomentum = tenets.momentum()\n\n# Configuration\ntenets.configure(\n    ranking_algorithm=\"thorough\",\n    use_ml=True,\n    cache_ttl_days=30\n)\n</code></pre>"},{"location":"architecture/code-analysis/","title":"Code Analysis Engine","text":""},{"location":"architecture/code-analysis/#language-analyzer-architecture","title":"Language Analyzer Architecture","text":"<pre><code>graph TB\n    subgraph \"Base Analyzer Interface\"\n        BASE[LanguageAnalyzer&lt;br/&gt;Abstract Base Class]\n        EXTRACT_IMP[extract_imports()]\n        EXTRACT_EXP[extract_exports()]\n        EXTRACT_CLS[extract_classes()]\n        EXTRACT_FN[extract_functions()]\n        CALC_COMP[calculate_complexity()]\n        TRACE_DEP[trace_dependencies()]\n    end\n\n    subgraph \"Language-Specific Analyzers\"\n        PYTHON[Python Analyzer&lt;br/&gt;Full AST parsing]\n        JAVASCRIPT[JavaScript Analyzer&lt;br/&gt;ES6+ support]\n        GOLANG[Go Analyzer&lt;br/&gt;Package detection]\n        JAVA[Java Analyzer&lt;br/&gt;OOP patterns]\n        RUST[Rust Analyzer&lt;br/&gt;Ownership patterns]\n        GENERIC[Generic Analyzer&lt;br/&gt;Pattern-based fallback]\n    end\n\n    subgraph \"Analysis Features\"\n        AST[AST Parsing]\n        IMPORTS[Import Resolution]\n        TYPES[Type Extraction]\n        DOCS[Documentation Parsing]\n        PATTERNS[Code Patterns]\n        COMPLEXITY[Complexity Metrics]\n    end\n\n    BASE --&gt; EXTRACT_IMP\n    BASE --&gt; EXTRACT_EXP\n    BASE --&gt; EXTRACT_CLS\n    BASE --&gt; EXTRACT_FN\n    BASE --&gt; CALC_COMP\n    BASE --&gt; TRACE_DEP\n\n    BASE --&gt; PYTHON\n    BASE --&gt; JAVASCRIPT\n    BASE --&gt; GOLANG\n    BASE --&gt; JAVA\n    BASE --&gt; RUST\n    BASE --&gt; GENERIC\n\n    PYTHON --&gt; AST\n    PYTHON --&gt; IMPORTS\n    PYTHON --&gt; TYPES\n    PYTHON --&gt; DOCS\n\n    JAVASCRIPT --&gt; PATTERNS\n    GOLANG --&gt; PATTERNS\n    JAVA --&gt; COMPLEXITY\n    RUST --&gt; COMPLEXITY\n    GENERIC --&gt; PATTERNS</code></pre>"},{"location":"architecture/code-analysis/#python-analyzer-detail","title":"Python Analyzer Detail","text":"<pre><code>graph LR\n    subgraph \"Python AST Analysis\"\n        AST_PARSE[AST Parser]\n        NODE_VISIT[Node Visitor]\n        SYMBOL_TABLE[Symbol Table]\n    end\n\n    subgraph \"Code Structure\"\n        CLASSES[Class Definitions&lt;br/&gt;Inheritance chains]\n        FUNCTIONS[Function Definitions&lt;br/&gt;Async detection]\n        DECORATORS[Decorator Analysis]\n        TYPE_HINTS[Type Hint Extraction]\n    end\n\n    subgraph \"Import Analysis\"\n        ABS_IMP[Absolute Imports]\n        REL_IMP[Relative Imports]\n        STAR_IMP[Star Imports]\n        IMPORT_GRAPH[Import Graph Building]\n    end\n\n    subgraph \"Complexity Metrics\"\n        CYCLO[Cyclomatic Complexity&lt;br/&gt;+1 for if, for, while]\n        COGNITIVE[Cognitive Complexity&lt;br/&gt;Nesting penalties]\n        HALSTEAD[Halstead Metrics&lt;br/&gt;Operators/operands]\n    end\n\n    AST_PARSE --&gt; NODE_VISIT\n    NODE_VISIT --&gt; SYMBOL_TABLE\n\n    SYMBOL_TABLE --&gt; CLASSES\n    SYMBOL_TABLE --&gt; FUNCTIONS\n    SYMBOL_TABLE --&gt; DECORATORS\n    SYMBOL_TABLE --&gt; TYPE_HINTS\n\n    NODE_VISIT --&gt; ABS_IMP\n    NODE_VISIT --&gt; REL_IMP\n    NODE_VISIT --&gt; STAR_IMP\n    ABS_IMP --&gt; IMPORT_GRAPH\n    REL_IMP --&gt; IMPORT_GRAPH\n    STAR_IMP --&gt; IMPORT_GRAPH\n\n    SYMBOL_TABLE --&gt; CYCLO\n    SYMBOL_TABLE --&gt; COGNITIVE\n    SYMBOL_TABLE --&gt; HALSTEAD</code></pre>"},{"location":"architecture/configuration/","title":"Configuration System","text":""},{"location":"architecture/configuration/#configuration-hierarchy","title":"Configuration Hierarchy","text":"<pre><code>graph TB\n    subgraph \"Configuration Sources (Priority Order)\"\n        CLI[Command-line Arguments&lt;br/&gt;Highest Priority&lt;br/&gt;--algorithm, --exclude]\n        ENV[Environment Variables&lt;br/&gt;TENETS_ALGORITHM=ml]\n        PROJECT[Project Configuration&lt;br/&gt;.tenets.yml in project root]\n        USER[User Configuration&lt;br/&gt;~/.config/tenets/config.yml]\n        SYSTEM[System Defaults&lt;br/&gt;Built-in fallbacks&lt;br/&gt;Lowest Priority]\n    end\n\n    subgraph \"Configuration Categories\"\n        RANKING_CONFIG[Ranking Configuration&lt;br/&gt;Algorithms, weights, factors]\n        NLP_CONFIG[NLP Configuration&lt;br/&gt;Tokenization, stopwords]\n        ML_CONFIG[ML Configuration&lt;br/&gt;Models, caching, devices]\n        CACHE_CONFIG[Cache Configuration&lt;br/&gt;TTL, size limits, storage]\n        SCANNER_CONFIG[Scanner Configuration&lt;br/&gt;Ignore patterns, limits&lt;br/&gt;Minified exclusion]\n        OUTPUT_CONFIG[Output Configuration&lt;br/&gt;Format, tokens, metadata]\n    end\n\n    subgraph \"Dynamic Configuration\"\n        HOT_RELOAD[Hot Reload&lt;br/&gt;File change detection]\n        API_UPDATE[Runtime API Updates&lt;br/&gt;Programmatic changes]\n        VALIDATION[Configuration Validation&lt;br/&gt;Type checking, constraints]\n        ROLLBACK[Error Rollback&lt;br/&gt;Revert on failure]\n    end\n\n    CLI --&gt; RANKING_CONFIG\n    ENV --&gt; NLP_CONFIG\n    PROJECT --&gt; ML_CONFIG\n    USER --&gt; CACHE_CONFIG\n    SYSTEM --&gt; SCANNER_CONFIG\n\n    RANKING_CONFIG --&gt; HOT_RELOAD\n    NLP_CONFIG --&gt; API_UPDATE\n    ML_CONFIG --&gt; VALIDATION\n    CACHE_CONFIG --&gt; ROLLBACK\n    SCANNER_CONFIG --&gt; ROLLBACK\n    OUTPUT_CONFIG --&gt; ROLLBACK</code></pre>"},{"location":"architecture/configuration/#complete-configuration-schema","title":"Complete Configuration Schema","text":"YAML<pre><code># .tenets.yml\nversion: 2\n\n# Ranking configuration\nranking:\n  algorithm: balanced  # fast|balanced|thorough|ml\n  threshold: 0.1       # Minimum relevance score\n  use_git: true        # Enable git signals\n  use_ml: true         # Enable ML features\n\n  # Factor weights (must sum to ~1.0)\n  weights:\n    semantic_similarity: 0.25\n    keyword_match: 0.15\n    bm25_similarity: 0.15\n    import_centrality: 0.10\n    path_relevance: 0.10\n    git_recency: 0.05\n    git_frequency: 0.05\n    git_authors: 0.05\n    file_type: 0.05\n    code_patterns: 0.05\n\n  # Performance\n  workers: 8           # Parallel workers\n  batch_size: 100      # Batch size for ML\n\n# NLP configuration\nnlp:\n  use_stopwords: true\n  stopword_set: minimal  # minimal|aggressive|custom\n  tokenizer: code        # code|text\n  keyword_extractor: rake # rake|yake|bm25|tfidf|frequency\n  text_similarity: bm25   # bm25|tfidf\n\n# ML configuration\nml:\n  model: all-MiniLM-L6-v2\n  device: auto         # auto|cpu|cuda\n  cache_embeddings: true\n  embedding_dim: 384\n\n# Cache configuration\ncache:\n  enabled: true\n  directory: ~/.tenets/cache\n  max_size_mb: 1000\n  ttl_days: 7\n\n  # SQLite pragmas\n  sqlite_pragmas:\n    journal_mode: WAL\n    synchronous: NORMAL\n    cache_size: -64000\n    temp_store: MEMORY\n\n# File scanning\nscanner:\n  respect_gitignore: true\n  include_hidden: false\n  follow_symlinks: false\n  max_file_size_mb: 10\n  binary_detection: true\n  exclude_minified: true\n  exclude_tests: auto\n\n  # Global ignores\n  ignore_patterns:\n    - \"*.pyc\"\n    - \"__pycache__\"\n    - \"node_modules\"\n    - \".git\"\n    - \".venv\"\n    - \"venv\"\n    - \"*.egg-info\"\n    - \"dist\"\n    - \"build\"\n\n# Summarization configuration\nsummarizer:\n  summarize_imports: true\n  import_summary_threshold: 5\n  docs_context_aware: true\n  docs_show_in_place_context: true\n  docs_context_search_depth: 2\n  docs_context_min_confidence: 0.6\n  docs_context_max_sections: 10\n  docs_context_preserve_examples: true\n\n# Output configuration\noutput:\n  format: markdown     # markdown|json|xml|html\n  max_tokens: 100000\n  include_metadata: true\n  include_instructions: true\n  copy_on_distill: false\n\n# Session configuration\nsession:\n  auto_save: true\n  history_limit: 100\n  branch_on_conflict: true\n\n# Examination configuration\nexamination:\n  complexity_threshold: 10\n  duplication_threshold: 0.1\n  min_test_coverage: 0.8\n\n# Chronicle configuration\nchronicle:\n  include_merges: false\n  max_commits: 1000\n  analyze_patterns: true\n\n# Momentum configuration\nmomentum:\n  sprint_duration: 14\n  velocity_window: 6\n  include_weekends: false\n\n# Tenet configuration\ntenet:\n  auto_instill: true\n  injection_frequency: adaptive\n  max_per_context: 5\n  system_instruction_enabled: true\n</code></pre>"},{"location":"architecture/context-management/","title":"Context Management &amp; Optimization","text":""},{"location":"architecture/context-management/#context-building-pipeline","title":"Context Building Pipeline","text":"<pre><code>graph TD\n    subgraph \"Input Processing\"\n        RANKED_FILES[Ranked File Results]\n        TOKEN_BUDGET[Available Token Budget]\n        USER_PREFS[User Preferences]\n    end\n\n    subgraph \"Selection Strategy\"\n        THRESHOLD[Score Threshold Filtering]\n        TOP_N[Top-N Selection]\n        DIVERSITY[Diversity Optimization]\n        DEPENDENCIES[Dependency Inclusion]\n    end\n\n    subgraph \"Token Management\"\n        MODEL_LIMITS[Model-Specific Limits&lt;br/&gt;4K, 8K, 16K, 32K, 100K]\n        PROMPT_RESERVE[Prompt Token Reserve]\n        RESPONSE_RESERVE[Response Token Reserve&lt;br/&gt;2K-4K]\n        SAFETY_MARGIN[Safety Margin&lt;br/&gt;5% buffer]\n    end\n\n    subgraph \"Content Optimization\"\n        SUMMARIZATION[Summarization Strategy]\n        EXTRACTION[Key Component Extraction]\n        COMPRESSION[Content Compression]\n        FORMATTING[Output Formatting]\n    end\n\n    subgraph \"Quality Assurance\"\n        COHERENCE[Context Coherence Check]\n        COMPLETENESS[Completeness Validation]\n        RELEVANCE[Relevance Verification]\n        FINAL_OUTPUT[Final Context Output]\n    end\n\n    RANKED_FILES --&gt; THRESHOLD\n    TOKEN_BUDGET --&gt; MODEL_LIMITS\n    USER_PREFS --&gt; TOP_N\n\n    THRESHOLD --&gt; TOP_N\n    TOP_N --&gt; DIVERSITY\n    DIVERSITY --&gt; DEPENDENCIES\n\n    MODEL_LIMITS --&gt; PROMPT_RESERVE\n    PROMPT_RESERVE --&gt; RESPONSE_RESERVE\n    RESPONSE_RESERVE --&gt; SAFETY_MARGIN\n\n    DEPENDENCIES --&gt; SUMMARIZATION\n    SAFETY_MARGIN --&gt; SUMMARIZATION\n    SUMMARIZATION --&gt; EXTRACTION\n    EXTRACTION --&gt; COMPRESSION\n    COMPRESSION --&gt; FORMATTING\n\n    FORMATTING --&gt; COHERENCE\n    COHERENCE --&gt; COMPLETENESS\n    COMPLETENESS --&gt; RELEVANCE\n    RELEVANCE --&gt; FINAL_OUTPUT</code></pre>"},{"location":"architecture/context-management/#summarization-strategies","title":"Summarization Strategies","text":"<pre><code>graph LR\n    subgraph \"Extraction Strategy\"\n        IMPORTS_EX[Import Summarization&lt;br/&gt;Condenses when &gt; threshold]\n        SIGNATURES[Function/Class Signatures&lt;br/&gt;High priority]\n        DOCSTRINGS[Docstrings/Comments&lt;br/&gt;Documentation]\n        TYPES[Type Definitions&lt;br/&gt;Interface contracts]\n    end\n\n    subgraph \"Compression Strategy\"\n        REDUNDANCY[Remove Redundancy&lt;br/&gt;Duplicate code]\n        WHITESPACE[Normalize Whitespace&lt;br/&gt;Consistent formatting]\n        COMMENTS[Condense Comments&lt;br/&gt;Key information only]\n        BOILERPLATE[Remove Boilerplate&lt;br/&gt;Standard patterns]\n    end\n\n    subgraph \"Semantic Strategy\"\n        MEANING[Preserve Meaning&lt;br/&gt;Core logic intact]\n        CONTEXT[Maintain Context&lt;br/&gt;Relationship preservation]\n        ABSTRACTIONS[Higher-level View&lt;br/&gt;Architectural overview]\n        EXAMPLES[Key Examples&lt;br/&gt;Usage patterns]\n    end\n\n    subgraph \"LLM Strategy (Optional)\"\n        EXTERNAL_API[External LLM API&lt;br/&gt;OpenAI/Anthropic]\n        INTELLIGENT[Intelligent Summarization&lt;br/&gt;Context-aware]\n        CONSENT[User Consent Required&lt;br/&gt;Privacy protection]\n        FALLBACK[Fallback to Local&lt;br/&gt;If API unavailable]\n    end\n\n    IMPORTS_EX --&gt; REDUNDANCY\n    SIGNATURES --&gt; WHITESPACE\n    DOCSTRINGS --&gt; COMMENTS\n    TYPES --&gt; BOILERPLATE\n\n    REDUNDANCY --&gt; MEANING\n    WHITESPACE --&gt; CONTEXT\n    COMMENTS --&gt; ABSTRACTIONS\n    BOILERPLATE --&gt; EXAMPLES\n\n    MEANING --&gt; EXTERNAL_API\n    CONTEXT --&gt; INTELLIGENT\n    ABSTRACTIONS --&gt; CONSENT\n    EXAMPLES --&gt; FALLBACK</code></pre>"},{"location":"architecture/core-architecture/","title":"Complete System Architecture","text":""},{"location":"architecture/core-architecture/#high-level-data-flow","title":"High-Level Data Flow","text":"<pre><code>graph TB\n    subgraph \"User Interaction Layer\"\n        CLI[CLI Interface&lt;br/&gt;typer]\n        API[Python API&lt;br/&gt;Library]\n        WebUI[Web UI&lt;br/&gt;Future]\n        IDE[IDE Extensions]\n    end\n\n    subgraph \"Command Orchestration\"\n        DISPATCHER[Command Dispatcher]\n        DISTILL[Distill Command]\n        EXAMINE[Examine Command]\n        CHRONICLE[Chronicle Command]\n        MOMENTUM[Momentum Command]\n        SESSION[Session Management]\n    end\n\n    subgraph \"Prompt Processing Layer\"\n        PARSER[Prompt Parser]\n        INTENT[Intent Detection]\n        KEYWORDS[Keyword Extraction]\n        ENTITIES[Entity Extraction]\n\n        subgraph \"NLP Pipeline\"\n            TOKENIZER[Tokenizer]\n            STOPWORDS[Stopwords]\n            RAKE[RAKE Keywords]\n            YAKE[YAKE Fallback]\n            TFIDF[BM25/TF-IDF Analysis]\n            BM25[BM25 Ranking]\n        end\n    end\n\n    subgraph \"File Discovery &amp; Analysis\"\n        SCANNER[File Scanner]\n        GITIGNORE[.gitignore Parser]\n        BINARY[Binary Detection]\n        PARALLEL[Parallel Scanner]\n\n        subgraph \"Code Analysis Engine\"\n            PYTHON_ANALYZER[Python Analyzer]\n            JS_ANALYZER[JavaScript Analyzer]\n            GO_ANALYZER[Go Analyzer]\n            JAVA_ANALYZER[Java Analyzer]\n            GENERIC_ANALYZER[Generic Analyzer]\n        end\n\n        subgraph \"AST &amp; Structure\"\n            CLASSES[Class Extraction]\n            FUNCTIONS[Function Extraction]\n            IMPORTS[Import Analysis]\n            EXPORTS[Export Analysis]\n        end\n    end\n\n    subgraph \"Intelligence &amp; Ranking\"\n        subgraph \"Ranking Engine\"\n            FAST[Fast Strategy]\n            BALANCED[Balanced Strategy]\n            THOROUGH[Thorough Strategy]\n            ML[ML Strategy]\n        end\n\n        subgraph \"Ranking Factors\"\n            SEMANTIC[Semantic Similarity&lt;br/&gt;25%]\n            KEYWORD_MATCH[Keyword Matching&lt;br/&gt;15%]\n            BM25_SIM[BM25 Similarity&lt;br/&gt;15%]\n            IMPORT_CENT[Import Centrality&lt;br/&gt;10%]\n            PATH_REL[Path Relevance&lt;br/&gt;10%]\n            GIT_SIG[Git Signals&lt;br/&gt;15%]\n        end\n\n        subgraph \"ML/NLP Pipeline\"\n            EMBEDDINGS[Local Embeddings]\n            EMBED_CACHE[Embedding Cache]\n            SIMILARITY[Similarity Computing]\n        end\n    end\n\n    subgraph \"Context Optimization\"\n        CONTEXT_BUILDER[Context Builder]\n        TOKEN_COUNTER[Token Counter]\n        SUMMARIZER[Summarizer]\n        FORMATTER[Output Formatter]\n    end\n\n    subgraph \"Storage &amp; Persistence\"\n        SQLITE[SQLite Database&lt;br/&gt;Sessions]\n        MEMORY[Memory Cache&lt;br/&gt;LRU]\n        DISK[Disk Cache&lt;br/&gt;Analysis Results]\n    end\n\n    CLI --&gt; DISPATCHER\n    API --&gt; DISPATCHER\n    WebUI --&gt; DISPATCHER\n    IDE --&gt; DISPATCHER\n\n    DISPATCHER --&gt; DISTILL\n    DISPATCHER --&gt; EXAMINE\n    DISPATCHER --&gt; CHRONICLE\n    DISPATCHER --&gt; MOMENTUM\n    DISPATCHER --&gt; SESSION\n\n    DISTILL --&gt; PARSER\n    PARSER --&gt; INTENT\n    PARSER --&gt; KEYWORDS\n    PARSER --&gt; ENTITIES\n\n    INTENT --&gt; TOKENIZER\n    KEYWORDS --&gt; RAKE\n    RAKE --&gt; YAKE\n    ENTITIES --&gt; TFIDF\n    ENTITIES --&gt; BM25\n\n    PARSER --&gt; SCANNER\n    SCANNER --&gt; GITIGNORE\n    SCANNER --&gt; BINARY\n    SCANNER --&gt; PARALLEL\n\n    SCANNER --&gt; PYTHON_ANALYZER\n    SCANNER --&gt; JS_ANALYZER\n    SCANNER --&gt; GO_ANALYZER\n    SCANNER --&gt; JAVA_ANALYZER\n    SCANNER --&gt; GENERIC_ANALYZER\n\n    PYTHON_ANALYZER --&gt; CLASSES\n    PYTHON_ANALYZER --&gt; FUNCTIONS\n    PYTHON_ANALYZER --&gt; IMPORTS\n    PYTHON_ANALYZER --&gt; EXPORTS\n\n    CLASSES --&gt; FAST\n    FUNCTIONS --&gt; BALANCED\n    IMPORTS --&gt; THOROUGH\n    EXPORTS --&gt; ML\n\n    FAST --&gt; SEMANTIC\n    BALANCED --&gt; KEYWORD_MATCH\n    THOROUGH --&gt; BM25_SIM\n    ML --&gt; IMPORT_CENT\n\n    SEMANTIC --&gt; EMBEDDINGS\n    EMBEDDINGS --&gt; EMBED_CACHE\n    EMBED_CACHE --&gt; SIMILARITY\n\n    SIMILARITY --&gt; CONTEXT_BUILDER\n    KEYWORD_MATCH --&gt; CONTEXT_BUILDER\n    BM25_SIM --&gt; CONTEXT_BUILDER\n\n    CONTEXT_BUILDER --&gt; TOKEN_COUNTER\n    CONTEXT_BUILDER --&gt; SUMMARIZER\n    CONTEXT_BUILDER --&gt; FORMATTER\n\n    FORMATTER --&gt; SQLITE\n    FORMATTER --&gt; MEMORY\n    FORMATTER --&gt; DISK</code></pre>"},{"location":"architecture/core-architecture/#system-component-overview","title":"System Component Overview","text":"<pre><code>graph LR\n    subgraph \"Core Components\"\n        NLP[NLP/ML Pipeline]\n        SCAN[File Scanner]\n        ANALYZE[Code Analyzer]\n        RANK[Ranking Engine]\n        CONTEXT[Context Builder]\n    end\n\n    subgraph \"Analysis Tools\"\n        EXAMINE[Examine Tool]\n        CHRONICLE[Chronicle Tool]\n        MOMENTUM[Momentum Tool]\n    end\n\n    subgraph \"Storage Systems\"\n        CACHE[Cache Manager]\n        SESSION[Session Store]\n        CONFIG[Configuration]\n    end\n\n    NLP --&gt; RANK\n    SCAN --&gt; ANALYZE\n    ANALYZE --&gt; RANK\n    RANK --&gt; CONTEXT\n\n    ANALYZE --&gt; EXAMINE\n    SCAN --&gt; CHRONICLE\n    CHRONICLE --&gt; MOMENTUM\n\n    RANK --&gt; CACHE\n    CONTEXT --&gt; SESSION\n    SESSION --&gt; CONFIG</code></pre>"},{"location":"architecture/file-scanning/","title":"File Discovery &amp; Scanning System","text":""},{"location":"architecture/file-scanning/#scanner-architecture-flow","title":"Scanner Architecture Flow","text":"<pre><code>graph TD\n    subgraph \"Entry Points\"\n        ROOT[Project Root]\n        PATHS[Specified Paths]\n        PATTERNS[Include Patterns]\n    end\n\n    subgraph \"Ignore System Hierarchy\"\n        CLI_IGNORE[CLI Arguments&lt;br/&gt;--exclude&lt;br/&gt;Highest Priority]\n        TENETS_IGNORE[.tenetsignore&lt;br/&gt;Project-specific]\n        GIT_IGNORE[.gitignore&lt;br/&gt;Version control]\n        GLOBAL_IGNORE[Global Ignores&lt;br/&gt;~/.config/tenets/ignore&lt;br/&gt;Lowest Priority]\n    end\n\n    subgraph \"Intelligent Test Exclusion\"\n        INTENT_DETECT[Intent Detection&lt;br/&gt;Test-related prompts?]\n        CLI_OVERRIDE[CLI Override&lt;br/&gt;--include-tests / --exclude-tests]\n        TEST_PATTERNS[Test Pattern Matching&lt;br/&gt;Multi-language support]\n        TEST_DIRS[Test Directory Detection&lt;br/&gt;tests/, __tests__, spec/]\n    end\n\n    subgraph \"Minified &amp; Build File Exclusion\"\n        MINIFIED_CHECK[Minified Detection&lt;br/&gt;*.min.js, *.bundle.js]\n        BUILD_DIRS[Build Directories&lt;br/&gt;dist/, build/, out/]\n        PROD_FILES[Production Files&lt;br/&gt;*.prod.js, *.compiled.js]\n        NODE_MODULES[Dependencies&lt;br/&gt;node_modules/, vendor/]\n    end\n\n    subgraph \"Detection Systems\"\n        BINARY_DET[Binary Detection]\n        EXT_CHECK[Extension Check]\n        SIZE_CHECK[Size Check&lt;br/&gt;Max 10MB default]\n        CONTENT_CHECK[Content Sampling&lt;br/&gt;Null byte detection]\n        MAGIC_CHECK[Magic Number&lt;br/&gt;File signatures]\n    end\n\n    subgraph \"Parallel Processing\"\n        WORK_QUEUE[Work Queue]\n        PROCESS_POOL[Process Pool&lt;br/&gt;CPU-bound operations]\n        THREAD_POOL[Thread Pool&lt;br/&gt;I/O operations]\n        PROGRESS[Progress Tracking&lt;br/&gt;tqdm]\n    end\n\n    subgraph \"Output\"\n        SCANNED_FILE[Scanned File Objects]\n        METADATA[File Metadata]\n        ANALYSIS_READY[Ready for Analysis]\n    end\n\n    ROOT --&gt; CLI_IGNORE\n    PATHS --&gt; CLI_IGNORE\n    PATTERNS --&gt; CLI_IGNORE\n\n    CLI_IGNORE --&gt; TENETS_IGNORE\n    TENETS_IGNORE --&gt; GIT_IGNORE\n    GIT_IGNORE --&gt; GLOBAL_IGNORE\n\n    GLOBAL_IGNORE --&gt; BINARY_DET\n    BINARY_DET --&gt; EXT_CHECK\n    EXT_CHECK --&gt; SIZE_CHECK\n    SIZE_CHECK --&gt; CONTENT_CHECK\n    CONTENT_CHECK --&gt; MAGIC_CHECK\n\n    MAGIC_CHECK --&gt; WORK_QUEUE\n    WORK_QUEUE --&gt; PROCESS_POOL\n    WORK_QUEUE --&gt; THREAD_POOL\n    PROCESS_POOL --&gt; PROGRESS\n    THREAD_POOL --&gt; PROGRESS\n\n    PROGRESS --&gt; SCANNED_FILE\n    SCANNED_FILE --&gt; METADATA\n    METADATA --&gt; ANALYSIS_READY</code></pre>"},{"location":"architecture/file-scanning/#binary-detection-strategy","title":"Binary Detection Strategy","text":"<pre><code>flowchart TD\n    FILE[Input File] --&gt; EXT{Known Binary&lt;br/&gt;Extension?}\n    EXT --&gt;|Yes| BINARY[Mark as Binary]\n    EXT --&gt;|No| SIZE{Size &gt; 10MB?}\n    SIZE --&gt;|Yes| SKIP[Skip File]\n    SIZE --&gt;|No| SAMPLE[Sample First 8KB]\n    SAMPLE --&gt; NULL{Contains&lt;br/&gt;Null Bytes?}\n    NULL --&gt;|Yes| BINARY\n    NULL --&gt;|No| RATIO[Calculate Text Ratio]\n    RATIO --&gt; THRESHOLD{Ratio &gt; 95%&lt;br/&gt;Printable?}\n    THRESHOLD --&gt;|Yes| TEXT[Mark as Text]\n    THRESHOLD --&gt;|No| BINARY\n    TEXT --&gt; ANALYZE[Ready for Analysis]\n    BINARY --&gt; IGNORE[Skip Analysis]\n    SKIP --&gt; IGNORE</code></pre>"},{"location":"architecture/file-scanning/#intelligent-test-file-exclusion","title":"Intelligent Test File Exclusion","text":"<pre><code>flowchart TD\n    PROMPT[User Prompt] --&gt; PARSE[Prompt Parsing]\n    PARSE --&gt; INTENT{Intent Detection&lt;br/&gt;Test-related?}\n\n    INTENT --&gt;|Yes| INCLUDE_TESTS[include_tests = True]\n    INTENT --&gt;|No| EXCLUDE_TESTS[include_tests = False]\n\n    CLI_OVERRIDE{CLI Override?&lt;br/&gt;--include-tests&lt;br/&gt;--exclude-tests}\n    CLI_OVERRIDE --&gt;|--include-tests| FORCE_INCLUDE[include_tests = True]\n    CLI_OVERRIDE --&gt;|--exclude-tests| FORCE_EXCLUDE[include_tests = False]\n    CLI_OVERRIDE --&gt;|None| INTENT\n\n    INCLUDE_TESTS --&gt; SCAN_ALL[Scan All Files]\n    EXCLUDE_TESTS --&gt; TEST_FILTER[Apply Test Filters]\n    FORCE_INCLUDE --&gt; SCAN_ALL\n    FORCE_EXCLUDE --&gt; TEST_FILTER\n\n    TEST_FILTER --&gt; PATTERN_MATCH[Pattern Matching]\n    PATTERN_MATCH --&gt; DIR_MATCH[Directory Matching]\n\n    subgraph \"Test Patterns (Multi-language)\"\n        PY_PATTERNS[\"Python: test_*.py, *_test.py\"]\n        JS_PATTERNS[\"JavaScript: *.test.js, *.spec.js\"]\n        JAVA_PATTERNS[\"Java: *Test.java, *Tests.java\"]\n        GO_PATTERNS[\"Go: *_test.go\"]\n        GENERIC_PATTERNS[\"Generic: **/test/**, **/tests/**\"]\n    end\n\n    PATTERN_MATCH --&gt; PY_PATTERNS\n    PATTERN_MATCH --&gt; JS_PATTERNS\n    PATTERN_MATCH --&gt; JAVA_PATTERNS\n    PATTERN_MATCH --&gt; GO_PATTERNS\n    PATTERN_MATCH --&gt; GENERIC_PATTERNS\n\n    PY_PATTERNS --&gt; FILTERED_FILES[Filtered File List]\n    JS_PATTERNS --&gt; FILTERED_FILES\n    JAVA_PATTERNS --&gt; FILTERED_FILES\n    GO_PATTERNS --&gt; FILTERED_FILES\n    GENERIC_PATTERNS --&gt; FILTERED_FILES\n\n    SCAN_ALL --&gt; ANALYSIS[File Analysis]\n    FILTERED_FILES --&gt; ANALYSIS</code></pre>"},{"location":"architecture/git-integration/","title":"Git Integration &amp; Chronicle System","text":""},{"location":"architecture/git-integration/#git-analysis-architecture","title":"Git Analysis Architecture","text":"<pre><code>graph TD\n    subgraph \"Git Data Sources\"\n        COMMIT_LOG[Commit History]\n        BLAME_DATA[Blame Information]\n        BRANCH_INFO[Branch Analysis]\n        MERGE_DATA[Merge Detection]\n        CONFLICT_HIST[Conflict History]\n    end\n\n    subgraph \"Chronicle Analysis\"\n        TEMPORAL[Temporal Analysis&lt;br/&gt;Activity patterns]\n        CONTRIBUTORS[Contributor Tracking&lt;br/&gt;Author patterns]\n        VELOCITY[Change Velocity&lt;br/&gt;Trend analysis]\n        HOTSPOTS[Change Hotspots&lt;br/&gt;Problem areas]\n    end\n\n    subgraph \"Metrics Calculation\"\n        BUS_FACTOR[Bus Factor&lt;br/&gt;Knowledge concentration]\n        EXPERTISE[Author Expertise&lt;br/&gt;Domain knowledge]\n        FRESHNESS[Code Freshness&lt;br/&gt;Age distribution]\n        STABILITY[Change Stability&lt;br/&gt;Frequency patterns]\n    end\n\n    subgraph \"Risk Assessment\"\n        KNOWLEDGE_RISK[Knowledge Risk&lt;br/&gt;Single points of failure]\n        CHURN_RISK[Churn Risk&lt;br/&gt;High-change areas]\n        COMPLEXITY_RISK[Complexity Risk&lt;br/&gt;Hard-to-maintain code]\n        SUCCESSION[Succession Planning&lt;br/&gt;Knowledge transfer]\n    end\n\n    COMMIT_LOG --&gt; TEMPORAL\n    BLAME_DATA --&gt; CONTRIBUTORS\n    BRANCH_INFO --&gt; VELOCITY\n    MERGE_DATA --&gt; HOTSPOTS\n    CONFLICT_HIST --&gt; HOTSPOTS\n\n    CONTRIBUTORS --&gt; BUS_FACTOR\n    TEMPORAL --&gt; EXPERTISE\n    VELOCITY --&gt; FRESHNESS\n    HOTSPOTS --&gt; STABILITY\n\n    BUS_FACTOR --&gt; KNOWLEDGE_RISK\n    EXPERTISE --&gt; CHURN_RISK\n    FRESHNESS --&gt; COMPLEXITY_RISK\n    STABILITY --&gt; SUCCESSION</code></pre>"},{"location":"architecture/git-integration/#chronicle-report-structure","title":"Chronicle Report Structure","text":"<pre><code>graph LR\n    subgraph \"Executive Summary\"\n        HEALTH[Repository Health Score]\n        KEY_METRICS[Key Metrics Dashboard]\n        ALERTS[Risk Alerts]\n    end\n\n    subgraph \"Activity Analysis\"\n        TIMELINE[Activity Timeline]\n        PATTERNS[Change Patterns]\n        TRENDS[Velocity Trends]\n    end\n\n    subgraph \"Contributor Analysis\"\n        TEAM[Team Composition]\n        EXPERTISE_MAP[Expertise Mapping]\n        CONTRIBUTION[Contribution Patterns]\n    end\n\n    subgraph \"Risk Assessment\"\n        RISKS[Identified Risks]\n        RECOMMENDATIONS[Recommendations]\n        ACTION_ITEMS[Action Items]\n    end\n\n    HEALTH --&gt; TIMELINE\n    KEY_METRICS --&gt; PATTERNS\n    ALERTS --&gt; TRENDS\n\n    TIMELINE --&gt; TEAM\n    PATTERNS --&gt; EXPERTISE_MAP\n    TRENDS --&gt; CONTRIBUTION\n\n    TEAM --&gt; RISKS\n    EXPERTISE_MAP --&gt; RECOMMENDATIONS\n    CONTRIBUTION --&gt; ACTION_ITEMS</code></pre>"},{"location":"architecture/guiding-principles/","title":"Guiding Principles (Tenets) System","text":""},{"location":"architecture/guiding-principles/#overview","title":"Overview","text":"<p>The Guiding Principles system provides persistent, context-aware instructions to maintain consistency across AI interactions and combat context drift.</p>"},{"location":"architecture/guiding-principles/#injection-strategy","title":"Injection Strategy","text":"<pre><code>graph TD\n    subgraph \"Injection Decision Engine\"\n        ANALYZER[Content Analyzer&lt;br/&gt;Structure &amp; complexity]\n        STRATEGY[Strategy Selector&lt;br/&gt;Top, distributed, contextual]\n        INJECTOR[Smart Injector&lt;br/&gt;Natural break detection]\n    end\n\n    subgraph \"Priority System\"\n        CRITICAL[Critical Principles&lt;br/&gt;Security, data integrity]\n        HIGH[High Priority&lt;br/&gt;Architecture, performance]\n        MEDIUM[Medium Priority&lt;br/&gt;Style, conventions]\n        LOW[Low Priority&lt;br/&gt;Preferences, suggestions]\n    end\n\n    subgraph \"Reinforcement\"\n        TOP_INJECTION[Top of Context&lt;br/&gt;Most visible]\n        DISTRIBUTED[Throughout Content&lt;br/&gt;Natural sections]\n        END_SUMMARY[End Reinforcement&lt;br/&gt;Key reminders]\n    end\n\n    ANALYZER --&gt; STRATEGY\n    STRATEGY --&gt; INJECTOR\n\n    CRITICAL --&gt; TOP_INJECTION\n    HIGH --&gt; DISTRIBUTED\n    MEDIUM --&gt; DISTRIBUTED\n    LOW --&gt; END_SUMMARY</code></pre>"},{"location":"architecture/guiding-principles/#output-formats","title":"Output Formats","text":"<p>Markdown: Markdown<pre><code>**\ud83c\udfaf Key Guiding Principle:** Always validate user input before processing\n**\ud83d\udccc Important Guiding Principle:** Use async/await for all I/O operations\n**\ud83d\udca1 Guiding Principle:** Prefer composition over inheritance\n</code></pre></p> <p>XML (Recommended by OpenAI): XML<pre><code>&lt;guiding_principle priority=\"high\" category=\"security\"&gt;\n  Always validate and sanitize user input\n&lt;/guiding_principle&gt;\n\n&lt;guiding_principles&gt;\n  &lt;guiding_principle priority=\"critical\"&gt;Maintain backward compatibility&lt;/guiding_principle&gt;\n  &lt;guiding_principle priority=\"medium\"&gt;Use descriptive variable names&lt;/guiding_principle&gt;\n&lt;/guiding_principles&gt;\n</code></pre></p>"},{"location":"architecture/guiding-principles/#configuration","title":"Configuration","text":"YAML<pre><code>tenet:\n  auto_instill: true\n  max_per_context: 5\n  injection_strategy: strategic\n  injection_frequency: adaptive  # 'always', 'periodic', 'adaptive', 'manual'\n  injection_interval: 3          # For periodic mode\n  min_session_length: 1          # First injection always happens\n  system_instruction: \"Prefer small, safe diffs and add tests\"\n  system_instruction_enabled: true\n</code></pre>"},{"location":"architecture/nlp-pipeline/","title":"NLP/ML Pipeline Architecture","text":""},{"location":"architecture/nlp-pipeline/#centralized-nlp-components","title":"Centralized NLP Components","text":"Text Only<pre><code>tenets/core/nlp/\n\u251c\u2500\u2500 __init__.py          # Main NLP API exports\n\u251c\u2500\u2500 similarity.py        # Centralized similarity computations\n\u251c\u2500\u2500 keyword_extractor.py # Unified keyword extraction with SimpleRAKE\n\u251c\u2500\u2500 tokenizer.py        # Code and text tokenization\n\u251c\u2500\u2500 stopwords.py        # Stopword management with fallbacks\n\u251c\u2500\u2500 embeddings.py       # Embedding generation (ML optional)\n\u251c\u2500\u2500 ml_utils.py         # ML utility functions\n\u251c\u2500\u2500 bm25.py            # BM25 ranking algorithm (primary)\n\u2514\u2500\u2500 tfidf.py           # TF-IDF calculations (optional alternative)\n</code></pre>"},{"location":"architecture/nlp-pipeline/#pipeline-component-flow","title":"Pipeline Component Flow","text":"<pre><code>graph TD\n    subgraph \"Input Processing\"\n        INPUT[Raw Text Input]\n        PROMPT[User Prompt]\n        CODE[Code Content]\n    end\n\n    subgraph \"Tokenization Layer\"\n        CODE_TOK[Code Tokenizer&lt;br/&gt;camelCase, snake_case]\n        TEXT_TOK[Text Tokenizer&lt;br/&gt;NLP processing]\n    end\n\n    subgraph \"Keyword Extraction\"\n        RAKE_EXT[RAKE Extractor&lt;br/&gt;Primary - Fast &amp; Python 3.13 Compatible]\n        YAKE_EXT[YAKE Extractor&lt;br/&gt;Secondary - Python &lt; 3.13 Only]\n        TFIDF_EXT[BM25/TF-IDF Extractor&lt;br/&gt;Frequency-based Fallback]\n        FREQ_EXT[Frequency Extractor&lt;br/&gt;Final Fallback]\n    end\n\n    subgraph \"Stopword Management\"\n        CODE_STOP[Code Stopwords&lt;br/&gt;Minimal - 30 words]\n        PROMPT_STOP[Prompt Stopwords&lt;br/&gt;Aggressive - 200+ words]\n    end\n\n    subgraph \"Embedding Generation\"\n        LOCAL_EMB[Local Embeddings&lt;br/&gt;sentence-transformers]\n        MODEL_SEL[Model Selection&lt;br/&gt;MiniLM, MPNet]\n        FALLBACK[BM25 Fallback&lt;br/&gt;No ML required]\n    end\n\n    subgraph \"Similarity Computing\"\n        COSINE[Cosine Similarity]\n        EUCLIDEAN[Euclidean Distance]\n        BATCH[Batch Processing]\n    end\n\n    subgraph \"Caching System\"\n        MEM_CACHE[Memory Cache&lt;br/&gt;LRU 1000 items]\n        DISK_CACHE[SQLite Cache&lt;br/&gt;30 day TTL]\n    end\n\n    INPUT --&gt; CODE_TOK\n    INPUT --&gt; TEXT_TOK\n    PROMPT --&gt; TEXT_TOK\n    CODE --&gt; CODE_TOK\n\n    CODE_TOK --&gt; CODE_STOP\n    TEXT_TOK --&gt; PROMPT_STOP\n\n    CODE_STOP --&gt; RAKE_EXT\n    PROMPT_STOP --&gt; RAKE_EXT\n    RAKE_EXT --&gt; YAKE_EXT\n    YAKE_EXT --&gt; TFIDF_EXT\n    TFIDF_EXT --&gt; FREQ_EXT\n\n    FREQ_EXT --&gt; LOCAL_EMB\n    LOCAL_EMB --&gt; MODEL_SEL\n    MODEL_SEL --&gt; FALLBACK\n\n    FALLBACK --&gt; COSINE\n    COSINE --&gt; EUCLIDEAN\n    EUCLIDEAN --&gt; BATCH\n\n    BATCH --&gt; MEM_CACHE\n    MEM_CACHE --&gt; DISK_CACHE</code></pre>"},{"location":"architecture/nlp-pipeline/#keyword-extraction-algorithms-comparison","title":"Keyword Extraction Algorithms Comparison","text":"Algorithm Speed Quality Memory Python 3.13 Best For Limitations RAKE Fast Good Low \u2705 Yes Technical docs, Multi-word phrases No semantic understanding SimpleRAKE Fast Good Minimal \u2705 Yes No NLTK dependencies, Built-in Basic tokenization only YAKE Moderate Very Good Low \u274c No Statistical analysis, Capital aware Python 3.13 bug BM25 Fast Excellent High \u2705 Yes Primary ranking, Length variation Needs corpus TF-IDF Fast Good Medium \u2705 Yes Alternative to BM25 Less effective for varying lengths Frequency Very Fast Basic Minimal \u2705 Yes Fallback option Very basic"},{"location":"architecture/nlp-pipeline/#embedding-model-architecture","title":"Embedding Model Architecture","text":"<pre><code>graph LR\n    subgraph \"Model Options\"\n        MINI_L6[all-MiniLM-L6-v2&lt;br/&gt;90MB, Fast]\n        MINI_L12[all-MiniLM-L12-v2&lt;br/&gt;120MB, Better]\n        MPNET[all-mpnet-base-v2&lt;br/&gt;420MB, Best]\n        QA_MINI[multi-qa-MiniLM&lt;br/&gt;Q&amp;A Optimized]\n    end\n\n    subgraph \"Processing Pipeline\"\n        BATCH_ENC[Batch Encoding]\n        CHUNK[Document Chunking&lt;br/&gt;1000 chars, 100 overlap]\n        VECTOR[Vector Operations&lt;br/&gt;NumPy optimized]\n    end\n\n    subgraph \"Cache Strategy\"\n        KEY_GEN[Cache Key Generation&lt;br/&gt;model + content hash]\n        WARM[Cache Warming]\n        INVALID[Intelligent Invalidation]\n    end\n\n    MINI_L6 --&gt; BATCH_ENC\n    MINI_L12 --&gt; BATCH_ENC\n    MPNET --&gt; BATCH_ENC\n    QA_MINI --&gt; BATCH_ENC\n\n    BATCH_ENC --&gt; CHUNK\n    CHUNK --&gt; VECTOR\n\n    VECTOR --&gt; KEY_GEN\n    KEY_GEN --&gt; WARM\n    WARM --&gt; INVALID</code></pre>"},{"location":"architecture/output-visualization/","title":"Output Generation &amp; Visualization","text":""},{"location":"architecture/output-visualization/#output-formatting-system","title":"Output Formatting System","text":"<pre><code>graph TB\n    subgraph \"Format Types\"\n        MARKDOWN[Markdown Format&lt;br/&gt;Human-readable]\n        JSON[JSON Format&lt;br/&gt;Machine-parseable]\n        XML[XML Format&lt;br/&gt;Structured data]\n        HTML[HTML Format&lt;br/&gt;Interactive reports]\n    end\n\n    subgraph \"HTML Report Features\"\n        INTERACTIVE[Interactive Elements&lt;br/&gt;Collapsible sections]\n        VISUALS[Visualizations&lt;br/&gt;Charts &amp; graphs]\n        STYLING[Professional Styling&lt;br/&gt;Modern UI]\n        RESPONSIVE[Responsive Design&lt;br/&gt;Mobile-friendly]\n    end\n\n    subgraph \"Report Components\"\n        HEADER[Report Header&lt;br/&gt;Title &amp; metadata]\n        PROMPT_DISPLAY[Prompt Analysis&lt;br/&gt;Keywords &amp; intent]\n        STATS[Statistics Dashboard&lt;br/&gt;Metrics &amp; KPIs]\n        FILES[File Listings&lt;br/&gt;Code previews]\n        GIT[Git Context&lt;br/&gt;Commits &amp; contributors]\n    end\n\n    HTML --&gt; INTERACTIVE\n    HTML --&gt; VISUALS\n    HTML --&gt; STYLING\n    HTML --&gt; RESPONSIVE\n\n    INTERACTIVE --&gt; HEADER\n    VISUALS --&gt; STATS\n    STYLING --&gt; FILES\n    RESPONSIVE --&gt; GIT</code></pre>"},{"location":"architecture/output-visualization/#visualization-components","title":"Visualization Components","text":"<pre><code>graph LR\n    subgraph \"Project Detection\"\n        DETECTOR[Project Detector&lt;br/&gt;Auto-detects type]\n        LANGUAGES[Language Analysis&lt;br/&gt;% distribution]\n        FRAMEWORKS[Framework Detection&lt;br/&gt;Django, React, etc]\n        ENTRYPOINTS[Entry Points&lt;br/&gt;main.py, index.js]\n    end\n\n    subgraph \"Graph Generation\"\n        GRAPHGEN[Graph Generator&lt;br/&gt;Multiple formats]\n        NETWORKX[NetworkX&lt;br/&gt;Graph algorithms]\n        GRAPHVIZ[Graphviz&lt;br/&gt;DOT rendering]\n        PLOTLY[Plotly&lt;br/&gt;Interactive HTML]\n        D3JS[D3.js&lt;br/&gt;Web visualization]\n    end\n\n    subgraph \"Dependency Visualization\"\n        FILE_DEPS[File-level&lt;br/&gt;Individual files]\n        MODULE_DEPS[Module-level&lt;br/&gt;Aggregated modules]\n        PACKAGE_DEPS[Package-level&lt;br/&gt;Top-level packages]\n        CLUSTERING[Clustering&lt;br/&gt;Group by criteria]\n    end\n\n    subgraph \"Output Formats\"\n        ASCII[ASCII Tree&lt;br/&gt;Terminal output]\n        SVG[SVG&lt;br/&gt;Vector graphics]\n        PNG[PNG/PDF&lt;br/&gt;Static images]\n        HTML_INT[Interactive HTML&lt;br/&gt;D3.js/Plotly]\n        DOT[DOT Format&lt;br/&gt;Graphviz source]\n        JSON_OUT[JSON&lt;br/&gt;Raw data]\n    end\n\n    subgraph \"Layout Algorithms\"\n        HIERARCHICAL[Hierarchical&lt;br/&gt;Tree layout]\n        CIRCULAR[Circular&lt;br/&gt;Radial layout]\n        SHELL[Shell&lt;br/&gt;Concentric circles]\n        KAMADA[Kamada-Kawai&lt;br/&gt;Force-directed]\n    end\n\n    DETECTOR --&gt; LANGUAGES\n    DETECTOR --&gt; FRAMEWORKS\n    DETECTOR --&gt; ENTRYPOINTS\n\n    GRAPHGEN --&gt; NETWORKX\n    GRAPHGEN --&gt; GRAPHVIZ\n    GRAPHGEN --&gt; PLOTLY\n    GRAPHGEN --&gt; D3JS\n\n    FILE_DEPS --&gt; MODULE_DEPS\n    MODULE_DEPS --&gt; PACKAGE_DEPS\n    PACKAGE_DEPS --&gt; CLUSTERING\n\n    GRAPHGEN --&gt; ASCII\n    GRAPHGEN --&gt; SVG\n    GRAPHGEN --&gt; PNG\n    GRAPHGEN --&gt; HTML_INT\n    GRAPHGEN --&gt; DOT\n    GRAPHGEN --&gt; JSON_OUT</code></pre>"},{"location":"architecture/performance/","title":"Performance Architecture","text":""},{"location":"architecture/performance/#optimization-strategy-overview","title":"Optimization Strategy Overview","text":"<pre><code>graph TD\n    subgraph \"Parallel Processing\"\n        FILE_SCAN[File Scanning&lt;br/&gt;Process Pool&lt;br/&gt;CPU-bound operations]\n        ANALYSIS[Code Analysis&lt;br/&gt;Thread Pool&lt;br/&gt;I/O operations]\n        RANKING[Relevance Ranking&lt;br/&gt;Thread Pool&lt;br/&gt;Computation]\n        EMBEDDING[Embedding Generation&lt;br/&gt;Batch Processing&lt;br/&gt;GPU if available]\n    end\n\n    subgraph \"Streaming Architecture\"\n        INCREMENTAL[Incremental Discovery&lt;br/&gt;Stream files as found]\n        PROGRESSIVE[Progressive Ranking&lt;br/&gt;Rank as analyzed]\n        CHUNKED[Chunked Analysis&lt;br/&gt;Process in batches]\n        STREAMING[Result Streaming&lt;br/&gt;First results quickly]\n    end\n\n    subgraph \"Lazy Evaluation\"\n        DEFER[Defer Analysis&lt;br/&gt;Until needed]\n        ON_DEMAND[On-demand Embeddings&lt;br/&gt;Generate when required]\n        PROGRESSIVE_ENH[Progressive Enhancement&lt;br/&gt;Add features incrementally]\n        JIT[Just-in-time Compilation&lt;br/&gt;Optimize hot paths]\n    end\n\n    subgraph \"Memory Management\"\n        STREAMING_PROC[Streaming Processing&lt;br/&gt;Constant memory usage]\n        GC[Incremental GC&lt;br/&gt;Prevent pauses]\n        MMAP[Memory-mapped Files&lt;br/&gt;Large file handling]\n        PRESSURE[Memory Pressure Monitor&lt;br/&gt;Adaptive behavior]\n    end\n\n    FILE_SCAN --&gt; INCREMENTAL\n    ANALYSIS --&gt; PROGRESSIVE\n    RANKING --&gt; CHUNKED\n    EMBEDDING --&gt; STREAMING\n\n    INCREMENTAL --&gt; DEFER\n    PROGRESSIVE --&gt; ON_DEMAND\n    CHUNKED --&gt; PROGRESSIVE_ENH\n    STREAMING --&gt; JIT\n\n    DEFER --&gt; STREAMING_PROC\n    ON_DEMAND --&gt; GC\n    PROGRESSIVE_ENH --&gt; MMAP\n    JIT --&gt; PRESSURE</code></pre>"},{"location":"architecture/ranking-system/","title":"Relevance Ranking System","text":""},{"location":"architecture/ranking-system/#unified-ranking-architecture","title":"Unified Ranking Architecture","text":"<pre><code>graph TD\n    subgraph \"Ranking Strategies\"\n        FAST[Fast Strategy&lt;br/&gt;Fastest&lt;br/&gt;Keyword + Path Only]\n        BALANCED[Balanced Strategy&lt;br/&gt;1.5x slower&lt;br/&gt;BM25 + Structure]\n        THOROUGH[Thorough Strategy&lt;br/&gt;4x slower&lt;br/&gt;Full Analysis + ML]\n        ML_STRAT[ML Strategy&lt;br/&gt;5x slower&lt;br/&gt;Semantic Embeddings]\n    end\n\n    subgraph \"Text Analysis (40% in Balanced)\"\n        KEY_MATCH[Keyword Matching&lt;br/&gt;20%&lt;br/&gt;Direct term hits]\n        BM25_SIM[BM25 Similarity&lt;br/&gt;20%&lt;br/&gt;Statistical relevance]\n        BM25_SCORE[BM25 Score&lt;br/&gt;15%&lt;br/&gt;Probabilistic ranking]\n    end\n\n    subgraph \"Code Structure Analysis (25% in Balanced)\"\n        PATH_REL[Path Relevance&lt;br/&gt;15%&lt;br/&gt;Directory structure]\n        IMP_CENT[Import Centrality&lt;br/&gt;10%&lt;br/&gt;Dependency importance]\n    end\n\n    subgraph \"File Characteristics (15% in Balanced)\"\n        COMPLEXITY_REL[Complexity Relevance&lt;br/&gt;5%&lt;br/&gt;Code complexity signals]\n        FILE_TYPE[File Type Relevance&lt;br/&gt;5%&lt;br/&gt;Extension/type matching]\n        CODE_PAT[Code Patterns&lt;br/&gt;5%&lt;br/&gt;AST pattern matching]\n    end\n\n    subgraph \"Git Signals (10% in Balanced)\"\n        GIT_REC[Git Recency&lt;br/&gt;5%&lt;br/&gt;Recent changes]\n        GIT_FREQ[Git Frequency&lt;br/&gt;5%&lt;br/&gt;Change frequency]\n    end\n\n    subgraph \"ML Enhancement (Only in ML Strategy)\"\n        SEM_SIM[Semantic Similarity&lt;br/&gt;25%&lt;br/&gt;Embedding-based understanding]\n        LOCAL_EMB[Local Embeddings&lt;br/&gt;sentence-transformers]\n        EMBED_CACHE[Embedding Cache&lt;br/&gt;Performance optimization]\n    end\n\n    subgraph \"Unified Pipeline\"\n        FILE_DISCOVERY[File Discovery&lt;br/&gt;Scanner + Filters]\n        ANALYSIS[Code Analysis&lt;br/&gt;AST + Structure]\n        RANKING[Multi-Factor Ranking&lt;br/&gt;Strategy-specific weights]\n        AGGREGATION[Context Aggregation&lt;br/&gt;Token optimization]\n    end\n\n    FAST --&gt; KEY_MATCH\n    BALANCED --&gt; BM25_SIM\n    BALANCED --&gt; BM25_SCORE\n    THOROUGH --&gt; IMP_CENT\n    ML_STRAT --&gt; SEM_SIM\n\n    FILE_DISCOVERY --&gt; ANALYSIS\n    ANALYSIS --&gt; RANKING\n    RANKING --&gt; AGGREGATION\n\n    KEY_MATCH --&gt; RANKING\n    BM25_SIM --&gt; RANKING\n    BM25_SCORE --&gt; RANKING\n    PATH_REL --&gt; RANKING\n    IMP_CENT --&gt; RANKING\n    COMPLEXITY_REL --&gt; RANKING\n    FILE_TYPE --&gt; RANKING\n    CODE_PAT --&gt; RANKING\n    GIT_REC --&gt; RANKING\n    GIT_FREQ --&gt; RANKING\n\n    SEM_SIM --&gt; LOCAL_EMB\n    LOCAL_EMB --&gt; EMBED_CACHE\n    EMBED_CACHE --&gt; RANKING</code></pre>"},{"location":"architecture/ranking-system/#strategy-comparison","title":"Strategy Comparison","text":"Strategy Speed Accuracy Use Cases Factors Used Fast Fastest Basic Quick file discovery Keyword (60%), Path (30%), File type (10%) Balanced 1.5x slower Good DEFAULT Production usage Keyword (20%), BM25 (35%), Structure (25%), Git (10%) Thorough 4x slower High Complex codebases All balanced factors + enhanced analysis ML 5x slower Highest Semantic search Embeddings (25%) + all thorough factors"},{"location":"architecture/ranking-system/#factor-calculation-details","title":"Factor Calculation Details","text":"<pre><code>graph LR\n    subgraph \"Semantic Similarity Calculation\"\n        CHUNK[Chunk Long Files&lt;br/&gt;1000 chars, 100 overlap]\n        EMBED[Generate Embeddings&lt;br/&gt;Local model]\n        COSINE[Cosine Similarity]\n        CACHE_SEM[Cache Results]\n    end\n\n    subgraph \"Keyword Matching\"\n        FILENAME[Filename Match&lt;br/&gt;Weight: 0.4]\n        IMPORT_M[Import Match&lt;br/&gt;Weight: 0.3]\n        CLASS_FN[Class/Function Name&lt;br/&gt;Weight: 0.25]\n        POSITION[Position Weight&lt;br/&gt;Early lines favored]\n    end\n\n    subgraph \"Import Centrality\"\n        IN_EDGES[Incoming Edges&lt;br/&gt;Files importing this&lt;br/&gt;70% weight]\n        OUT_EDGES[Outgoing Edges&lt;br/&gt;Files this imports&lt;br/&gt;30% weight]\n        LOG_SCALE[Logarithmic Scaling&lt;br/&gt;High-degree nodes]\n        NORMALIZE[Normalize 0-1]\n    end\n\n    subgraph \"Git Signals\"\n        RECENCY[Recency Score&lt;br/&gt;Exponential decay&lt;br/&gt;30-day half-life]\n        FREQUENCY[Frequency Score&lt;br/&gt;Log of commit count]\n        EXPERTISE[Author Expertise&lt;br/&gt;Contribution volume]\n        CHURN[Recent Churn&lt;br/&gt;Lines changed]\n    end\n\n    CHUNK --&gt; EMBED\n    EMBED --&gt; COSINE\n    COSINE --&gt; CACHE_SEM\n\n    FILENAME --&gt; POSITION\n    IMPORT_M --&gt; POSITION\n    CLASS_FN --&gt; POSITION\n\n    IN_EDGES --&gt; LOG_SCALE\n    OUT_EDGES --&gt; LOG_SCALE\n    LOG_SCALE --&gt; NORMALIZE\n\n    RECENCY --&gt; EXPERTISE\n    FREQUENCY --&gt; EXPERTISE\n    EXPERTISE --&gt; CHURN</code></pre>"},{"location":"architecture/roadmap/","title":"Future Roadmap &amp; Vision","text":""},{"location":"architecture/roadmap/#near-term","title":"Near Term","text":"<pre><code>graph TB\n    subgraph \"Core Improvements\"\n        INCREMENTAL[Incremental Indexing&lt;br/&gt;Real-time updates&lt;br/&gt;Watch file changes]\n        FASTER_EMBED[Faster Embeddings&lt;br/&gt;Model quantization&lt;br/&gt;ONNX optimization]\n        LANGUAGE_SUP[Better Language Support&lt;br/&gt;30+ languages&lt;br/&gt;Language-specific patterns]\n        IDE_PLUGINS[IDE Plugin Ecosystem&lt;br/&gt;VS Code, IntelliJ, Vim]\n        CROSS_REPO[Cross-repository Analysis&lt;br/&gt;Monorepo support&lt;br/&gt;Dependency tracking]\n    end\n\n    subgraph \"ML Enhancements\"\n        NEWER_MODELS[Newer Embedding Models&lt;br/&gt;Code-specific transformers&lt;br/&gt;Better accuracy]\n        FINE_TUNING[Fine-tuning Pipeline&lt;br/&gt;Domain-specific models&lt;br/&gt;Custom training]\n        MULTIMODAL[Multi-modal Understanding&lt;br/&gt;Diagrams, images&lt;br/&gt;Architecture docs]\n        CODE_TRANSFORMERS[Code-specific Models&lt;br/&gt;Programming language aware&lt;br/&gt;Syntax understanding]\n    end\n\n    INCREMENTAL --&gt; NEWER_MODELS\n    FASTER_EMBED --&gt; FINE_TUNING\n    LANGUAGE_SUP --&gt; MULTIMODAL\n    IDE_PLUGINS --&gt; CODE_TRANSFORMERS\n    CROSS_REPO --&gt; CODE_TRANSFORMERS</code></pre>"},{"location":"architecture/roadmap/#medium-term","title":"Medium Term","text":"<pre><code>graph TB\n    subgraph \"Platform Features\"\n        WEB_UI[Web UI&lt;br/&gt;Real-time collaboration&lt;br/&gt;Team workspaces]\n        SHARED_CONTEXT[Shared Context Libraries&lt;br/&gt;Team knowledge base&lt;br/&gt;Best practices]\n        KNOWLEDGE_GRAPHS[Knowledge Graphs&lt;br/&gt;Code relationships&lt;br/&gt;Semantic connections]\n        AI_AGENTS[AI Agent Integration&lt;br/&gt;Autonomous assistance&lt;br/&gt;Proactive suggestions]\n    end\n\n    subgraph \"Enterprise Features\"\n        SSO[SSO/SAML Support&lt;br/&gt;Enterprise authentication&lt;br/&gt;Role-based access]\n        AUDIT[Audit Logging&lt;br/&gt;Compliance tracking&lt;br/&gt;Usage monitoring]\n        COMPLIANCE[Compliance Modes&lt;br/&gt;GDPR, SOX, HIPAA&lt;br/&gt;Data governance]\n        AIR_GAPPED[Air-gapped Deployment&lt;br/&gt;Offline operation&lt;br/&gt;Secure environments]\n        CUSTOM_ML[Custom ML Models&lt;br/&gt;Private model training&lt;br/&gt;Domain expertise]\n    end\n\n    WEB_UI --&gt; SSO\n    SHARED_CONTEXT --&gt; AUDIT\n    KNOWLEDGE_GRAPHS --&gt; COMPLIANCE\n    AI_AGENTS --&gt; AIR_GAPPED\n    AI_AGENTS --&gt; CUSTOM_ML</code></pre>"},{"location":"architecture/roadmap/#long-term-vision","title":"Long Term Vision","text":"<pre><code>graph TB\n    subgraph \"Vision Goals\"\n        AUTONOMOUS[Autonomous Code Understanding&lt;br/&gt;Self-improving analysis&lt;br/&gt;Minimal human input]\n        PREDICTIVE[Predictive Development&lt;br/&gt;Anticipate needs&lt;br/&gt;Suggest improvements]\n        UNIVERSAL[Universal Code Intelligence&lt;br/&gt;Any language, any domain&lt;br/&gt;Contextual understanding]\n        INDUSTRY_STANDARD[Industry Standard&lt;br/&gt;AI pair programming&lt;br/&gt;Developer toolchain]\n    end\n\n    subgraph \"Research Areas\"\n        GRAPH_NEURAL[Graph Neural Networks&lt;br/&gt;Code structure understanding&lt;br/&gt;Relationship modeling]\n        REINFORCEMENT[Reinforcement Learning&lt;br/&gt;Ranking optimization&lt;br/&gt;Adaptive behavior]\n        FEW_SHOT[Few-shot Learning&lt;br/&gt;New language support&lt;br/&gt;Rapid adaptation]\n        EXPLAINABLE[Explainable AI&lt;br/&gt;Ranking transparency&lt;br/&gt;Decision reasoning]\n        FEDERATED[Federated Learning&lt;br/&gt;Team knowledge sharing&lt;br/&gt;Privacy-preserving]\n    end\n\n    AUTONOMOUS --&gt; GRAPH_NEURAL\n    PREDICTIVE --&gt; REINFORCEMENT\n    UNIVERSAL --&gt; FEW_SHOT\n    INDUSTRY_STANDARD --&gt; EXPLAINABLE\n    INDUSTRY_STANDARD --&gt; FEDERATED</code></pre>"},{"location":"architecture/security/","title":"Security &amp; Privacy Architecture","text":""},{"location":"architecture/security/#local-first-security-model","title":"Local-First Security Model","text":"<pre><code>graph TB\n    subgraph \"Privacy Guarantees\"\n        LOCAL[All Processing Local&lt;br/&gt;No external API calls for analysis]\n        NO_TELEMETRY[No Telemetry&lt;br/&gt;No usage tracking]\n        NO_CLOUD[No Cloud Storage&lt;br/&gt;All data stays local]\n        NO_PHONE_HOME[No Phone Home&lt;br/&gt;No automatic updates]\n    end\n\n    subgraph \"Secret Detection\"\n        API_KEYS[API Key Detection&lt;br/&gt;Common patterns]\n        PASSWORDS[Password Detection&lt;br/&gt;Credential patterns]\n        TOKENS[Token Detection&lt;br/&gt;JWT, OAuth tokens]\n        PRIVATE_KEYS[Private Key Detection&lt;br/&gt;RSA, SSH keys]\n        CONNECTION_STRINGS[Connection Strings&lt;br/&gt;Database URLs]\n        ENV_VARS[Environment Variables&lt;br/&gt;Sensitive values]\n    end\n\n    subgraph \"Output Sanitization (Roadmap)\"\n        REDACT[Redact Secrets&lt;br/&gt;**WIP** - Coming soon]\n        MASK_PII[Mask PII&lt;br/&gt;**WIP** - Planned feature]\n        CLEAN_PATHS[Clean File Paths&lt;br/&gt;Remove sensitive paths]\n        REMOVE_URLS[Remove Internal URLs&lt;br/&gt;**WIP** - Under development]\n        ANONYMIZE[Anonymization&lt;br/&gt;**WIP** - Future release]\n    end\n\n    subgraph \"Data Protection\"\n        ENCRYPTED_CACHE[Encrypted Cache&lt;br/&gt;Optional encryption at rest]\n        SECURE_DELETE[Secure Deletion&lt;br/&gt;Overwrite sensitive data]\n        ACCESS_CONTROL[File Access Control&lt;br/&gt;Respect permissions]\n        AUDIT_LOG[Audit Logging&lt;br/&gt;Security events]\n    end\n\n    LOCAL --&gt; API_KEYS\n    NO_TELEMETRY --&gt; PASSWORDS\n    NO_CLOUD --&gt; TOKENS\n    NO_PHONE_HOME --&gt; PRIVATE_KEYS\n\n    API_KEYS --&gt; REDACT\n    PASSWORDS --&gt; MASK_PII\n    TOKENS --&gt; CLEAN_PATHS\n    PRIVATE_KEYS --&gt; REMOVE_URLS\n    CONNECTION_STRINGS --&gt; ANONYMIZE\n    ENV_VARS --&gt; ANONYMIZE\n\n    REDACT --&gt; ENCRYPTED_CACHE\n    MASK_PII --&gt; SECURE_DELETE\n    CLEAN_PATHS --&gt; ACCESS_CONTROL\n    REMOVE_URLS --&gt; AUDIT_LOG\n    ANONYMIZE --&gt; AUDIT_LOG</code></pre>"},{"location":"architecture/security/#secret-detection-patterns-roadmap","title":"Secret Detection Patterns (Roadmap)","text":"<pre><code>graph LR\n    subgraph \"Detection Methods\"\n        REGEX[Regex Patterns&lt;br/&gt;Known formats]\n        ENTROPY[Entropy Analysis&lt;br/&gt;Random strings]\n        CONTEXT[Context Analysis&lt;br/&gt;Variable names]\n        KEYWORDS[Keyword Detection&lt;br/&gt;password, secret, key]\n    end\n\n    subgraph \"Secret Types\"\n        AWS[AWS Access Keys&lt;br/&gt;AKIA...]\n        GITHUB[GitHub Tokens&lt;br/&gt;ghp_, gho_]\n        JWT[JWT Tokens&lt;br/&gt;eyJ pattern]\n        RSA[RSA Private Keys&lt;br/&gt;-----BEGIN RSA]\n        DATABASE[Database URLs&lt;br/&gt;postgres://, mysql://]\n        GENERIC[Generic Secrets&lt;br/&gt;High entropy strings]\n    end\n\n    subgraph \"Response Actions\"\n        FLAG[Flag for Review&lt;br/&gt;Warn user]\n        REDACT_AUTO[Auto Redaction&lt;br/&gt;Replace with [REDACTED]]\n        EXCLUDE[Exclude File&lt;br/&gt;Skip entirely]\n        LOG[Security Log&lt;br/&gt;Record detection]\n    end\n\n    REGEX --&gt; AWS\n    ENTROPY --&gt; GITHUB\n    CONTEXT --&gt; JWT\n    KEYWORDS --&gt; RSA\n\n    AWS --&gt; FLAG\n    GITHUB --&gt; REDACT_AUTO\n    JWT --&gt; EXCLUDE\n    RSA --&gt; LOG\n    DATABASE --&gt; LOG\n    GENERIC --&gt; FLAG</code></pre>"},{"location":"architecture/session-management/","title":"Session Management Architecture","text":""},{"location":"architecture/session-management/#session-lifecycle-flow","title":"Session Lifecycle Flow","text":"<pre><code>stateDiagram-v2\n    [*] --&gt; Created\n    Created --&gt; FirstPrompt: User provides initial prompt\n    FirstPrompt --&gt; Analyzing: Full codebase analysis\n    Analyzing --&gt; Active: Context built\n    Active --&gt; Interaction: Subsequent prompts\n    Interaction --&gt; Analyzing: Incremental updates\n    Interaction --&gt; Branching: Alternative exploration\n    Branching --&gt; Active: Branch selected\n    Active --&gt; Export: Save for sharing\n    Export --&gt; Archived: Long-term storage\n    Archived --&gt; [*]\n    Active --&gt; [*]: Session ends\n\n    note right of FirstPrompt\n        - Comprehensive analysis\n        - All relevant files\n        - Setup instructions\n        - AI guidance\n    end note\n\n    note right of Interaction\n        - Incremental updates only\n        - Changed files highlighted\n        - Previous context referenced\n        - Minimal redundancy\n    end note</code></pre>"},{"location":"architecture/session-management/#session-storage-architecture","title":"Session Storage Architecture","text":"<pre><code>graph TB\n    subgraph \"Session Tables\"\n        SESSIONS[sessions&lt;br/&gt;id, name, project, created, updated]\n        PROMPTS[prompts&lt;br/&gt;id, session_id, text, timestamp]\n        CONTEXTS[contexts&lt;br/&gt;id, session_id, prompt_id, content]\n        FILE_STATES[file_states&lt;br/&gt;session_id, file_path, state]\n        AI_REQUESTS[ai_requests&lt;br/&gt;id, session_id, type, request]\n    end\n\n    subgraph \"Relationships\"\n        SESSION_PROMPT[Session \u2192 Prompts&lt;br/&gt;One-to-Many]\n        PROMPT_CONTEXT[Prompt \u2192 Context&lt;br/&gt;One-to-One]\n        SESSION_FILES[Session \u2192 File States&lt;br/&gt;One-to-Many]\n        SESSION_AI[Session \u2192 AI Requests&lt;br/&gt;One-to-Many]\n    end\n\n    subgraph \"Operations\"\n        CREATE[Create Session]\n        SAVE[Save State]\n        RESTORE[Restore State]\n        BRANCH[Branch Session]\n        MERGE[Merge Sessions]\n        EXPORT[Export Session]\n    end\n\n    SESSIONS --&gt; SESSION_PROMPT\n    SESSIONS --&gt; SESSION_FILES\n    SESSIONS --&gt; SESSION_AI\n    PROMPTS --&gt; PROMPT_CONTEXT\n\n    SESSION_PROMPT --&gt; CREATE\n    PROMPT_CONTEXT --&gt; SAVE\n    SESSION_FILES --&gt; RESTORE\n    SESSION_AI --&gt; BRANCH\n    CREATE --&gt; MERGE\n    SAVE --&gt; EXPORT</code></pre>"},{"location":"architecture/storage-caching/","title":"Storage &amp; Caching Architecture","text":""},{"location":"architecture/storage-caching/#storage-hierarchy","title":"Storage Hierarchy","text":"<pre><code>graph TB\n    subgraph \"Memory Cache (Hottest)\"\n        LRU[LRU Cache&lt;br/&gt;1000 items default&lt;br/&gt;Sub-millisecond access]\n        HOT_DATA[Frequently accessed data&lt;br/&gt;Recent analyses&lt;br/&gt;Active embeddings]\n    end\n\n    subgraph \"SQLite Database (Structured)\"\n        SESSIONS_DB[Session Storage&lt;br/&gt;User interactions]\n        CONFIG_DB[Configuration&lt;br/&gt;Settings &amp; preferences]\n        RELATIONS[Relationship data&lt;br/&gt;File dependencies]\n        PERF[1-10ms access time]\n    end\n\n    subgraph \"Disk Cache (Bulk)\"\n        ANALYSIS[Analysis Results&lt;br/&gt;File parsing cache]\n        EMBEDDINGS[Embedding Cache&lt;br/&gt;ML vectors]\n        FILE_CONTENT[File Content Cache&lt;br/&gt;Preprocessed data]\n        BULK_PERF[10-100ms access time]\n    end\n\n    subgraph \"File System (Cold)\"\n        LOGS[Application Logs&lt;br/&gt;Debugging information]\n        EXPORTS[Exported Sessions&lt;br/&gt;Sharing &amp; backup]\n        ARCHIVES[Archived Data&lt;br/&gt;Historical sessions]\n        COLD_PERF[100ms+ access time]\n    end\n\n    LRU --&gt; SESSIONS_DB\n    HOT_DATA --&gt; CONFIG_DB\n\n    SESSIONS_DB --&gt; ANALYSIS\n    CONFIG_DB --&gt; EMBEDDINGS\n    RELATIONS --&gt; FILE_CONTENT\n\n    ANALYSIS --&gt; LOGS\n    EMBEDDINGS --&gt; EXPORTS\n    FILE_CONTENT --&gt; ARCHIVES</code></pre>"},{"location":"architecture/storage-caching/#cache-invalidation-strategy","title":"Cache Invalidation Strategy","text":"<pre><code>graph LR\n    subgraph \"Invalidation Triggers\"\n        FILE_MTIME[File Modification Time&lt;br/&gt;Filesystem change]\n        CONTENT_HASH[Content Hash Change&lt;br/&gt;Actual content differs]\n        GIT_COMMIT[Git Commit&lt;br/&gt;Version control change]\n        DEP_CHANGE[Dependency Change&lt;br/&gt;Import graph update]\n        TTL_EXPIRE[TTL Expiration&lt;br/&gt;Time-based cleanup]\n        MANUAL[Manual Refresh&lt;br/&gt;User-initiated]\n    end\n\n    subgraph \"Cache Levels Affected\"\n        MEMORY_INV[Memory Cache&lt;br/&gt;Immediate eviction]\n        SQLITE_INV[SQLite Cache&lt;br/&gt;Mark as stale]\n        DISK_INV[Disk Cache&lt;br/&gt;File removal]\n        CASCADE[Cascade Invalidation&lt;br/&gt;Dependent entries]\n    end\n\n    subgraph \"Rebuilding Strategy\"\n        LAZY[Lazy Rebuilding&lt;br/&gt;On-demand refresh]\n        EAGER[Eager Rebuilding&lt;br/&gt;Background refresh]\n        PARTIAL[Partial Rebuilding&lt;br/&gt;Incremental updates]\n        BATCH[Batch Rebuilding&lt;br/&gt;Multiple files]\n    end\n\n    FILE_MTIME --&gt; MEMORY_INV\n    CONTENT_HASH --&gt; SQLITE_INV\n    GIT_COMMIT --&gt; DISK_INV\n    DEP_CHANGE --&gt; CASCADE\n    TTL_EXPIRE --&gt; CASCADE\n    MANUAL --&gt; CASCADE\n\n    MEMORY_INV --&gt; LAZY\n    SQLITE_INV --&gt; EAGER\n    DISK_INV --&gt; PARTIAL\n    CASCADE --&gt; BATCH</code></pre>"},{"location":"architecture/system-overview/","title":"System Overview and Core Philosophy","text":"<p>Tenets is a sophisticated, local-first code intelligence platform that revolutionizes how developers interact with their codebases when working with AI assistants. Unlike traditional code search tools, Tenets employs advanced multi-stage analysis combining NLP, ML, static code analysis, git history mining, and intelligent ranking to build optimal context.</p>"},{"location":"architecture/system-overview/#core-architecture-principles","title":"Core Architecture Principles","text":"<ol> <li> <p>Local-First Processing: All analysis happens on the developer's machine. No code leaves the local environment. External API calls only for optional LLM-based summarization with explicit consent.</p> </li> <li> <p>Progressive Enhancement: Provides value immediately with just Python installed, scales with optional dependencies. Core functionality works without ML libraries, git integration works without configuration.</p> </li> <li> <p>Intelligent Caching: Every expensive operation is cached at multiple levels - memory caches for hot data, SQLite for structured data, disk caches for analysis results, specialized caches for embeddings.</p> </li> <li> <p>Configurable Intelligence: Every aspect of ranking and analysis can be configured. Users can adjust factor weights, enable/disable features, add custom ranking functions.</p> </li> <li> <p>Streaming Architecture: Uses streaming and incremental processing wherever possible. Files analyzed as discovered, rankings computed in parallel, results stream to user.</p> </li> </ol>"},{"location":"architecture/testing/","title":"Testing &amp; Quality Assurance","text":""},{"location":"architecture/testing/#test-architecture","title":"Test Architecture","text":"<pre><code>graph TB\n    subgraph \"Test Categories\"\n        UNIT[Unit Tests&lt;br/&gt;Target: &gt;90% coverage&lt;br/&gt;Fast, isolated]\n        INTEGRATION[Integration Tests&lt;br/&gt;Component interaction&lt;br/&gt;Real workflows]\n        E2E[End-to-End Tests&lt;br/&gt;Complete user journeys&lt;br/&gt;CLI to output]\n        PERFORMANCE[Performance Tests&lt;br/&gt;Benchmark regression&lt;br/&gt;Memory usage]\n    end\n\n    subgraph \"Test Structure\"\n        FIXTURES[Test Fixtures&lt;br/&gt;Sample codebases&lt;br/&gt;Known outputs]\n        MOCKS[Mock Objects&lt;br/&gt;External dependencies&lt;br/&gt;Controlled behavior]\n        HELPERS[Test Helpers&lt;br/&gt;Common operations&lt;br/&gt;Assertion utilities]\n        FACTORIES[Data Factories&lt;br/&gt;Generate test data&lt;br/&gt;Realistic scenarios]\n    end\n\n    subgraph \"Quality Metrics\"\n        COVERAGE[Code Coverage&lt;br/&gt;Line and branch coverage]\n        COMPLEXITY[Complexity Limits&lt;br/&gt;Cyclomatic &lt; 10]\n        DUPLICATION[Duplication Check&lt;br/&gt;&lt; 5% duplicate code]\n        DOCUMENTATION[Documentation&lt;br/&gt;100% public API]\n    end\n\n    subgraph \"Continuous Testing\"\n        PRE_COMMIT[Pre-commit Hooks&lt;br/&gt;Fast feedback]\n        CI_PIPELINE[CI Pipeline&lt;br/&gt;Full test suite]\n        NIGHTLY[Nightly Tests&lt;br/&gt;Extended scenarios]\n        BENCHMARKS[Benchmark Tracking&lt;br/&gt;Performance trends]\n    end\n\n    UNIT --&gt; FIXTURES\n    INTEGRATION --&gt; MOCKS\n    E2E --&gt; HELPERS\n    PERFORMANCE --&gt; FACTORIES\n\n    FIXTURES --&gt; COVERAGE\n    MOCKS --&gt; COMPLEXITY\n    HELPERS --&gt; DUPLICATION\n    FACTORIES --&gt; DOCUMENTATION\n\n    COVERAGE --&gt; PRE_COMMIT\n    COMPLEXITY --&gt; CI_PIPELINE\n    DUPLICATION --&gt; NIGHTLY\n    DOCUMENTATION --&gt; BENCHMARKS</code></pre>"},{"location":"architecture/testing/#test-coverage-requirements","title":"Test Coverage Requirements","text":"<pre><code>graph LR\n    subgraph \"Coverage Targets\"\n        UNIT_COV[Unit Tests&lt;br/&gt;&gt;90% coverage&lt;br/&gt;Critical paths 100%]\n        INTEGRATION_COV[Integration Tests&lt;br/&gt;All major workflows&lt;br/&gt;Error scenarios]\n        E2E_COV[E2E Tests&lt;br/&gt;Critical user journeys&lt;br/&gt;Happy paths]\n        PERF_COV[Performance Tests&lt;br/&gt;Regression prevention&lt;br/&gt;Memory leak detection]\n    end\n\n    subgraph \"Quality Gates\"\n        CODE_QUALITY[Code Quality&lt;br/&gt;Complexity &lt; 10&lt;br/&gt;Function length &lt; 50]\n        DOCUMENTATION[Documentation&lt;br/&gt;100% public API&lt;br/&gt;Usage examples]\n        SECURITY[Security Tests&lt;br/&gt;Secret detection&lt;br/&gt;Input validation]\n        COMPATIBILITY[Compatibility&lt;br/&gt;Python 3.8+&lt;br/&gt;Multiple platforms]\n    end\n\n    UNIT_COV --&gt; CODE_QUALITY\n    INTEGRATION_COV --&gt; DOCUMENTATION\n    E2E_COV --&gt; SECURITY\n    PERF_COV --&gt; COMPATIBILITY</code></pre>"}]}